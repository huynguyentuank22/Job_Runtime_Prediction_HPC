{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a888f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import pandas as pd\n",
    "import torch\n",
    "from preprocessing import *\n",
    "import time\n",
    "from PC_transformer import PCTransformer\n",
    "\n",
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c16d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15886 entries, 0 to 15885\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   job_id                    15886 non-null  float64\n",
      " 1   submit_time               15886 non-null  float64\n",
      " 2   wait_time                 15886 non-null  float64\n",
      " 3   run_time                  15886 non-null  float64\n",
      " 4   num_allocated_processors  15886 non-null  float64\n",
      " 5   avg_cpu_time_used         15886 non-null  float64\n",
      " 6   used_memory               15886 non-null  float64\n",
      " 7   requested_processors      15886 non-null  float64\n",
      " 8   requested_time            15886 non-null  float64\n",
      " 9   requested_memory          15886 non-null  float64\n",
      " 10  status                    15886 non-null  float64\n",
      " 11  user_id                   15886 non-null  float64\n",
      " 12  group_id                  15886 non-null  float64\n",
      " 13  executable_id             15886 non-null  float64\n",
      " 14  queue_id                  15886 non-null  float64\n",
      " 15  partition_id              15886 non-null  float64\n",
      " 16  preceding_job_id          15886 non-null  float64\n",
      " 17  think_time                15886 non-null  float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'..\\output_csv\\HCMUT-SuperNodeXP-2017-1.0.swf.csv')\n",
    "# df = df.head(100)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38614446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "job_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "submit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wait_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "run_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_allocated_processors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_cpu_time_used",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "used_memory",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "requested_processors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "requested_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "requested_memory",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "status",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "group_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "executable_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "queue_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "partition_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "preceding_job_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "think_time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0ea481c9-6796-4cca-b10e-12e828f39bd8",
       "rows": [
        [
         "0",
         "4.0",
         "0.0",
         "0.0",
         "13.0",
         "24.0",
         "7.0",
         "14761.0",
         "24.0",
         "21600.0",
         "218453.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "-1.0"
        ],
        [
         "1",
         "8.0",
         "40819.0",
         "0.0",
         "61.0",
         "24.0",
         "45.0",
         "14761.0",
         "24.0",
         "21600.0",
         "218453.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "-1.0"
        ],
        [
         "2",
         "10.0",
         "45255.0",
         "0.0",
         "60.0",
         "24.0",
         "45.0",
         "14760.0",
         "24.0",
         "21600.0",
         "218453.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "-1.0"
        ],
        [
         "3",
         "11.0",
         "45782.0",
         "0.0",
         "1.0",
         "24.0",
         "0.0",
         "0.0",
         "24.0",
         "21600.0",
         "218453.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "-1.0"
        ],
        [
         "4",
         "12.0",
         "56510.0",
         "0.0",
         "1.0",
         "24.0",
         "0.0",
         "0.0",
         "24.0",
         "21600.0",
         "218453.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "-1.0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>run_time</th>\n",
       "      <th>num_allocated_processors</th>\n",
       "      <th>avg_cpu_time_used</th>\n",
       "      <th>used_memory</th>\n",
       "      <th>requested_processors</th>\n",
       "      <th>requested_time</th>\n",
       "      <th>requested_memory</th>\n",
       "      <th>status</th>\n",
       "      <th>user_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>executable_id</th>\n",
       "      <th>queue_id</th>\n",
       "      <th>partition_id</th>\n",
       "      <th>preceding_job_id</th>\n",
       "      <th>think_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14761.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>218453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>40819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14761.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>218453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>45255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14760.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>218453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>45782.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>218453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>56510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>218453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id  submit_time  wait_time  run_time  num_allocated_processors  \\\n",
       "0     4.0          0.0        0.0      13.0                      24.0   \n",
       "1     8.0      40819.0        0.0      61.0                      24.0   \n",
       "2    10.0      45255.0        0.0      60.0                      24.0   \n",
       "3    11.0      45782.0        0.0       1.0                      24.0   \n",
       "4    12.0      56510.0        0.0       1.0                      24.0   \n",
       "\n",
       "   avg_cpu_time_used  used_memory  requested_processors  requested_time  \\\n",
       "0                7.0      14761.0                  24.0         21600.0   \n",
       "1               45.0      14761.0                  24.0         21600.0   \n",
       "2               45.0      14760.0                  24.0         21600.0   \n",
       "3                0.0          0.0                  24.0         21600.0   \n",
       "4                0.0          0.0                  24.0         21600.0   \n",
       "\n",
       "   requested_memory  status  user_id  group_id  executable_id  queue_id  \\\n",
       "0          218453.0     1.0      1.0       1.0            1.0       1.0   \n",
       "1          218453.0     1.0      1.0       1.0            1.0       1.0   \n",
       "2          218453.0     1.0      1.0       1.0            1.0       1.0   \n",
       "3          218453.0     1.0      1.0       1.0            1.0       1.0   \n",
       "4          218453.0     1.0      1.0       1.0            1.0       1.0   \n",
       "\n",
       "   partition_id  preceding_job_id  think_time  \n",
       "0           1.0              -1.0        -1.0  \n",
       "1           1.0              -1.0        -1.0  \n",
       "2           1.0              -1.0        -1.0  \n",
       "3           1.0              -1.0        -1.0  \n",
       "4           1.0              -1.0        -1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c29a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['requested_processors', 'requested_time', 'avg_cpu_time_used', 'used_memory', 'submit_time', 'wait_time', 'user_id', 'group_id', 'executable_id', 'queue_id']\n",
    "target_column = 'run_time'\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = len(feature_columns)    # Example input dimension\n",
    "d_model = 64      # Model dimension\n",
    "num_heads = 8     # Number of attention heads\n",
    "d_ff = 256        # Feed-forward dimension\n",
    "num_layers = 3    # Number of transformer blocks\n",
    "output_dim = 1    # Output dimension\n",
    "batch_size = 128  # Batch size\n",
    "seq_len = 20      # Length of data group\n",
    "num_epochs = 100   # Number of training epochs\n",
    "dropout = 0.2    # Dropout rate\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataloaders, scaler = prepare_data_seq(df, feature_columns, target_column, seq_len=seq_len, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc93063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3294, Val Loss: 0.2910\n",
      "Val RMSE: 144678.2726, Val MAE: 82680.0731, Val MSE: 20931802549.7689, Val R2: -0.0635\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2783, Val Loss: 0.2755\n",
      "Val RMSE: 141359.8837, Val MAE: 84561.8485, Val MSE: 19982616728.2692, Val R2: -0.0152\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2702, Val Loss: 0.2752\n",
      "Val RMSE: 142146.0182, Val MAE: 82616.5615, Val MSE: 20205490504.0981, Val R2: -0.0266\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2830\n",
      "Val RMSE: 141567.1403, Val MAE: 88264.7121, Val MSE: 20041255199.5232, Val R2: -0.0182\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2770\n",
      "Val RMSE: 143296.0407, Val MAE: 80337.0110, Val MSE: 20533755284.4947, Val R2: -0.0432\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2633, Val Loss: 0.2729\n",
      "Val RMSE: 142361.2777, Val MAE: 81335.7606, Val MSE: 20266733388.3923, Val R2: -0.0297\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2704\n",
      "Val RMSE: 141165.7799, Val MAE: 83006.7213, Val MSE: 19927777425.4504, Val R2: -0.0125\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2851\n",
      "Val RMSE: 142046.9833, Val MAE: 87543.2771, Val MSE: 20177345469.2508, Val R2: -0.0251\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2660\n",
      "Val RMSE: 141812.8508, Val MAE: 79861.9211, Val MSE: 20110884653.6779, Val R2: -0.0218\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2640\n",
      "Val RMSE: 140820.1233, Val MAE: 79004.0132, Val MSE: 19830307112.4754, Val R2: -0.0075\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2690\n",
      "Val RMSE: 140523.7771, Val MAE: 76670.3384, Val MSE: 19746931938.3303, Val R2: -0.0033\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2585\n",
      "Val RMSE: 136140.5658, Val MAE: 79413.8242, Val MSE: 18534253669.2302, Val R2: 0.0583\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2418, Val Loss: 0.2570\n",
      "Val RMSE: 137109.4709, Val MAE: 79133.3169, Val MSE: 18799007013.9159, Val R2: 0.0449\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2444, Val Loss: 0.2585\n",
      "Val RMSE: 135704.1221, Val MAE: 81076.1223, Val MSE: 18415608749.6001, Val R2: 0.0644\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2397, Val Loss: 0.2496\n",
      "Val RMSE: 133157.7692, Val MAE: 78388.2101, Val MSE: 17730991487.6610, Val R2: 0.0992\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2321, Val Loss: 0.2607\n",
      "Val RMSE: 133201.6978, Val MAE: 79469.2179, Val MSE: 17742692309.7286, Val R2: 0.0986\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2272, Val Loss: 0.2580\n",
      "Val RMSE: 130338.9314, Val MAE: 79389.5600, Val MSE: 16988237041.3467, Val R2: 0.1369\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2171, Val Loss: 0.2411\n",
      "Val RMSE: 130187.1334, Val MAE: 78296.8203, Val MSE: 16948689700.0215, Val R2: 0.1389\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2116, Val Loss: 0.2393\n",
      "Val RMSE: 129908.2124, Val MAE: 77996.9968, Val MSE: 16876143635.9728, Val R2: 0.1426\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2300\n",
      "Val RMSE: 130687.3353, Val MAE: 69515.7299, Val MSE: 17079179617.0028, Val R2: 0.1323\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2050, Val Loss: 0.2377\n",
      "Val RMSE: 133766.6970, Val MAE: 72092.1626, Val MSE: 17893529220.9453, Val R2: 0.0909\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2004, Val Loss: 0.2270\n",
      "Val RMSE: 128648.1590, Val MAE: 69696.7354, Val MSE: 16550348808.1292, Val R2: 0.1591\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1949, Val Loss: 0.2208\n",
      "Val RMSE: 126416.2164, Val MAE: 69293.1160, Val MSE: 15981059762.2747, Val R2: 0.1881\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1864, Val Loss: 0.1980\n",
      "Val RMSE: 113699.6037, Val MAE: 63998.1292, Val MSE: 12927599892.3842, Val R2: 0.3432\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.2114\n",
      "Val RMSE: 114494.3072, Val MAE: 68499.7544, Val MSE: 13108946389.6576, Val R2: 0.3340\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1789, Val Loss: 0.1956\n",
      "Val RMSE: 108120.2341, Val MAE: 65582.3942, Val MSE: 11689985027.0519, Val R2: 0.4061\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1689, Val Loss: 0.1795\n",
      "Val RMSE: 103662.6138, Val MAE: 62050.3588, Val MSE: 10745937491.0301, Val R2: 0.4540\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1667, Val Loss: 0.1771\n",
      "Val RMSE: 104159.6883, Val MAE: 60477.6249, Val MSE: 10849240666.9420, Val R2: 0.4488\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1641, Val Loss: 0.1639\n",
      "Val RMSE: 98653.9652, Val MAE: 58817.0120, Val MSE: 9732604844.1925, Val R2: 0.5055\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1623, Val Loss: 0.1679\n",
      "Val RMSE: 100082.0175, Val MAE: 59547.1260, Val MSE: 10016410225.7396, Val R2: 0.4911\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1583, Val Loss: 0.1643\n",
      "Val RMSE: 99860.3120, Val MAE: 58128.0363, Val MSE: 9972081911.8539, Val R2: 0.4934\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1561, Val Loss: 0.1640\n",
      "Val RMSE: 99386.0917, Val MAE: 56796.8226, Val MSE: 9877595221.7699, Val R2: 0.4982\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1545, Val Loss: 0.1604\n",
      "Val RMSE: 98001.5986, Val MAE: 57994.5401, Val MSE: 9604313333.4094, Val R2: 0.5120\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1478, Val Loss: 0.1580\n",
      "Val RMSE: 98256.8540, Val MAE: 56003.1096, Val MSE: 9654409359.8589, Val R2: 0.5095\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1456, Val Loss: 0.1640\n",
      "Val RMSE: 98795.8298, Val MAE: 59391.5247, Val MSE: 9760615979.7353, Val R2: 0.5041\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1575\n",
      "Val RMSE: 97044.1518, Val MAE: 55057.1029, Val MSE: 9417567396.2257, Val R2: 0.5215\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1341, Val Loss: 0.1509\n",
      "Val RMSE: 94949.3732, Val MAE: 51962.8682, Val MSE: 9015383465.3296, Val R2: 0.5420\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1284, Val Loss: 0.1449\n",
      "Val RMSE: 93083.2297, Val MAE: 54251.9288, Val MSE: 8664487651.7572, Val R2: 0.5598\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1254, Val Loss: 0.1393\n",
      "Val RMSE: 92412.0722, Val MAE: 50691.2107, Val MSE: 8539991080.2800, Val R2: 0.5661\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1211, Val Loss: 0.1534\n",
      "Val RMSE: 96918.6230, Val MAE: 54025.8029, Val MSE: 9393219476.8619, Val R2: 0.5228\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1213, Val Loss: 0.1444\n",
      "Val RMSE: 93840.7957, Val MAE: 52619.2937, Val MSE: 8806094943.8402, Val R2: 0.5526\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1150, Val Loss: 0.1486\n",
      "Val RMSE: 95543.0941, Val MAE: 53931.6319, Val MSE: 9128482835.2029, Val R2: 0.5362\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1146, Val Loss: 0.1427\n",
      "Val RMSE: 92188.6726, Val MAE: 55101.7999, Val MSE: 8498751359.8346, Val R2: 0.5682\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1123, Val Loss: 0.1499\n",
      "Val RMSE: 95138.0725, Val MAE: 56279.8327, Val MSE: 9051252834.1913, Val R2: 0.5401\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1460\n",
      "Val RMSE: 93740.2580, Val MAE: 53480.1190, Val MSE: 8787235972.5055, Val R2: 0.5536\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1466\n",
      "Val RMSE: 93164.6029, Val MAE: 52994.2568, Val MSE: 8679643240.4434, Val R2: 0.5590\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1042, Val Loss: 0.1530\n",
      "Val RMSE: 96309.3572, Val MAE: 52634.9489, Val MSE: 9275492282.9032, Val R2: 0.5287\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1396\n",
      "Val RMSE: 91527.3974, Val MAE: 51749.0266, Val MSE: 8377264476.5134, Val R2: 0.5744\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0987, Val Loss: 0.1457\n",
      "Val RMSE: 91491.4423, Val MAE: 55017.4850, Val MSE: 8370684011.4627, Val R2: 0.5747\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1564\n",
      "Val RMSE: 96537.0869, Val MAE: 54466.2015, Val MSE: 9319409150.3310, Val R2: 0.5265\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1483\n",
      "Val RMSE: 92523.4667, Val MAE: 52059.2683, Val MSE: 8560591896.7233, Val R2: 0.5651\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1059, Val Loss: 0.1458\n",
      "Val RMSE: 93257.4795, Val MAE: 53192.0717, Val MSE: 8696957486.0441, Val R2: 0.5581\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1448\n",
      "Val RMSE: 91725.2855, Val MAE: 55050.0587, Val MSE: 8413528006.8036, Val R2: 0.5725\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1463\n",
      "Val RMSE: 92592.0705, Val MAE: 52041.7219, Val MSE: 8573291515.2290, Val R2: 0.5644\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0927, Val Loss: 0.1516\n",
      "Val RMSE: 93744.6901, Val MAE: 53475.9032, Val MSE: 8788066916.8099, Val R2: 0.5535\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1500\n",
      "Val RMSE: 93715.1487, Val MAE: 52802.2065, Val MSE: 8782529103.3191, Val R2: 0.5538\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1582\n",
      "Val RMSE: 95975.9860, Val MAE: 57190.6316, Val MSE: 9211389889.1863, Val R2: 0.5320\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0880, Val Loss: 0.1352\n",
      "Val RMSE: 87533.7447, Val MAE: 52444.0744, Val MSE: 7662156463.5045, Val R2: 0.6107\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0860, Val Loss: 0.1537\n",
      "Val RMSE: 92593.9078, Val MAE: 55861.5563, Val MSE: 8573631769.5474, Val R2: 0.5644\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1460\n",
      "Val RMSE: 89438.1705, Val MAE: 53414.4364, Val MSE: 7999186345.5349, Val R2: 0.5936\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1379\n",
      "Val RMSE: 85122.1409, Val MAE: 52256.9395, Val MSE: 7245778867.6069, Val R2: 0.6319\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1443\n",
      "Val RMSE: 87664.6836, Val MAE: 54797.6033, Val MSE: 7685096749.2341, Val R2: 0.6095\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0795, Val Loss: 0.1404\n",
      "Val RMSE: 87203.8501, Val MAE: 50232.9226, Val MSE: 7604511476.0179, Val R2: 0.6136\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1407\n",
      "Val RMSE: 86060.4825, Val MAE: 52668.9941, Val MSE: 7406406640.8920, Val R2: 0.6237\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1396\n",
      "Val RMSE: 85271.9418, Val MAE: 52448.5850, Val MSE: 7271304058.8955, Val R2: 0.6306\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1558\n",
      "Val RMSE: 92995.9399, Val MAE: 56183.9720, Val MSE: 8648244843.4958, Val R2: 0.5606\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1429\n",
      "Val RMSE: 88281.1033, Val MAE: 53377.2550, Val MSE: 7793553204.0217, Val R2: 0.6040\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1505\n",
      "Val RMSE: 90203.9086, Val MAE: 53778.0118, Val MSE: 8136745132.1551, Val R2: 0.5866\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1474\n",
      "Val RMSE: 87889.8298, Val MAE: 52146.4251, Val MSE: 7724622184.0007, Val R2: 0.6075\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1461\n",
      "Val RMSE: 90572.7476, Val MAE: 54266.4492, Val MSE: 8203422611.2146, Val R2: 0.5832\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1497\n",
      "Val RMSE: 91409.4713, Val MAE: 54492.0195, Val MSE: 8355691447.2422, Val R2: 0.5755\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1436\n",
      "Val RMSE: 88843.0670, Val MAE: 53985.3524, Val MSE: 7893090558.5485, Val R2: 0.5990\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1493\n",
      "Val RMSE: 92448.0721, Val MAE: 52775.4155, Val MSE: 8546646030.2058, Val R2: 0.5658\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1484\n",
      "Val RMSE: 90051.9456, Val MAE: 58599.6672, Val MSE: 8109352898.5701, Val R2: 0.5880\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1493\n",
      "Val RMSE: 92390.1682, Val MAE: 54306.9374, Val MSE: 8535943171.7261, Val R2: 0.5663\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1477\n",
      "Val RMSE: 90618.7606, Val MAE: 52864.4047, Val MSE: 8211759775.9023, Val R2: 0.5828\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1406\n",
      "Val RMSE: 87581.0353, Val MAE: 51600.2285, Val MSE: 7670437741.0388, Val R2: 0.6103\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1379\n",
      "Val RMSE: 87344.6229, Val MAE: 53318.8883, Val MSE: 7629083148.8260, Val R2: 0.6124\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0590, Val Loss: 0.1441\n",
      "Val RMSE: 89962.9209, Val MAE: 53466.1709, Val MSE: 8093327143.1812, Val R2: 0.5888\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1336\n",
      "Val RMSE: 85487.2212, Val MAE: 50990.3317, Val MSE: 7308064987.6386, Val R2: 0.6287\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1489\n",
      "Val RMSE: 90470.3266, Val MAE: 57178.8650, Val MSE: 8184879995.4817, Val R2: 0.5842\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1398\n",
      "Val RMSE: 86914.2811, Val MAE: 53358.9709, Val MSE: 7554092262.1348, Val R2: 0.6162\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1388\n",
      "Val RMSE: 86381.7153, Val MAE: 52681.6283, Val MSE: 7461800732.7555, Val R2: 0.6209\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1413\n",
      "Val RMSE: 87921.3843, Val MAE: 53522.3467, Val MSE: 7730169824.8595, Val R2: 0.6073\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1361\n",
      "Val RMSE: 85072.6053, Val MAE: 53363.1269, Val MSE: 7237348176.9677, Val R2: 0.6323\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1358\n",
      "Val RMSE: 84112.7767, Val MAE: 48153.4079, Val MSE: 7074959197.9878, Val R2: 0.6405\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1359\n",
      "Val RMSE: 85577.2885, Val MAE: 51969.2311, Val MSE: 7323472304.7647, Val R2: 0.6279\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1384\n",
      "Val RMSE: 86803.3475, Val MAE: 49394.2434, Val MSE: 7534821131.2086, Val R2: 0.6172\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1514\n",
      "Val RMSE: 92852.2672, Val MAE: 52110.1765, Val MSE: 8621543523.0754, Val R2: 0.5620\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1353\n",
      "Val RMSE: 84833.9764, Val MAE: 53258.2599, Val MSE: 7196803550.2545, Val R2: 0.6344\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1384\n",
      "Val RMSE: 86834.7310, Val MAE: 51424.9162, Val MSE: 7540270511.4454, Val R2: 0.6169\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1437\n",
      "Val RMSE: 88322.4244, Val MAE: 55329.3306, Val MSE: 7800850655.7278, Val R2: 0.6037\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1492\n",
      "Val RMSE: 89711.2088, Val MAE: 51698.7754, Val MSE: 8048100982.0430, Val R2: 0.5911\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1401\n",
      "Val RMSE: 86785.6777, Val MAE: 53866.9147, Val MSE: 7531753848.7889, Val R2: 0.6173\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1505\n",
      "Val RMSE: 90511.2206, Val MAE: 50938.6413, Val MSE: 8192281053.1935, Val R2: 0.5838\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1347\n",
      "Val RMSE: 85945.6935, Val MAE: 51862.2575, Val MSE: 7386662223.7344, Val R2: 0.6247\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1388\n",
      "Val RMSE: 86985.3386, Val MAE: 50925.1468, Val MSE: 7566449123.9927, Val R2: 0.6156\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1435\n",
      "Val RMSE: 87924.6568, Val MAE: 54817.8891, Val MSE: 7730745278.0484, Val R2: 0.6072\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1330\n",
      "Val RMSE: 84692.9928, Val MAE: 51307.3962, Val MSE: 7172903034.8939, Val R2: 0.6356\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1373\n",
      "Val RMSE: 86476.5159, Val MAE: 51561.8437, Val MSE: 7478187796.4894, Val R2: 0.6201\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 92791.5699, Test MAE: 55345.0766, Test MSE: 8610275442.0567, Test R2: 0.4481\n",
      "Inference Time: 3.2850485581618086e-05 seconds per sample\n",
      "\n",
      "Iteration 2 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4035, Val Loss: 0.3159\n",
      "Val RMSE: 150058.2304, Val MAE: 82642.0495, Val MSE: 22517472503.0134, Val R2: -0.1440\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2858, Val Loss: 0.2914\n",
      "Val RMSE: 144333.1264, Val MAE: 83522.6908, Val MSE: 20832051387.1766, Val R2: -0.0584\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2784, Val Loss: 0.2859\n",
      "Val RMSE: 143011.4952, Val MAE: 84099.3219, Val MSE: 20452287762.5212, Val R2: -0.0391\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2746, Val Loss: 0.2788\n",
      "Val RMSE: 142677.7708, Val MAE: 82401.0813, Val MSE: 20356946287.1005, Val R2: -0.0343\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2691, Val Loss: 0.2775\n",
      "Val RMSE: 143035.2624, Val MAE: 81323.2667, Val MSE: 20459086291.5889, Val R2: -0.0395\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2659, Val Loss: 0.2745\n",
      "Val RMSE: 142370.9658, Val MAE: 81841.6243, Val MSE: 20269491892.6733, Val R2: -0.0298\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2763\n",
      "Val RMSE: 141602.4586, Val MAE: 85143.0165, Val MSE: 20051256289.6765, Val R2: -0.0187\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2714\n",
      "Val RMSE: 141077.3619, Val MAE: 82997.0019, Val MSE: 19902822042.1520, Val R2: -0.0112\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2719\n",
      "Val RMSE: 140304.6901, Val MAE: 84680.9576, Val MSE: 19685406073.4847, Val R2: -0.0001\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2738\n",
      "Val RMSE: 140581.5105, Val MAE: 85468.5389, Val MSE: 19763161098.8006, Val R2: -0.0041\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2766\n",
      "Val RMSE: 142396.4917, Val MAE: 83479.2845, Val MSE: 20276760841.9113, Val R2: -0.0302\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2568, Val Loss: 0.2713\n",
      "Val RMSE: 140597.8569, Val MAE: 83285.6428, Val MSE: 19767757376.5528, Val R2: -0.0043\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2704\n",
      "Val RMSE: 141990.8001, Val MAE: 80272.8692, Val MSE: 20161387313.9678, Val R2: -0.0243\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2707\n",
      "Val RMSE: 143235.2946, Val MAE: 78855.0004, Val MSE: 20516349605.1432, Val R2: -0.0424\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2678\n",
      "Val RMSE: 142037.0337, Val MAE: 79589.6338, Val MSE: 20174518949.2830, Val R2: -0.0250\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2509, Val Loss: 0.2821\n",
      "Val RMSE: 145111.4969, Val MAE: 78799.1536, Val MSE: 21057346544.0856, Val R2: -0.0698\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2733\n",
      "Val RMSE: 140892.8406, Val MAE: 83686.1137, Val MSE: 19850792518.7265, Val R2: -0.0085\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2782\n",
      "Val RMSE: 141191.5098, Val MAE: 85067.4596, Val MSE: 19935042433.6935, Val R2: -0.0128\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2475, Val Loss: 0.2691\n",
      "Val RMSE: 142303.2009, Val MAE: 79769.4330, Val MSE: 20250200992.5109, Val R2: -0.0288\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2450, Val Loss: 0.2622\n",
      "Val RMSE: 139557.2438, Val MAE: 76211.2000, Val MSE: 19476224308.9295, Val R2: 0.0105\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2542\n",
      "Val RMSE: 135210.4944, Val MAE: 78530.4106, Val MSE: 18281877791.9204, Val R2: 0.0712\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2277, Val Loss: 0.2494\n",
      "Val RMSE: 136161.4628, Val MAE: 72681.3054, Val MSE: 18539943960.6702, Val R2: 0.0581\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2190, Val Loss: 0.2497\n",
      "Val RMSE: 137377.8345, Val MAE: 75475.4958, Val MSE: 18872669415.1192, Val R2: 0.0411\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2158, Val Loss: 0.2363\n",
      "Val RMSE: 132245.6608, Val MAE: 72439.8022, Val MSE: 17488914810.6332, Val R2: 0.1115\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2079, Val Loss: 0.2423\n",
      "Val RMSE: 134964.6035, Val MAE: 71958.7654, Val MSE: 18215444188.1213, Val R2: 0.0745\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2038, Val Loss: 0.2356\n",
      "Val RMSE: 133151.9459, Val MAE: 71952.4917, Val MSE: 17729440708.1201, Val R2: 0.0992\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1899, Val Loss: 0.2305\n",
      "Val RMSE: 125076.0831, Val MAE: 68853.2183, Val MSE: 15644026566.7679, Val R2: 0.2052\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1856, Val Loss: 0.2338\n",
      "Val RMSE: 131222.1039, Val MAE: 69452.8291, Val MSE: 17219240539.3493, Val R2: 0.1252\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2023\n",
      "Val RMSE: 113484.2524, Val MAE: 64048.7587, Val MSE: 12878675538.7001, Val R2: 0.3457\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1759, Val Loss: 0.2134\n",
      "Val RMSE: 112911.0334, Val MAE: 65003.7937, Val MSE: 12748901458.5151, Val R2: 0.3523\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1690, Val Loss: 0.1761\n",
      "Val RMSE: 102891.0255, Val MAE: 61488.3484, Val MSE: 10586563120.6432, Val R2: 0.4621\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1668, Val Loss: 0.1927\n",
      "Val RMSE: 105893.8972, Val MAE: 61758.8226, Val MSE: 11213517458.7269, Val R2: 0.4303\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1615, Val Loss: 0.1709\n",
      "Val RMSE: 102096.3005, Val MAE: 58820.3637, Val MSE: 10423654575.7088, Val R2: 0.4704\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1590, Val Loss: 0.1507\n",
      "Val RMSE: 95841.2887, Val MAE: 54808.1507, Val MSE: 9185552629.2143, Val R2: 0.5333\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1522, Val Loss: 0.1877\n",
      "Val RMSE: 104330.0024, Val MAE: 60257.6530, Val MSE: 10884749400.0374, Val R2: 0.4470\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1496, Val Loss: 0.1739\n",
      "Val RMSE: 100564.4652, Val MAE: 59116.2882, Val MSE: 10113211670.7995, Val R2: 0.4862\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1458, Val Loss: 0.1490\n",
      "Val RMSE: 94059.6710, Val MAE: 56946.0546, Val MSE: 8847221704.7966, Val R2: 0.5505\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1446, Val Loss: 0.1605\n",
      "Val RMSE: 97587.5313, Val MAE: 56702.4086, Val MSE: 9523326274.9831, Val R2: 0.5162\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1573\n",
      "Val RMSE: 97163.9655, Val MAE: 55495.1496, Val MSE: 9440836199.5684, Val R2: 0.5203\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1405, Val Loss: 0.1769\n",
      "Val RMSE: 100989.7343, Val MAE: 58136.3125, Val MSE: 10198926425.8183, Val R2: 0.4818\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1363, Val Loss: 0.1529\n",
      "Val RMSE: 94865.8804, Val MAE: 53986.3691, Val MSE: 8999535266.6875, Val R2: 0.5428\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1308, Val Loss: 0.1416\n",
      "Val RMSE: 92624.2623, Val MAE: 53037.4249, Val MSE: 8579253959.4949, Val R2: 0.5641\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1244, Val Loss: 0.1553\n",
      "Val RMSE: 95855.4107, Val MAE: 53827.9971, Val MSE: 9188259762.0612, Val R2: 0.5332\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1171, Val Loss: 0.1352\n",
      "Val RMSE: 90765.2828, Val MAE: 48321.1584, Val MSE: 8238336569.9946, Val R2: 0.5814\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1140, Val Loss: 0.1476\n",
      "Val RMSE: 93344.5432, Val MAE: 50646.3321, Val MSE: 8713203744.4260, Val R2: 0.5573\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1275\n",
      "Val RMSE: 89216.3236, Val MAE: 48031.3039, Val MSE: 7959552395.1210, Val R2: 0.5956\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1042, Val Loss: 0.1362\n",
      "Val RMSE: 89854.1247, Val MAE: 46967.8273, Val MSE: 8073763717.3802, Val R2: 0.5898\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1501\n",
      "Val RMSE: 93328.4049, Val MAE: 50629.9428, Val MSE: 8710191166.3994, Val R2: 0.5575\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1055, Val Loss: 0.1282\n",
      "Val RMSE: 87551.7315, Val MAE: 46383.9037, Val MSE: 7665305694.2504, Val R2: 0.6106\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0984, Val Loss: 0.1301\n",
      "Val RMSE: 88338.5849, Val MAE: 46793.7403, Val MSE: 7803705582.8410, Val R2: 0.6035\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0974, Val Loss: 0.1314\n",
      "Val RMSE: 88560.3543, Val MAE: 46836.8893, Val MSE: 7842936351.4389, Val R2: 0.6015\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0936, Val Loss: 0.1292\n",
      "Val RMSE: 89833.3611, Val MAE: 45800.0168, Val MSE: 8070032764.6062, Val R2: 0.5900\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0915, Val Loss: 0.1139\n",
      "Val RMSE: 84903.7007, Val MAE: 44280.3226, Val MSE: 7208638399.6431, Val R2: 0.6338\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0908, Val Loss: 0.1199\n",
      "Val RMSE: 86108.1582, Val MAE: 45065.9398, Val MSE: 7414614914.5823, Val R2: 0.6233\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1246\n",
      "Val RMSE: 85449.5961, Val MAE: 45200.3484, Val MSE: 7301633473.2716, Val R2: 0.6290\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1030\n",
      "Val RMSE: 81021.5143, Val MAE: 42592.4557, Val MSE: 6564485777.1400, Val R2: 0.6665\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0915, Val Loss: 0.1085\n",
      "Val RMSE: 79480.3702, Val MAE: 40660.1300, Val MSE: 6317129249.1371, Val R2: 0.6790\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1078\n",
      "Val RMSE: 80407.1834, Val MAE: 43877.0303, Val MSE: 6465315134.8013, Val R2: 0.6715\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0830, Val Loss: 0.1200\n",
      "Val RMSE: 82288.9672, Val MAE: 43036.5566, Val MSE: 6771474123.0778, Val R2: 0.6560\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1219\n",
      "Val RMSE: 81509.9868, Val MAE: 43081.1293, Val MSE: 6643877952.7623, Val R2: 0.6624\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1366\n",
      "Val RMSE: 85025.5177, Val MAE: 50943.9208, Val MSE: 7229338664.6177, Val R2: 0.6327\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1276\n",
      "Val RMSE: 83986.2817, Val MAE: 46801.2062, Val MSE: 7053695510.8778, Val R2: 0.6416\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1103\n",
      "Val RMSE: 75570.0881, Val MAE: 42947.0099, Val MSE: 5710838211.6161, Val R2: 0.7099\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1065\n",
      "Val RMSE: 74814.5827, Val MAE: 42606.1905, Val MSE: 5597221780.1333, Val R2: 0.7156\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0746, Val Loss: 0.1136\n",
      "Val RMSE: 79202.8787, Val MAE: 45309.6681, Val MSE: 6273095988.1217, Val R2: 0.6813\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1152\n",
      "Val RMSE: 78409.0713, Val MAE: 42999.5516, Val MSE: 6147982458.1497, Val R2: 0.6876\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1056\n",
      "Val RMSE: 74440.3426, Val MAE: 39706.6295, Val MSE: 5541364606.9996, Val R2: 0.7185\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1126\n",
      "Val RMSE: 77507.3347, Val MAE: 42769.1567, Val MSE: 6007386937.0784, Val R2: 0.6948\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1133\n",
      "Val RMSE: 73979.4325, Val MAE: 40624.6888, Val MSE: 5472956425.6323, Val R2: 0.7219\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1065\n",
      "Val RMSE: 71576.4603, Val MAE: 39619.3114, Val MSE: 5123189662.7579, Val R2: 0.7397\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1145\n",
      "Val RMSE: 70169.0626, Val MAE: 41422.3219, Val MSE: 4923697345.7063, Val R2: 0.7498\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1142\n",
      "Val RMSE: 77338.0321, Val MAE: 45266.4546, Val MSE: 5981171205.7674, Val R2: 0.6961\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0975, Val Loss: 0.1165\n",
      "Val RMSE: 85518.0926, Val MAE: 48401.0090, Val MSE: 7313344159.9805, Val R2: 0.6284\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1092\n",
      "Val RMSE: 82965.8574, Val MAE: 45824.2543, Val MSE: 6883333487.1416, Val R2: 0.6503\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0928, Val Loss: 0.0939\n",
      "Val RMSE: 73735.9371, Val MAE: 41350.2431, Val MSE: 5436988425.9029, Val R2: 0.7238\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0777, Val Loss: 0.1086\n",
      "Val RMSE: 75232.7102, Val MAE: 42637.3045, Val MSE: 5659960680.9104, Val R2: 0.7124\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0755, Val Loss: 0.0923\n",
      "Val RMSE: 69024.3181, Val MAE: 39723.7027, Val MSE: 4764356483.1041, Val R2: 0.7579\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.0874\n",
      "Val RMSE: 67135.6066, Val MAE: 37165.6459, Val MSE: 4507189670.8066, Val R2: 0.7710\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.0912\n",
      "Val RMSE: 68116.7522, Val MAE: 37638.4426, Val MSE: 4639891928.7937, Val R2: 0.7643\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0649, Val Loss: 0.0893\n",
      "Val RMSE: 67128.4291, Val MAE: 37432.8013, Val MSE: 4506225999.7418, Val R2: 0.7711\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.0930\n",
      "Val RMSE: 68593.5420, Val MAE: 37464.7160, Val MSE: 4705074009.2863, Val R2: 0.7610\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.0902\n",
      "Val RMSE: 66360.1248, Val MAE: 36902.8280, Val MSE: 4403666165.7116, Val R2: 0.7763\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.0969\n",
      "Val RMSE: 70365.1281, Val MAE: 39156.5845, Val MSE: 4951251245.7917, Val R2: 0.7484\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.0854\n",
      "Val RMSE: 64481.7729, Val MAE: 35943.8880, Val MSE: 4157899032.3145, Val R2: 0.7888\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.0895\n",
      "Val RMSE: 63786.6536, Val MAE: 36329.4907, Val MSE: 4068737174.6923, Val R2: 0.7933\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.0976\n",
      "Val RMSE: 69921.4177, Val MAE: 38606.8843, Val MSE: 4889004650.2104, Val R2: 0.7516\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.0865\n",
      "Val RMSE: 67395.2799, Val MAE: 36259.7383, Val MSE: 4542123758.1329, Val R2: 0.7692\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.0852\n",
      "Val RMSE: 62885.2287, Val MAE: 35212.8302, Val MSE: 3954551983.8645, Val R2: 0.7991\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.0949\n",
      "Val RMSE: 70010.9309, Val MAE: 37313.3362, Val MSE: 4901530450.9666, Val R2: 0.7510\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.0861\n",
      "Val RMSE: 64157.5065, Val MAE: 35668.7101, Val MSE: 4116185638.8789, Val R2: 0.7909\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.0970\n",
      "Val RMSE: 69416.5534, Val MAE: 37674.6170, Val MSE: 4818657889.8852, Val R2: 0.7552\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.0930\n",
      "Val RMSE: 67796.5302, Val MAE: 38013.1358, Val MSE: 4596369504.3810, Val R2: 0.7665\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.0886\n",
      "Val RMSE: 64873.9223, Val MAE: 35856.6829, Val MSE: 4208625799.1583, Val R2: 0.7862\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.0825\n",
      "Val RMSE: 63836.1219, Val MAE: 35654.9032, Val MSE: 4075050454.4063, Val R2: 0.7930\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.0936\n",
      "Val RMSE: 68420.6889, Val MAE: 37691.7885, Val MSE: 4681390663.4034, Val R2: 0.7622\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0548, Val Loss: 0.1077\n",
      "Val RMSE: 73058.5410, Val MAE: 40953.2281, Val MSE: 5337550411.7728, Val R2: 0.7288\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.0755\n",
      "Val RMSE: 62588.2249, Val MAE: 33829.7958, Val MSE: 3917285891.2667, Val R2: 0.8010\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.0894\n",
      "Val RMSE: 66084.2346, Val MAE: 36758.5538, Val MSE: 4367126059.4003, Val R2: 0.7781\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.0844\n",
      "Val RMSE: 64317.3925, Val MAE: 36943.8716, Val MSE: 4136726974.4366, Val R2: 0.7898\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.0923\n",
      "Val RMSE: 67224.9651, Val MAE: 36236.4246, Val MSE: 4519195929.4595, Val R2: 0.7704\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69672.5040, Test MAE: 38492.0078, Test MSE: 4854257816.8571, Test R2: 0.6888\n",
      "Inference Time: 3.881725898155799e-05 seconds per sample\n",
      "\n",
      "Iteration 3 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3664, Val Loss: 0.2903\n",
      "Val RMSE: 145857.2662, Val MAE: 80598.6568, Val MSE: 21274342093.2715, Val R2: -0.0809\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2752, Val Loss: 0.2758\n",
      "Val RMSE: 141357.3599, Val MAE: 83864.6152, Val MSE: 19981903185.5352, Val R2: -0.0152\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2719, Val Loss: 0.2768\n",
      "Val RMSE: 141980.5592, Val MAE: 82824.5384, Val MSE: 20158479177.6709, Val R2: -0.0242\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2674, Val Loss: 0.2755\n",
      "Val RMSE: 140702.2985, Val MAE: 85584.4361, Val MSE: 19797136804.8789, Val R2: -0.0058\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2656, Val Loss: 0.2824\n",
      "Val RMSE: 144291.6019, Val MAE: 80492.8583, Val MSE: 20820066371.7854, Val R2: -0.0578\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2647, Val Loss: 0.2745\n",
      "Val RMSE: 141295.9082, Val MAE: 84479.4904, Val MSE: 19964533671.9927, Val R2: -0.0143\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2696\n",
      "Val RMSE: 140699.9322, Val MAE: 83645.7376, Val MSE: 19796470920.7894, Val R2: -0.0058\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2574, Val Loss: 0.2751\n",
      "Val RMSE: 141408.5719, Val MAE: 84104.0411, Val MSE: 19996384206.8652, Val R2: -0.0159\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2712\n",
      "Val RMSE: 142706.3524, Val MAE: 79381.4085, Val MSE: 20365103018.7926, Val R2: -0.0347\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2675\n",
      "Val RMSE: 142251.8392, Val MAE: 78763.6351, Val MSE: 20235585764.5440, Val R2: -0.0281\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2678\n",
      "Val RMSE: 140600.2981, Val MAE: 82145.0319, Val MSE: 19768443830.9011, Val R2: -0.0044\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2709\n",
      "Val RMSE: 140654.9265, Val MAE: 83754.1939, Val MSE: 19783808349.5699, Val R2: -0.0051\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2488, Val Loss: 0.2660\n",
      "Val RMSE: 142162.7367, Val MAE: 79022.4435, Val MSE: 20210243701.4442, Val R2: -0.0268\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2486, Val Loss: 0.2674\n",
      "Val RMSE: 140003.6393, Val MAE: 82016.4429, Val MSE: 19601019006.3107, Val R2: 0.0041\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2429, Val Loss: 0.2831\n",
      "Val RMSE: 145162.9055, Val MAE: 79061.9674, Val MSE: 21072269140.3549, Val R2: -0.0706\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2456, Val Loss: 0.2636\n",
      "Val RMSE: 140507.9147, Val MAE: 79771.5686, Val MSE: 19742474087.5439, Val R2: -0.0030\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2440, Val Loss: 0.2699\n",
      "Val RMSE: 139212.2796, Val MAE: 84310.3913, Val MSE: 19380058793.8481, Val R2: 0.0154\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2561\n",
      "Val RMSE: 138351.8800, Val MAE: 75824.2923, Val MSE: 19141242709.6568, Val R2: 0.0275\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2297, Val Loss: 0.2436\n",
      "Val RMSE: 132642.3411, Val MAE: 77692.4744, Val MSE: 17593990650.7820, Val R2: 0.1061\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2233, Val Loss: 0.2406\n",
      "Val RMSE: 132546.4327, Val MAE: 77802.3961, Val MSE: 17568556813.0317, Val R2: 0.1074\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2204, Val Loss: 0.2306\n",
      "Val RMSE: 132053.7579, Val MAE: 72502.6114, Val MSE: 17438194973.0221, Val R2: 0.1140\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2274\n",
      "Val RMSE: 130368.4583, Val MAE: 73286.0278, Val MSE: 16995934928.0146, Val R2: 0.1365\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2506\n",
      "Val RMSE: 138280.8776, Val MAE: 71140.0341, Val MSE: 19121601117.6513, Val R2: 0.0285\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1959, Val Loss: 0.2049\n",
      "Val RMSE: 119435.5048, Val MAE: 67203.6113, Val MSE: 14264839812.7760, Val R2: 0.2753\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1836, Val Loss: 0.1991\n",
      "Val RMSE: 113385.8186, Val MAE: 68118.6096, Val MSE: 12856343860.2383, Val R2: 0.3468\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1762, Val Loss: 0.1918\n",
      "Val RMSE: 109080.2858, Val MAE: 64553.9282, Val MSE: 11898508739.5174, Val R2: 0.3955\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1844\n",
      "Val RMSE: 105748.0528, Val MAE: 60530.8173, Val MSE: 11182650670.1258, Val R2: 0.4319\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1632, Val Loss: 0.1743\n",
      "Val RMSE: 102649.0828, Val MAE: 60419.1443, Val MSE: 10536834204.7100, Val R2: 0.4647\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1778\n",
      "Val RMSE: 103747.4176, Val MAE: 57986.9185, Val MSE: 10763526663.8844, Val R2: 0.4531\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1560, Val Loss: 0.1632\n",
      "Val RMSE: 99284.2855, Val MAE: 57405.9344, Val MSE: 9857369355.6291, Val R2: 0.4992\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1532, Val Loss: 0.1616\n",
      "Val RMSE: 99700.2184, Val MAE: 56865.6063, Val MSE: 9940133558.2152, Val R2: 0.4950\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1472, Val Loss: 0.1557\n",
      "Val RMSE: 96482.7771, Val MAE: 54803.0200, Val MSE: 9308926268.6194, Val R2: 0.5270\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1408, Val Loss: 0.1507\n",
      "Val RMSE: 94782.4605, Val MAE: 55875.4572, Val MSE: 8983714826.7666, Val R2: 0.5436\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1411, Val Loss: 0.1425\n",
      "Val RMSE: 92895.5972, Val MAE: 52056.8588, Val MSE: 8629591987.7174, Val R2: 0.5616\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1347, Val Loss: 0.1402\n",
      "Val RMSE: 92234.1803, Val MAE: 50868.0306, Val MSE: 8507144007.3005, Val R2: 0.5678\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1331, Val Loss: 0.1381\n",
      "Val RMSE: 90777.2635, Val MAE: 51983.2445, Val MSE: 8240511567.6193, Val R2: 0.5813\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1286, Val Loss: 0.1299\n",
      "Val RMSE: 89392.9679, Val MAE: 48304.8802, Val MSE: 7991102708.9627, Val R2: 0.5940\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1228, Val Loss: 0.1426\n",
      "Val RMSE: 94964.6969, Val MAE: 51900.5511, Val MSE: 9018293649.0809, Val R2: 0.5418\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1312, Val Loss: 0.1325\n",
      "Val RMSE: 92101.7535, Val MAE: 48481.9922, Val MSE: 8482732994.6049, Val R2: 0.5690\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1185, Val Loss: 0.1173\n",
      "Val RMSE: 86913.1606, Val MAE: 46842.6970, Val MSE: 7553897482.8022, Val R2: 0.6162\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1274\n",
      "Val RMSE: 89035.6679, Val MAE: 48497.2064, Val MSE: 7927350166.5986, Val R2: 0.5972\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1141, Val Loss: 0.1201\n",
      "Val RMSE: 87046.4303, Val MAE: 46830.6167, Val MSE: 7577081034.1172, Val R2: 0.6150\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1092, Val Loss: 0.1248\n",
      "Val RMSE: 86754.5193, Val MAE: 50527.0463, Val MSE: 7526346622.8394, Val R2: 0.6176\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1061, Val Loss: 0.1235\n",
      "Val RMSE: 87725.5159, Val MAE: 47345.6419, Val MSE: 7695766145.9937, Val R2: 0.6090\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1235\n",
      "Val RMSE: 87309.1808, Val MAE: 45050.2707, Val MSE: 7622893057.7848, Val R2: 0.6127\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1001, Val Loss: 0.1161\n",
      "Val RMSE: 82728.8157, Val MAE: 44392.4150, Val MSE: 6844056955.3872, Val R2: 0.6523\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1293\n",
      "Val RMSE: 86508.2019, Val MAE: 48331.8427, Val MSE: 7483668987.4653, Val R2: 0.6198\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0927, Val Loss: 0.1093\n",
      "Val RMSE: 78313.9361, Val MAE: 43556.9266, Val MSE: 6133072593.8654, Val R2: 0.6884\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0906, Val Loss: 0.1233\n",
      "Val RMSE: 85850.7305, Val MAE: 44703.7071, Val MSE: 7370347930.9554, Val R2: 0.6255\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1220\n",
      "Val RMSE: 84404.0523, Val MAE: 44656.5560, Val MSE: 7124044050.6554, Val R2: 0.6381\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1200\n",
      "Val RMSE: 82155.7493, Val MAE: 44545.8704, Val MSE: 6749567139.0694, Val R2: 0.6571\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0844, Val Loss: 0.1178\n",
      "Val RMSE: 78002.5287, Val MAE: 47317.8158, Val MSE: 6084394487.5384, Val R2: 0.6909\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0819, Val Loss: 0.1139\n",
      "Val RMSE: 78069.3676, Val MAE: 44067.9110, Val MSE: 6094826154.7259, Val R2: 0.6903\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0817, Val Loss: 0.1100\n",
      "Val RMSE: 76063.4551, Val MAE: 43089.2128, Val MSE: 5785649208.2568, Val R2: 0.7061\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0793, Val Loss: 0.1207\n",
      "Val RMSE: 79893.1708, Val MAE: 43970.9084, Val MSE: 6382918745.7159, Val R2: 0.6757\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0793, Val Loss: 0.1166\n",
      "Val RMSE: 79295.7467, Val MAE: 46989.9244, Val MSE: 6287815437.3238, Val R2: 0.6805\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0755, Val Loss: 0.1118\n",
      "Val RMSE: 77655.8731, Val MAE: 42911.1136, Val MSE: 6030434621.4776, Val R2: 0.6936\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0749, Val Loss: 0.1196\n",
      "Val RMSE: 80038.7583, Val MAE: 47102.0442, Val MSE: 6406202837.0053, Val R2: 0.6745\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1048\n",
      "Val RMSE: 73801.5112, Val MAE: 42195.4574, Val MSE: 5446663060.7421, Val R2: 0.7233\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1091\n",
      "Val RMSE: 74799.7863, Val MAE: 42462.3764, Val MSE: 5595008030.5701, Val R2: 0.7157\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1167\n",
      "Val RMSE: 81071.3080, Val MAE: 44340.9328, Val MSE: 6572556988.5336, Val R2: 0.6661\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0713, Val Loss: 0.1123\n",
      "Val RMSE: 78143.3490, Val MAE: 42194.5674, Val MSE: 6106382992.2897, Val R2: 0.6898\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1107\n",
      "Val RMSE: 76303.7680, Val MAE: 43630.2228, Val MSE: 5822265014.0145, Val R2: 0.7042\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1189\n",
      "Val RMSE: 80024.0568, Val MAE: 43667.1936, Val MSE: 6403849665.0519, Val R2: 0.6746\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1161\n",
      "Val RMSE: 77119.8138, Val MAE: 45976.1227, Val MSE: 5947465687.9310, Val R2: 0.6978\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1006\n",
      "Val RMSE: 74013.8892, Val MAE: 39518.1438, Val MSE: 5478055793.7076, Val R2: 0.7217\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1090\n",
      "Val RMSE: 75174.8104, Val MAE: 41051.4097, Val MSE: 5651252125.8408, Val R2: 0.7129\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.0925\n",
      "Val RMSE: 71863.0942, Val MAE: 37457.2770, Val MSE: 5164304307.6951, Val R2: 0.7376\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1126\n",
      "Val RMSE: 75831.0128, Val MAE: 44154.7737, Val MSE: 5750342499.3559, Val R2: 0.7078\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1025\n",
      "Val RMSE: 72818.2892, Val MAE: 40079.3551, Val MSE: 5302503235.1462, Val R2: 0.7306\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.0989\n",
      "Val RMSE: 71814.5923, Val MAE: 39090.7744, Val MSE: 5157335667.0757, Val R2: 0.7380\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1136\n",
      "Val RMSE: 77660.1268, Val MAE: 45257.8755, Val MSE: 6031095293.8064, Val R2: 0.6936\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.0992\n",
      "Val RMSE: 72266.5693, Val MAE: 39775.7804, Val MSE: 5222457042.0330, Val R2: 0.7347\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.0932\n",
      "Val RMSE: 69540.2724, Val MAE: 37601.7997, Val MSE: 4835849488.1671, Val R2: 0.7543\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.0978\n",
      "Val RMSE: 71902.0005, Val MAE: 39004.7471, Val MSE: 5169897679.8120, Val R2: 0.7373\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.0968\n",
      "Val RMSE: 71068.0062, Val MAE: 38711.1958, Val MSE: 5050661499.4445, Val R2: 0.7434\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.0994\n",
      "Val RMSE: 72707.8641, Val MAE: 39593.1077, Val MSE: 5286433500.8460, Val R2: 0.7314\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1006\n",
      "Val RMSE: 71981.3978, Val MAE: 39415.7704, Val MSE: 5181321628.3409, Val R2: 0.7368\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.0960\n",
      "Val RMSE: 71484.6795, Val MAE: 38535.8122, Val MSE: 5110059397.0417, Val R2: 0.7404\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1005\n",
      "Val RMSE: 71866.2233, Val MAE: 39296.9478, Val MSE: 5164754045.0098, Val R2: 0.7376\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1087\n",
      "Val RMSE: 74821.8271, Val MAE: 42075.1179, Val MSE: 5598305803.9113, Val R2: 0.7156\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1028\n",
      "Val RMSE: 74108.0690, Val MAE: 40121.0900, Val MSE: 5492005885.3248, Val R2: 0.7210\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.0801\n",
      "Val RMSE: 65452.2688, Val MAE: 32105.1297, Val MSE: 4283999497.3855, Val R2: 0.7823\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0912\n",
      "Val RMSE: 69512.7118, Val MAE: 36690.8158, Val MSE: 4832017098.4190, Val R2: 0.7545\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.0916\n",
      "Val RMSE: 70458.4606, Val MAE: 36393.8095, Val MSE: 4964394671.3772, Val R2: 0.7478\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.0872\n",
      "Val RMSE: 69668.4087, Val MAE: 35030.6539, Val MSE: 4853687169.2020, Val R2: 0.7534\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.0840\n",
      "Val RMSE: 66719.0114, Val MAE: 34789.2153, Val MSE: 4451426485.6997, Val R2: 0.7738\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1032\n",
      "Val RMSE: 73585.5896, Val MAE: 41586.7608, Val MSE: 5414838995.8038, Val R2: 0.7249\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.0857\n",
      "Val RMSE: 66580.4450, Val MAE: 35491.0567, Val MSE: 4432955654.0260, Val R2: 0.7748\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.0966\n",
      "Val RMSE: 71215.7786, Val MAE: 39272.7657, Val MSE: 5071687127.6760, Val R2: 0.7423\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.0935\n",
      "Val RMSE: 71688.5659, Val MAE: 37325.5572, Val MSE: 5139250478.2640, Val R2: 0.7389\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.0977\n",
      "Val RMSE: 73099.0502, Val MAE: 37717.1309, Val MSE: 5343471138.5332, Val R2: 0.7285\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.0899\n",
      "Val RMSE: 70044.3360, Val MAE: 35466.7300, Val MSE: 4906209011.1681, Val R2: 0.7507\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.0850\n",
      "Val RMSE: 67926.8891, Val MAE: 35159.0345, Val MSE: 4614062265.9723, Val R2: 0.7656\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.0863\n",
      "Val RMSE: 67849.2662, Val MAE: 34954.4525, Val MSE: 4603522929.9778, Val R2: 0.7661\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.0876\n",
      "Val RMSE: 68895.9209, Val MAE: 34375.4024, Val MSE: 4746647921.2136, Val R2: 0.7588\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.0847\n",
      "Val RMSE: 67332.6027, Val MAE: 33721.9182, Val MSE: 4533679383.6445, Val R2: 0.7697\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1042\n",
      "Val RMSE: 73999.9827, Val MAE: 41231.2502, Val MSE: 5475997439.4589, Val R2: 0.7218\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.0908\n",
      "Val RMSE: 68884.3621, Val MAE: 36386.2567, Val MSE: 4745055341.2017, Val R2: 0.7589\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1013\n",
      "Val RMSE: 73803.7483, Val MAE: 39853.7582, Val MSE: 5446993258.4501, Val R2: 0.7233\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 72080.0381, Test MAE: 33974.7705, Test MSE: 5195531899.6622, Test R2: 0.6670\n",
      "Inference Time: 3.1368622413048376e-05 seconds per sample\n",
      "\n",
      "Iteration 4 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3817, Val Loss: 0.2831\n",
      "Val RMSE: 140717.4795, Val MAE: 88970.2737, Val MSE: 19801409042.4005, Val R2: -0.0060\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2826, Val Loss: 0.2834\n",
      "Val RMSE: 141930.2503, Val MAE: 85721.7381, Val MSE: 20144195962.1974, Val R2: -0.0235\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2772, Val Loss: 0.2766\n",
      "Val RMSE: 141943.5751, Val MAE: 83535.6569, Val MSE: 20147978506.7341, Val R2: -0.0236\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2714, Val Loss: 0.2752\n",
      "Val RMSE: 142084.4653, Val MAE: 82980.1950, Val MSE: 20187995273.1490, Val R2: -0.0257\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2624, Val Loss: 0.2762\n",
      "Val RMSE: 142380.1361, Val MAE: 82136.3642, Val MSE: 20272103147.1267, Val R2: -0.0300\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2769\n",
      "Val RMSE: 143226.5442, Val MAE: 80039.2864, Val MSE: 20513842966.8795, Val R2: -0.0422\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2770\n",
      "Val RMSE: 140891.1829, Val MAE: 86284.4313, Val MSE: 19850325418.1097, Val R2: -0.0085\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2790\n",
      "Val RMSE: 141101.4586, Val MAE: 86339.7963, Val MSE: 19909621607.2553, Val R2: -0.0115\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2703\n",
      "Val RMSE: 141852.4947, Val MAE: 81930.3827, Val MSE: 20122130239.0159, Val R2: -0.0223\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2764\n",
      "Val RMSE: 141276.1491, Val MAE: 84863.8635, Val MSE: 19958950303.7054, Val R2: -0.0140\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2694\n",
      "Val RMSE: 141658.0138, Val MAE: 80521.6599, Val MSE: 20066992878.7282, Val R2: -0.0195\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2738\n",
      "Val RMSE: 141211.7761, Val MAE: 84186.1628, Val MSE: 19940765707.8014, Val R2: -0.0131\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2903\n",
      "Val RMSE: 141822.7337, Val MAE: 89248.4330, Val MSE: 20113687789.9369, Val R2: -0.0219\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2495, Val Loss: 0.2627\n",
      "Val RMSE: 138569.1602, Val MAE: 78241.9693, Val MSE: 19201412146.4782, Val R2: 0.0244\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2408, Val Loss: 0.2660\n",
      "Val RMSE: 134742.7783, Val MAE: 84416.1685, Val MSE: 18155616297.0582, Val R2: 0.0776\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2329, Val Loss: 0.2298\n",
      "Val RMSE: 130906.9344, Val MAE: 72131.3332, Val MSE: 17136625478.1577, Val R2: 0.1294\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2222, Val Loss: 0.2299\n",
      "Val RMSE: 131133.5904, Val MAE: 71111.2723, Val MSE: 17196018521.4903, Val R2: 0.1263\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2206, Val Loss: 0.2379\n",
      "Val RMSE: 131579.6896, Val MAE: 75801.0021, Val MSE: 17313214722.7767, Val R2: 0.1204\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2253, Val Loss: 0.2313\n",
      "Val RMSE: 129896.0655, Val MAE: 75247.9682, Val MSE: 16872987841.2895, Val R2: 0.1427\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2172, Val Loss: 0.2372\n",
      "Val RMSE: 134343.6886, Val MAE: 72065.3393, Val MSE: 18048226671.0016, Val R2: 0.0830\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2155, Val Loss: 0.2513\n",
      "Val RMSE: 135969.8962, Val MAE: 77939.8759, Val MSE: 18487812680.0002, Val R2: 0.0607\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2168, Val Loss: 0.2337\n",
      "Val RMSE: 129634.5509, Val MAE: 74131.5028, Val MSE: 16805116778.4490, Val R2: 0.1462\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2439\n",
      "Val RMSE: 136171.2428, Val MAE: 73459.5018, Val MSE: 18542607363.9341, Val R2: 0.0579\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2084, Val Loss: 0.2299\n",
      "Val RMSE: 129487.1405, Val MAE: 73203.5401, Val MSE: 16766919556.6726, Val R2: 0.1481\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2052, Val Loss: 0.2379\n",
      "Val RMSE: 131585.2694, Val MAE: 76572.2430, Val MSE: 17314683115.8539, Val R2: 0.1203\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2029, Val Loss: 0.2270\n",
      "Val RMSE: 127958.2542, Val MAE: 73857.4355, Val MSE: 16373314811.4827, Val R2: 0.1681\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2025, Val Loss: 0.2264\n",
      "Val RMSE: 128577.0180, Val MAE: 72662.2770, Val MSE: 16532049545.1422, Val R2: 0.1601\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1984, Val Loss: 0.2412\n",
      "Val RMSE: 133801.9727, Val MAE: 76649.1438, Val MSE: 17902967900.3869, Val R2: 0.0904\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2356\n",
      "Val RMSE: 134169.7328, Val MAE: 72817.9238, Val MSE: 18001517201.7046, Val R2: 0.0854\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2365\n",
      "Val RMSE: 132595.9037, Val MAE: 75076.2659, Val MSE: 17581673665.4566, Val R2: 0.1067\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1948, Val Loss: 0.2534\n",
      "Val RMSE: 130573.6409, Val MAE: 80795.1294, Val MSE: 17049475692.6059, Val R2: 0.1338\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1909, Val Loss: 0.2127\n",
      "Val RMSE: 119198.3220, Val MAE: 69289.8039, Val MSE: 14208239971.1991, Val R2: 0.2781\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1864, Val Loss: 0.1997\n",
      "Val RMSE: 112973.3085, Val MAE: 67402.7055, Val MSE: 12762968423.1058, Val R2: 0.3516\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1795, Val Loss: 0.1909\n",
      "Val RMSE: 108902.4446, Val MAE: 64387.9064, Val MSE: 11859742432.9090, Val R2: 0.3975\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1761, Val Loss: 0.1958\n",
      "Val RMSE: 106747.3590, Val MAE: 66124.4554, Val MSE: 11394998647.7922, Val R2: 0.4211\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1721, Val Loss: 0.1903\n",
      "Val RMSE: 106839.6991, Val MAE: 64647.5060, Val MSE: 11414721295.7617, Val R2: 0.4201\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1678, Val Loss: 0.1926\n",
      "Val RMSE: 106767.2779, Val MAE: 66504.7766, Val MSE: 11399251624.1580, Val R2: 0.4208\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1624, Val Loss: 0.1769\n",
      "Val RMSE: 101849.9183, Val MAE: 60893.7836, Val MSE: 10373405848.6990, Val R2: 0.4730\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1624, Val Loss: 0.1753\n",
      "Val RMSE: 101684.7204, Val MAE: 60248.2431, Val MSE: 10339782362.4712, Val R2: 0.4747\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1600, Val Loss: 0.1819\n",
      "Val RMSE: 101737.1230, Val MAE: 60424.7512, Val MSE: 10350442186.6077, Val R2: 0.4741\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1582, Val Loss: 0.1662\n",
      "Val RMSE: 98871.6205, Val MAE: 59287.8046, Val MSE: 9775597333.4325, Val R2: 0.5033\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1532, Val Loss: 0.1661\n",
      "Val RMSE: 97731.4675, Val MAE: 58183.0250, Val MSE: 9551439737.8242, Val R2: 0.5147\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1450, Val Loss: 0.1626\n",
      "Val RMSE: 95669.2717, Val MAE: 58251.8117, Val MSE: 9152609541.5749, Val R2: 0.5350\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1436, Val Loss: 0.1504\n",
      "Val RMSE: 94743.5017, Val MAE: 53186.9854, Val MSE: 8976331110.9163, Val R2: 0.5439\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1392, Val Loss: 0.1634\n",
      "Val RMSE: 95053.8410, Val MAE: 59710.8841, Val MSE: 9035232691.1623, Val R2: 0.5410\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1345, Val Loss: 0.1480\n",
      "Val RMSE: 91848.7089, Val MAE: 54642.2014, Val MSE: 8436185330.0101, Val R2: 0.5714\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1299, Val Loss: 0.1500\n",
      "Val RMSE: 93437.7822, Val MAE: 53058.5073, Val MSE: 8730619136.8878, Val R2: 0.5564\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1477\n",
      "Val RMSE: 91293.1441, Val MAE: 56850.4424, Val MSE: 8334438155.3044, Val R2: 0.5766\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1615\n",
      "Val RMSE: 95131.8289, Val MAE: 53258.2336, Val MSE: 9050064877.3091, Val R2: 0.5402\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1237, Val Loss: 0.1592\n",
      "Val RMSE: 95151.3850, Val MAE: 55451.2828, Val MSE: 9053786068.5528, Val R2: 0.5400\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1154, Val Loss: 0.1464\n",
      "Val RMSE: 91840.9589, Val MAE: 51249.0920, Val MSE: 8434761736.1773, Val R2: 0.5715\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1099, Val Loss: 0.1476\n",
      "Val RMSE: 91713.9076, Val MAE: 54720.9215, Val MSE: 8411440843.4557, Val R2: 0.5726\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1432\n",
      "Val RMSE: 89822.2440, Val MAE: 52145.8715, Val MSE: 8068035525.0311, Val R2: 0.5901\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1015, Val Loss: 0.1347\n",
      "Val RMSE: 87745.4678, Val MAE: 51619.8412, Val MSE: 7699267123.0452, Val R2: 0.6088\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1597\n",
      "Val RMSE: 92270.3135, Val MAE: 57812.2321, Val MSE: 8513810746.2884, Val R2: 0.5674\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1301\n",
      "Val RMSE: 86290.0252, Val MAE: 50404.7809, Val MSE: 7445968449.2688, Val R2: 0.6217\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0955, Val Loss: 0.1339\n",
      "Val RMSE: 86942.8139, Val MAE: 49814.5920, Val MSE: 7559052885.4675, Val R2: 0.6160\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0924, Val Loss: 0.1377\n",
      "Val RMSE: 87558.6462, Val MAE: 53107.1040, Val MSE: 7666516520.5239, Val R2: 0.6105\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0913, Val Loss: 0.1433\n",
      "Val RMSE: 88811.3649, Val MAE: 53796.8177, Val MSE: 7887458535.4959, Val R2: 0.5993\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1456\n",
      "Val RMSE: 90415.4492, Val MAE: 53309.9804, Val MSE: 8174953447.5129, Val R2: 0.5847\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1391\n",
      "Val RMSE: 89167.2278, Val MAE: 49010.9306, Val MSE: 7950794506.2227, Val R2: 0.5960\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1420\n",
      "Val RMSE: 90510.7969, Val MAE: 49790.5673, Val MSE: 8192204360.7339, Val R2: 0.5838\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1421\n",
      "Val RMSE: 90925.2445, Val MAE: 50067.9074, Val MSE: 8267400088.2594, Val R2: 0.5800\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1366\n",
      "Val RMSE: 87936.2356, Val MAE: 50986.5065, Val MSE: 7732781522.8680, Val R2: 0.6071\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1260\n",
      "Val RMSE: 85600.0151, Val MAE: 48106.0534, Val MSE: 7327362580.0552, Val R2: 0.6277\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1376\n",
      "Val RMSE: 88804.8497, Val MAE: 50164.5725, Val MSE: 7886301330.1042, Val R2: 0.5993\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1378\n",
      "Val RMSE: 88771.9507, Val MAE: 49962.3907, Val MSE: 7880459230.1537, Val R2: 0.5996\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1470\n",
      "Val RMSE: 88872.8054, Val MAE: 54565.2083, Val MSE: 7898375538.1461, Val R2: 0.5987\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1423\n",
      "Val RMSE: 89868.5514, Val MAE: 51833.2200, Val MSE: 8076356533.3026, Val R2: 0.5897\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1407\n",
      "Val RMSE: 90950.4251, Val MAE: 48445.1560, Val MSE: 8271979833.5283, Val R2: 0.5797\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1283\n",
      "Val RMSE: 84436.9333, Val MAE: 47404.1689, Val MSE: 7129595704.3439, Val R2: 0.6378\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1419\n",
      "Val RMSE: 87512.9838, Val MAE: 52562.9263, Val MSE: 7658522327.0685, Val R2: 0.6109\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1382\n",
      "Val RMSE: 85063.1818, Val MAE: 48889.8087, Val MSE: 7235744895.9637, Val R2: 0.6324\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0705, Val Loss: 0.1482\n",
      "Val RMSE: 88002.9820, Val MAE: 54317.4164, Val MSE: 7744524843.9735, Val R2: 0.6065\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1474\n",
      "Val RMSE: 90692.0090, Val MAE: 53861.6832, Val MSE: 8225040492.8866, Val R2: 0.5821\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1466\n",
      "Val RMSE: 90861.0065, Val MAE: 50938.7424, Val MSE: 8255722507.2477, Val R2: 0.5806\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1329\n",
      "Val RMSE: 86479.3054, Val MAE: 50946.7503, Val MSE: 7478670254.7486, Val R2: 0.6200\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1420\n",
      "Val RMSE: 87795.1644, Val MAE: 52624.1966, Val MSE: 7707990892.7231, Val R2: 0.6084\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1399\n",
      "Val RMSE: 87775.4589, Val MAE: 51772.2230, Val MSE: 7704531190.3478, Val R2: 0.6086\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1474\n",
      "Val RMSE: 91125.8404, Val MAE: 51433.1138, Val MSE: 8303918794.9368, Val R2: 0.5781\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.2061\n",
      "Val RMSE: 105228.1905, Val MAE: 65351.3381, Val MSE: 11072972077.3478, Val R2: 0.4374\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.1266, Val Loss: 0.1845\n",
      "Val RMSE: 101361.5452, Val MAE: 65716.8824, Val MSE: 10274162848.1519, Val R2: 0.4780\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.1065, Val Loss: 0.1563\n",
      "Val RMSE: 95125.1173, Val MAE: 55897.7766, Val MSE: 9048787950.4682, Val R2: 0.5403\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0912, Val Loss: 0.1472\n",
      "Val RMSE: 93425.9684, Val MAE: 54329.3490, Val MSE: 8728411577.4461, Val R2: 0.5565\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1543\n",
      "Val RMSE: 94535.1288, Val MAE: 54002.0947, Val MSE: 8936890581.9753, Val R2: 0.5459\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1580\n",
      "Val RMSE: 91145.9198, Val MAE: 55755.3514, Val MSE: 8307578696.7038, Val R2: 0.5779\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1725\n",
      "Val RMSE: 95577.1274, Val MAE: 58912.3390, Val MSE: 9134987273.7131, Val R2: 0.5359\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0644, Val Loss: 0.1363\n",
      "Val RMSE: 86652.4957, Val MAE: 49891.1376, Val MSE: 7508655011.8419, Val R2: 0.6185\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1769\n",
      "Val RMSE: 94176.4707, Val MAE: 60762.8606, Val MSE: 8869207640.3896, Val R2: 0.5494\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1487\n",
      "Val RMSE: 89343.2507, Val MAE: 54928.1993, Val MSE: 7982216437.1669, Val R2: 0.5945\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1338\n",
      "Val RMSE: 85836.0123, Val MAE: 50056.7373, Val MSE: 7367821012.3520, Val R2: 0.6257\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1567\n",
      "Val RMSE: 88090.0719, Val MAE: 53901.4643, Val MSE: 7759860774.9438, Val R2: 0.6058\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1427\n",
      "Val RMSE: 85036.7262, Val MAE: 52324.1505, Val MSE: 7231244796.5958, Val R2: 0.6326\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1700\n",
      "Val RMSE: 98528.4446, Val MAE: 53479.0578, Val MSE: 9707854389.4603, Val R2: 0.5068\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1410\n",
      "Val RMSE: 89577.9587, Val MAE: 51154.1599, Val MSE: 8024210689.2693, Val R2: 0.5923\n",
      "Early stopping triggered after epoch 95\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 99763.5767, Test MAE: 54208.3554, Test MSE: 9952771234.2983, Test R2: 0.3620\n",
      "Inference Time: 2.0037174224853516e-05 seconds per sample\n",
      "\n",
      "Iteration 5 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3579, Val Loss: 0.2797\n",
      "Val RMSE: 142773.8820, Val MAE: 82392.1295, Val MSE: 20384381387.5274, Val R2: -0.0357\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2771\n",
      "Val RMSE: 142181.0092, Val MAE: 82755.1244, Val MSE: 20215439363.4152, Val R2: -0.0271\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2742, Val Loss: 0.2779\n",
      "Val RMSE: 142578.0967, Val MAE: 82105.0866, Val MSE: 20328513661.1816, Val R2: -0.0328\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2652, Val Loss: 0.2812\n",
      "Val RMSE: 143717.7036, Val MAE: 81128.7408, Val MSE: 20654778337.1476, Val R2: -0.0494\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2694, Val Loss: 0.2767\n",
      "Val RMSE: 140693.6049, Val MAE: 86146.8437, Val MSE: 19794690471.1074, Val R2: -0.0057\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2644, Val Loss: 0.2763\n",
      "Val RMSE: 141848.5631, Val MAE: 83280.4912, Val MSE: 20121014853.7097, Val R2: -0.0223\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2626, Val Loss: 0.2753\n",
      "Val RMSE: 141476.0204, Val MAE: 83971.8032, Val MSE: 20015464356.2709, Val R2: -0.0169\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2623, Val Loss: 0.2743\n",
      "Val RMSE: 141910.8280, Val MAE: 82083.8588, Val MSE: 20138683096.1277, Val R2: -0.0232\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2735\n",
      "Val RMSE: 141413.6590, Val MAE: 83020.8153, Val MSE: 19997822957.1515, Val R2: -0.0160\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2564, Val Loss: 0.3038\n",
      "Val RMSE: 147401.0452, Val MAE: 81606.7439, Val MSE: 21727068127.3198, Val R2: -0.1039\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2600, Val Loss: 0.2877\n",
      "Val RMSE: 141599.4942, Val MAE: 89699.4910, Val MSE: 20050416758.5266, Val R2: -0.0187\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2676\n",
      "Val RMSE: 140814.0125, Val MAE: 81214.8959, Val MSE: 19828586122.0432, Val R2: -0.0074\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2515, Val Loss: 0.2682\n",
      "Val RMSE: 140816.6365, Val MAE: 81763.6705, Val MSE: 19829325103.2394, Val R2: -0.0075\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2870\n",
      "Val RMSE: 143157.2205, Val MAE: 86652.8313, Val MSE: 20493989777.5599, Val R2: -0.0412\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2777\n",
      "Val RMSE: 142266.0543, Val MAE: 82821.9742, Val MSE: 20239630204.9313, Val R2: -0.0283\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2464, Val Loss: 0.2676\n",
      "Val RMSE: 140942.3918, Val MAE: 80874.3126, Val MSE: 19864757820.1336, Val R2: -0.0093\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2441, Val Loss: 0.2662\n",
      "Val RMSE: 140229.4663, Val MAE: 81675.7466, Val MSE: 19664303223.0766, Val R2: 0.0009\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2433, Val Loss: 0.2622\n",
      "Val RMSE: 141187.3267, Val MAE: 78713.8601, Val MSE: 19933861212.3668, Val R2: -0.0128\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2430, Val Loss: 0.2664\n",
      "Val RMSE: 143018.6794, Val MAE: 77224.0751, Val MSE: 20454342665.5516, Val R2: -0.0392\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2411, Val Loss: 0.2696\n",
      "Val RMSE: 141221.7537, Val MAE: 81118.9205, Val MSE: 19943583708.1186, Val R2: -0.0133\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2747\n",
      "Val RMSE: 141658.8244, Val MAE: 81936.3537, Val MSE: 20067222530.2208, Val R2: -0.0195\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2626\n",
      "Val RMSE: 140665.2269, Val MAE: 79053.2306, Val MSE: 19786706064.2639, Val R2: -0.0053\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2365, Val Loss: 0.2598\n",
      "Val RMSE: 140169.3659, Val MAE: 78874.9709, Val MSE: 19647451143.9796, Val R2: 0.0018\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2387, Val Loss: 0.2624\n",
      "Val RMSE: 140039.8403, Val MAE: 80009.7083, Val MSE: 19611156884.3881, Val R2: 0.0036\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2390, Val Loss: 0.2536\n",
      "Val RMSE: 137003.0569, Val MAE: 77506.2857, Val MSE: 18769837593.6558, Val R2: 0.0464\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2227, Val Loss: 0.2334\n",
      "Val RMSE: 132564.9555, Val MAE: 71673.1502, Val MSE: 17573467414.6720, Val R2: 0.1072\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2159, Val Loss: 0.2443\n",
      "Val RMSE: 136816.1781, Val MAE: 74702.9316, Val MSE: 18718666599.8598, Val R2: 0.0490\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2094, Val Loss: 0.2678\n",
      "Val RMSE: 141009.1293, Val MAE: 75759.3608, Val MSE: 19883574550.8571, Val R2: -0.0102\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2018, Val Loss: 0.2305\n",
      "Val RMSE: 130126.2506, Val MAE: 73010.9484, Val MSE: 16932841096.3778, Val R2: 0.1397\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1897, Val Loss: 0.2242\n",
      "Val RMSE: 127261.0447, Val MAE: 70540.2622, Val MSE: 16195373489.0952, Val R2: 0.1772\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1885, Val Loss: 0.2519\n",
      "Val RMSE: 130153.6427, Val MAE: 81557.7014, Val MSE: 16939970704.2940, Val R2: 0.1393\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2081, Val Loss: 0.2094\n",
      "Val RMSE: 118338.5541, Val MAE: 66174.0985, Val MSE: 14004013387.6202, Val R2: 0.2885\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1945, Val Loss: 0.2476\n",
      "Val RMSE: 130908.9923, Val MAE: 70392.1618, Val MSE: 17137164273.4470, Val R2: 0.1293\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1802, Val Loss: 0.2072\n",
      "Val RMSE: 116964.6137, Val MAE: 65606.9245, Val MSE: 13680720868.9321, Val R2: 0.3049\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1779, Val Loss: 0.2072\n",
      "Val RMSE: 112910.9631, Val MAE: 67897.4073, Val MSE: 12748885593.0010, Val R2: 0.3523\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1739, Val Loss: 0.2179\n",
      "Val RMSE: 113197.6703, Val MAE: 71989.6785, Val MSE: 12813712560.4409, Val R2: 0.3490\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1845, Val Loss: 0.2148\n",
      "Val RMSE: 118735.7219, Val MAE: 70328.1651, Val MSE: 14098171662.7293, Val R2: 0.2837\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1676, Val Loss: 0.1953\n",
      "Val RMSE: 108450.9278, Val MAE: 66404.6137, Val MSE: 11761603737.2106, Val R2: 0.4024\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1598, Val Loss: 0.2041\n",
      "Val RMSE: 109733.4088, Val MAE: 65025.7853, Val MSE: 12041421007.9026, Val R2: 0.3882\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1608, Val Loss: 0.1939\n",
      "Val RMSE: 108814.3936, Val MAE: 66040.7944, Val MSE: 11840572260.0170, Val R2: 0.3984\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1573, Val Loss: 0.1911\n",
      "Val RMSE: 106785.0431, Val MAE: 66863.6215, Val MSE: 11403045434.7736, Val R2: 0.4207\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1505, Val Loss: 0.1705\n",
      "Val RMSE: 101100.2444, Val MAE: 60260.5359, Val MSE: 10221259410.5793, Val R2: 0.4807\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1475, Val Loss: 0.1659\n",
      "Val RMSE: 100300.1920, Val MAE: 58866.5496, Val MSE: 10060128511.9780, Val R2: 0.4889\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1634\n",
      "Val RMSE: 98681.9857, Val MAE: 58234.1324, Val MSE: 9738134309.8663, Val R2: 0.5052\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1550\n",
      "Val RMSE: 96869.1698, Val MAE: 56376.6522, Val MSE: 9383636055.2030, Val R2: 0.5233\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1761\n",
      "Val RMSE: 98171.0812, Val MAE: 59069.3711, Val MSE: 9637561191.7484, Val R2: 0.5104\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1294, Val Loss: 0.1556\n",
      "Val RMSE: 95314.4470, Val MAE: 54125.4203, Val MSE: 9084843804.6290, Val R2: 0.5384\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1227, Val Loss: 0.1447\n",
      "Val RMSE: 94822.5867, Val MAE: 52028.9287, Val MSE: 8991322956.3070, Val R2: 0.5432\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1168, Val Loss: 0.1332\n",
      "Val RMSE: 91171.8449, Val MAE: 50936.4743, Val MSE: 8312305302.2137, Val R2: 0.5777\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1392\n",
      "Val RMSE: 92073.4039, Val MAE: 51934.7358, Val MSE: 8477511698.8197, Val R2: 0.5693\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1107, Val Loss: 0.1334\n",
      "Val RMSE: 91149.2879, Val MAE: 49640.6256, Val MSE: 8308192691.7999, Val R2: 0.5779\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1312\n",
      "Val RMSE: 89866.7538, Val MAE: 50245.8925, Val MSE: 8076033430.8902, Val R2: 0.5897\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1330\n",
      "Val RMSE: 89614.3094, Val MAE: 49166.7737, Val MSE: 8030724451.5605, Val R2: 0.5920\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1027, Val Loss: 0.1310\n",
      "Val RMSE: 89988.0480, Val MAE: 50363.8431, Val MSE: 8097848782.6143, Val R2: 0.5886\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0999, Val Loss: 0.1317\n",
      "Val RMSE: 88684.9835, Val MAE: 48940.6104, Val MSE: 7865026293.0174, Val R2: 0.6004\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0948, Val Loss: 0.1315\n",
      "Val RMSE: 88485.5645, Val MAE: 49443.1084, Val MSE: 7829695122.1320, Val R2: 0.6022\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1279\n",
      "Val RMSE: 87919.6313, Val MAE: 47560.9898, Val MSE: 7729861573.3780, Val R2: 0.6073\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0930, Val Loss: 0.1300\n",
      "Val RMSE: 87372.1651, Val MAE: 50198.8384, Val MSE: 7633895229.5685, Val R2: 0.6121\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1259\n",
      "Val RMSE: 86647.1563, Val MAE: 47841.7780, Val MSE: 7507729692.1185, Val R2: 0.6186\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0898, Val Loss: 0.1252\n",
      "Val RMSE: 86705.0155, Val MAE: 47035.5649, Val MSE: 7517759711.7967, Val R2: 0.6181\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1339\n",
      "Val RMSE: 87213.2875, Val MAE: 49903.6237, Val MSE: 7606157524.0737, Val R2: 0.6136\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0846, Val Loss: 0.1206\n",
      "Val RMSE: 82829.4052, Val MAE: 46595.0345, Val MSE: 6860710357.7169, Val R2: 0.6514\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0826, Val Loss: 0.1263\n",
      "Val RMSE: 86465.9224, Val MAE: 48905.3613, Val MSE: 7476355735.2498, Val R2: 0.6202\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0810, Val Loss: 0.1239\n",
      "Val RMSE: 82469.1849, Val MAE: 47717.8354, Val MSE: 6801166455.6890, Val R2: 0.6545\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.1233\n",
      "Val RMSE: 83999.8197, Val MAE: 48189.6198, Val MSE: 7055969703.5650, Val R2: 0.6415\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1163\n",
      "Val RMSE: 79772.2092, Val MAE: 47317.4774, Val MSE: 6363605365.2228, Val R2: 0.6767\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1204\n",
      "Val RMSE: 79514.4706, Val MAE: 46129.7919, Val MSE: 6322551041.1203, Val R2: 0.6788\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.1222\n",
      "Val RMSE: 81454.4623, Val MAE: 46298.2348, Val MSE: 6634829434.2646, Val R2: 0.6629\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1242\n",
      "Val RMSE: 79746.9329, Val MAE: 46362.2552, Val MSE: 6359573308.8745, Val R2: 0.6769\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1268\n",
      "Val RMSE: 81411.7498, Val MAE: 49979.7657, Val MSE: 6627873001.7379, Val R2: 0.6633\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1219\n",
      "Val RMSE: 79495.6366, Val MAE: 46657.8839, Val MSE: 6319556237.6748, Val R2: 0.6789\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1320\n",
      "Val RMSE: 84236.8379, Val MAE: 47083.2048, Val MSE: 7095844858.3379, Val R2: 0.6395\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0707, Val Loss: 0.1229\n",
      "Val RMSE: 80070.1718, Val MAE: 46358.4048, Val MSE: 6411232418.4486, Val R2: 0.6743\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1209\n",
      "Val RMSE: 77711.3893, Val MAE: 46238.5517, Val MSE: 6039060020.2106, Val R2: 0.6932\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1291\n",
      "Val RMSE: 79500.3758, Val MAE: 48683.7976, Val MSE: 6320309755.1701, Val R2: 0.6789\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.1288\n",
      "Val RMSE: 82267.2025, Val MAE: 48551.0675, Val MSE: 6767892601.0595, Val R2: 0.6561\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1401\n",
      "Val RMSE: 87286.9967, Val MAE: 49120.9274, Val MSE: 7619019794.5279, Val R2: 0.6129\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1630\n",
      "Val RMSE: 99856.7694, Val MAE: 52754.6865, Val MSE: 9971374387.4684, Val R2: 0.4934\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1141\n",
      "Val RMSE: 74147.7534, Val MAE: 44333.8237, Val MSE: 5497889330.8854, Val R2: 0.7207\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1120\n",
      "Val RMSE: 76661.4061, Val MAE: 43641.8076, Val MSE: 5876971188.0870, Val R2: 0.7014\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1189\n",
      "Val RMSE: 78777.8744, Val MAE: 46146.3105, Val MSE: 6205953489.7554, Val R2: 0.6847\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1184\n",
      "Val RMSE: 78330.6795, Val MAE: 44086.6269, Val MSE: 6135695356.9741, Val R2: 0.6883\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1356\n",
      "Val RMSE: 85790.4842, Val MAE: 47575.7779, Val MSE: 7360007179.5549, Val R2: 0.6261\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1247\n",
      "Val RMSE: 79679.1065, Val MAE: 46433.9989, Val MSE: 6348760018.8060, Val R2: 0.6774\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.0994\n",
      "Val RMSE: 70300.4313, Val MAE: 41971.6159, Val MSE: 4942150641.4897, Val R2: 0.7489\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.1239\n",
      "Val RMSE: 78213.9393, Val MAE: 46580.3007, Val MSE: 6117420306.0978, Val R2: 0.6892\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1129\n",
      "Val RMSE: 75868.8144, Val MAE: 43551.6734, Val MSE: 5756076995.6765, Val R2: 0.7076\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1097\n",
      "Val RMSE: 76024.4080, Val MAE: 42205.7984, Val MSE: 5779710618.9472, Val R2: 0.7064\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1667\n",
      "Val RMSE: 111940.9162, Val MAE: 53605.8521, Val MSE: 12530768713.6521, Val R2: 0.3634\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1239\n",
      "Val RMSE: 81483.1082, Val MAE: 44870.7982, Val MSE: 6639496920.1738, Val R2: 0.6627\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.2065\n",
      "Val RMSE: 136609.5196, Val MAE: 60551.3289, Val MSE: 18662160848.0461, Val R2: 0.0518\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1142\n",
      "Val RMSE: 76388.1068, Val MAE: 44285.0477, Val MSE: 5835142857.6777, Val R2: 0.7035\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1507\n",
      "Val RMSE: 94789.7181, Val MAE: 50505.4586, Val MSE: 8985090657.2118, Val R2: 0.5435\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1978\n",
      "Val RMSE: 133549.3275, Val MAE: 57163.5260, Val MSE: 17835422888.0774, Val R2: 0.0938\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1635\n",
      "Val RMSE: 107721.6234, Val MAE: 51002.5859, Val MSE: 11603948145.1604, Val R2: 0.4104\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1083\n",
      "Val RMSE: 76719.6612, Val MAE: 41044.2310, Val MSE: 5885906407.9748, Val R2: 0.7010\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.0930\n",
      "Val RMSE: 69949.0118, Val MAE: 37827.5774, Val MSE: 4892864245.9154, Val R2: 0.7514\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1913\n",
      "Val RMSE: 128994.6692, Val MAE: 56208.7587, Val MSE: 16639624672.1695, Val R2: 0.1546\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1936\n",
      "Val RMSE: 130647.3363, Val MAE: 56515.3952, Val MSE: 17068726478.5224, Val R2: 0.1328\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1034\n",
      "Val RMSE: 72334.1574, Val MAE: 40025.9708, Val MSE: 5232230333.5446, Val R2: 0.7342\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69820.3475, Test MAE: 36997.9586, Test MSE: 4874880923.7504, Test R2: 0.6875\n",
      "Inference Time: 2.353660876934345e-05 seconds per sample\n",
      "\n",
      "Iteration 6 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3354, Val Loss: 0.2879\n",
      "Val RMSE: 145733.2942, Val MAE: 80195.6917, Val MSE: 21238193024.4365, Val R2: -0.0790\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2783, Val Loss: 0.2741\n",
      "Val RMSE: 140923.7857, Val MAE: 84527.8359, Val MSE: 19859513371.9179, Val R2: -0.0090\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2679, Val Loss: 0.2754\n",
      "Val RMSE: 142394.5192, Val MAE: 82248.6095, Val MSE: 20276199112.0803, Val R2: -0.0302\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2660, Val Loss: 0.2753\n",
      "Val RMSE: 141059.8724, Val MAE: 86037.5039, Val MSE: 19897887614.0774, Val R2: -0.0109\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2649, Val Loss: 0.2764\n",
      "Val RMSE: 142964.7407, Val MAE: 80704.6564, Val MSE: 20438917078.7213, Val R2: -0.0384\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2722\n",
      "Val RMSE: 141192.7475, Val MAE: 82194.6025, Val MSE: 19935391950.2333, Val R2: -0.0128\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2588, Val Loss: 0.2709\n",
      "Val RMSE: 140904.1057, Val MAE: 83367.7714, Val MSE: 19853966993.1639, Val R2: -0.0087\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2571, Val Loss: 0.2706\n",
      "Val RMSE: 139865.7021, Val MAE: 83804.6427, Val MSE: 19562414632.1239, Val R2: 0.0061\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2549, Val Loss: 0.2694\n",
      "Val RMSE: 141463.6728, Val MAE: 79346.7373, Val MSE: 20011970713.5427, Val R2: -0.0167\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2667\n",
      "Val RMSE: 139903.1453, Val MAE: 79002.7375, Val MSE: 19572890059.7742, Val R2: 0.0056\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2493, Val Loss: 0.2572\n",
      "Val RMSE: 138667.7292, Val MAE: 75463.2081, Val MSE: 19228739116.1353, Val R2: 0.0231\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2522\n",
      "Val RMSE: 134289.1611, Val MAE: 78342.7826, Val MSE: 18033578794.6194, Val R2: 0.0838\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2682\n",
      "Val RMSE: 134849.8327, Val MAE: 86204.7790, Val MSE: 18184477375.4051, Val R2: 0.0761\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2425, Val Loss: 0.2528\n",
      "Val RMSE: 134785.8410, Val MAE: 74791.3392, Val MSE: 18167222946.7018, Val R2: 0.0770\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2276, Val Loss: 0.2421\n",
      "Val RMSE: 130167.9557, Val MAE: 80895.8847, Val MSE: 16943696700.4544, Val R2: 0.1392\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2231, Val Loss: 0.2338\n",
      "Val RMSE: 130600.1385, Val MAE: 74407.1021, Val MSE: 17056396183.4349, Val R2: 0.1334\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2172, Val Loss: 0.2325\n",
      "Val RMSE: 128757.1312, Val MAE: 76244.8470, Val MSE: 16578398825.1132, Val R2: 0.1577\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2155, Val Loss: 0.2368\n",
      "Val RMSE: 129408.6643, Val MAE: 78051.5032, Val MSE: 16746602408.4771, Val R2: 0.1492\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2133, Val Loss: 0.2288\n",
      "Val RMSE: 129166.0746, Val MAE: 74412.1231, Val MSE: 16683874816.3780, Val R2: 0.1524\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2104, Val Loss: 0.2428\n",
      "Val RMSE: 132780.5938, Val MAE: 73264.4194, Val MSE: 17630686086.9483, Val R2: 0.1042\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2386\n",
      "Val RMSE: 129764.5418, Val MAE: 76815.4329, Val MSE: 16838836298.1014, Val R2: 0.1445\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2216, Val Loss: 0.2510\n",
      "Val RMSE: 132393.3003, Val MAE: 80595.1090, Val MSE: 17527985970.7817, Val R2: 0.1095\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2404, Val Loss: 0.2320\n",
      "Val RMSE: 130729.4687, Val MAE: 72094.7882, Val MSE: 17090193977.7650, Val R2: 0.1317\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2135, Val Loss: 0.2523\n",
      "Val RMSE: 134323.9894, Val MAE: 73066.5085, Val MSE: 18042934120.6271, Val R2: 0.0833\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2100, Val Loss: 0.2267\n",
      "Val RMSE: 127985.1656, Val MAE: 70613.0295, Val MSE: 16380202623.1565, Val R2: 0.1678\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2040, Val Loss: 0.2254\n",
      "Val RMSE: 125459.0278, Val MAE: 68170.2822, Val MSE: 15739967644.8954, Val R2: 0.2003\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1943, Val Loss: 0.2044\n",
      "Val RMSE: 116002.1478, Val MAE: 67239.4380, Val MSE: 13456498297.4667, Val R2: 0.3163\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1865, Val Loss: 0.2030\n",
      "Val RMSE: 113036.3342, Val MAE: 68470.3677, Val MSE: 12777212846.4958, Val R2: 0.3508\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1836, Val Loss: 0.1918\n",
      "Val RMSE: 107860.0762, Val MAE: 64934.2371, Val MSE: 11633796047.3992, Val R2: 0.4089\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1772, Val Loss: 0.1924\n",
      "Val RMSE: 107844.4896, Val MAE: 64372.5839, Val MSE: 11630433940.6128, Val R2: 0.4091\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1750, Val Loss: 0.1893\n",
      "Val RMSE: 107143.4839, Val MAE: 63295.6306, Val MSE: 11479726141.3458, Val R2: 0.4168\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1728, Val Loss: 0.1905\n",
      "Val RMSE: 106399.5610, Val MAE: 63196.4306, Val MSE: 11320866585.8611, Val R2: 0.4248\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1685, Val Loss: 0.1870\n",
      "Val RMSE: 103804.2959, Val MAE: 64696.8557, Val MSE: 10775331839.8069, Val R2: 0.4525\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1659, Val Loss: 0.1742\n",
      "Val RMSE: 102111.1077, Val MAE: 59125.8083, Val MSE: 10426678309.8878, Val R2: 0.4703\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1790\n",
      "Val RMSE: 102056.5963, Val MAE: 60431.8860, Val MSE: 10415548853.3840, Val R2: 0.4708\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1594, Val Loss: 0.1825\n",
      "Val RMSE: 102310.3190, Val MAE: 61127.8145, Val MSE: 10467401364.8669, Val R2: 0.4682\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1593, Val Loss: 0.1794\n",
      "Val RMSE: 101583.6777, Val MAE: 59596.2340, Val MSE: 10319243573.3027, Val R2: 0.4757\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1483, Val Loss: 0.1724\n",
      "Val RMSE: 100036.8167, Val MAE: 57758.9073, Val MSE: 10007364685.8798, Val R2: 0.4916\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1458, Val Loss: 0.1783\n",
      "Val RMSE: 100190.7035, Val MAE: 60744.5688, Val MSE: 10038177071.6408, Val R2: 0.4900\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1412, Val Loss: 0.1651\n",
      "Val RMSE: 99085.5180, Val MAE: 58677.1853, Val MSE: 9817939877.6981, Val R2: 0.5012\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1904\n",
      "Val RMSE: 101065.9559, Val MAE: 61406.9670, Val MSE: 10214327432.3488, Val R2: 0.4810\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1332, Val Loss: 0.1628\n",
      "Val RMSE: 97613.0820, Val MAE: 59267.9319, Val MSE: 9528313787.2343, Val R2: 0.5159\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1568\n",
      "Val RMSE: 95870.5761, Val MAE: 55693.0792, Val MSE: 9191167366.9398, Val R2: 0.5330\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1249, Val Loss: 0.1624\n",
      "Val RMSE: 98144.7775, Val MAE: 57809.6272, Val MSE: 9632397354.7192, Val R2: 0.5106\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1597\n",
      "Val RMSE: 98048.3467, Val MAE: 55179.1809, Val MSE: 9613478298.3198, Val R2: 0.5116\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1198, Val Loss: 0.1633\n",
      "Val RMSE: 98166.6321, Val MAE: 56350.2892, Val MSE: 9636687657.8867, Val R2: 0.5104\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1195, Val Loss: 0.1566\n",
      "Val RMSE: 96617.1562, Val MAE: 55762.8241, Val MSE: 9334874862.5288, Val R2: 0.5257\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1172, Val Loss: 0.1716\n",
      "Val RMSE: 100009.7102, Val MAE: 60490.1014, Val MSE: 10001942128.1475, Val R2: 0.4918\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1152, Val Loss: 0.1620\n",
      "Val RMSE: 98340.7195, Val MAE: 56640.6523, Val MSE: 9670897111.5832, Val R2: 0.5087\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1133, Val Loss: 0.1622\n",
      "Val RMSE: 99097.2679, Val MAE: 57102.2779, Val MSE: 9820268505.5486, Val R2: 0.5011\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1643\n",
      "Val RMSE: 98673.5347, Val MAE: 59108.5335, Val MSE: 9736466447.2123, Val R2: 0.5053\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1099, Val Loss: 0.1579\n",
      "Val RMSE: 96990.1412, Val MAE: 58105.8054, Val MSE: 9407087490.5513, Val R2: 0.5221\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1130, Val Loss: 0.1612\n",
      "Val RMSE: 99910.4435, Val MAE: 54560.9082, Val MSE: 9982096721.3399, Val R2: 0.4928\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1511\n",
      "Val RMSE: 94818.1799, Val MAE: 55243.8833, Val MSE: 8990487247.4872, Val R2: 0.5432\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1058, Val Loss: 0.1578\n",
      "Val RMSE: 97010.8811, Val MAE: 55781.9629, Val MSE: 9411111056.5021, Val R2: 0.5219\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1086, Val Loss: 0.1553\n",
      "Val RMSE: 95635.9008, Val MAE: 51565.1964, Val MSE: 9146225527.0911, Val R2: 0.5353\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1066, Val Loss: 0.1557\n",
      "Val RMSE: 95544.2352, Val MAE: 56573.0322, Val MSE: 9128700880.8530, Val R2: 0.5362\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1446\n",
      "Val RMSE: 91900.0564, Val MAE: 53069.6737, Val MSE: 8445620371.7277, Val R2: 0.5709\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1450\n",
      "Val RMSE: 92507.9022, Val MAE: 53975.0494, Val MSE: 8557711961.3987, Val R2: 0.5652\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1618\n",
      "Val RMSE: 97115.9634, Val MAE: 59313.0128, Val MSE: 9431510348.7943, Val R2: 0.5208\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0999, Val Loss: 0.1518\n",
      "Val RMSE: 95122.1686, Val MAE: 54529.6421, Val MSE: 9048226966.4186, Val R2: 0.5403\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0998, Val Loss: 0.1470\n",
      "Val RMSE: 93567.2215, Val MAE: 52547.0740, Val MSE: 8754824939.1199, Val R2: 0.5552\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1614\n",
      "Val RMSE: 98070.9904, Val MAE: 55755.9279, Val MSE: 9617919151.4551, Val R2: 0.5113\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1446\n",
      "Val RMSE: 92035.1792, Val MAE: 53853.0087, Val MSE: 8470474216.9296, Val R2: 0.5696\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0982, Val Loss: 0.1558\n",
      "Val RMSE: 95258.7424, Val MAE: 56731.6170, Val MSE: 9074228011.2960, Val R2: 0.5390\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1451\n",
      "Val RMSE: 92576.5136, Val MAE: 53724.3915, Val MSE: 8570410869.7228, Val R2: 0.5646\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1495\n",
      "Val RMSE: 92508.2066, Val MAE: 56023.1310, Val MSE: 8557768291.6011, Val R2: 0.5652\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0980, Val Loss: 0.1498\n",
      "Val RMSE: 93009.5626, Val MAE: 54911.3905, Val MSE: 8650778725.7873, Val R2: 0.5605\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0957, Val Loss: 0.1445\n",
      "Val RMSE: 92951.0941, Val MAE: 52970.0259, Val MSE: 8639905902.4535, Val R2: 0.5610\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0955, Val Loss: 0.1480\n",
      "Val RMSE: 92696.8918, Val MAE: 53554.2702, Val MSE: 8592713743.3834, Val R2: 0.5634\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1472\n",
      "Val RMSE: 92844.8393, Val MAE: 53470.0766, Val MSE: 8620164176.6769, Val R2: 0.5620\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1520\n",
      "Val RMSE: 93874.0370, Val MAE: 57724.8950, Val MSE: 8812334829.5531, Val R2: 0.5523\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0921, Val Loss: 0.1504\n",
      "Val RMSE: 92828.9287, Val MAE: 57239.6767, Val MSE: 8617210012.2144, Val R2: 0.5622\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0904, Val Loss: 0.1458\n",
      "Val RMSE: 92230.7412, Val MAE: 54028.8786, Val MSE: 8506509618.9847, Val R2: 0.5678\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1418\n",
      "Val RMSE: 90775.2667, Val MAE: 51746.7100, Val MSE: 8240149052.0431, Val R2: 0.5813\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1445\n",
      "Val RMSE: 93354.8432, Val MAE: 52413.7894, Val MSE: 8715126754.6986, Val R2: 0.5572\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1419\n",
      "Val RMSE: 92660.0462, Val MAE: 51317.7782, Val MSE: 8585884154.8515, Val R2: 0.5638\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1475\n",
      "Val RMSE: 93837.9492, Val MAE: 50799.2048, Val MSE: 8805560712.2191, Val R2: 0.5526\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1397\n",
      "Val RMSE: 91011.2781, Val MAE: 49626.7169, Val MSE: 8283052739.9697, Val R2: 0.5792\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1326\n",
      "Val RMSE: 88962.4503, Val MAE: 49499.2192, Val MSE: 7914317557.0188, Val R2: 0.5979\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0820, Val Loss: 0.1527\n",
      "Val RMSE: 94837.2676, Val MAE: 53432.5434, Val MSE: 8994107328.0081, Val R2: 0.5430\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0793, Val Loss: 0.1344\n",
      "Val RMSE: 89215.7303, Val MAE: 49098.7241, Val MSE: 7959446539.4392, Val R2: 0.5956\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1446\n",
      "Val RMSE: 92032.5088, Val MAE: 53990.0655, Val MSE: 8469982670.9940, Val R2: 0.5697\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1503\n",
      "Val RMSE: 94568.5976, Val MAE: 53244.2513, Val MSE: 8943219650.0829, Val R2: 0.5456\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1435\n",
      "Val RMSE: 92300.6412, Val MAE: 50244.2095, Val MSE: 8519408358.2698, Val R2: 0.5672\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1449\n",
      "Val RMSE: 95128.0590, Val MAE: 51071.8115, Val MSE: 9049347607.7532, Val R2: 0.5402\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1378\n",
      "Val RMSE: 89456.4216, Val MAE: 49304.3914, Val MSE: 8002451368.6458, Val R2: 0.5934\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1486\n",
      "Val RMSE: 96335.6080, Val MAE: 51549.6298, Val MSE: 9280549364.0288, Val R2: 0.5285\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1387\n",
      "Val RMSE: 92642.7721, Val MAE: 50287.4518, Val MSE: 8582683221.7608, Val R2: 0.5639\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1488\n",
      "Val RMSE: 93193.2081, Val MAE: 53634.1915, Val MSE: 8684974044.0885, Val R2: 0.5587\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1361\n",
      "Val RMSE: 88515.5034, Val MAE: 51384.3720, Val MSE: 7834994336.2910, Val R2: 0.6019\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0649, Val Loss: 0.1419\n",
      "Val RMSE: 90222.3422, Val MAE: 50232.7497, Val MSE: 8140071026.0546, Val R2: 0.5864\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1376\n",
      "Val RMSE: 88967.2562, Val MAE: 50969.1511, Val MSE: 7915172667.9352, Val R2: 0.5979\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.1429\n",
      "Val RMSE: 88168.1571, Val MAE: 54407.4470, Val MSE: 7773623929.0621, Val R2: 0.6051\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1455\n",
      "Val RMSE: 89879.9038, Val MAE: 53873.0359, Val MSE: 8078397114.2043, Val R2: 0.5896\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1515\n",
      "Val RMSE: 93261.9496, Val MAE: 53510.8349, Val MSE: 8697791246.0498, Val R2: 0.5581\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0611, Val Loss: 0.1415\n",
      "Val RMSE: 89596.8983, Val MAE: 51672.6850, Val MSE: 8027604181.0816, Val R2: 0.5921\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1389\n",
      "Val RMSE: 89765.4759, Val MAE: 49395.9772, Val MSE: 8057840655.9009, Val R2: 0.5906\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1440\n",
      "Val RMSE: 91264.5094, Val MAE: 51477.6666, Val MSE: 8329210678.2698, Val R2: 0.5768\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1432\n",
      "Val RMSE: 90684.3712, Val MAE: 52748.0758, Val MSE: 8223655177.9514, Val R2: 0.5822\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 103612.1047, Test MAE: 56752.8149, Test MSE: 10735468238.9895, Test R2: 0.3118\n",
      "Inference Time: 1.902451881995568e-05 seconds per sample\n",
      "\n",
      "Iteration 7 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3823, Val Loss: 0.2845\n",
      "Val RMSE: 144478.1429, Val MAE: 80896.6180, Val MSE: 20873933789.3035, Val R2: -0.0605\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2807, Val Loss: 0.2758\n",
      "Val RMSE: 141413.4482, Val MAE: 83709.5277, Val MSE: 19997763338.1025, Val R2: -0.0160\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2704, Val Loss: 0.2770\n",
      "Val RMSE: 142095.9510, Val MAE: 82654.7945, Val MSE: 20191259302.9856, Val R2: -0.0258\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2664, Val Loss: 0.2783\n",
      "Val RMSE: 142831.3584, Val MAE: 81773.5458, Val MSE: 20400796952.1656, Val R2: -0.0365\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2798\n",
      "Val RMSE: 143337.3245, Val MAE: 81725.9693, Val MSE: 20545588608.6346, Val R2: -0.0438\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2595, Val Loss: 0.2724\n",
      "Val RMSE: 141774.5290, Val MAE: 82677.6948, Val MSE: 20100017078.4907, Val R2: -0.0212\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2566, Val Loss: 0.2818\n",
      "Val RMSE: 142110.8246, Val MAE: 87031.0386, Val MSE: 20195486475.0129, Val R2: -0.0261\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2732\n",
      "Val RMSE: 142726.7553, Val MAE: 80983.3941, Val MSE: 20370926664.5087, Val R2: -0.0350\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2668\n",
      "Val RMSE: 142337.8447, Val MAE: 78265.5291, Val MSE: 20260062039.2597, Val R2: -0.0293\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2606\n",
      "Val RMSE: 139598.9687, Val MAE: 77943.3788, Val MSE: 19487872063.5590, Val R2: 0.0099\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2443, Val Loss: 0.2549\n",
      "Val RMSE: 137299.3209, Val MAE: 76105.4121, Val MSE: 18851103512.8250, Val R2: 0.0422\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2430, Val Loss: 0.2634\n",
      "Val RMSE: 133836.9264, Val MAE: 84882.1280, Val MSE: 17912322855.2405, Val R2: 0.0899\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2623\n",
      "Val RMSE: 136191.6817, Val MAE: 81183.4449, Val MSE: 18548174151.8358, Val R2: 0.0576\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2609\n",
      "Val RMSE: 135789.8803, Val MAE: 80687.7534, Val MSE: 18438891593.5424, Val R2: 0.0632\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2373, Val Loss: 0.2497\n",
      "Val RMSE: 134958.0774, Val MAE: 75841.2342, Val MSE: 18213682650.5291, Val R2: 0.0746\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2332, Val Loss: 0.2425\n",
      "Val RMSE: 132533.2328, Val MAE: 73460.8497, Val MSE: 17565057788.8025, Val R2: 0.1076\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2282, Val Loss: 0.2355\n",
      "Val RMSE: 132464.3410, Val MAE: 72132.0402, Val MSE: 17546801642.1070, Val R2: 0.1085\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2222, Val Loss: 0.2572\n",
      "Val RMSE: 131087.7841, Val MAE: 84413.4717, Val MSE: 17184007140.3079, Val R2: 0.1269\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2232, Val Loss: 0.2409\n",
      "Val RMSE: 129570.9215, Val MAE: 78948.8971, Val MSE: 16788623701.4178, Val R2: 0.1470\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2203, Val Loss: 0.2407\n",
      "Val RMSE: 130963.6832, Val MAE: 76459.9811, Val MSE: 17151486309.9944, Val R2: 0.1286\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2159, Val Loss: 0.2312\n",
      "Val RMSE: 128809.3688, Val MAE: 75920.6939, Val MSE: 16591853481.9314, Val R2: 0.1570\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2120, Val Loss: 0.2301\n",
      "Val RMSE: 129392.3779, Val MAE: 74028.0954, Val MSE: 16742387450.7899, Val R2: 0.1494\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2105, Val Loss: 0.2309\n",
      "Val RMSE: 130222.7391, Val MAE: 71776.7961, Val MSE: 16957961777.4958, Val R2: 0.1384\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2096, Val Loss: 0.2418\n",
      "Val RMSE: 131176.0411, Val MAE: 76319.9823, Val MSE: 17207153771.6571, Val R2: 0.1258\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2065, Val Loss: 0.2275\n",
      "Val RMSE: 128033.5600, Val MAE: 73023.5696, Val MSE: 16392592479.2146, Val R2: 0.1672\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2027, Val Loss: 0.2240\n",
      "Val RMSE: 123739.3862, Val MAE: 74372.2766, Val MSE: 15311435705.8828, Val R2: 0.2221\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1992, Val Loss: 0.2042\n",
      "Val RMSE: 115211.8372, Val MAE: 65998.0123, Val MSE: 13273767436.7112, Val R2: 0.3256\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2019, Val Loss: 0.2320\n",
      "Val RMSE: 126739.3149, Val MAE: 74054.8829, Val MSE: 16062853947.8303, Val R2: 0.1839\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1974, Val Loss: 0.2037\n",
      "Val RMSE: 114389.3036, Val MAE: 67173.3484, Val MSE: 13084912767.5871, Val R2: 0.3352\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1827, Val Loss: 0.2126\n",
      "Val RMSE: 114444.3263, Val MAE: 69250.7939, Val MSE: 13097503820.5934, Val R2: 0.3346\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1816, Val Loss: 0.1925\n",
      "Val RMSE: 109191.8385, Val MAE: 64469.5423, Val MSE: 11922857605.1182, Val R2: 0.3942\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1735, Val Loss: 0.1819\n",
      "Val RMSE: 104009.1253, Val MAE: 64742.9571, Val MSE: 10817898138.3726, Val R2: 0.4504\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1690, Val Loss: 0.1798\n",
      "Val RMSE: 105755.5986, Val MAE: 60556.7414, Val MSE: 11184246643.6964, Val R2: 0.4318\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1681, Val Loss: 0.1685\n",
      "Val RMSE: 102883.3286, Val MAE: 59424.2222, Val MSE: 10584979314.0740, Val R2: 0.4622\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1567, Val Loss: 0.1735\n",
      "Val RMSE: 98140.0094, Val MAE: 62296.5814, Val MSE: 9631461437.5889, Val R2: 0.5107\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1484, Val Loss: 0.1648\n",
      "Val RMSE: 98319.6708, Val MAE: 57111.7239, Val MSE: 9666757672.3052, Val R2: 0.5089\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1411, Val Loss: 0.1786\n",
      "Val RMSE: 101949.4590, Val MAE: 61781.7953, Val MSE: 10393692194.9190, Val R2: 0.4719\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1316, Val Loss: 0.1800\n",
      "Val RMSE: 101344.8417, Val MAE: 62344.7568, Val MSE: 10270776931.2764, Val R2: 0.4782\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1275, Val Loss: 0.1598\n",
      "Val RMSE: 96482.6452, Val MAE: 57961.8875, Val MSE: 9308900815.1614, Val R2: 0.5270\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1707\n",
      "Val RMSE: 100029.8217, Val MAE: 59786.1679, Val MSE: 10005965225.9711, Val R2: 0.4916\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1749\n",
      "Val RMSE: 100248.9875, Val MAE: 63101.4618, Val MSE: 10049859496.4625, Val R2: 0.4894\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1166, Val Loss: 0.1684\n",
      "Val RMSE: 99071.4665, Val MAE: 58696.1778, Val MSE: 9815155473.2929, Val R2: 0.5013\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1125, Val Loss: 0.1727\n",
      "Val RMSE: 100621.1019, Val MAE: 59745.6422, Val MSE: 10124606154.7067, Val R2: 0.4856\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1085, Val Loss: 0.1801\n",
      "Val RMSE: 101073.1671, Val MAE: 63796.3205, Val MSE: 10215785101.6557, Val R2: 0.4810\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1039, Val Loss: 0.1581\n",
      "Val RMSE: 96185.8528, Val MAE: 56505.5755, Val MSE: 9251718272.7780, Val R2: 0.5300\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1033, Val Loss: 0.1520\n",
      "Val RMSE: 92955.3849, Val MAE: 54594.0723, Val MSE: 8640703578.5198, Val R2: 0.5610\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1657\n",
      "Val RMSE: 95136.1889, Val MAE: 60422.1191, Val MSE: 9050894431.2892, Val R2: 0.5402\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0979, Val Loss: 0.1606\n",
      "Val RMSE: 95686.4248, Val MAE: 56787.4003, Val MSE: 9155891892.1148, Val R2: 0.5348\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0959, Val Loss: 0.1564\n",
      "Val RMSE: 94955.2161, Val MAE: 52976.2933, Val MSE: 9016493065.6679, Val R2: 0.5419\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1564\n",
      "Val RMSE: 94816.6504, Val MAE: 56145.7889, Val MSE: 8990197185.5856, Val R2: 0.5432\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0940, Val Loss: 0.1483\n",
      "Val RMSE: 90232.9021, Val MAE: 54806.7111, Val MSE: 8141976624.2949, Val R2: 0.5863\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1571\n",
      "Val RMSE: 93207.5709, Val MAE: 56245.9648, Val MSE: 8687651279.8028, Val R2: 0.5586\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1507\n",
      "Val RMSE: 90887.4431, Val MAE: 53510.4399, Val MSE: 8260527314.0008, Val R2: 0.5803\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0876, Val Loss: 0.1576\n",
      "Val RMSE: 92531.0815, Val MAE: 58119.1681, Val MSE: 8562001051.5530, Val R2: 0.5650\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0876, Val Loss: 0.1537\n",
      "Val RMSE: 91755.7331, Val MAE: 56370.6456, Val MSE: 8419114558.7329, Val R2: 0.5723\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0844, Val Loss: 0.1451\n",
      "Val RMSE: 87520.4992, Val MAE: 53719.9951, Val MSE: 7659837778.5931, Val R2: 0.6108\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0842, Val Loss: 0.1574\n",
      "Val RMSE: 93164.8911, Val MAE: 54438.5311, Val MSE: 8679696940.9387, Val R2: 0.5590\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0831, Val Loss: 0.1420\n",
      "Val RMSE: 86542.1970, Val MAE: 50913.2623, Val MSE: 7489551855.0048, Val R2: 0.6195\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0807, Val Loss: 0.1608\n",
      "Val RMSE: 93144.0529, Val MAE: 53013.6659, Val MSE: 8675814586.4406, Val R2: 0.5592\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1480\n",
      "Val RMSE: 89708.2882, Val MAE: 53588.0413, Val MSE: 8047576963.0242, Val R2: 0.5911\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0783, Val Loss: 0.1422\n",
      "Val RMSE: 87395.7789, Val MAE: 52486.9478, Val MSE: 7638022171.6936, Val R2: 0.6119\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1426\n",
      "Val RMSE: 87579.0209, Val MAE: 52176.4634, Val MSE: 7670084907.9798, Val R2: 0.6103\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1441\n",
      "Val RMSE: 88336.4264, Val MAE: 50109.5680, Val MSE: 7803324221.4974, Val R2: 0.6035\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1461\n",
      "Val RMSE: 88831.8737, Val MAE: 52977.6582, Val MSE: 7891101786.9235, Val R2: 0.5991\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1497\n",
      "Val RMSE: 90762.2561, Val MAE: 51975.3661, Val MSE: 8237787137.1896, Val R2: 0.5815\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1395\n",
      "Val RMSE: 84736.3379, Val MAE: 51355.2895, Val MSE: 7180246958.7181, Val R2: 0.6352\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1472\n",
      "Val RMSE: 90537.2886, Val MAE: 53293.7293, Val MSE: 8197000626.4106, Val R2: 0.5835\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1669\n",
      "Val RMSE: 91408.2356, Val MAE: 58290.3709, Val MSE: 8355465528.6757, Val R2: 0.5755\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0670, Val Loss: 0.1410\n",
      "Val RMSE: 87414.0910, Val MAE: 50667.4134, Val MSE: 7641223307.0881, Val R2: 0.6118\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.1382\n",
      "Val RMSE: 84531.9272, Val MAE: 48987.9274, Val MSE: 7145646712.2040, Val R2: 0.6370\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1459\n",
      "Val RMSE: 86769.8507, Val MAE: 52877.5041, Val MSE: 7529006989.8937, Val R2: 0.6175\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1427\n",
      "Val RMSE: 86425.4668, Val MAE: 52218.0862, Val MSE: 7469361306.8200, Val R2: 0.6205\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1423\n",
      "Val RMSE: 87347.7235, Val MAE: 51161.1875, Val MSE: 7629624802.2003, Val R2: 0.6124\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1338\n",
      "Val RMSE: 83507.1034, Val MAE: 47769.5614, Val MSE: 6973436320.2307, Val R2: 0.6457\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1356\n",
      "Val RMSE: 83820.0069, Val MAE: 47409.8949, Val MSE: 7025793555.2255, Val R2: 0.6430\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1273\n",
      "Val RMSE: 81538.6598, Val MAE: 47039.1837, Val MSE: 6648553045.8112, Val R2: 0.6622\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1373\n",
      "Val RMSE: 85108.7730, Val MAE: 49366.1470, Val MSE: 7243503236.1654, Val R2: 0.6320\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1267\n",
      "Val RMSE: 81337.3529, Val MAE: 46730.8692, Val MSE: 6615764979.0183, Val R2: 0.6639\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1392\n",
      "Val RMSE: 83716.2433, Val MAE: 52748.7018, Val MSE: 7008409396.9700, Val R2: 0.6439\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1304\n",
      "Val RMSE: 82100.3349, Val MAE: 46704.8308, Val MSE: 6740464983.6383, Val R2: 0.6575\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.1310\n",
      "Val RMSE: 82073.4943, Val MAE: 48922.9565, Val MSE: 6736058463.1226, Val R2: 0.6578\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1230\n",
      "Val RMSE: 79351.6698, Val MAE: 45210.3394, Val MSE: 6296687503.9804, Val R2: 0.6801\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1268\n",
      "Val RMSE: 82085.3744, Val MAE: 46437.8460, Val MSE: 6738008691.0754, Val R2: 0.6577\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1327\n",
      "Val RMSE: 81475.1808, Val MAE: 48286.1985, Val MSE: 6638205089.4775, Val R2: 0.6627\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1374\n",
      "Val RMSE: 86138.7871, Val MAE: 48876.0586, Val MSE: 7419890649.0101, Val R2: 0.6230\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1343\n",
      "Val RMSE: 80165.8260, Val MAE: 49314.4440, Val MSE: 6426559655.5419, Val R2: 0.6735\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1331\n",
      "Val RMSE: 81650.6479, Val MAE: 49632.7656, Val MSE: 6666828298.5236, Val R2: 0.6613\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1297\n",
      "Val RMSE: 82103.0856, Val MAE: 47251.0001, Val MSE: 6740916668.4018, Val R2: 0.6575\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.1413\n",
      "Val RMSE: 85834.2132, Val MAE: 52638.7127, Val MSE: 7367512156.8809, Val R2: 0.6257\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1267\n",
      "Val RMSE: 79697.6010, Val MAE: 47476.4613, Val MSE: 6351707606.5850, Val R2: 0.6773\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1331\n",
      "Val RMSE: 81302.1274, Val MAE: 51416.2521, Val MSE: 6610035922.0504, Val R2: 0.6642\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1353\n",
      "Val RMSE: 83900.0191, Val MAE: 49836.5005, Val MSE: 7039213198.6204, Val R2: 0.6424\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1293\n",
      "Val RMSE: 81809.0563, Val MAE: 47083.9076, Val MSE: 6692721694.4375, Val R2: 0.6600\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1279\n",
      "Val RMSE: 80928.5370, Val MAE: 45652.6376, Val MSE: 6549428105.6597, Val R2: 0.6672\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1253\n",
      "Val RMSE: 81754.5407, Val MAE: 45046.1476, Val MSE: 6683804917.9941, Val R2: 0.6604\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1528\n",
      "Val RMSE: 88572.1029, Val MAE: 54811.8798, Val MSE: 7845017420.6283, Val R2: 0.6014\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1271\n",
      "Val RMSE: 80439.8225, Val MAE: 48232.9793, Val MSE: 6470565040.5386, Val R2: 0.6713\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1452\n",
      "Val RMSE: 87352.2023, Val MAE: 51963.9470, Val MSE: 7630407244.1503, Val R2: 0.6123\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1227\n",
      "Val RMSE: 78488.4988, Val MAE: 44828.3313, Val MSE: 6160444436.5455, Val R2: 0.6870\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1329\n",
      "Val RMSE: 80853.6069, Val MAE: 49027.6727, Val MSE: 6537305749.2409, Val R2: 0.6679\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76128.4566, Test MAE: 44263.3252, Test MSE: 5795541908.0513, Test R2: 0.6285\n",
      "Inference Time: 2.121767630943885e-05 seconds per sample\n",
      "\n",
      "Iteration 8 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3248, Val Loss: 0.2788\n",
      "Val RMSE: 142626.5336, Val MAE: 82596.1265, Val MSE: 20342328081.5132, Val R2: -0.0335\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2763\n",
      "Val RMSE: 142041.7006, Val MAE: 82768.7469, Val MSE: 20175844715.1722, Val R2: -0.0251\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2766\n",
      "Val RMSE: 142031.5988, Val MAE: 83100.9256, Val MSE: 20172975065.7076, Val R2: -0.0249\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2649, Val Loss: 0.2739\n",
      "Val RMSE: 140331.0697, Val MAE: 86023.1377, Val MSE: 19692809122.2756, Val R2: -0.0005\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2608, Val Loss: 0.2766\n",
      "Val RMSE: 142653.3008, Val MAE: 82700.7617, Val MSE: 20349964235.3184, Val R2: -0.0339\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2814\n",
      "Val RMSE: 141797.0976, Val MAE: 83784.2632, Val MSE: 20106416899.8110, Val R2: -0.0215\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2671\n",
      "Val RMSE: 141190.1323, Val MAE: 80667.3329, Val MSE: 19934653464.9434, Val R2: -0.0128\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2731\n",
      "Val RMSE: 141261.2102, Val MAE: 82857.5042, Val MSE: 19954729500.2050, Val R2: -0.0138\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2693\n",
      "Val RMSE: 141317.5297, Val MAE: 80666.8317, Val MSE: 19970644204.2513, Val R2: -0.0146\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2477, Val Loss: 0.2705\n",
      "Val RMSE: 141732.6304, Val MAE: 81171.3343, Val MSE: 20088138527.6378, Val R2: -0.0206\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2464, Val Loss: 0.2708\n",
      "Val RMSE: 141531.0804, Val MAE: 81447.0424, Val MSE: 20031046708.7175, Val R2: -0.0177\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2429, Val Loss: 0.2693\n",
      "Val RMSE: 143267.2283, Val MAE: 77812.5945, Val MSE: 20525498718.0062, Val R2: -0.0428\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2400, Val Loss: 0.2641\n",
      "Val RMSE: 139742.3135, Val MAE: 81661.3858, Val MSE: 19527914169.8704, Val R2: 0.0079\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2391, Val Loss: 0.2668\n",
      "Val RMSE: 140754.8540, Val MAE: 80652.5600, Val MSE: 19811928922.4045, Val R2: -0.0066\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2385, Val Loss: 0.2637\n",
      "Val RMSE: 141505.0623, Val MAE: 78290.2990, Val MSE: 20023682658.5758, Val R2: -0.0173\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2355, Val Loss: 0.2467\n",
      "Val RMSE: 134544.2161, Val MAE: 75540.2697, Val MSE: 18102146080.3018, Val R2: 0.0803\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2195, Val Loss: 0.2461\n",
      "Val RMSE: 134244.2881, Val MAE: 76938.3889, Val MSE: 18021528886.2181, Val R2: 0.0844\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2156, Val Loss: 0.2310\n",
      "Val RMSE: 131098.0254, Val MAE: 72722.8639, Val MSE: 17186692263.4995, Val R2: 0.1268\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2059, Val Loss: 0.2262\n",
      "Val RMSE: 128611.6252, Val MAE: 73235.5690, Val MSE: 16540950138.6923, Val R2: 0.1596\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2268\n",
      "Val RMSE: 127242.6272, Val MAE: 72950.9399, Val MSE: 16190686166.7811, Val R2: 0.1774\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2066, Val Loss: 0.2259\n",
      "Val RMSE: 129810.7118, Val MAE: 69664.2078, Val MSE: 16850820893.6130, Val R2: 0.1439\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1947, Val Loss: 0.2067\n",
      "Val RMSE: 119212.9685, Val MAE: 69777.9973, Val MSE: 14211731863.4642, Val R2: 0.2780\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1843, Val Loss: 0.1898\n",
      "Val RMSE: 107360.6941, Val MAE: 66960.1927, Val MSE: 11526318632.7627, Val R2: 0.4144\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1768, Val Loss: 0.1823\n",
      "Val RMSE: 103693.9259, Val MAE: 64687.8994, Val MSE: 10752430277.9365, Val R2: 0.4537\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1696, Val Loss: 0.1772\n",
      "Val RMSE: 102007.7199, Val MAE: 60843.9680, Val MSE: 10405574910.5309, Val R2: 0.4713\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1670, Val Loss: 0.1667\n",
      "Val RMSE: 98733.9069, Val MAE: 57676.2329, Val MSE: 9748384373.4403, Val R2: 0.5047\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1594, Val Loss: 0.1589\n",
      "Val RMSE: 97520.4126, Val MAE: 57402.9848, Val MSE: 9510230864.3367, Val R2: 0.5168\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1580, Val Loss: 0.1733\n",
      "Val RMSE: 99615.8264, Val MAE: 58972.3451, Val MSE: 9923312870.9633, Val R2: 0.4958\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1562, Val Loss: 0.1657\n",
      "Val RMSE: 100177.5814, Val MAE: 56731.1849, Val MSE: 10035547815.5884, Val R2: 0.4901\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1524\n",
      "Val RMSE: 95477.1224, Val MAE: 55277.1025, Val MSE: 9115880893.0891, Val R2: 0.5369\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1465, Val Loss: 0.1517\n",
      "Val RMSE: 94840.6290, Val MAE: 54676.2838, Val MSE: 8994744917.0670, Val R2: 0.5430\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1527\n",
      "Val RMSE: 95487.4880, Val MAE: 55328.7816, Val MSE: 9117860366.5033, Val R2: 0.5368\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1389, Val Loss: 0.1445\n",
      "Val RMSE: 93728.4572, Val MAE: 52030.5630, Val MSE: 8785023692.8882, Val R2: 0.5537\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1402, Val Loss: 0.1471\n",
      "Val RMSE: 94117.1406, Val MAE: 53123.4888, Val MSE: 8858036145.4492, Val R2: 0.5500\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1350, Val Loss: 0.1510\n",
      "Val RMSE: 95549.1535, Val MAE: 53357.4776, Val MSE: 9129640738.3373, Val R2: 0.5362\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1319, Val Loss: 0.1516\n",
      "Val RMSE: 94630.9705, Val MAE: 52545.2216, Val MSE: 8955020579.1685, Val R2: 0.5450\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1318, Val Loss: 0.1543\n",
      "Val RMSE: 93569.0955, Val MAE: 52762.0040, Val MSE: 8755175640.7122, Val R2: 0.5552\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1226, Val Loss: 0.1587\n",
      "Val RMSE: 96547.7039, Val MAE: 52587.9933, Val MSE: 9321459122.2999, Val R2: 0.5264\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1227, Val Loss: 0.2360\n",
      "Val RMSE: 106370.5072, Val MAE: 66205.2393, Val MSE: 11314684798.3034, Val R2: 0.4251\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1178, Val Loss: 0.1266\n",
      "Val RMSE: 88918.2402, Val MAE: 49069.1448, Val MSE: 7906453431.6282, Val R2: 0.5983\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1028, Val Loss: 0.1289\n",
      "Val RMSE: 90688.5901, Val MAE: 47794.6557, Val MSE: 8224420381.0643, Val R2: 0.5821\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1015, Val Loss: 0.1581\n",
      "Val RMSE: 96179.0314, Val MAE: 53961.0750, Val MSE: 9250406076.5888, Val R2: 0.5300\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1189\n",
      "Val RMSE: 86971.3335, Val MAE: 45828.1551, Val MSE: 7564012844.5961, Val R2: 0.6157\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1167\n",
      "Val RMSE: 87463.6839, Val MAE: 44953.4200, Val MSE: 7649895994.0577, Val R2: 0.6113\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1094\n",
      "Val RMSE: 84104.1235, Val MAE: 45162.6201, Val MSE: 7073503590.2640, Val R2: 0.6406\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1153\n",
      "Val RMSE: 85995.2739, Val MAE: 45008.5843, Val MSE: 7395187141.3164, Val R2: 0.6243\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0866, Val Loss: 0.0952\n",
      "Val RMSE: 81078.7388, Val MAE: 39423.1733, Val MSE: 6573761884.9282, Val R2: 0.6660\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0842, Val Loss: 0.1094\n",
      "Val RMSE: 84596.6556, Val MAE: 41198.2556, Val MSE: 7156594141.5573, Val R2: 0.6364\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0862, Val Loss: 0.0969\n",
      "Val RMSE: 80112.0745, Val MAE: 39162.3628, Val MSE: 6417944478.6327, Val R2: 0.6739\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1004\n",
      "Val RMSE: 80402.7440, Val MAE: 40694.5505, Val MSE: 6464601244.8069, Val R2: 0.6716\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0802, Val Loss: 0.1030\n",
      "Val RMSE: 80416.2723, Val MAE: 40267.0358, Val MSE: 6466776852.0787, Val R2: 0.6714\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1000\n",
      "Val RMSE: 78985.6804, Val MAE: 40733.9005, Val MSE: 6238737714.1871, Val R2: 0.6830\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.0963\n",
      "Val RMSE: 76286.8785, Val MAE: 40463.3823, Val MSE: 5819687826.8694, Val R2: 0.7043\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.0985\n",
      "Val RMSE: 77951.4939, Val MAE: 39248.6780, Val MSE: 6076435408.2701, Val R2: 0.6913\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.0993\n",
      "Val RMSE: 76705.6786, Val MAE: 39264.5317, Val MSE: 5883761126.5643, Val R2: 0.7011\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.0966\n",
      "Val RMSE: 75192.3410, Val MAE: 40300.1134, Val MSE: 5653888148.4375, Val R2: 0.7127\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1011\n",
      "Val RMSE: 76633.3809, Val MAE: 39839.7028, Val MSE: 5872675070.4592, Val R2: 0.7016\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1015\n",
      "Val RMSE: 74926.0732, Val MAE: 42459.3512, Val MSE: 5613916450.7885, Val R2: 0.7148\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1228\n",
      "Val RMSE: 82546.1777, Val MAE: 47031.9605, Val MSE: 6813871450.3858, Val R2: 0.6538\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.0931\n",
      "Val RMSE: 72247.7688, Val MAE: 38825.0671, Val MSE: 5219740098.8441, Val R2: 0.7348\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0649, Val Loss: 0.0972\n",
      "Val RMSE: 74640.5311, Val MAE: 38777.4212, Val MSE: 5571208888.1479, Val R2: 0.7169\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0653, Val Loss: 0.1261\n",
      "Val RMSE: 79484.7693, Val MAE: 49186.5747, Val MSE: 6317828552.7039, Val R2: 0.6790\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1122\n",
      "Val RMSE: 73641.7742, Val MAE: 45564.8131, Val MSE: 5423110906.1258, Val R2: 0.7245\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.0939\n",
      "Val RMSE: 71019.8627, Val MAE: 38947.2715, Val MSE: 5043820892.5963, Val R2: 0.7437\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.0836\n",
      "Val RMSE: 67889.9486, Val MAE: 37135.2244, Val MSE: 4609045116.0823, Val R2: 0.7658\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1631\n",
      "Val RMSE: 87281.3318, Val MAE: 55925.5595, Val MSE: 7618030880.3011, Val R2: 0.6130\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.0943\n",
      "Val RMSE: 71617.7454, Val MAE: 39301.2456, Val MSE: 5129101460.3667, Val R2: 0.7394\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.0898\n",
      "Val RMSE: 70208.1543, Val MAE: 38793.5477, Val MSE: 4929184923.9898, Val R2: 0.7496\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.0976\n",
      "Val RMSE: 71920.9828, Val MAE: 41143.7091, Val MSE: 5172627761.2459, Val R2: 0.7372\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.0836\n",
      "Val RMSE: 67285.6359, Val MAE: 34803.7060, Val MSE: 4527356793.0289, Val R2: 0.7700\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.0878\n",
      "Val RMSE: 68880.6423, Val MAE: 37259.4335, Val MSE: 4744542885.4258, Val R2: 0.7589\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.0964\n",
      "Val RMSE: 69811.4789, Val MAE: 42513.6306, Val MSE: 4873642590.5000, Val R2: 0.7524\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1020\n",
      "Val RMSE: 74463.0995, Val MAE: 41327.6783, Val MSE: 5544753185.3899, Val R2: 0.7183\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.0919\n",
      "Val RMSE: 70208.3193, Val MAE: 38686.9377, Val MSE: 4929208094.6285, Val R2: 0.7496\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.0887\n",
      "Val RMSE: 67337.9501, Val MAE: 39040.4688, Val MSE: 4534399529.0640, Val R2: 0.7696\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.0979\n",
      "Val RMSE: 72356.5910, Val MAE: 40396.4255, Val MSE: 5235476259.2078, Val R2: 0.7340\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.0833\n",
      "Val RMSE: 65926.5274, Val MAE: 35983.4949, Val MSE: 4346307020.1550, Val R2: 0.7792\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.0842\n",
      "Val RMSE: 67087.7790, Val MAE: 36997.3124, Val MSE: 4500770088.7465, Val R2: 0.7713\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.0868\n",
      "Val RMSE: 67850.0756, Val MAE: 37795.4007, Val MSE: 4603632758.3624, Val R2: 0.7661\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.0810\n",
      "Val RMSE: 64891.8208, Val MAE: 35044.0561, Val MSE: 4210948402.0320, Val R2: 0.7861\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.0936\n",
      "Val RMSE: 69931.2762, Val MAE: 38355.6208, Val MSE: 4890383393.6370, Val R2: 0.7515\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.0839\n",
      "Val RMSE: 66553.0760, Val MAE: 37193.4387, Val MSE: 4429311920.1430, Val R2: 0.7750\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.0911\n",
      "Val RMSE: 70832.2163, Val MAE: 37320.6979, Val MSE: 5017202869.8521, Val R2: 0.7451\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.0877\n",
      "Val RMSE: 67296.3793, Val MAE: 37913.3015, Val MSE: 4528802660.4053, Val R2: 0.7699\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.0913\n",
      "Val RMSE: 70463.3571, Val MAE: 37902.3539, Val MSE: 4965084697.5774, Val R2: 0.7477\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.0865\n",
      "Val RMSE: 68611.7351, Val MAE: 35852.9097, Val MSE: 4707570196.2585, Val R2: 0.7608\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1248\n",
      "Val RMSE: 77223.2746, Val MAE: 47992.8226, Val MSE: 5963434132.9768, Val R2: 0.6970\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.0840\n",
      "Val RMSE: 69135.4794, Val MAE: 36001.2687, Val MSE: 4779714509.6612, Val R2: 0.7572\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.0887\n",
      "Val RMSE: 68670.5125, Val MAE: 36732.2299, Val MSE: 4715639291.3924, Val R2: 0.7604\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.0869\n",
      "Val RMSE: 67098.9896, Val MAE: 36736.4437, Val MSE: 4502274404.3913, Val R2: 0.7713\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.0885\n",
      "Val RMSE: 67041.8395, Val MAE: 37381.3880, Val MSE: 4494608243.6955, Val R2: 0.7716\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.0951\n",
      "Val RMSE: 72845.4611, Val MAE: 38900.1589, Val MSE: 5306461207.7767, Val R2: 0.7304\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.0915\n",
      "Val RMSE: 69868.5066, Val MAE: 36803.5626, Val MSE: 4881608213.1316, Val R2: 0.7520\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.0948\n",
      "Val RMSE: 69420.7498, Val MAE: 40005.1254, Val MSE: 4819240503.4056, Val R2: 0.7552\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.0979\n",
      "Val RMSE: 72022.3783, Val MAE: 39798.2622, Val MSE: 5187222970.8737, Val R2: 0.7365\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.0902\n",
      "Val RMSE: 68203.2285, Val MAE: 37981.5279, Val MSE: 4651680377.7256, Val R2: 0.7637\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.0929\n",
      "Val RMSE: 70403.5849, Val MAE: 37468.9229, Val MSE: 4956664773.1465, Val R2: 0.7482\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1004\n",
      "Val RMSE: 72109.3945, Val MAE: 40346.8497, Val MSE: 5199764769.3060, Val R2: 0.7358\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.0839\n",
      "Val RMSE: 64481.5068, Val MAE: 35997.4875, Val MSE: 4157864723.9344, Val R2: 0.7888\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.0954\n",
      "Val RMSE: 70639.9409, Val MAE: 39322.3966, Val MSE: 4990001248.8487, Val R2: 0.7465\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 66073.8950, Test MAE: 37822.0876, Test MSE: 4365759605.4565, Test R2: 0.7202\n",
      "Inference Time: 3.167423835167518e-05 seconds per sample\n",
      "\n",
      "Iteration 9 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3593, Val Loss: 0.2816\n",
      "Val RMSE: 142994.6665, Val MAE: 82291.5667, Val MSE: 20447474647.0267, Val R2: -0.0389\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2697, Val Loss: 0.2771\n",
      "Val RMSE: 142490.0093, Val MAE: 82188.6323, Val MSE: 20303402761.8203, Val R2: -0.0315\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2666, Val Loss: 0.2762\n",
      "Val RMSE: 142358.7090, Val MAE: 81927.6397, Val MSE: 20266002023.2109, Val R2: -0.0296\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2629, Val Loss: 0.2840\n",
      "Val RMSE: 144453.1840, Val MAE: 80294.2437, Val MSE: 20866722374.6979, Val R2: -0.0602\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2642, Val Loss: 0.2711\n",
      "Val RMSE: 140825.2747, Val MAE: 82967.8631, Val MSE: 19831758000.9892, Val R2: -0.0076\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2695\n",
      "Val RMSE: 141500.2695, Val MAE: 80487.8659, Val MSE: 20022326261.7434, Val R2: -0.0173\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2735\n",
      "Val RMSE: 140932.6007, Val MAE: 84540.8898, Val MSE: 19861997940.7897, Val R2: -0.0091\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2698\n",
      "Val RMSE: 141626.9546, Val MAE: 80572.2362, Val MSE: 20058194269.2669, Val R2: -0.0191\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2709\n",
      "Val RMSE: 141396.9292, Val MAE: 81736.6332, Val MSE: 19993091595.3851, Val R2: -0.0158\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2663\n",
      "Val RMSE: 140375.8209, Val MAE: 81549.2354, Val MSE: 19705371093.2918, Val R2: -0.0012\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2739\n",
      "Val RMSE: 141814.1802, Val MAE: 82727.9442, Val MSE: 20111261719.7822, Val R2: -0.0218\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2782\n",
      "Val RMSE: 140465.0327, Val MAE: 86659.5235, Val MSE: 19730425411.4433, Val R2: -0.0024\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2664\n",
      "Val RMSE: 140232.3231, Val MAE: 82029.2505, Val MSE: 19665104448.5316, Val R2: 0.0009\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2505, Val Loss: 0.2709\n",
      "Val RMSE: 140636.8905, Val MAE: 83270.8459, Val MSE: 19778734968.4802, Val R2: -0.0049\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2664\n",
      "Val RMSE: 141244.6270, Val MAE: 79746.3117, Val MSE: 19950044656.8466, Val R2: -0.0136\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2481, Val Loss: 0.2677\n",
      "Val RMSE: 140287.1063, Val MAE: 82027.2082, Val MSE: 19680472194.2011, Val R2: 0.0001\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2454, Val Loss: 0.2669\n",
      "Val RMSE: 141322.4771, Val MAE: 80234.2158, Val MSE: 19972042526.0409, Val R2: -0.0147\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2395, Val Loss: 0.2543\n",
      "Val RMSE: 136189.4257, Val MAE: 77158.7540, Val MSE: 18547559663.9514, Val R2: 0.0577\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2333, Val Loss: 0.2527\n",
      "Val RMSE: 135280.7422, Val MAE: 76649.0025, Val MSE: 18300879208.6110, Val R2: 0.0702\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2328, Val Loss: 0.2606\n",
      "Val RMSE: 135550.4779, Val MAE: 80298.4187, Val MSE: 18373932069.6799, Val R2: 0.0665\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2329, Val Loss: 0.2515\n",
      "Val RMSE: 135215.4552, Val MAE: 77520.3759, Val MSE: 18283219318.9582, Val R2: 0.0711\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2285, Val Loss: 0.2542\n",
      "Val RMSE: 136179.1657, Val MAE: 76552.5010, Val MSE: 18544765170.5871, Val R2: 0.0578\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2286, Val Loss: 0.2603\n",
      "Val RMSE: 133993.4536, Val MAE: 81906.5734, Val MSE: 17954245603.9837, Val R2: 0.0878\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2307, Val Loss: 0.2519\n",
      "Val RMSE: 134458.8758, Val MAE: 78890.7935, Val MSE: 18079189270.7783, Val R2: 0.0815\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2190, Val Loss: 0.2342\n",
      "Val RMSE: 132534.7642, Val MAE: 72776.1402, Val MSE: 17565463710.3867, Val R2: 0.1076\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2074, Val Loss: 0.2375\n",
      "Val RMSE: 132449.1128, Val MAE: 73457.2216, Val MSE: 17542767488.3807, Val R2: 0.1087\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2020, Val Loss: 0.2196\n",
      "Val RMSE: 124260.1730, Val MAE: 71114.5528, Val MSE: 15440590584.0937, Val R2: 0.2155\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2038, Val Loss: 0.2191\n",
      "Val RMSE: 124553.0920, Val MAE: 67119.0355, Val MSE: 15513472734.1426, Val R2: 0.2118\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1922, Val Loss: 0.2265\n",
      "Val RMSE: 122143.0002, Val MAE: 66863.1588, Val MSE: 14918912496.0540, Val R2: 0.2420\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1889, Val Loss: 0.2278\n",
      "Val RMSE: 121876.4223, Val MAE: 67763.2482, Val MSE: 14853862310.1653, Val R2: 0.2453\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1806, Val Loss: 0.1915\n",
      "Val RMSE: 107121.4172, Val MAE: 65216.3039, Val MSE: 11474998028.2097, Val R2: 0.4170\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1939\n",
      "Val RMSE: 108322.8195, Val MAE: 63381.3693, Val MSE: 11733833223.9647, Val R2: 0.4038\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1689, Val Loss: 0.1756\n",
      "Val RMSE: 102363.5965, Val MAE: 59664.6097, Val MSE: 10478305883.1832, Val R2: 0.4676\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1612, Val Loss: 0.1757\n",
      "Val RMSE: 102670.6492, Val MAE: 61188.0908, Val MSE: 10541262213.2548, Val R2: 0.4644\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1561, Val Loss: 0.1755\n",
      "Val RMSE: 102670.9632, Val MAE: 59492.9060, Val MSE: 10541326681.3338, Val R2: 0.4644\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1516, Val Loss: 0.1607\n",
      "Val RMSE: 98315.7425, Val MAE: 56838.2274, Val MSE: 9665985220.4887, Val R2: 0.5089\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1571\n",
      "Val RMSE: 97021.2692, Val MAE: 56082.1959, Val MSE: 9413126672.1669, Val R2: 0.5218\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1467, Val Loss: 0.1615\n",
      "Val RMSE: 99520.7402, Val MAE: 55841.8823, Val MSE: 9904377722.9001, Val R2: 0.4968\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1409, Val Loss: 0.1533\n",
      "Val RMSE: 97149.5296, Val MAE: 53215.7410, Val MSE: 9438031099.8668, Val R2: 0.5205\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1349, Val Loss: 0.1533\n",
      "Val RMSE: 97545.5072, Val MAE: 52660.4621, Val MSE: 9515125984.1594, Val R2: 0.5166\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1293, Val Loss: 0.1636\n",
      "Val RMSE: 100767.6427, Val MAE: 56585.8226, Val MSE: 10154117821.4747, Val R2: 0.4841\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1236, Val Loss: 0.1477\n",
      "Val RMSE: 94242.5649, Val MAE: 51340.9393, Val MSE: 8881661030.4527, Val R2: 0.5488\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1191, Val Loss: 0.1343\n",
      "Val RMSE: 89811.1809, Val MAE: 49975.3880, Val MSE: 8066048211.8861, Val R2: 0.5902\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1159, Val Loss: 0.1415\n",
      "Val RMSE: 93476.1606, Val MAE: 50068.8763, Val MSE: 8737792603.7982, Val R2: 0.5561\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1432\n",
      "Val RMSE: 93667.8509, Val MAE: 49752.4395, Val MSE: 8773666295.3487, Val R2: 0.5542\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1049, Val Loss: 0.1398\n",
      "Val RMSE: 92616.2779, Val MAE: 49689.9579, Val MSE: 8577774931.4288, Val R2: 0.5642\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1316\n",
      "Val RMSE: 89793.9155, Val MAE: 48401.3125, Val MSE: 8062947263.8580, Val R2: 0.5904\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1342\n",
      "Val RMSE: 90180.3872, Val MAE: 47506.5256, Val MSE: 8132502226.8099, Val R2: 0.5868\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0962, Val Loss: 0.1324\n",
      "Val RMSE: 89870.5605, Val MAE: 49632.2765, Val MSE: 8076717638.7967, Val R2: 0.5897\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0914, Val Loss: 0.1240\n",
      "Val RMSE: 86024.2423, Val MAE: 46445.7362, Val MSE: 7400170269.3103, Val R2: 0.6240\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0904, Val Loss: 0.1400\n",
      "Val RMSE: 92994.7956, Val MAE: 49273.0585, Val MSE: 8648032017.4459, Val R2: 0.5606\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0875, Val Loss: 0.1384\n",
      "Val RMSE: 91934.7994, Val MAE: 49307.6230, Val MSE: 8452007344.3081, Val R2: 0.5706\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1515\n",
      "Val RMSE: 97339.5985, Val MAE: 53339.0916, Val MSE: 9474997439.6597, Val R2: 0.5186\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0846, Val Loss: 0.1408\n",
      "Val RMSE: 92015.4473, Val MAE: 50859.4873, Val MSE: 8466842544.5489, Val R2: 0.5698\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0802, Val Loss: 0.1483\n",
      "Val RMSE: 93154.1505, Val MAE: 51307.1173, Val MSE: 8677695762.6840, Val R2: 0.5591\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1486\n",
      "Val RMSE: 93270.0275, Val MAE: 53511.0670, Val MSE: 8699298023.2089, Val R2: 0.5580\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1458\n",
      "Val RMSE: 88266.8847, Val MAE: 52127.4327, Val MSE: 7791042932.7450, Val R2: 0.6042\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0760, Val Loss: 0.1277\n",
      "Val RMSE: 83227.5332, Val MAE: 46430.1742, Val MSE: 6926822280.4858, Val R2: 0.6481\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1216\n",
      "Val RMSE: 78712.6206, Val MAE: 45054.8936, Val MSE: 6195676634.3801, Val R2: 0.6852\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1412\n",
      "Val RMSE: 83417.4088, Val MAE: 50348.4358, Val MSE: 6958464090.4056, Val R2: 0.6465\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1343\n",
      "Val RMSE: 84477.0759, Val MAE: 47757.4386, Val MSE: 7136376352.9553, Val R2: 0.6374\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0690, Val Loss: 0.1359\n",
      "Val RMSE: 82606.2816, Val MAE: 50005.1872, Val MSE: 6823797756.9269, Val R2: 0.6533\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1196\n",
      "Val RMSE: 76953.4694, Val MAE: 44285.6329, Val MSE: 5921836454.7544, Val R2: 0.6991\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1275\n",
      "Val RMSE: 80949.7862, Val MAE: 45723.3469, Val MSE: 6552867888.2072, Val R2: 0.6671\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1275\n",
      "Val RMSE: 80416.3736, Val MAE: 45411.2148, Val MSE: 6466793135.4607, Val R2: 0.6714\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1265\n",
      "Val RMSE: 80762.7257, Val MAE: 45248.1365, Val MSE: 6522617870.4361, Val R2: 0.6686\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1394\n",
      "Val RMSE: 84139.7874, Val MAE: 51152.3033, Val MSE: 7079503824.8036, Val R2: 0.6403\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1223\n",
      "Val RMSE: 78066.6431, Val MAE: 44414.7084, Val MSE: 6094400765.4022, Val R2: 0.6904\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1483\n",
      "Val RMSE: 86640.1038, Val MAE: 52875.5973, Val MSE: 7506507592.2674, Val R2: 0.6186\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1378\n",
      "Val RMSE: 81380.9297, Val MAE: 52268.4449, Val MSE: 6622855723.7672, Val R2: 0.6635\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1334\n",
      "Val RMSE: 78710.1974, Val MAE: 49878.6170, Val MSE: 6195295172.4279, Val R2: 0.6852\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1253\n",
      "Val RMSE: 78769.6110, Val MAE: 47654.3949, Val MSE: 6204651613.6839, Val R2: 0.6848\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1439\n",
      "Val RMSE: 86059.1685, Val MAE: 51697.6214, Val MSE: 7406180486.7092, Val R2: 0.6237\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1282\n",
      "Val RMSE: 79214.8592, Val MAE: 46772.4313, Val MSE: 6274993923.0442, Val R2: 0.6812\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1246\n",
      "Val RMSE: 79105.1148, Val MAE: 46468.1729, Val MSE: 6257619182.7683, Val R2: 0.6821\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1321\n",
      "Val RMSE: 82966.5045, Val MAE: 47623.0079, Val MSE: 6883440876.5594, Val R2: 0.6503\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1312\n",
      "Val RMSE: 80357.1726, Val MAE: 48554.7201, Val MSE: 6457275180.4608, Val R2: 0.6719\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1228\n",
      "Val RMSE: 77476.4611, Val MAE: 46224.3140, Val MSE: 6002602028.0894, Val R2: 0.6950\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1287\n",
      "Val RMSE: 79792.4054, Val MAE: 46459.9001, Val MSE: 6366827954.0678, Val R2: 0.6765\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1297\n",
      "Val RMSE: 79239.8704, Val MAE: 46230.1200, Val MSE: 6278957065.6315, Val R2: 0.6810\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1351\n",
      "Val RMSE: 80122.9617, Val MAE: 50054.6729, Val MSE: 6419688987.1157, Val R2: 0.6738\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1388\n",
      "Val RMSE: 84714.3603, Val MAE: 50762.6753, Val MSE: 7176522839.3758, Val R2: 0.6354\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1210\n",
      "Val RMSE: 76656.1536, Val MAE: 45460.7818, Val MSE: 5876165889.6623, Val R2: 0.7015\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1216\n",
      "Val RMSE: 78173.5667, Val MAE: 45249.1089, Val MSE: 6111106538.0849, Val R2: 0.6895\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1278\n",
      "Val RMSE: 79266.5425, Val MAE: 46675.1672, Val MSE: 6283184762.3834, Val R2: 0.6808\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1205\n",
      "Val RMSE: 77964.4686, Val MAE: 46145.5286, Val MSE: 6078458357.8982, Val R2: 0.6912\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1378\n",
      "Val RMSE: 81518.2373, Val MAE: 51563.2804, Val MSE: 6645223015.4139, Val R2: 0.6624\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1236\n",
      "Val RMSE: 80454.9814, Val MAE: 45706.7477, Val MSE: 6473004025.6023, Val R2: 0.6711\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1248\n",
      "Val RMSE: 78698.5330, Val MAE: 44607.1678, Val MSE: 6193459101.7754, Val R2: 0.6853\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1234\n",
      "Val RMSE: 78163.6115, Val MAE: 46569.1592, Val MSE: 6109550156.9304, Val R2: 0.6896\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1187\n",
      "Val RMSE: 75489.9713, Val MAE: 45698.1937, Val MSE: 5698735765.8148, Val R2: 0.7105\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.1162\n",
      "Val RMSE: 77350.8366, Val MAE: 43082.7732, Val MSE: 5983151915.3060, Val R2: 0.6960\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1253\n",
      "Val RMSE: 79149.6153, Val MAE: 46057.8048, Val MSE: 6264661599.5709, Val R2: 0.6817\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.1178\n",
      "Val RMSE: 76687.4377, Val MAE: 44943.2113, Val MSE: 5880963101.7432, Val R2: 0.7012\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.1152\n",
      "Val RMSE: 76961.5026, Val MAE: 43068.8044, Val MSE: 5923072889.2848, Val R2: 0.6991\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.1112\n",
      "Val RMSE: 72405.4134, Val MAE: 43112.5503, Val MSE: 5242543894.7618, Val R2: 0.7336\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0414, Val Loss: 0.1132\n",
      "Val RMSE: 74320.6796, Val MAE: 42797.8064, Val MSE: 5523563411.4338, Val R2: 0.7194\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.1195\n",
      "Val RMSE: 78356.6338, Val MAE: 43889.1428, Val MSE: 6139762055.8492, Val R2: 0.6881\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0409, Val Loss: 0.1183\n",
      "Val RMSE: 78568.5596, Val MAE: 44540.0224, Val MSE: 6173018559.9019, Val R2: 0.6864\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0405, Val Loss: 0.1200\n",
      "Val RMSE: 78791.9912, Val MAE: 44475.7360, Val MSE: 6208177873.3086, Val R2: 0.6846\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 85863.1782, Test MAE: 50467.3060, Test MSE: 7372485370.7539, Test R2: 0.5274\n",
      "Inference Time: 2.7878394493689905e-05 seconds per sample\n",
      "\n",
      "Iteration 10 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3290, Val Loss: 0.2850\n",
      "Val RMSE: 143661.7996, Val MAE: 82152.0446, Val MSE: 20638712654.4360, Val R2: -0.0486\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2737, Val Loss: 0.2751\n",
      "Val RMSE: 140928.7120, Val MAE: 84766.9930, Val MSE: 19860901859.3705, Val R2: -0.0091\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2683, Val Loss: 0.2767\n",
      "Val RMSE: 142063.4960, Val MAE: 82629.5477, Val MSE: 20182036894.1071, Val R2: -0.0254\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2638, Val Loss: 0.2797\n",
      "Val RMSE: 143450.4773, Val MAE: 81241.0252, Val MSE: 20578039425.9141, Val R2: -0.0455\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2630, Val Loss: 0.2738\n",
      "Val RMSE: 141720.2774, Val MAE: 82897.7944, Val MSE: 20084637019.5434, Val R2: -0.0204\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2594, Val Loss: 0.2724\n",
      "Val RMSE: 140757.6392, Val MAE: 84366.3121, Val MSE: 19812713004.7903, Val R2: -0.0066\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2583, Val Loss: 0.2697\n",
      "Val RMSE: 141360.9789, Val MAE: 81850.5816, Val MSE: 19982926357.8089, Val R2: -0.0153\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2809\n",
      "Val RMSE: 143263.0285, Val MAE: 80977.5850, Val MSE: 20524295323.5968, Val R2: -0.0428\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2725\n",
      "Val RMSE: 141126.9289, Val MAE: 81710.0790, Val MSE: 19916810067.2817, Val R2: -0.0119\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2673\n",
      "Val RMSE: 140906.7917, Val MAE: 81070.7342, Val MSE: 19854723957.6955, Val R2: -0.0087\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2664\n",
      "Val RMSE: 141339.0231, Val MAE: 79324.1722, Val MSE: 19976719462.1983, Val R2: -0.0149\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2518, Val Loss: 0.2670\n",
      "Val RMSE: 140107.4786, Val MAE: 82533.2088, Val MSE: 19630105554.1593, Val R2: 0.0027\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2588\n",
      "Val RMSE: 138002.7101, Val MAE: 78105.6538, Val MSE: 19044747985.0122, Val R2: 0.0324\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2472\n",
      "Val RMSE: 135563.1657, Val MAE: 73464.1402, Val MSE: 18377371882.0756, Val R2: 0.0663\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2308, Val Loss: 0.2326\n",
      "Val RMSE: 129369.6473, Val MAE: 77706.6757, Val MSE: 16736505629.8416, Val R2: 0.1497\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2241, Val Loss: 0.2308\n",
      "Val RMSE: 133035.0886, Val MAE: 71999.0043, Val MSE: 17698334795.8999, Val R2: 0.1008\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2219, Val Loss: 0.2701\n",
      "Val RMSE: 138470.4888, Val MAE: 75103.8061, Val MSE: 19174076281.2463, Val R2: 0.0258\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2259, Val Loss: 0.2432\n",
      "Val RMSE: 132719.6640, Val MAE: 74150.5038, Val MSE: 17614509213.2465, Val R2: 0.1051\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2364\n",
      "Val RMSE: 133888.5376, Val MAE: 72472.6161, Val MSE: 17926140496.6178, Val R2: 0.0892\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2118, Val Loss: 0.2372\n",
      "Val RMSE: 133562.8815, Val MAE: 75457.7576, Val MSE: 17839043307.2092, Val R2: 0.0937\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2368\n",
      "Val RMSE: 133783.0695, Val MAE: 72847.3146, Val MSE: 17897909685.8644, Val R2: 0.0907\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2114, Val Loss: 0.2563\n",
      "Val RMSE: 141729.5422, Val MAE: 76347.1659, Val MSE: 20087263144.5523, Val R2: -0.0206\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2110, Val Loss: 0.2382\n",
      "Val RMSE: 129948.3909, Val MAE: 77715.5149, Val MSE: 16886584289.6356, Val R2: 0.1421\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2139, Val Loss: 0.2338\n",
      "Val RMSE: 129063.8252, Val MAE: 76723.4117, Val MSE: 16657470978.9445, Val R2: 0.1537\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2337\n",
      "Val RMSE: 131673.9377, Val MAE: 73244.0256, Val MSE: 17338025860.1668, Val R2: 0.1191\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2296\n",
      "Val RMSE: 129652.0397, Val MAE: 72886.5988, Val MSE: 16809651401.2199, Val R2: 0.1460\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2040, Val Loss: 0.2240\n",
      "Val RMSE: 128585.2647, Val MAE: 71322.5936, Val MSE: 16534170304.8907, Val R2: 0.1600\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1977, Val Loss: 0.2165\n",
      "Val RMSE: 122296.2433, Val MAE: 70278.6013, Val MSE: 14956371123.5442, Val R2: 0.2401\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1908, Val Loss: 0.2031\n",
      "Val RMSE: 114058.4392, Val MAE: 69184.9158, Val MSE: 13009327553.0932, Val R2: 0.3390\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1852, Val Loss: 0.2079\n",
      "Val RMSE: 118541.0508, Val MAE: 69029.1199, Val MSE: 14051980726.4404, Val R2: 0.2861\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1840, Val Loss: 0.2047\n",
      "Val RMSE: 116114.6925, Val MAE: 69229.8563, Val MSE: 13482621810.9253, Val R2: 0.3150\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1787, Val Loss: 0.1919\n",
      "Val RMSE: 107988.4959, Val MAE: 64782.0911, Val MSE: 11661515240.6900, Val R2: 0.4075\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1777, Val Loss: 0.1841\n",
      "Val RMSE: 103961.4485, Val MAE: 63188.5040, Val MSE: 10807982779.4287, Val R2: 0.4509\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1692, Val Loss: 0.2002\n",
      "Val RMSE: 113121.7542, Val MAE: 65099.9718, Val MSE: 12796531278.5553, Val R2: 0.3499\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1791, Val Loss: 0.2040\n",
      "Val RMSE: 112838.3231, Val MAE: 64982.8526, Val MSE: 12732487155.9651, Val R2: 0.3531\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1718, Val Loss: 0.1948\n",
      "Val RMSE: 108436.7567, Val MAE: 62801.4108, Val MSE: 11758530198.3629, Val R2: 0.4026\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1656, Val Loss: 0.1856\n",
      "Val RMSE: 105700.1775, Val MAE: 63043.2249, Val MSE: 11172527534.0076, Val R2: 0.4324\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1615, Val Loss: 0.1743\n",
      "Val RMSE: 101608.7180, Val MAE: 59361.2504, Val MSE: 10324331576.5613, Val R2: 0.4755\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1569, Val Loss: 0.1603\n",
      "Val RMSE: 97636.2973, Val MAE: 55227.3819, Val MSE: 9532846543.7131, Val R2: 0.5157\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1481, Val Loss: 0.1623\n",
      "Val RMSE: 97182.6141, Val MAE: 57444.2223, Val MSE: 9444460486.8975, Val R2: 0.5202\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1434, Val Loss: 0.1533\n",
      "Val RMSE: 96568.7276, Val MAE: 53792.1502, Val MSE: 9325519145.5959, Val R2: 0.5262\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1401, Val Loss: 0.1720\n",
      "Val RMSE: 101233.3444, Val MAE: 58812.0342, Val MSE: 10248190011.8366, Val R2: 0.4793\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1377, Val Loss: 0.1554\n",
      "Val RMSE: 95501.0196, Val MAE: 56938.2065, Val MSE: 9120444753.8737, Val R2: 0.5366\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1390, Val Loss: 0.1602\n",
      "Val RMSE: 97952.4355, Val MAE: 56180.5779, Val MSE: 9594679620.9188, Val R2: 0.5125\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1312, Val Loss: 0.1450\n",
      "Val RMSE: 94323.3378, Val MAE: 53026.2552, Val MSE: 8896892055.6609, Val R2: 0.5480\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1267, Val Loss: 0.1431\n",
      "Val RMSE: 94649.8939, Val MAE: 52949.8989, Val MSE: 8958602419.5986, Val R2: 0.5448\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1227, Val Loss: 0.1428\n",
      "Val RMSE: 93280.8140, Val MAE: 51805.2557, Val MSE: 8701310262.8227, Val R2: 0.5579\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1372\n",
      "Val RMSE: 92169.4094, Val MAE: 52725.5170, Val MSE: 8495200021.0642, Val R2: 0.5684\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1168, Val Loss: 0.1325\n",
      "Val RMSE: 90405.5112, Val MAE: 50727.8002, Val MSE: 8173156447.5408, Val R2: 0.5848\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1166, Val Loss: 0.1318\n",
      "Val RMSE: 91218.7492, Val MAE: 48730.2856, Val MSE: 8320860197.9765, Val R2: 0.5772\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1117, Val Loss: 0.1241\n",
      "Val RMSE: 88243.9595, Val MAE: 48297.8279, Val MSE: 7786996380.1473, Val R2: 0.6044\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1107, Val Loss: 0.1257\n",
      "Val RMSE: 89069.7457, Val MAE: 46273.7116, Val MSE: 7933419598.8812, Val R2: 0.5969\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1088, Val Loss: 0.1322\n",
      "Val RMSE: 91658.0753, Val MAE: 48697.9918, Val MSE: 8401202759.8741, Val R2: 0.5732\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1398\n",
      "Val RMSE: 91357.9393, Val MAE: 50173.1174, Val MSE: 8346273074.9643, Val R2: 0.5760\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1081, Val Loss: 0.1272\n",
      "Val RMSE: 89608.6478, Val MAE: 48013.5126, Val MSE: 8029709765.0737, Val R2: 0.5920\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1011, Val Loss: 0.1358\n",
      "Val RMSE: 91984.6994, Val MAE: 50199.8314, Val MSE: 8461184921.5422, Val R2: 0.5701\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1308\n",
      "Val RMSE: 90681.1830, Val MAE: 47952.6029, Val MSE: 8223076953.8081, Val R2: 0.5822\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1209\n",
      "Val RMSE: 87384.6426, Val MAE: 47881.6857, Val MSE: 7636075755.2627, Val R2: 0.6120\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0951, Val Loss: 0.1277\n",
      "Val RMSE: 88253.3948, Val MAE: 48219.7592, Val MSE: 7788661691.4647, Val R2: 0.6043\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1327\n",
      "Val RMSE: 91150.2855, Val MAE: 48495.0523, Val MSE: 8308374555.5806, Val R2: 0.5779\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1297\n",
      "Val RMSE: 89600.7983, Val MAE: 48005.6684, Val MSE: 8028303054.8779, Val R2: 0.5921\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1233\n",
      "Val RMSE: 88097.1053, Val MAE: 47198.8807, Val MSE: 7761099961.1624, Val R2: 0.6057\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0882, Val Loss: 0.1317\n",
      "Val RMSE: 90517.7938, Val MAE: 48194.6795, Val MSE: 8193470989.9626, Val R2: 0.5837\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1285\n",
      "Val RMSE: 89238.7372, Val MAE: 48828.5551, Val MSE: 7963552215.1804, Val R2: 0.5954\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0847, Val Loss: 0.1275\n",
      "Val RMSE: 89503.4772, Val MAE: 47991.0989, Val MSE: 8010872432.3974, Val R2: 0.5930\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0833, Val Loss: 0.1215\n",
      "Val RMSE: 86483.5144, Val MAE: 46424.6176, Val MSE: 7479398256.7957, Val R2: 0.6200\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1189\n",
      "Val RMSE: 85878.7516, Val MAE: 45504.9416, Val MSE: 7375159975.9251, Val R2: 0.6253\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1196\n",
      "Val RMSE: 86779.3370, Val MAE: 44002.2723, Val MSE: 7530653332.5618, Val R2: 0.6174\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0807, Val Loss: 0.1219\n",
      "Val RMSE: 85392.1323, Val MAE: 44411.0384, Val MSE: 7291816256.9236, Val R2: 0.6295\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1119\n",
      "Val RMSE: 82593.3243, Val MAE: 42780.5550, Val MSE: 6821657222.9528, Val R2: 0.6534\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1104\n",
      "Val RMSE: 81136.6337, Val MAE: 42792.3965, Val MSE: 6583153333.0731, Val R2: 0.6655\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1151\n",
      "Val RMSE: 84381.3628, Val MAE: 42896.4645, Val MSE: 7120214384.3643, Val R2: 0.6382\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1198\n",
      "Val RMSE: 85488.8584, Val MAE: 44217.3171, Val MSE: 7308344914.5025, Val R2: 0.6287\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1128\n",
      "Val RMSE: 83203.9258, Val MAE: 42127.7041, Val MSE: 6922893268.6067, Val R2: 0.6483\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1153\n",
      "Val RMSE: 82159.7814, Val MAE: 45149.8966, Val MSE: 6750229682.4043, Val R2: 0.6570\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1098\n",
      "Val RMSE: 80471.7779, Val MAE: 42223.4244, Val MSE: 6475707032.1659, Val R2: 0.6710\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1116\n",
      "Val RMSE: 80196.0826, Val MAE: 43764.6461, Val MSE: 6431411669.5310, Val R2: 0.6732\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0691, Val Loss: 0.1101\n",
      "Val RMSE: 81382.5451, Val MAE: 41310.0463, Val MSE: 6623118645.6710, Val R2: 0.6635\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0686, Val Loss: 0.1121\n",
      "Val RMSE: 78088.3491, Val MAE: 42836.9054, Val MSE: 6097790269.4400, Val R2: 0.6902\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0670, Val Loss: 0.1062\n",
      "Val RMSE: 77258.7571, Val MAE: 40756.1457, Val MSE: 5968915548.1739, Val R2: 0.6967\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1073\n",
      "Val RMSE: 77346.9229, Val MAE: 42048.8266, Val MSE: 5982546476.8839, Val R2: 0.6960\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1067\n",
      "Val RMSE: 77275.3725, Val MAE: 42538.0718, Val MSE: 5971483195.5805, Val R2: 0.6966\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1070\n",
      "Val RMSE: 75512.3305, Val MAE: 41912.3860, Val MSE: 5702112062.7292, Val R2: 0.7103\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1144\n",
      "Val RMSE: 77239.6778, Val MAE: 44491.7693, Val MSE: 5965967820.4674, Val R2: 0.6969\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1070\n",
      "Val RMSE: 75574.3439, Val MAE: 44081.7729, Val MSE: 5711481460.5187, Val R2: 0.7098\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1049\n",
      "Val RMSE: 75990.8188, Val MAE: 41610.9258, Val MSE: 5774604538.5308, Val R2: 0.7066\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1063\n",
      "Val RMSE: 77954.2738, Val MAE: 40744.0394, Val MSE: 6076868797.7676, Val R2: 0.6913\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1143\n",
      "Val RMSE: 80966.3118, Val MAE: 44692.6659, Val MSE: 6555543647.0799, Val R2: 0.6669\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0611, Val Loss: 0.1053\n",
      "Val RMSE: 75482.8987, Val MAE: 41135.9525, Val MSE: 5697667988.9327, Val R2: 0.7105\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.0984\n",
      "Val RMSE: 74184.8966, Val MAE: 39529.9157, Val MSE: 5503398890.5058, Val R2: 0.7204\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1010\n",
      "Val RMSE: 72968.0457, Val MAE: 42057.3852, Val MSE: 5324335697.9405, Val R2: 0.7295\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.0909\n",
      "Val RMSE: 71219.1300, Val MAE: 37437.2489, Val MSE: 5072164480.7888, Val R2: 0.7423\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1008\n",
      "Val RMSE: 74599.8764, Val MAE: 40557.8851, Val MSE: 5565141557.5241, Val R2: 0.7173\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1036\n",
      "Val RMSE: 76688.5228, Val MAE: 40264.6049, Val MSE: 5881129529.3722, Val R2: 0.7012\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1095\n",
      "Val RMSE: 76285.5293, Val MAE: 44938.9066, Val MSE: 5819481981.7407, Val R2: 0.7043\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1011\n",
      "Val RMSE: 74038.7003, Val MAE: 41554.9050, Val MSE: 5481729144.0119, Val R2: 0.7215\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1060\n",
      "Val RMSE: 76337.9542, Val MAE: 42695.5948, Val MSE: 5827483253.1257, Val R2: 0.7039\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.0958\n",
      "Val RMSE: 74402.2556, Val MAE: 38729.9213, Val MSE: 5535695631.0779, Val R2: 0.7188\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1022\n",
      "Val RMSE: 76623.7971, Val MAE: 39083.2764, Val MSE: 5871206286.9460, Val R2: 0.7017\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1038\n",
      "Val RMSE: 76113.5608, Val MAE: 40999.9479, Val MSE: 5793274144.7480, Val R2: 0.7057\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76604.7248, Test MAE: 40192.6806, Test MSE: 5868283869.0436, Test R2: 0.6238\n",
      "Inference Time: 3.490580045259916e-05 seconds per sample\n",
      "\n",
      "Iteration 11 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4002, Val Loss: 0.2785\n",
      "Val RMSE: 139692.2831, Val MAE: 89722.1803, Val MSE: 19513933952.1694, Val R2: 0.0086\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2777, Val Loss: 0.2759\n",
      "Val RMSE: 141698.2630, Val MAE: 83293.4075, Val MSE: 20078397724.2441, Val R2: -0.0201\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2705, Val Loss: 0.2756\n",
      "Val RMSE: 141451.2538, Val MAE: 83608.3906, Val MSE: 20008457199.9600, Val R2: -0.0166\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2672, Val Loss: 0.2752\n",
      "Val RMSE: 141249.6976, Val MAE: 84052.7801, Val MSE: 19951477084.1104, Val R2: -0.0137\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2654, Val Loss: 0.2760\n",
      "Val RMSE: 141696.2583, Val MAE: 83323.9452, Val MSE: 20077829615.0753, Val R2: -0.0201\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2634, Val Loss: 0.2769\n",
      "Val RMSE: 140609.9141, Val MAE: 86079.6218, Val MSE: 19771147937.4389, Val R2: -0.0045\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2912\n",
      "Val RMSE: 141658.8250, Val MAE: 91602.2285, Val MSE: 20067222706.3931, Val R2: -0.0195\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2722\n",
      "Val RMSE: 139954.7882, Val MAE: 85738.7829, Val MSE: 19587342737.8269, Val R2: 0.0048\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2853\n",
      "Val RMSE: 142311.8705, Val MAE: 88158.3949, Val MSE: 20252668474.0395, Val R2: -0.0290\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2723\n",
      "Val RMSE: 140895.0466, Val MAE: 83699.8075, Val MSE: 19851414167.6769, Val R2: -0.0086\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2555, Val Loss: 0.2777\n",
      "Val RMSE: 143255.1943, Val MAE: 79790.8645, Val MSE: 20522050693.5162, Val R2: -0.0426\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2743\n",
      "Val RMSE: 140957.4207, Val MAE: 84623.2601, Val MSE: 19868994458.8181, Val R2: -0.0095\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2518, Val Loss: 0.2650\n",
      "Val RMSE: 140954.8594, Val MAE: 79759.0111, Val MSE: 19868272376.5630, Val R2: -0.0094\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2951\n",
      "Val RMSE: 146790.6232, Val MAE: 79784.4899, Val MSE: 21547487047.3939, Val R2: -0.0947\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2479, Val Loss: 0.2656\n",
      "Val RMSE: 140559.9519, Val MAE: 80232.7095, Val MSE: 19757100079.5920, Val R2: -0.0038\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2695\n",
      "Val RMSE: 140731.4573, Val MAE: 81206.9485, Val MSE: 19805343078.1552, Val R2: -0.0062\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2662\n",
      "Val RMSE: 140381.5170, Val MAE: 79708.6488, Val MSE: 19706970320.7317, Val R2: -0.0012\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2441, Val Loss: 0.2657\n",
      "Val RMSE: 139542.5105, Val MAE: 81720.0160, Val MSE: 19472112223.4055, Val R2: 0.0107\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2423, Val Loss: 0.2584\n",
      "Val RMSE: 136172.1663, Val MAE: 79819.4722, Val MSE: 18542858877.2405, Val R2: 0.0579\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2277, Val Loss: 0.2345\n",
      "Val RMSE: 129892.7789, Val MAE: 76238.9422, Val MSE: 16872133999.8640, Val R2: 0.1428\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2245, Val Loss: 0.2318\n",
      "Val RMSE: 130695.4884, Val MAE: 72882.2630, Val MSE: 17081310698.8390, Val R2: 0.1322\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2359\n",
      "Val RMSE: 130678.3116, Val MAE: 72936.2150, Val MSE: 17076821120.4025, Val R2: 0.1324\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2090, Val Loss: 0.2271\n",
      "Val RMSE: 127696.7999, Val MAE: 74451.7741, Val MSE: 16306472710.8201, Val R2: 0.1715\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2024, Val Loss: 0.2381\n",
      "Val RMSE: 130300.2625, Val MAE: 71320.7482, Val MSE: 16978158400.0362, Val R2: 0.1374\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1965, Val Loss: 0.2267\n",
      "Val RMSE: 127671.0456, Val MAE: 70371.1444, Val MSE: 16299895872.6593, Val R2: 0.1719\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2178\n",
      "Val RMSE: 125029.6913, Val MAE: 69225.3203, Val MSE: 15632423695.0542, Val R2: 0.2058\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1848, Val Loss: 0.2084\n",
      "Val RMSE: 115916.2969, Val MAE: 66949.5813, Val MSE: 13436587896.5902, Val R2: 0.3173\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.1862\n",
      "Val RMSE: 106037.8996, Val MAE: 63180.5157, Val MSE: 11244036144.9619, Val R2: 0.4287\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1693, Val Loss: 0.1807\n",
      "Val RMSE: 105987.2698, Val MAE: 62603.9541, Val MSE: 11233301358.6864, Val R2: 0.4293\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1618, Val Loss: 0.1635\n",
      "Val RMSE: 98950.4612, Val MAE: 58412.6502, Val MSE: 9791193775.9070, Val R2: 0.5025\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1591, Val Loss: 0.1589\n",
      "Val RMSE: 96257.7307, Val MAE: 57250.1099, Val MSE: 9265550716.0301, Val R2: 0.5293\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1552, Val Loss: 0.1555\n",
      "Val RMSE: 98078.8558, Val MAE: 56191.6298, Val MSE: 9619461956.8140, Val R2: 0.5113\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1543, Val Loss: 0.1618\n",
      "Val RMSE: 97348.8171, Val MAE: 56035.9915, Val MSE: 9476792191.0073, Val R2: 0.5185\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1472, Val Loss: 0.1548\n",
      "Val RMSE: 98276.4422, Val MAE: 53260.2597, Val MSE: 9658259093.4247, Val R2: 0.5093\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1596, Val Loss: 0.1560\n",
      "Val RMSE: 97086.4398, Val MAE: 55849.5804, Val MSE: 9425776786.8370, Val R2: 0.5211\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1555\n",
      "Val RMSE: 96747.7452, Val MAE: 54778.9508, Val MSE: 9360126191.8018, Val R2: 0.5244\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1491, Val Loss: 0.1474\n",
      "Val RMSE: 94725.0203, Val MAE: 53001.9800, Val MSE: 8972829478.7622, Val R2: 0.5441\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1457, Val Loss: 0.1500\n",
      "Val RMSE: 94725.4476, Val MAE: 52378.2644, Val MSE: 8972910430.3740, Val R2: 0.5441\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1429, Val Loss: 0.1521\n",
      "Val RMSE: 96625.9471, Val MAE: 51989.7962, Val MSE: 9336573660.1252, Val R2: 0.5256\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1389, Val Loss: 0.1582\n",
      "Val RMSE: 96151.0033, Val MAE: 55001.8203, Val MSE: 9245015441.6617, Val R2: 0.5303\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1324, Val Loss: 0.1348\n",
      "Val RMSE: 91899.2677, Val MAE: 50207.5915, Val MSE: 8445475397.0392, Val R2: 0.5709\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1303, Val Loss: 0.1463\n",
      "Val RMSE: 95457.9724, Val MAE: 51967.2004, Val MSE: 9112224489.6212, Val R2: 0.5370\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1362\n",
      "Val RMSE: 89149.5540, Val MAE: 51609.5722, Val MSE: 7947642984.8330, Val R2: 0.5962\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1268\n",
      "Val RMSE: 87821.8385, Val MAE: 49082.1296, Val MSE: 7712675320.6694, Val R2: 0.6081\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1214\n",
      "Val RMSE: 86420.7322, Val MAE: 47088.9210, Val MSE: 7468542956.0606, Val R2: 0.6206\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1029, Val Loss: 0.1243\n",
      "Val RMSE: 85183.8867, Val MAE: 46502.7125, Val MSE: 7256294547.6095, Val R2: 0.6313\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0986, Val Loss: 0.1256\n",
      "Val RMSE: 83430.7157, Val MAE: 46354.8690, Val MSE: 6960684317.9039, Val R2: 0.6464\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1216\n",
      "Val RMSE: 84374.3877, Val MAE: 45100.4038, Val MSE: 7119037307.9399, Val R2: 0.6383\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1177\n",
      "Val RMSE: 79032.4961, Val MAE: 44509.8579, Val MSE: 6246135434.4837, Val R2: 0.6827\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0874, Val Loss: 0.1264\n",
      "Val RMSE: 83731.6603, Val MAE: 47147.4461, Val MSE: 7010990934.6732, Val R2: 0.6438\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1221\n",
      "Val RMSE: 81537.7077, Val MAE: 45271.2909, Val MSE: 6648397784.2386, Val R2: 0.6622\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1206\n",
      "Val RMSE: 81814.1650, Val MAE: 44474.3709, Val MSE: 6693557590.8847, Val R2: 0.6599\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0796, Val Loss: 0.1225\n",
      "Val RMSE: 81380.1693, Val MAE: 44896.9377, Val MSE: 6622731949.3464, Val R2: 0.6635\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1265\n",
      "Val RMSE: 84126.7384, Val MAE: 44840.6866, Val MSE: 7077308120.0812, Val R2: 0.6404\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0770, Val Loss: 0.1216\n",
      "Val RMSE: 84830.6323, Val MAE: 45862.2146, Val MSE: 7196236178.6915, Val R2: 0.6344\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1394\n",
      "Val RMSE: 88483.3634, Val MAE: 49315.7197, Val MSE: 7829305590.5565, Val R2: 0.6022\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0749, Val Loss: 0.1268\n",
      "Val RMSE: 85083.8731, Val MAE: 44920.0138, Val MSE: 7239265457.3243, Val R2: 0.6322\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1277\n",
      "Val RMSE: 82586.3442, Val MAE: 46694.5808, Val MSE: 6820504246.2804, Val R2: 0.6535\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1272\n",
      "Val RMSE: 83555.5249, Val MAE: 44600.4926, Val MSE: 6981525733.2936, Val R2: 0.6453\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1288\n",
      "Val RMSE: 84895.3526, Val MAE: 45397.0206, Val MSE: 7207220889.0256, Val R2: 0.6338\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1173\n",
      "Val RMSE: 80428.0694, Val MAE: 42368.4584, Val MSE: 6468674354.9791, Val R2: 0.6714\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1034\n",
      "Val RMSE: 71064.3727, Val MAE: 40157.7486, Val MSE: 5050145065.3255, Val R2: 0.7434\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1184\n",
      "Val RMSE: 79337.6697, Val MAE: 43596.6661, Val MSE: 6294465835.6548, Val R2: 0.6802\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1183\n",
      "Val RMSE: 80809.5570, Val MAE: 42175.6260, Val MSE: 6530184496.2841, Val R2: 0.6682\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1204\n",
      "Val RMSE: 80664.9620, Val MAE: 43697.2546, Val MSE: 6506836096.3233, Val R2: 0.6694\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1103\n",
      "Val RMSE: 76730.4184, Val MAE: 41290.4453, Val MSE: 5887557107.9988, Val R2: 0.7009\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1144\n",
      "Val RMSE: 76573.9722, Val MAE: 43282.8837, Val MSE: 5863573211.8491, Val R2: 0.7021\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1250\n",
      "Val RMSE: 82819.5885, Val MAE: 44279.8254, Val MSE: 6859084233.7069, Val R2: 0.6515\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1134\n",
      "Val RMSE: 76372.4401, Val MAE: 42029.9555, Val MSE: 5832749601.2966, Val R2: 0.7037\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1284\n",
      "Val RMSE: 83324.0848, Val MAE: 46347.4221, Val MSE: 6942903110.7965, Val R2: 0.6473\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1147\n",
      "Val RMSE: 77152.6035, Val MAE: 43334.9385, Val MSE: 5952524222.8489, Val R2: 0.6976\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1302\n",
      "Val RMSE: 82058.8250, Val MAE: 46902.6048, Val MSE: 6733650754.0581, Val R2: 0.6579\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1165\n",
      "Val RMSE: 77449.3219, Val MAE: 44324.0725, Val MSE: 5998397464.3427, Val R2: 0.6952\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1266\n",
      "Val RMSE: 81564.4097, Val MAE: 46059.7429, Val MSE: 6652752927.6974, Val R2: 0.6620\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1281\n",
      "Val RMSE: 82681.2492, Val MAE: 45259.0200, Val MSE: 6836188963.0393, Val R2: 0.6527\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1252\n",
      "Val RMSE: 80328.6246, Val MAE: 45853.7362, Val MSE: 6452687936.9348, Val R2: 0.6722\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1163\n",
      "Val RMSE: 78098.2779, Val MAE: 42247.8411, Val MSE: 6099341005.2748, Val R2: 0.6901\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1177\n",
      "Val RMSE: 77346.3590, Val MAE: 44172.5500, Val MSE: 5982459255.9087, Val R2: 0.6961\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1368\n",
      "Val RMSE: 84345.1972, Val MAE: 48721.5553, Val MSE: 7114112283.3422, Val R2: 0.6386\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1116\n",
      "Val RMSE: 76583.5991, Val MAE: 41311.0291, Val MSE: 5865047657.0417, Val R2: 0.7020\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1350\n",
      "Val RMSE: 84002.6223, Val MAE: 47660.8001, Val MSE: 7056440561.6054, Val R2: 0.6415\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1386\n",
      "Val RMSE: 85778.7785, Val MAE: 48378.7890, Val MSE: 7357998846.2256, Val R2: 0.6262\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1344\n",
      "Val RMSE: 85590.4944, Val MAE: 48313.1043, Val MSE: 7325732730.8087, Val R2: 0.6278\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1351\n",
      "Val RMSE: 84975.8037, Val MAE: 48041.5030, Val MSE: 7220887210.5913, Val R2: 0.6331\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1158\n",
      "Val RMSE: 79534.6718, Val MAE: 42150.1523, Val MSE: 6325764021.9799, Val R2: 0.6786\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1192\n",
      "Val RMSE: 80704.0719, Val MAE: 43466.7476, Val MSE: 6513147213.6246, Val R2: 0.6691\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1205\n",
      "Val RMSE: 79596.2926, Val MAE: 43670.1450, Val MSE: 6335569799.6651, Val R2: 0.6781\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1143\n",
      "Val RMSE: 78028.4521, Val MAE: 42803.3674, Val MSE: 6088439329.8646, Val R2: 0.6907\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.1350\n",
      "Val RMSE: 85886.1829, Val MAE: 47536.4178, Val MSE: 7376436411.8327, Val R2: 0.6252\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1144\n",
      "Val RMSE: 78090.6470, Val MAE: 42365.1847, Val MSE: 6098149143.6677, Val R2: 0.6902\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1066\n",
      "Val RMSE: 74816.5523, Val MAE: 40997.4580, Val MSE: 5597516502.2232, Val R2: 0.7156\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1095\n",
      "Val RMSE: 76819.8371, Val MAE: 40304.4101, Val MSE: 5901287366.1177, Val R2: 0.7002\n",
      "Early stopping triggered after epoch 92\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74871.6326, Test MAE: 43435.1778, Test MSE: 5605761365.3200, Test R2: 0.6407\n",
      "Inference Time: 2.0484594198373646e-05 seconds per sample\n",
      "\n",
      "Iteration 12 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3104, Val Loss: 0.3019\n",
      "Val RMSE: 146890.3693, Val MAE: 82770.1660, Val MSE: 21576780606.5225, Val R2: -0.0962\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2771, Val Loss: 0.2842\n",
      "Val RMSE: 142056.3124, Val MAE: 85698.2268, Val MSE: 20179995897.7943, Val R2: -0.0253\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2706, Val Loss: 0.2763\n",
      "Val RMSE: 142822.5457, Val MAE: 81953.0739, Val MSE: 20398279566.4780, Val R2: -0.0364\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2637, Val Loss: 0.2860\n",
      "Val RMSE: 142187.3326, Val MAE: 88839.9988, Val MSE: 20217237550.5924, Val R2: -0.0272\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2804\n",
      "Val RMSE: 142161.5559, Val MAE: 85287.6326, Val MSE: 20209907961.7575, Val R2: -0.0268\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2758\n",
      "Val RMSE: 142219.5246, Val MAE: 81648.3677, Val MSE: 20226393181.9335, Val R2: -0.0276\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2679\n",
      "Val RMSE: 142125.2781, Val MAE: 80287.7864, Val MSE: 20199594689.1538, Val R2: -0.0263\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2656\n",
      "Val RMSE: 141883.2598, Val MAE: 78988.6056, Val MSE: 20130859424.6739, Val R2: -0.0228\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2695\n",
      "Val RMSE: 140862.0454, Val MAE: 82909.5264, Val MSE: 19842115828.9082, Val R2: -0.0081\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2501, Val Loss: 0.2647\n",
      "Val RMSE: 141765.3007, Val MAE: 78715.6471, Val MSE: 20097400480.4140, Val R2: -0.0211\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2555\n",
      "Val RMSE: 137177.3736, Val MAE: 78856.3891, Val MSE: 18817631838.2128, Val R2: 0.0439\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2376, Val Loss: 0.2530\n",
      "Val RMSE: 137086.1497, Val MAE: 74155.0424, Val MSE: 18792612432.0177, Val R2: 0.0452\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2265, Val Loss: 0.2694\n",
      "Val RMSE: 143135.1346, Val MAE: 82302.7574, Val MSE: 20487666758.9089, Val R2: -0.0409\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2199, Val Loss: 0.2366\n",
      "Val RMSE: 131182.6751, Val MAE: 74542.6901, Val MSE: 17208894253.7713, Val R2: 0.1257\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2150, Val Loss: 0.2265\n",
      "Val RMSE: 129086.9989, Val MAE: 73666.4218, Val MSE: 16663453274.0674, Val R2: 0.1534\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2125, Val Loss: 0.2318\n",
      "Val RMSE: 132310.7790, Val MAE: 70596.2452, Val MSE: 17506142230.4241, Val R2: 0.1106\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2341\n",
      "Val RMSE: 130323.9678, Val MAE: 71889.7344, Val MSE: 16984336588.4383, Val R2: 0.1371\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2136, Val Loss: 0.2305\n",
      "Val RMSE: 128765.2235, Val MAE: 73561.8831, Val MSE: 16580482782.4523, Val R2: 0.1576\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2088, Val Loss: 0.2354\n",
      "Val RMSE: 128437.5782, Val MAE: 76748.0129, Val MSE: 16496211491.7190, Val R2: 0.1619\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2059, Val Loss: 0.2474\n",
      "Val RMSE: 136734.3167, Val MAE: 75868.8113, Val MSE: 18696273366.3864, Val R2: 0.0501\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2291\n",
      "Val RMSE: 129329.3987, Val MAE: 71772.8420, Val MSE: 16726093365.7050, Val R2: 0.1502\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1930, Val Loss: 0.2330\n",
      "Val RMSE: 130397.0327, Val MAE: 71415.2360, Val MSE: 17003386127.1081, Val R2: 0.1361\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1902, Val Loss: 0.2069\n",
      "Val RMSE: 115992.4565, Val MAE: 68557.7773, Val MSE: 13454249958.8044, Val R2: 0.3164\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1812, Val Loss: 0.2134\n",
      "Val RMSE: 117801.9764, Val MAE: 71188.9350, Val MSE: 13877305649.3433, Val R2: 0.2949\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1776, Val Loss: 0.2016\n",
      "Val RMSE: 111985.8254, Val MAE: 67560.5227, Val MSE: 12540825097.4409, Val R2: 0.3628\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1700, Val Loss: 0.1953\n",
      "Val RMSE: 113333.6379, Val MAE: 66129.5098, Val MSE: 12844513485.0078, Val R2: 0.3474\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1698, Val Loss: 0.1722\n",
      "Val RMSE: 104030.3361, Val MAE: 62987.0477, Val MSE: 10822310838.6278, Val R2: 0.4502\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1637, Val Loss: 0.2058\n",
      "Val RMSE: 112786.2188, Val MAE: 64894.5104, Val MSE: 12720731140.0370, Val R2: 0.3537\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1596, Val Loss: 0.1726\n",
      "Val RMSE: 104378.8151, Val MAE: 60834.8147, Val MSE: 10894937033.5126, Val R2: 0.4465\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1558, Val Loss: 0.1682\n",
      "Val RMSE: 102048.2372, Val MAE: 58416.0707, Val MSE: 10413842706.5988, Val R2: 0.4709\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1557, Val Loss: 0.1724\n",
      "Val RMSE: 103658.7193, Val MAE: 59628.0679, Val MSE: 10745130091.3513, Val R2: 0.4541\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1523, Val Loss: 0.1595\n",
      "Val RMSE: 97468.6013, Val MAE: 59483.1019, Val MSE: 9500128235.0997, Val R2: 0.5173\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1596\n",
      "Val RMSE: 97994.3469, Val MAE: 58115.0140, Val MSE: 9602892020.0306, Val R2: 0.5121\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1457, Val Loss: 0.1435\n",
      "Val RMSE: 93242.7888, Val MAE: 56401.8313, Val MSE: 8694217670.5427, Val R2: 0.5583\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1412, Val Loss: 0.1499\n",
      "Val RMSE: 95606.9648, Val MAE: 54966.4625, Val MSE: 9140691726.3764, Val R2: 0.5356\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1367, Val Loss: 0.1696\n",
      "Val RMSE: 99881.7891, Val MAE: 55973.5342, Val MSE: 9976371788.6833, Val R2: 0.4931\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1392, Val Loss: 0.1307\n",
      "Val RMSE: 91119.6758, Val MAE: 50349.8895, Val MSE: 8302795319.6272, Val R2: 0.5782\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1327, Val Loss: 0.1368\n",
      "Val RMSE: 91213.5820, Val MAE: 51984.6918, Val MSE: 8319917539.8732, Val R2: 0.5773\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1278, Val Loss: 0.1274\n",
      "Val RMSE: 88781.9296, Val MAE: 49267.4142, Val MSE: 7882231028.6265, Val R2: 0.5995\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1235, Val Loss: 0.1261\n",
      "Val RMSE: 89496.3645, Val MAE: 48150.4593, Val MSE: 8009599257.1080, Val R2: 0.5931\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1208, Val Loss: 0.1407\n",
      "Val RMSE: 93804.1116, Val MAE: 49163.3332, Val MSE: 8799211352.3651, Val R2: 0.5529\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1164, Val Loss: 0.1200\n",
      "Val RMSE: 87929.9959, Val MAE: 47017.7689, Val MSE: 7731684173.7285, Val R2: 0.6072\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1111, Val Loss: 0.1261\n",
      "Val RMSE: 88638.7119, Val MAE: 49166.9050, Val MSE: 7856821247.2697, Val R2: 0.6008\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1102, Val Loss: 0.1209\n",
      "Val RMSE: 86741.5395, Val MAE: 49135.2232, Val MSE: 7524094679.2655, Val R2: 0.6177\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1081, Val Loss: 0.1265\n",
      "Val RMSE: 88642.3738, Val MAE: 49389.1683, Val MSE: 7857470438.0977, Val R2: 0.6008\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1272\n",
      "Val RMSE: 89213.2981, Val MAE: 49564.0391, Val MSE: 7959012556.1784, Val R2: 0.5956\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1025, Val Loss: 0.1248\n",
      "Val RMSE: 87857.6826, Val MAE: 49110.5660, Val MSE: 7718972396.5449, Val R2: 0.6078\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1235\n",
      "Val RMSE: 88585.9388, Val MAE: 49422.9274, Val MSE: 7847468557.2676, Val R2: 0.6013\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1288\n",
      "Val RMSE: 89713.1277, Val MAE: 51605.6132, Val MSE: 8048445279.8041, Val R2: 0.5911\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0969, Val Loss: 0.1325\n",
      "Val RMSE: 90527.8135, Val MAE: 51090.5598, Val MSE: 8195285016.3670, Val R2: 0.5836\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1008, Val Loss: 0.1423\n",
      "Val RMSE: 92727.4603, Val MAE: 52388.3787, Val MSE: 8598381891.8879, Val R2: 0.5631\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1281\n",
      "Val RMSE: 89785.0317, Val MAE: 49235.2586, Val MSE: 8061351922.3139, Val R2: 0.5904\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1228\n",
      "Val RMSE: 88635.3921, Val MAE: 48061.0490, Val MSE: 7856232724.7644, Val R2: 0.6009\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1325\n",
      "Val RMSE: 91457.3748, Val MAE: 49228.0418, Val MSE: 8364451405.0330, Val R2: 0.5750\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1238\n",
      "Val RMSE: 87629.3654, Val MAE: 49305.0356, Val MSE: 7678905685.5426, Val R2: 0.6099\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0881, Val Loss: 0.1412\n",
      "Val RMSE: 92218.4907, Val MAE: 52926.1107, Val MSE: 8504250020.8793, Val R2: 0.5679\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1381\n",
      "Val RMSE: 93348.7255, Val MAE: 51538.0138, Val MSE: 8713984561.4706, Val R2: 0.5573\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1302\n",
      "Val RMSE: 89503.8588, Val MAE: 48402.3206, Val MSE: 8010940735.1888, Val R2: 0.5930\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1362\n",
      "Val RMSE: 89758.1739, Val MAE: 51425.2233, Val MSE: 8056529783.2977, Val R2: 0.5907\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1197\n",
      "Val RMSE: 82967.2511, Val MAE: 46176.0634, Val MSE: 6883564752.0052, Val R2: 0.6503\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1222\n",
      "Val RMSE: 82744.2795, Val MAE: 47445.0689, Val MSE: 6846615790.0171, Val R2: 0.6521\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1148\n",
      "Val RMSE: 78006.4185, Val MAE: 46771.6599, Val MSE: 6085001329.5593, Val R2: 0.6908\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1268\n",
      "Val RMSE: 84736.0499, Val MAE: 47153.0356, Val MSE: 7180198158.9314, Val R2: 0.6352\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1223\n",
      "Val RMSE: 82559.9033, Val MAE: 48059.1373, Val MSE: 6816137631.3188, Val R2: 0.6537\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1246\n",
      "Val RMSE: 82461.2197, Val MAE: 47673.9703, Val MSE: 6799852760.0674, Val R2: 0.6545\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1160\n",
      "Val RMSE: 77379.2363, Val MAE: 46002.4976, Val MSE: 5987546217.0854, Val R2: 0.6958\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0691, Val Loss: 0.1340\n",
      "Val RMSE: 82728.5555, Val MAE: 55280.4308, Val MSE: 6844013891.7116, Val R2: 0.6523\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1080\n",
      "Val RMSE: 72061.1072, Val MAE: 44887.2638, Val MSE: 5192803169.9568, Val R2: 0.7362\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1186\n",
      "Val RMSE: 78062.0915, Val MAE: 46678.8936, Val MSE: 6093690127.6887, Val R2: 0.6904\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1168\n",
      "Val RMSE: 76920.8407, Val MAE: 47110.7218, Val MSE: 5916815736.4019, Val R2: 0.6994\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1149\n",
      "Val RMSE: 76206.2512, Val MAE: 45499.8178, Val MSE: 5807392726.8910, Val R2: 0.7049\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1187\n",
      "Val RMSE: 79688.8418, Val MAE: 45218.8629, Val MSE: 6350311509.5922, Val R2: 0.6774\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1225\n",
      "Val RMSE: 78818.2224, Val MAE: 47805.7019, Val MSE: 6212312181.6978, Val R2: 0.6844\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1231\n",
      "Val RMSE: 81674.9823, Val MAE: 45109.1618, Val MSE: 6670802726.7921, Val R2: 0.6611\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1134\n",
      "Val RMSE: 77299.3412, Val MAE: 44343.9476, Val MSE: 5975188149.5452, Val R2: 0.6964\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1219\n",
      "Val RMSE: 76842.9728, Val MAE: 45733.7497, Val MSE: 5904842468.6933, Val R2: 0.7000\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1325\n",
      "Val RMSE: 82565.3952, Val MAE: 49127.3639, Val MSE: 6817044492.3675, Val R2: 0.6537\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1157\n",
      "Val RMSE: 80377.2405, Val MAE: 44100.4295, Val MSE: 6460500783.9349, Val R2: 0.6718\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1230\n",
      "Val RMSE: 82068.7499, Val MAE: 45610.7477, Val MSE: 6735279703.4498, Val R2: 0.6578\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1274\n",
      "Val RMSE: 84613.9591, Val MAE: 45499.0341, Val MSE: 7159522068.2449, Val R2: 0.6363\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1272\n",
      "Val RMSE: 84243.3551, Val MAE: 46689.6702, Val MSE: 7096942875.0326, Val R2: 0.6394\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1244\n",
      "Val RMSE: 84909.4034, Val MAE: 44667.8026, Val MSE: 7209606785.8726, Val R2: 0.6337\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1221\n",
      "Val RMSE: 82716.6500, Val MAE: 44904.1483, Val MSE: 6842044184.1207, Val R2: 0.6524\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.1212\n",
      "Val RMSE: 83144.9136, Val MAE: 45392.6370, Val MSE: 6913076650.1209, Val R2: 0.6488\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1141\n",
      "Val RMSE: 80547.0781, Val MAE: 43251.1055, Val MSE: 6487831793.7980, Val R2: 0.6704\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1154\n",
      "Val RMSE: 79702.6085, Val MAE: 43920.8609, Val MSE: 6352505804.8250, Val R2: 0.6773\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1381\n",
      "Val RMSE: 89406.9210, Val MAE: 47734.0923, Val MSE: 7993597529.0151, Val R2: 0.5939\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1291\n",
      "Val RMSE: 85492.2094, Val MAE: 46905.5368, Val MSE: 7308917875.1076, Val R2: 0.6287\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1207\n",
      "Val RMSE: 80568.0398, Val MAE: 45589.9680, Val MSE: 6491209032.8016, Val R2: 0.6702\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1074\n",
      "Val RMSE: 75250.5373, Val MAE: 42660.9841, Val MSE: 5662643371.2504, Val R2: 0.7123\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.1142\n",
      "Val RMSE: 77632.5395, Val MAE: 43698.3161, Val MSE: 6026811195.5575, Val R2: 0.6938\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1174\n",
      "Val RMSE: 79534.2090, Val MAE: 44992.1458, Val MSE: 6325690404.0415, Val R2: 0.6786\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1171\n",
      "Val RMSE: 79346.5729, Val MAE: 42921.3131, Val MSE: 6295878632.6264, Val R2: 0.6801\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1233\n",
      "Val RMSE: 83731.6779, Val MAE: 44602.1144, Val MSE: 7010993887.0857, Val R2: 0.6438\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1232\n",
      "Val RMSE: 80828.7455, Val MAE: 46405.1734, Val MSE: 6533286105.9992, Val R2: 0.6681\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1048\n",
      "Val RMSE: 74901.8499, Val MAE: 41747.4477, Val MSE: 5610287124.6175, Val R2: 0.7150\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1202\n",
      "Val RMSE: 81991.8840, Val MAE: 44109.0922, Val MSE: 6722669049.5821, Val R2: 0.6584\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0427, Val Loss: 0.1174\n",
      "Val RMSE: 80248.9090, Val MAE: 44274.6692, Val MSE: 6439887402.7868, Val R2: 0.6728\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0427, Val Loss: 0.1176\n",
      "Val RMSE: 80055.5247, Val MAE: 45127.5407, Val MSE: 6408887032.7845, Val R2: 0.6744\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.1227\n",
      "Val RMSE: 82910.8007, Val MAE: 45234.4091, Val MSE: 6874200869.9273, Val R2: 0.6507\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 68455.5697, Test MAE: 42192.0967, Test MSE: 4686165028.0921, Test R2: 0.6996\n",
      "Inference Time: 2.4517499483548678e-05 seconds per sample\n",
      "\n",
      "Iteration 13 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3457, Val Loss: 0.2955\n",
      "Val RMSE: 146244.5294, Val MAE: 81385.1113, Val MSE: 21387462374.8142, Val R2: -0.0866\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2749, Val Loss: 0.2747\n",
      "Val RMSE: 140743.1497, Val MAE: 85350.4923, Val MSE: 19808634174.6597, Val R2: -0.0064\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2699, Val Loss: 0.2747\n",
      "Val RMSE: 140342.0470, Val MAE: 86327.3292, Val MSE: 19695890145.8006, Val R2: -0.0007\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2686, Val Loss: 0.2768\n",
      "Val RMSE: 142677.0483, Val MAE: 81946.3438, Val MSE: 20356740115.7205, Val R2: -0.0343\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2654, Val Loss: 0.2731\n",
      "Val RMSE: 140921.9462, Val MAE: 84164.1978, Val MSE: 19858994910.7811, Val R2: -0.0090\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2585, Val Loss: 0.2723\n",
      "Val RMSE: 140728.7052, Val MAE: 84684.3756, Val MSE: 19804568474.7344, Val R2: -0.0062\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2562, Val Loss: 0.2760\n",
      "Val RMSE: 142395.8247, Val MAE: 81232.4630, Val MSE: 20276570892.0338, Val R2: -0.0302\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2705\n",
      "Val RMSE: 141560.2521, Val MAE: 81157.7752, Val MSE: 20039304976.9760, Val R2: -0.0181\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2691\n",
      "Val RMSE: 140687.1391, Val MAE: 81919.4602, Val MSE: 19792871096.2562, Val R2: -0.0056\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2548, Val Loss: 0.2663\n",
      "Val RMSE: 141102.8441, Val MAE: 80144.1149, Val MSE: 19910012604.2679, Val R2: -0.0116\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2520, Val Loss: 0.2639\n",
      "Val RMSE: 140932.9165, Val MAE: 79255.9333, Val MSE: 19862086943.2069, Val R2: -0.0091\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2508, Val Loss: 0.2654\n",
      "Val RMSE: 140224.1435, Val MAE: 80998.3291, Val MSE: 19662810421.9109, Val R2: 0.0010\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2483, Val Loss: 0.2685\n",
      "Val RMSE: 139604.8090, Val MAE: 83731.4210, Val MSE: 19489502706.7843, Val R2: 0.0098\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2689\n",
      "Val RMSE: 142420.7411, Val MAE: 78524.5815, Val MSE: 20283667485.4875, Val R2: -0.0305\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2458, Val Loss: 0.2742\n",
      "Val RMSE: 142406.3896, Val MAE: 81482.8578, Val MSE: 20279579789.9758, Val R2: -0.0303\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2437, Val Loss: 0.2571\n",
      "Val RMSE: 137874.4856, Val MAE: 78869.2259, Val MSE: 19009373771.8366, Val R2: 0.0342\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2278, Val Loss: 0.2439\n",
      "Val RMSE: 131446.0719, Val MAE: 78023.0220, Val MSE: 17278069812.2966, Val R2: 0.1222\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2236, Val Loss: 0.2380\n",
      "Val RMSE: 131399.5805, Val MAE: 79316.4126, Val MSE: 17265849746.4686, Val R2: 0.1228\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2155, Val Loss: 0.2198\n",
      "Val RMSE: 128238.5313, Val MAE: 71189.0669, Val MSE: 16445120899.3348, Val R2: 0.1645\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2195, Val Loss: 0.2254\n",
      "Val RMSE: 129453.8067, Val MAE: 72369.5707, Val MSE: 16758288080.5393, Val R2: 0.1486\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2078, Val Loss: 0.2416\n",
      "Val RMSE: 132364.5358, Val MAE: 75807.2514, Val MSE: 17520370346.9867, Val R2: 0.1099\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2347\n",
      "Val RMSE: 130177.0848, Val MAE: 74332.3376, Val MSE: 16946073410.0271, Val R2: 0.1390\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2344\n",
      "Val RMSE: 130024.0771, Val MAE: 74119.2963, Val MSE: 16906260630.3693, Val R2: 0.1411\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2271\n",
      "Val RMSE: 131363.4192, Val MAE: 70045.8252, Val MSE: 17256347912.2068, Val R2: 0.1233\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2044, Val Loss: 0.2303\n",
      "Val RMSE: 128612.5449, Val MAE: 74268.2468, Val MSE: 16541186693.1363, Val R2: 0.1596\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2014, Val Loss: 0.2348\n",
      "Val RMSE: 129183.9089, Val MAE: 75134.7733, Val MSE: 16688482314.5002, Val R2: 0.1521\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1972, Val Loss: 0.2228\n",
      "Val RMSE: 126664.7428, Val MAE: 71315.7573, Val MSE: 16043957066.3025, Val R2: 0.1849\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1907, Val Loss: 0.2205\n",
      "Val RMSE: 123202.3409, Val MAE: 70613.9659, Val MSE: 15178816805.1693, Val R2: 0.2288\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1891, Val Loss: 0.1997\n",
      "Val RMSE: 113110.4733, Val MAE: 66998.8748, Val MSE: 12793979176.3248, Val R2: 0.3500\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1800, Val Loss: 0.2013\n",
      "Val RMSE: 113582.1081, Val MAE: 64307.9124, Val MSE: 12900895272.5409, Val R2: 0.3446\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1744, Val Loss: 0.1755\n",
      "Val RMSE: 100325.8070, Val MAE: 63325.9450, Val MSE: 10065267545.0848, Val R2: 0.4886\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1698, Val Loss: 0.1749\n",
      "Val RMSE: 101686.8954, Val MAE: 60645.4233, Val MSE: 10340224698.9913, Val R2: 0.4747\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1619, Val Loss: 0.1699\n",
      "Val RMSE: 99304.3229, Val MAE: 60379.4939, Val MSE: 9861348551.7845, Val R2: 0.4990\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1556, Val Loss: 0.1552\n",
      "Val RMSE: 95016.6937, Val MAE: 59064.3069, Val MSE: 9028172084.1784, Val R2: 0.5413\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1522, Val Loss: 0.1455\n",
      "Val RMSE: 92104.9409, Val MAE: 56849.7499, Val MSE: 8483320146.3105, Val R2: 0.5690\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1464, Val Loss: 0.1616\n",
      "Val RMSE: 96988.7635, Val MAE: 59504.1535, Val MSE: 9406820242.2659, Val R2: 0.5221\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1507\n",
      "Val RMSE: 94962.1520, Val MAE: 53708.9378, Val MSE: 9017810312.4280, Val R2: 0.5418\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1473\n",
      "Val RMSE: 94614.9454, Val MAE: 52813.0544, Val MSE: 8951987899.5267, Val R2: 0.5452\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1301, Val Loss: 0.1432\n",
      "Val RMSE: 93720.9304, Val MAE: 51086.3917, Val MSE: 8783612800.4819, Val R2: 0.5537\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1235, Val Loss: 0.1358\n",
      "Val RMSE: 91193.2582, Val MAE: 51815.2599, Val MSE: 8316210341.5507, Val R2: 0.5775\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1184, Val Loss: 0.1310\n",
      "Val RMSE: 89735.0814, Val MAE: 49879.9158, Val MSE: 8052384825.8134, Val R2: 0.5909\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1140, Val Loss: 0.1252\n",
      "Val RMSE: 87999.7910, Val MAE: 48701.9017, Val MSE: 7743963211.8814, Val R2: 0.6066\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1075, Val Loss: 0.1332\n",
      "Val RMSE: 90150.9544, Val MAE: 46997.5701, Val MSE: 8127194577.2738, Val R2: 0.5871\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1274\n",
      "Val RMSE: 89761.5141, Val MAE: 46103.0930, Val MSE: 8057129413.7721, Val R2: 0.5906\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1164\n",
      "Val RMSE: 85570.1350, Val MAE: 44960.0249, Val MSE: 7322248011.4827, Val R2: 0.6280\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0993, Val Loss: 0.1209\n",
      "Val RMSE: 86929.3153, Val MAE: 45756.7593, Val MSE: 7556705852.9305, Val R2: 0.6161\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1300\n",
      "Val RMSE: 87678.6543, Val MAE: 48853.9557, Val MSE: 7687546423.9934, Val R2: 0.6094\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0942, Val Loss: 0.1350\n",
      "Val RMSE: 95111.2257, Val MAE: 47448.3712, Val MSE: 9046145248.2624, Val R2: 0.5404\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0939, Val Loss: 0.1091\n",
      "Val RMSE: 84302.8708, Val MAE: 42622.3383, Val MSE: 7106974017.7447, Val R2: 0.6389\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1353\n",
      "Val RMSE: 89819.4648, Val MAE: 46485.9592, Val MSE: 8067536248.6400, Val R2: 0.5901\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1379\n",
      "Val RMSE: 90071.5927, Val MAE: 47138.7106, Val MSE: 8112891805.5527, Val R2: 0.5878\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1297\n",
      "Val RMSE: 87260.2831, Val MAE: 47059.3095, Val MSE: 7614357001.4270, Val R2: 0.6131\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1226\n",
      "Val RMSE: 85283.5202, Val MAE: 48079.8318, Val MSE: 7273278813.5904, Val R2: 0.6305\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1253\n",
      "Val RMSE: 87371.4907, Val MAE: 45137.7793, Val MSE: 7633777382.7528, Val R2: 0.6122\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1268\n",
      "Val RMSE: 85885.5711, Val MAE: 47379.5615, Val MSE: 7376331330.5571, Val R2: 0.6252\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1231\n",
      "Val RMSE: 82682.4790, Val MAE: 45977.9985, Val MSE: 6836392338.4080, Val R2: 0.6527\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1217\n",
      "Val RMSE: 82208.7066, Val MAE: 45180.8738, Val MSE: 6758271434.6736, Val R2: 0.6566\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1294\n",
      "Val RMSE: 83661.2987, Val MAE: 46667.0380, Val MSE: 6999212905.6361, Val R2: 0.6444\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1278\n",
      "Val RMSE: 84198.9869, Val MAE: 45625.9995, Val MSE: 7089469388.1666, Val R2: 0.6398\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1313\n",
      "Val RMSE: 86518.1225, Val MAE: 47272.3811, Val MSE: 7485385528.6139, Val R2: 0.6197\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1243\n",
      "Val RMSE: 79150.6565, Val MAE: 44672.5616, Val MSE: 6264826426.9749, Val R2: 0.6817\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1183\n",
      "Val RMSE: 78349.1404, Val MAE: 43591.3800, Val MSE: 6138587804.7771, Val R2: 0.6881\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0707, Val Loss: 0.1208\n",
      "Val RMSE: 80948.8363, Val MAE: 44101.1671, Val MSE: 6552714106.1800, Val R2: 0.6671\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0702, Val Loss: 0.1251\n",
      "Val RMSE: 81876.3984, Val MAE: 46841.2167, Val MSE: 6703744611.9542, Val R2: 0.6594\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0686, Val Loss: 0.1247\n",
      "Val RMSE: 80394.4357, Val MAE: 45416.8113, Val MSE: 6463265297.0663, Val R2: 0.6716\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1199\n",
      "Val RMSE: 77970.9384, Val MAE: 44724.1830, Val MSE: 6079467234.2335, Val R2: 0.6911\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1149\n",
      "Val RMSE: 76147.2588, Val MAE: 42160.2233, Val MSE: 5798405018.7770, Val R2: 0.7054\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1203\n",
      "Val RMSE: 77168.2921, Val MAE: 43510.9414, Val MSE: 5954945309.8805, Val R2: 0.6975\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1322\n",
      "Val RMSE: 81441.7630, Val MAE: 46341.0440, Val MSE: 6632760768.3712, Val R2: 0.6630\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1096\n",
      "Val RMSE: 73703.4021, Val MAE: 41777.7993, Val MSE: 5432191477.7846, Val R2: 0.7240\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1265\n",
      "Val RMSE: 79367.6014, Val MAE: 46117.7959, Val MSE: 6299216153.1890, Val R2: 0.6800\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1093\n",
      "Val RMSE: 74265.3714, Val MAE: 40697.5395, Val MSE: 5515345381.8897, Val R2: 0.7198\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1547\n",
      "Val RMSE: 92229.1180, Val MAE: 51493.0702, Val MSE: 8506210207.7676, Val R2: 0.5678\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1305\n",
      "Val RMSE: 82385.8392, Val MAE: 46134.9672, Val MSE: 6787426499.2762, Val R2: 0.6552\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0589, Val Loss: 0.1228\n",
      "Val RMSE: 76720.7457, Val MAE: 44074.5391, Val MSE: 5886072818.0414, Val R2: 0.7010\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1206\n",
      "Val RMSE: 78140.8959, Val MAE: 43289.3781, Val MSE: 6105999608.6921, Val R2: 0.6898\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1140\n",
      "Val RMSE: 74675.8609, Val MAE: 42600.7267, Val MSE: 5576484199.9083, Val R2: 0.7167\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1374\n",
      "Val RMSE: 85757.9067, Val MAE: 46768.3587, Val MSE: 7354418555.4175, Val R2: 0.6263\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1169\n",
      "Val RMSE: 76093.7379, Val MAE: 42761.1579, Val MSE: 5790256945.1599, Val R2: 0.7058\n",
      "Early stopping triggered after epoch 79\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 82867.9194, Test MAE: 43495.9151, Test MSE: 6867092070.9037, Test R2: 0.5598\n",
      "Inference Time: 2.0850585057185246e-05 seconds per sample\n",
      "\n",
      "Iteration 14 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3659, Val Loss: 0.2812\n",
      "Val RMSE: 140782.6001, Val MAE: 87798.8507, Val MSE: 19819740490.1349, Val R2: -0.0070\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2826, Val Loss: 0.2811\n",
      "Val RMSE: 142546.1296, Val MAE: 83160.2976, Val MSE: 20319399067.9230, Val R2: -0.0324\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2773\n",
      "Val RMSE: 142477.4545, Val MAE: 82604.1158, Val MSE: 20299825048.9986, Val R2: -0.0314\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2684, Val Loss: 0.2774\n",
      "Val RMSE: 142804.7874, Val MAE: 81607.6062, Val MSE: 20393207310.6704, Val R2: -0.0361\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2646, Val Loss: 0.2749\n",
      "Val RMSE: 141403.9940, Val MAE: 84389.0210, Val MSE: 19995089521.8296, Val R2: -0.0159\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2786\n",
      "Val RMSE: 141093.5428, Val MAE: 86368.0311, Val MSE: 19907387830.7190, Val R2: -0.0114\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2595, Val Loss: 0.2735\n",
      "Val RMSE: 142128.9768, Val MAE: 82526.2715, Val MSE: 20200646035.4567, Val R2: -0.0263\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2742\n",
      "Val RMSE: 142609.7920, Val MAE: 79950.8954, Val MSE: 20337552766.2538, Val R2: -0.0333\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2588, Val Loss: 0.2748\n",
      "Val RMSE: 140467.4177, Val MAE: 85824.5370, Val MSE: 19731095424.0891, Val R2: -0.0025\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2668\n",
      "Val RMSE: 140331.6123, Val MAE: 81521.0761, Val MSE: 19692961400.3248, Val R2: -0.0005\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2620\n",
      "Val RMSE: 138438.6150, Val MAE: 80700.6016, Val MSE: 19165250117.6450, Val R2: 0.0263\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2483, Val Loss: 0.2567\n",
      "Val RMSE: 134496.9860, Val MAE: 79172.3599, Val MSE: 18089439253.1149, Val R2: 0.0809\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2410, Val Loss: 0.2494\n",
      "Val RMSE: 134482.8939, Val MAE: 75853.3450, Val MSE: 18085648754.2909, Val R2: 0.0811\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2452, Val Loss: 0.2520\n",
      "Val RMSE: 134453.8477, Val MAE: 78819.1322, Val MSE: 18077837164.3995, Val R2: 0.0815\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2392, Val Loss: 0.2547\n",
      "Val RMSE: 135534.4747, Val MAE: 78242.2509, Val MSE: 18369593819.1874, Val R2: 0.0667\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2396, Val Loss: 0.2499\n",
      "Val RMSE: 135255.3251, Val MAE: 76893.1624, Val MSE: 18294002980.4500, Val R2: 0.0705\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2362, Val Loss: 0.2752\n",
      "Val RMSE: 137709.8116, Val MAE: 77301.4359, Val MSE: 18963992211.1489, Val R2: 0.0365\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2283, Val Loss: 0.2496\n",
      "Val RMSE: 135739.2148, Val MAE: 78977.5478, Val MSE: 18425134440.3827, Val R2: 0.0639\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2184, Val Loss: 0.2599\n",
      "Val RMSE: 142766.2417, Val MAE: 78438.7752, Val MSE: 20382199783.1032, Val R2: -0.0355\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2165, Val Loss: 0.2416\n",
      "Val RMSE: 134077.3566, Val MAE: 73466.0653, Val MSE: 17976737553.7236, Val R2: 0.0867\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2401\n",
      "Val RMSE: 135502.8687, Val MAE: 74045.7896, Val MSE: 18361027418.7494, Val R2: 0.0671\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2074, Val Loss: 0.2483\n",
      "Val RMSE: 139884.0263, Val MAE: 74866.3231, Val MSE: 19567540817.5839, Val R2: 0.0058\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2060, Val Loss: 0.2416\n",
      "Val RMSE: 136205.9870, Val MAE: 75229.3649, Val MSE: 18552070902.8052, Val R2: 0.0574\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2077, Val Loss: 0.2359\n",
      "Val RMSE: 130167.0189, Val MAE: 77031.2551, Val MSE: 16943452798.3946, Val R2: 0.1392\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2602\n",
      "Val RMSE: 140903.3314, Val MAE: 80317.6388, Val MSE: 19853748799.7382, Val R2: -0.0087\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2067, Val Loss: 0.2515\n",
      "Val RMSE: 137326.6169, Val MAE: 79283.5880, Val MSE: 18858599699.3550, Val R2: 0.0419\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2503\n",
      "Val RMSE: 137473.9625, Val MAE: 79335.3192, Val MSE: 18899090362.1493, Val R2: 0.0398\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2039, Val Loss: 0.2430\n",
      "Val RMSE: 133097.2707, Val MAE: 77167.7142, Val MSE: 17714883477.5666, Val R2: 0.1000\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2009, Val Loss: 0.2496\n",
      "Val RMSE: 138621.2490, Val MAE: 76478.5334, Val MSE: 19215850687.2540, Val R2: 0.0237\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1986, Val Loss: 0.2410\n",
      "Val RMSE: 135177.3394, Val MAE: 73840.2929, Val MSE: 18272913098.8141, Val R2: 0.0716\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1985, Val Loss: 0.2498\n",
      "Val RMSE: 137766.4057, Val MAE: 76435.2527, Val MSE: 18979582532.3385, Val R2: 0.0357\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1970, Val Loss: 0.2475\n",
      "Val RMSE: 135852.9486, Val MAE: 76329.3420, Val MSE: 18456023654.0265, Val R2: 0.0623\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1953, Val Loss: 0.2363\n",
      "Val RMSE: 130777.3011, Val MAE: 73561.6508, Val MSE: 17102702481.4628, Val R2: 0.1311\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1937, Val Loss: 0.2424\n",
      "Val RMSE: 131444.1172, Val MAE: 74461.0962, Val MSE: 17277555954.9978, Val R2: 0.1222\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1863, Val Loss: 0.2167\n",
      "Val RMSE: 119891.8704, Val MAE: 70924.3603, Val MSE: 14374060578.0691, Val R2: 0.2697\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1837, Val Loss: 0.2131\n",
      "Val RMSE: 115345.7598, Val MAE: 72302.3821, Val MSE: 13304644293.9324, Val R2: 0.3240\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1797, Val Loss: 0.2120\n",
      "Val RMSE: 110958.7327, Val MAE: 72390.1867, Val MSE: 12311840365.7216, Val R2: 0.3745\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1799, Val Loss: 0.1938\n",
      "Val RMSE: 108853.0651, Val MAE: 65297.2266, Val MSE: 11848989778.0220, Val R2: 0.3980\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1699, Val Loss: 0.1855\n",
      "Val RMSE: 105021.1356, Val MAE: 62632.7848, Val MSE: 11029438921.1168, Val R2: 0.4396\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1647, Val Loss: 0.1813\n",
      "Val RMSE: 102915.3820, Val MAE: 63531.2651, Val MSE: 10591575860.7812, Val R2: 0.4619\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1633, Val Loss: 0.1749\n",
      "Val RMSE: 101062.5392, Val MAE: 60922.4714, Val MSE: 10213636834.9652, Val R2: 0.4811\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1562, Val Loss: 0.1717\n",
      "Val RMSE: 100266.8998, Val MAE: 59011.9659, Val MSE: 10053451201.9256, Val R2: 0.4892\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1526, Val Loss: 0.1740\n",
      "Val RMSE: 100459.1575, Val MAE: 59269.6031, Val MSE: 10092042335.4973, Val R2: 0.4873\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1508, Val Loss: 0.1745\n",
      "Val RMSE: 101850.0082, Val MAE: 58597.5970, Val MSE: 10373424173.4730, Val R2: 0.4730\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1494, Val Loss: 0.1650\n",
      "Val RMSE: 97536.4033, Val MAE: 58040.3748, Val MSE: 9513349975.3403, Val R2: 0.5167\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1452, Val Loss: 0.1728\n",
      "Val RMSE: 99034.7499, Val MAE: 60816.0087, Val MSE: 9807881683.3305, Val R2: 0.5017\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1433, Val Loss: 0.1520\n",
      "Val RMSE: 96163.6582, Val MAE: 54398.9367, Val MSE: 9247449159.3015, Val R2: 0.5302\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1442, Val Loss: 0.1682\n",
      "Val RMSE: 100482.5524, Val MAE: 57111.1461, Val MSE: 10096743328.9680, Val R2: 0.4870\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1369, Val Loss: 0.1428\n",
      "Val RMSE: 93377.8083, Val MAE: 51569.1570, Val MSE: 8719415087.9230, Val R2: 0.5570\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1346, Val Loss: 0.1457\n",
      "Val RMSE: 93412.3204, Val MAE: 55454.0482, Val MSE: 8725861602.0232, Val R2: 0.5567\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1320, Val Loss: 0.1501\n",
      "Val RMSE: 96576.2054, Val MAE: 55301.4300, Val MSE: 9326963448.1604, Val R2: 0.5261\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1284, Val Loss: 0.1433\n",
      "Val RMSE: 93382.0597, Val MAE: 55119.6188, Val MSE: 8720209077.1364, Val R2: 0.5570\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1265, Val Loss: 0.1494\n",
      "Val RMSE: 94388.7175, Val MAE: 53588.1854, Val MSE: 8909229991.9848, Val R2: 0.5474\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1235, Val Loss: 0.1384\n",
      "Val RMSE: 94015.5016, Val MAE: 49353.2091, Val MSE: 8838914535.7069, Val R2: 0.5509\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1172, Val Loss: 0.1366\n",
      "Val RMSE: 92662.5888, Val MAE: 49716.3420, Val MSE: 8586355358.0178, Val R2: 0.5638\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1364\n",
      "Val RMSE: 92631.9112, Val MAE: 50015.0431, Val MSE: 8580670976.9546, Val R2: 0.5640\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1105, Val Loss: 0.1335\n",
      "Val RMSE: 91463.4482, Val MAE: 49220.8738, Val MSE: 8365562359.7923, Val R2: 0.5750\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1100, Val Loss: 0.1316\n",
      "Val RMSE: 89423.5596, Val MAE: 50863.3154, Val MSE: 7996573008.8029, Val R2: 0.5937\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1070, Val Loss: 0.1263\n",
      "Val RMSE: 89364.7840, Val MAE: 46647.3113, Val MSE: 7986064625.8248, Val R2: 0.5943\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1028, Val Loss: 0.1202\n",
      "Val RMSE: 87384.5117, Val MAE: 45581.7498, Val MSE: 7636052883.5190, Val R2: 0.6120\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0982, Val Loss: 0.1393\n",
      "Val RMSE: 90886.0779, Val MAE: 51471.7341, Val MSE: 8260279151.6825, Val R2: 0.5803\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1254\n",
      "Val RMSE: 88421.7505, Val MAE: 47001.0407, Val MSE: 7818405956.7144, Val R2: 0.6028\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1284\n",
      "Val RMSE: 88571.5817, Val MAE: 47554.5880, Val MSE: 7844925083.3177, Val R2: 0.6014\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1260\n",
      "Val RMSE: 87791.7177, Val MAE: 47251.6596, Val MSE: 7707385696.2011, Val R2: 0.6084\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0936, Val Loss: 0.1338\n",
      "Val RMSE: 85970.0890, Val MAE: 48976.2107, Val MSE: 7390856197.4268, Val R2: 0.6245\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0921, Val Loss: 0.1219\n",
      "Val RMSE: 83550.5047, Val MAE: 45671.0130, Val MSE: 6980686838.4991, Val R2: 0.6453\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1228\n",
      "Val RMSE: 83536.1427, Val MAE: 46997.9564, Val MSE: 6978287135.4295, Val R2: 0.6455\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0866, Val Loss: 0.1395\n",
      "Val RMSE: 86658.5315, Val MAE: 51682.4103, Val MSE: 7509701078.9169, Val R2: 0.6185\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1242\n",
      "Val RMSE: 85170.7750, Val MAE: 47398.8431, Val MSE: 7254060916.3796, Val R2: 0.6314\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.1342\n",
      "Val RMSE: 87640.9891, Val MAE: 47373.1685, Val MSE: 7680942973.1819, Val R2: 0.6098\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1206\n",
      "Val RMSE: 78057.5872, Val MAE: 47683.4915, Val MSE: 6092986914.9268, Val R2: 0.6904\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1265\n",
      "Val RMSE: 81666.8151, Val MAE: 46345.2685, Val MSE: 6669468681.9359, Val R2: 0.6611\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0770, Val Loss: 0.1480\n",
      "Val RMSE: 86701.3367, Val MAE: 52883.5741, Val MSE: 7517121788.4803, Val R2: 0.6181\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1224\n",
      "Val RMSE: 78197.9721, Val MAE: 46148.4402, Val MSE: 6114922845.9534, Val R2: 0.6893\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1121\n",
      "Val RMSE: 73482.7441, Val MAE: 43642.4496, Val MSE: 5399713675.1613, Val R2: 0.7257\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1410\n",
      "Val RMSE: 84029.1897, Val MAE: 50603.3875, Val MSE: 7060904721.2421, Val R2: 0.6413\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1115\n",
      "Val RMSE: 73601.9563, Val MAE: 42451.4432, Val MSE: 5417247966.5345, Val R2: 0.7248\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1174\n",
      "Val RMSE: 75780.2291, Val MAE: 43822.7629, Val MSE: 5742643124.3452, Val R2: 0.7082\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1241\n",
      "Val RMSE: 80583.7901, Val MAE: 46109.5748, Val MSE: 6493747223.0135, Val R2: 0.6701\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1237\n",
      "Val RMSE: 79232.2975, Val MAE: 45460.1406, Val MSE: 6277756963.9375, Val R2: 0.6811\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0646, Val Loss: 0.1190\n",
      "Val RMSE: 73372.2822, Val MAE: 45473.4905, Val MSE: 5383491793.1449, Val R2: 0.7265\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1198\n",
      "Val RMSE: 77984.1649, Val MAE: 44872.0822, Val MSE: 6081529970.8241, Val R2: 0.6910\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1185\n",
      "Val RMSE: 74114.9770, Val MAE: 44745.0153, Val MSE: 5493029820.3186, Val R2: 0.7209\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1207\n",
      "Val RMSE: 77066.9741, Val MAE: 45104.0955, Val MSE: 5939318490.2813, Val R2: 0.6982\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1151\n",
      "Val RMSE: 73992.6626, Val MAE: 43563.8130, Val MSE: 5474914114.8421, Val R2: 0.7218\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1205\n",
      "Val RMSE: 76623.7573, Val MAE: 44991.0293, Val MSE: 5871200178.0530, Val R2: 0.7017\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1150\n",
      "Val RMSE: 75586.2511, Val MAE: 42684.8407, Val MSE: 5713281355.5570, Val R2: 0.7097\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1140\n",
      "Val RMSE: 76072.8641, Val MAE: 42550.9882, Val MSE: 5787080646.0565, Val R2: 0.7060\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1082\n",
      "Val RMSE: 70544.6215, Val MAE: 41841.1676, Val MSE: 4976543622.4593, Val R2: 0.7472\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1161\n",
      "Val RMSE: 76378.3895, Val MAE: 43391.5229, Val MSE: 5833658385.2756, Val R2: 0.7036\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1187\n",
      "Val RMSE: 74546.8642, Val MAE: 44001.7204, Val MSE: 5557234966.2299, Val R2: 0.7177\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1157\n",
      "Val RMSE: 75282.5699, Val MAE: 42844.4255, Val MSE: 5667465324.3372, Val R2: 0.7121\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1150\n",
      "Val RMSE: 74668.0147, Val MAE: 43352.4177, Val MSE: 5575312417.6910, Val R2: 0.7167\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1192\n",
      "Val RMSE: 74952.0703, Val MAE: 44543.7903, Val MSE: 5617812848.5597, Val R2: 0.7146\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1160\n",
      "Val RMSE: 75607.2833, Val MAE: 43271.5505, Val MSE: 5716461281.8287, Val R2: 0.7096\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1359\n",
      "Val RMSE: 80521.6196, Val MAE: 46298.3462, Val MSE: 6483731229.7195, Val R2: 0.6706\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1128\n",
      "Val RMSE: 73086.7977, Val MAE: 42364.2351, Val MSE: 5341679996.4830, Val R2: 0.7286\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1121\n",
      "Val RMSE: 74082.9376, Val MAE: 41669.3126, Val MSE: 5488281648.1905, Val R2: 0.7212\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1086\n",
      "Val RMSE: 72551.1217, Val MAE: 40871.7188, Val MSE: 5263665267.1153, Val R2: 0.7326\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1206\n",
      "Val RMSE: 75568.0575, Val MAE: 44193.4507, Val MSE: 5710531311.5920, Val R2: 0.7099\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 78346.9665, Test MAE: 43795.7947, Test MSE: 6138247158.4033, Test R2: 0.6065\n",
      "Inference Time: 2.1632634676419773e-05 seconds per sample\n",
      "\n",
      "Iteration 15 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3768, Val Loss: 0.2857\n",
      "Val RMSE: 143135.9408, Val MAE: 83713.5469, Val MSE: 20487897536.8897, Val R2: -0.0409\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2803, Val Loss: 0.2791\n",
      "Val RMSE: 142087.0973, Val MAE: 83692.6620, Val MSE: 20188743209.9041, Val R2: -0.0257\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2714, Val Loss: 0.2775\n",
      "Val RMSE: 142444.8991, Val MAE: 82365.3694, Val MSE: 20290549269.7642, Val R2: -0.0309\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2671, Val Loss: 0.2746\n",
      "Val RMSE: 140810.6478, Val MAE: 84817.0956, Val MSE: 19827638528.6725, Val R2: -0.0074\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2745\n",
      "Val RMSE: 141096.3048, Val MAE: 84489.1693, Val MSE: 19908167223.9427, Val R2: -0.0115\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2642, Val Loss: 0.2809\n",
      "Val RMSE: 142224.1788, Val MAE: 86528.1379, Val MSE: 20227717032.4865, Val R2: -0.0277\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2752\n",
      "Val RMSE: 141555.8023, Val MAE: 84024.8819, Val MSE: 20038045155.1287, Val R2: -0.0181\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2784\n",
      "Val RMSE: 141705.6208, Val MAE: 85525.9124, Val MSE: 20080482980.3846, Val R2: -0.0202\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2824\n",
      "Val RMSE: 144938.3618, Val MAE: 79189.9594, Val MSE: 21007128717.2746, Val R2: -0.0673\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2804\n",
      "Val RMSE: 144413.6095, Val MAE: 79288.7309, Val MSE: 20855290601.8820, Val R2: -0.0596\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2708\n",
      "Val RMSE: 140642.2712, Val MAE: 82781.0907, Val MSE: 19780248452.7537, Val R2: -0.0050\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2538, Val Loss: 0.2755\n",
      "Val RMSE: 140955.1620, Val MAE: 84605.8969, Val MSE: 19868357692.8936, Val R2: -0.0094\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2726\n",
      "Val RMSE: 143604.6620, Val MAE: 78157.9756, Val MSE: 20622298934.8945, Val R2: -0.0477\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2708\n",
      "Val RMSE: 139875.6218, Val MAE: 83916.5972, Val MSE: 19565189572.6007, Val R2: 0.0060\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2440, Val Loss: 0.2631\n",
      "Val RMSE: 140154.8320, Val MAE: 79808.6257, Val MSE: 19643376940.6770, Val R2: 0.0020\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2626\n",
      "Val RMSE: 140306.0176, Val MAE: 79054.4987, Val MSE: 19685778582.8999, Val R2: -0.0002\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2637\n",
      "Val RMSE: 142113.4394, Val MAE: 77396.0132, Val MSE: 20196229655.9489, Val R2: -0.0261\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2433, Val Loss: 0.2895\n",
      "Val RMSE: 142340.3526, Val MAE: 85406.9492, Val MSE: 20260775965.5243, Val R2: -0.0294\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2495\n",
      "Val RMSE: 134638.5444, Val MAE: 75907.8584, Val MSE: 18127537646.3994, Val R2: 0.0790\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2303, Val Loss: 0.2458\n",
      "Val RMSE: 135102.1210, Val MAE: 74129.0280, Val MSE: 18252583100.5778, Val R2: 0.0727\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2249, Val Loss: 0.2435\n",
      "Val RMSE: 132177.9231, Val MAE: 74568.7311, Val MSE: 17471003357.9511, Val R2: 0.1124\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2197, Val Loss: 0.2376\n",
      "Val RMSE: 132490.2711, Val MAE: 73244.4355, Val MSE: 17553671948.9669, Val R2: 0.1082\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2135, Val Loss: 0.2362\n",
      "Val RMSE: 133243.8297, Val MAE: 72862.0537, Val MSE: 17753918163.8272, Val R2: 0.0980\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2115, Val Loss: 0.2551\n",
      "Val RMSE: 133355.1488, Val MAE: 76885.4235, Val MSE: 17783595708.5113, Val R2: 0.0965\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2318\n",
      "Val RMSE: 128825.0386, Val MAE: 75175.0497, Val MSE: 16595890562.3704, Val R2: 0.1568\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1969, Val Loss: 0.2208\n",
      "Val RMSE: 125172.5011, Val MAE: 72054.3066, Val MSE: 15668155031.4737, Val R2: 0.2040\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1904, Val Loss: 0.2144\n",
      "Val RMSE: 121013.0596, Val MAE: 70939.7522, Val MSE: 14644160583.4117, Val R2: 0.2560\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1823, Val Loss: 0.1974\n",
      "Val RMSE: 111505.7868, Val MAE: 65783.6759, Val MSE: 12433540483.7379, Val R2: 0.3683\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1729, Val Loss: 0.1941\n",
      "Val RMSE: 108855.3582, Val MAE: 66838.8543, Val MSE: 11849489018.1946, Val R2: 0.3980\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1668, Val Loss: 0.1673\n",
      "Val RMSE: 101047.3404, Val MAE: 60692.6898, Val MSE: 10210565008.0067, Val R2: 0.4812\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1623, Val Loss: 0.1638\n",
      "Val RMSE: 98799.5288, Val MAE: 59792.2058, Val MSE: 9761346896.8121, Val R2: 0.5041\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1580, Val Loss: 0.1686\n",
      "Val RMSE: 101269.9245, Val MAE: 58681.8914, Val MSE: 10255597611.6908, Val R2: 0.4790\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1539, Val Loss: 0.1565\n",
      "Val RMSE: 98275.1258, Val MAE: 55894.7410, Val MSE: 9658000353.4250, Val R2: 0.5093\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1514, Val Loss: 0.1540\n",
      "Val RMSE: 96231.7695, Val MAE: 57535.0449, Val MSE: 9260553464.6576, Val R2: 0.5295\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1484, Val Loss: 0.1613\n",
      "Val RMSE: 99217.4639, Val MAE: 57174.9958, Val MSE: 9844105148.9962, Val R2: 0.4999\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1438\n",
      "Val RMSE: 94345.1450, Val MAE: 53014.0555, Val MSE: 8901006390.0550, Val R2: 0.5478\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1420, Val Loss: 0.1480\n",
      "Val RMSE: 94972.8058, Val MAE: 53847.6713, Val MSE: 9019833840.7871, Val R2: 0.5417\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1401, Val Loss: 0.1521\n",
      "Val RMSE: 95863.1432, Val MAE: 54509.5267, Val MSE: 9189742232.1363, Val R2: 0.5331\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1351, Val Loss: 0.1521\n",
      "Val RMSE: 96566.7772, Val MAE: 53122.1313, Val MSE: 9325142463.5488, Val R2: 0.5262\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1346, Val Loss: 0.1482\n",
      "Val RMSE: 92281.4800, Val MAE: 53752.5937, Val MSE: 8515871552.1478, Val R2: 0.5673\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1268, Val Loss: 0.1377\n",
      "Val RMSE: 91852.3237, Val MAE: 49950.5680, Val MSE: 8436849364.9624, Val R2: 0.5714\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1214, Val Loss: 0.1262\n",
      "Val RMSE: 88960.5841, Val MAE: 46941.4251, Val MSE: 7913985525.6558, Val R2: 0.5979\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1139, Val Loss: 0.1277\n",
      "Val RMSE: 88263.7792, Val MAE: 47226.7672, Val MSE: 7790494712.4313, Val R2: 0.6042\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1102, Val Loss: 0.1245\n",
      "Val RMSE: 89185.6873, Val MAE: 47312.2087, Val MSE: 7954086822.9704, Val R2: 0.5959\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1058, Val Loss: 0.1380\n",
      "Val RMSE: 90574.7496, Val MAE: 51347.2991, Val MSE: 8203785257.5017, Val R2: 0.5832\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1049, Val Loss: 0.1213\n",
      "Val RMSE: 87245.2543, Val MAE: 47498.8841, Val MSE: 7611734395.7112, Val R2: 0.6133\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1348\n",
      "Val RMSE: 91814.4500, Val MAE: 48661.9643, Val MSE: 8429893229.1455, Val R2: 0.5717\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0951, Val Loss: 0.1290\n",
      "Val RMSE: 89930.2585, Val MAE: 47745.0757, Val MSE: 8087451385.3043, Val R2: 0.5891\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1335\n",
      "Val RMSE: 90556.3824, Val MAE: 49205.9387, Val MSE: 8200458386.2210, Val R2: 0.5834\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0930, Val Loss: 0.1222\n",
      "Val RMSE: 87548.5640, Val MAE: 46566.1604, Val MSE: 7664751054.8577, Val R2: 0.6106\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0885, Val Loss: 0.1223\n",
      "Val RMSE: 87956.8520, Val MAE: 45392.8325, Val MSE: 7736407819.1343, Val R2: 0.6069\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1217\n",
      "Val RMSE: 86341.3837, Val MAE: 46950.1122, Val MSE: 7454834536.6722, Val R2: 0.6212\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1263\n",
      "Val RMSE: 89457.8786, Val MAE: 46283.9247, Val MSE: 8002712037.1485, Val R2: 0.5934\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1250\n",
      "Val RMSE: 88132.1446, Val MAE: 44856.0458, Val MSE: 7767274915.2903, Val R2: 0.6054\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1225\n",
      "Val RMSE: 86650.4288, Val MAE: 45439.8120, Val MSE: 7508296819.4728, Val R2: 0.6185\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0787, Val Loss: 0.1160\n",
      "Val RMSE: 83693.7317, Val MAE: 44635.8628, Val MSE: 7004640721.7892, Val R2: 0.6441\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1210\n",
      "Val RMSE: 84847.7275, Val MAE: 44172.8467, Val MSE: 7199136857.1453, Val R2: 0.6342\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1173\n",
      "Val RMSE: 83863.4469, Val MAE: 43351.3381, Val MSE: 7033077720.5516, Val R2: 0.6427\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1148\n",
      "Val RMSE: 83721.7875, Val MAE: 43751.9967, Val MSE: 7009337699.5742, Val R2: 0.6439\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1148\n",
      "Val RMSE: 81986.8001, Val MAE: 43472.7372, Val MSE: 6721835389.8434, Val R2: 0.6585\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1097\n",
      "Val RMSE: 78919.7267, Val MAE: 44405.0819, Val MSE: 6228323261.3694, Val R2: 0.6836\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1136\n",
      "Val RMSE: 80957.7395, Val MAE: 42928.8582, Val MSE: 6554155580.9125, Val R2: 0.6670\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1071\n",
      "Val RMSE: 79807.0893, Val MAE: 41294.3944, Val MSE: 6369171495.0913, Val R2: 0.6764\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1135\n",
      "Val RMSE: 78712.3123, Val MAE: 44745.4373, Val MSE: 6195628114.8422, Val R2: 0.6852\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1142\n",
      "Val RMSE: 82313.4426, Val MAE: 43142.0552, Val MSE: 6775502831.9876, Val R2: 0.6558\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1102\n",
      "Val RMSE: 79145.0713, Val MAE: 40770.0209, Val MSE: 6263942309.6513, Val R2: 0.6818\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1021\n",
      "Val RMSE: 76206.3130, Val MAE: 41187.9555, Val MSE: 5807402144.4675, Val R2: 0.7049\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.0996\n",
      "Val RMSE: 73888.9358, Val MAE: 40966.0981, Val MSE: 5459574839.3476, Val R2: 0.7226\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1050\n",
      "Val RMSE: 76767.3525, Val MAE: 41036.2627, Val MSE: 5893226411.7687, Val R2: 0.7006\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0626, Val Loss: 0.1088\n",
      "Val RMSE: 78787.3158, Val MAE: 40840.0791, Val MSE: 6207441131.9011, Val R2: 0.6846\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1056\n",
      "Val RMSE: 76323.7081, Val MAE: 42832.3325, Val MSE: 5825308421.8308, Val R2: 0.7040\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1066\n",
      "Val RMSE: 77665.8766, Val MAE: 39295.3779, Val MSE: 6031988393.5144, Val R2: 0.6935\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1002\n",
      "Val RMSE: 75773.9949, Val MAE: 39750.0531, Val MSE: 5741698296.8144, Val R2: 0.7083\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1180\n",
      "Val RMSE: 79565.0608, Val MAE: 45347.1744, Val MSE: 6330598905.0931, Val R2: 0.6784\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1114\n",
      "Val RMSE: 79374.9569, Val MAE: 39988.8354, Val MSE: 6300383776.2478, Val R2: 0.6799\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1075\n",
      "Val RMSE: 76489.2331, Val MAE: 39033.3995, Val MSE: 5850602780.2718, Val R2: 0.7028\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1008\n",
      "Val RMSE: 74975.2204, Val MAE: 38282.1876, Val MSE: 5621283669.4464, Val R2: 0.7144\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1050\n",
      "Val RMSE: 76707.2155, Val MAE: 40690.1598, Val MSE: 5883996903.2331, Val R2: 0.7011\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.0918\n",
      "Val RMSE: 72645.0563, Val MAE: 37256.4159, Val MSE: 5277304208.2258, Val R2: 0.7319\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1050\n",
      "Val RMSE: 77211.0846, Val MAE: 40647.2968, Val MSE: 5961551586.6962, Val R2: 0.6971\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1109\n",
      "Val RMSE: 79307.7561, Val MAE: 41504.6784, Val MSE: 6289720171.9241, Val R2: 0.6804\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1020\n",
      "Val RMSE: 76232.1265, Val MAE: 38724.5026, Val MSE: 5811337114.6477, Val R2: 0.7047\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.0906\n",
      "Val RMSE: 72943.4855, Val MAE: 36984.7149, Val MSE: 5320752070.0506, Val R2: 0.7297\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.0985\n",
      "Val RMSE: 74336.6636, Val MAE: 38892.5181, Val MSE: 5525939549.7226, Val R2: 0.7192\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.0991\n",
      "Val RMSE: 75991.8847, Val MAE: 37257.1187, Val MSE: 5774766544.7643, Val R2: 0.7066\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.0989\n",
      "Val RMSE: 75211.1858, Val MAE: 38133.9183, Val MSE: 5656722474.5222, Val R2: 0.7126\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1142\n",
      "Val RMSE: 78934.3183, Val MAE: 39052.7540, Val MSE: 6230626598.9597, Val R2: 0.6834\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.0964\n",
      "Val RMSE: 75816.5722, Val MAE: 38607.2310, Val MSE: 5748152613.6017, Val R2: 0.7080\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.0985\n",
      "Val RMSE: 74375.6728, Val MAE: 36765.1354, Val MSE: 5531740703.6578, Val R2: 0.7190\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1019\n",
      "Val RMSE: 75144.4273, Val MAE: 39215.8700, Val MSE: 5646684959.7810, Val R2: 0.7131\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.0978\n",
      "Val RMSE: 73194.8423, Val MAE: 37728.9322, Val MSE: 5357484943.4009, Val R2: 0.7278\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.0971\n",
      "Val RMSE: 73087.6429, Val MAE: 39283.9934, Val MSE: 5341803541.8887, Val R2: 0.7286\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.0915\n",
      "Val RMSE: 71284.6837, Val MAE: 37631.0984, Val MSE: 5081506124.8128, Val R2: 0.7418\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.0886\n",
      "Val RMSE: 70971.2508, Val MAE: 36581.1243, Val MSE: 5036918437.5074, Val R2: 0.7441\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.0947\n",
      "Val RMSE: 72609.2602, Val MAE: 38934.1150, Val MSE: 5272104663.7550, Val R2: 0.7321\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.0959\n",
      "Val RMSE: 74676.8805, Val MAE: 37922.0105, Val MSE: 5576636477.5680, Val R2: 0.7167\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.0909\n",
      "Val RMSE: 73823.2862, Val MAE: 35198.7752, Val MSE: 5449877581.1529, Val R2: 0.7231\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.0925\n",
      "Val RMSE: 73812.7102, Val MAE: 37460.0290, Val MSE: 5448316191.7854, Val R2: 0.7232\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.0899\n",
      "Val RMSE: 72319.9698, Val MAE: 35138.0579, Val MSE: 5230178033.0374, Val R2: 0.7343\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.0868\n",
      "Val RMSE: 69660.4838, Val MAE: 34844.0959, Val MSE: 4852583005.3440, Val R2: 0.7535\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 66905.4634, Test MAE: 35639.8803, Test MSE: 4476341027.8711, Test R2: 0.7131\n",
      "Inference Time: 2.7583158933199368e-05 seconds per sample\n",
      "\n",
      "Iteration 16 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3211, Val Loss: 0.2792\n",
      "Val RMSE: 141028.7770, Val MAE: 86146.3521, Val MSE: 19889115945.7814, Val R2: -0.0105\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2768\n",
      "Val RMSE: 141900.1183, Val MAE: 83136.4295, Val MSE: 20135643568.6133, Val R2: -0.0230\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2672, Val Loss: 0.2797\n",
      "Val RMSE: 143128.3149, Val MAE: 81614.4343, Val MSE: 20485714536.1817, Val R2: -0.0408\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2655, Val Loss: 0.2814\n",
      "Val RMSE: 144024.7012, Val MAE: 80856.9429, Val MSE: 20743114569.0610, Val R2: -0.0539\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2733\n",
      "Val RMSE: 141622.4329, Val MAE: 84047.3297, Val MSE: 20056913507.8655, Val R2: -0.0190\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2587, Val Loss: 0.2725\n",
      "Val RMSE: 142695.6823, Val MAE: 80541.1327, Val MSE: 20362057755.0056, Val R2: -0.0345\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2673\n",
      "Val RMSE: 142049.9535, Val MAE: 80103.7186, Val MSE: 20178189297.4152, Val R2: -0.0252\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2674\n",
      "Val RMSE: 143173.3246, Val MAE: 78047.0223, Val MSE: 20498600870.2280, Val R2: -0.0415\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2713\n",
      "Val RMSE: 141213.4312, Val MAE: 83032.1691, Val MSE: 19941233155.4880, Val R2: -0.0131\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2703\n",
      "Val RMSE: 142049.7598, Val MAE: 81594.0971, Val MSE: 20178134268.5599, Val R2: -0.0252\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2491, Val Loss: 0.2652\n",
      "Val RMSE: 141446.4832, Val MAE: 78984.0227, Val MSE: 20007107619.4173, Val R2: -0.0165\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2515, Val Loss: 0.2743\n",
      "Val RMSE: 140936.1174, Val MAE: 83885.4864, Val MSE: 19862989183.5347, Val R2: -0.0092\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2468, Val Loss: 0.2744\n",
      "Val RMSE: 144109.0284, Val MAE: 77788.3128, Val MSE: 20767412059.2436, Val R2: -0.0551\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2458, Val Loss: 0.2638\n",
      "Val RMSE: 141532.5862, Val MAE: 78545.7734, Val MSE: 20031472963.8622, Val R2: -0.0177\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2429, Val Loss: 0.2708\n",
      "Val RMSE: 140860.6653, Val MAE: 82205.6923, Val MSE: 19841727021.7053, Val R2: -0.0081\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2432, Val Loss: 0.2678\n",
      "Val RMSE: 142272.3749, Val MAE: 79235.3789, Val MSE: 20241428657.5070, Val R2: -0.0284\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2414, Val Loss: 0.2612\n",
      "Val RMSE: 141225.3767, Val MAE: 78037.9205, Val MSE: 19944607020.1300, Val R2: -0.0133\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2376, Val Loss: 0.2623\n",
      "Val RMSE: 140309.1839, Val MAE: 79412.5198, Val MSE: 19686667098.1687, Val R2: -0.0002\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2383, Val Loss: 0.2601\n",
      "Val RMSE: 140442.6365, Val MAE: 78495.4033, Val MSE: 19724134137.2875, Val R2: -0.0021\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2390, Val Loss: 0.2590\n",
      "Val RMSE: 140137.1244, Val MAE: 78711.3721, Val MSE: 19638413624.7921, Val R2: 0.0022\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2392, Val Loss: 0.2611\n",
      "Val RMSE: 139284.1809, Val MAE: 80435.5251, Val MSE: 19400083062.4576, Val R2: 0.0144\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2382, Val Loss: 0.2533\n",
      "Val RMSE: 138407.1118, Val MAE: 77103.8063, Val MSE: 19156528603.1108, Val R2: 0.0267\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2302, Val Loss: 0.2530\n",
      "Val RMSE: 137118.6815, Val MAE: 76334.4229, Val MSE: 18801532821.3976, Val R2: 0.0448\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2280, Val Loss: 0.2521\n",
      "Val RMSE: 136358.1516, Val MAE: 76159.5929, Val MSE: 18593545500.9323, Val R2: 0.0553\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2279, Val Loss: 0.2491\n",
      "Val RMSE: 135987.7796, Val MAE: 75612.5350, Val MSE: 18492676200.5529, Val R2: 0.0605\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2258, Val Loss: 0.2485\n",
      "Val RMSE: 133266.1336, Val MAE: 75986.8441, Val MSE: 17759862357.6551, Val R2: 0.0977\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2246, Val Loss: 0.2435\n",
      "Val RMSE: 132142.2781, Val MAE: 76171.6637, Val MSE: 17461581665.3685, Val R2: 0.1128\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2122, Val Loss: 0.2672\n",
      "Val RMSE: 146090.4485, Val MAE: 76397.0178, Val MSE: 21342419140.7358, Val R2: -0.0843\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2242, Val Loss: 0.2448\n",
      "Val RMSE: 134062.5930, Val MAE: 75453.1484, Val MSE: 17972778852.9807, Val R2: 0.0869\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2207, Val Loss: 0.2865\n",
      "Val RMSE: 144584.0745, Val MAE: 77708.6433, Val MSE: 20904554611.8939, Val R2: -0.0621\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2371, Val Loss: 0.2647\n",
      "Val RMSE: 135285.4602, Val MAE: 74159.3721, Val MSE: 18302155731.7213, Val R2: 0.0701\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2103, Val Loss: 0.2145\n",
      "Val RMSE: 123044.9082, Val MAE: 66834.5053, Val MSE: 15140049443.8129, Val R2: 0.2308\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1914, Val Loss: 0.2197\n",
      "Val RMSE: 122105.7648, Val MAE: 69776.3541, Val MSE: 14909817786.9500, Val R2: 0.2425\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1849, Val Loss: 0.1932\n",
      "Val RMSE: 110285.3534, Val MAE: 65761.7669, Val MSE: 12162859174.7968, Val R2: 0.3820\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1795, Val Loss: 0.2029\n",
      "Val RMSE: 112527.6543, Val MAE: 65678.0167, Val MSE: 12662472979.1112, Val R2: 0.3567\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1755, Val Loss: 0.1823\n",
      "Val RMSE: 106539.0944, Val MAE: 61821.2825, Val MSE: 11350578645.9836, Val R2: 0.4233\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1720, Val Loss: 0.1813\n",
      "Val RMSE: 106004.9311, Val MAE: 61775.9583, Val MSE: 11237045414.2999, Val R2: 0.4291\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1677, Val Loss: 0.1918\n",
      "Val RMSE: 108188.5457, Val MAE: 63067.7890, Val MSE: 11704761427.4765, Val R2: 0.4053\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1621, Val Loss: 0.1712\n",
      "Val RMSE: 103218.1986, Val MAE: 60660.9585, Val MSE: 10653996512.2165, Val R2: 0.4587\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1548, Val Loss: 0.1717\n",
      "Val RMSE: 101791.2242, Val MAE: 60633.5291, Val MSE: 10361453317.4439, Val R2: 0.4736\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1512, Val Loss: 0.1910\n",
      "Val RMSE: 106166.1783, Val MAE: 61283.4898, Val MSE: 11271257412.8861, Val R2: 0.4273\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1534, Val Loss: 0.1716\n",
      "Val RMSE: 102088.2854, Val MAE: 57938.8083, Val MSE: 10422018025.0884, Val R2: 0.4705\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1451, Val Loss: 0.1657\n",
      "Val RMSE: 100784.8605, Val MAE: 57069.7495, Val MSE: 10157588101.5595, Val R2: 0.4839\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1409, Val Loss: 0.1652\n",
      "Val RMSE: 100422.1727, Val MAE: 57144.3443, Val MSE: 10084612776.6269, Val R2: 0.4876\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1414, Val Loss: 0.1709\n",
      "Val RMSE: 99694.7995, Val MAE: 57657.8109, Val MSE: 9939053054.3024, Val R2: 0.4950\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1350, Val Loss: 0.1579\n",
      "Val RMSE: 99225.6714, Val MAE: 54598.4300, Val MSE: 9845733857.7875, Val R2: 0.4998\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1328, Val Loss: 0.1558\n",
      "Val RMSE: 97297.2614, Val MAE: 54794.9602, Val MSE: 9466757085.6348, Val R2: 0.5190\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1267, Val Loss: 0.1532\n",
      "Val RMSE: 96775.7322, Val MAE: 53987.1282, Val MSE: 9365542334.9552, Val R2: 0.5242\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1212, Val Loss: 0.1708\n",
      "Val RMSE: 101206.1054, Val MAE: 56128.5797, Val MSE: 10242675772.6470, Val R2: 0.4796\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1177, Val Loss: 0.1554\n",
      "Val RMSE: 96528.5996, Val MAE: 55376.3628, Val MSE: 9317770549.4662, Val R2: 0.5266\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1123, Val Loss: 0.1491\n",
      "Val RMSE: 96193.7505, Val MAE: 52192.8257, Val MSE: 9253237639.9050, Val R2: 0.5299\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1061, Val Loss: 0.1623\n",
      "Val RMSE: 100094.1851, Val MAE: 55800.3034, Val MSE: 10018845895.4060, Val R2: 0.4910\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1480\n",
      "Val RMSE: 96444.2700, Val MAE: 52959.4205, Val MSE: 9301497222.3279, Val R2: 0.5274\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0971, Val Loss: 0.1357\n",
      "Val RMSE: 91292.8147, Val MAE: 48340.7249, Val MSE: 8334378013.4832, Val R2: 0.5766\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0960, Val Loss: 0.1501\n",
      "Val RMSE: 95302.4369, Val MAE: 51186.9791, Val MSE: 9082554469.7218, Val R2: 0.5385\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0931, Val Loss: 0.1499\n",
      "Val RMSE: 94043.3742, Val MAE: 51729.2887, Val MSE: 8844156232.3506, Val R2: 0.5507\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0896, Val Loss: 0.1404\n",
      "Val RMSE: 90521.9286, Val MAE: 50100.1156, Val MSE: 8194219565.4215, Val R2: 0.5837\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1400\n",
      "Val RMSE: 90751.2425, Val MAE: 51823.2418, Val MSE: 8235788010.5345, Val R2: 0.5816\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0870, Val Loss: 0.1394\n",
      "Val RMSE: 88597.9602, Val MAE: 49634.7274, Val MSE: 7849598554.7082, Val R2: 0.6012\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1391\n",
      "Val RMSE: 90866.5198, Val MAE: 49724.5684, Val MSE: 8256724416.3686, Val R2: 0.5805\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1401\n",
      "Val RMSE: 85038.9892, Val MAE: 49897.7692, Val MSE: 7231629678.5208, Val R2: 0.6326\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1203\n",
      "Val RMSE: 79869.4127, Val MAE: 45797.4825, Val MSE: 6379123082.8599, Val R2: 0.6759\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1314\n",
      "Val RMSE: 86468.2696, Val MAE: 47575.5929, Val MSE: 7476761649.9361, Val R2: 0.6201\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1263\n",
      "Val RMSE: 78102.1453, Val MAE: 49083.7666, Val MSE: 6099945108.2696, Val R2: 0.6901\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0783, Val Loss: 0.1253\n",
      "Val RMSE: 80333.4389, Val MAE: 46590.3047, Val MSE: 6453461407.7662, Val R2: 0.6721\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1223\n",
      "Val RMSE: 77457.8299, Val MAE: 47950.4587, Val MSE: 5999715413.2836, Val R2: 0.6952\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1193\n",
      "Val RMSE: 78712.7190, Val MAE: 44856.8629, Val MSE: 6195692126.9058, Val R2: 0.6852\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1147\n",
      "Val RMSE: 75786.5075, Val MAE: 43013.1483, Val MSE: 5743594714.0867, Val R2: 0.7082\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0735, Val Loss: 0.1128\n",
      "Val RMSE: 74962.8601, Val MAE: 42966.1244, Val MSE: 5619430393.6307, Val R2: 0.7145\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1400\n",
      "Val RMSE: 82319.1558, Val MAE: 52458.5758, Val MSE: 6776443410.5263, Val R2: 0.6557\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1335\n",
      "Val RMSE: 81123.6554, Val MAE: 51817.6567, Val MSE: 6581047467.7440, Val R2: 0.6656\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1206\n",
      "Val RMSE: 79037.3172, Val MAE: 46104.8759, Val MSE: 6246897510.8350, Val R2: 0.6826\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1255\n",
      "Val RMSE: 79689.5358, Val MAE: 47310.4706, Val MSE: 6350422114.6796, Val R2: 0.6774\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.1061\n",
      "Val RMSE: 71694.8436, Val MAE: 43331.5561, Val MSE: 5140150597.1096, Val R2: 0.7388\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1226\n",
      "Val RMSE: 77724.8348, Val MAE: 49455.5936, Val MSE: 6041149948.7032, Val R2: 0.6931\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1121\n",
      "Val RMSE: 75975.2404, Val MAE: 42795.4798, Val MSE: 5772237160.5006, Val R2: 0.7067\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1076\n",
      "Val RMSE: 72574.2986, Val MAE: 41872.1423, Val MSE: 5267028823.4408, Val R2: 0.7324\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1019\n",
      "Val RMSE: 70802.5277, Val MAE: 40457.8992, Val MSE: 5012997925.2794, Val R2: 0.7453\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1103\n",
      "Val RMSE: 73543.0801, Val MAE: 44309.6932, Val MSE: 5408584636.0801, Val R2: 0.7252\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1123\n",
      "Val RMSE: 76940.2446, Val MAE: 42915.0096, Val MSE: 5919801241.0095, Val R2: 0.6992\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1063\n",
      "Val RMSE: 73014.7003, Val MAE: 39883.0546, Val MSE: 5331146455.7789, Val R2: 0.7291\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1041\n",
      "Val RMSE: 72925.4195, Val MAE: 41536.9621, Val MSE: 5318116805.2034, Val R2: 0.7298\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1111\n",
      "Val RMSE: 75833.4772, Val MAE: 42334.1958, Val MSE: 5750716261.1335, Val R2: 0.7078\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1040\n",
      "Val RMSE: 72280.3697, Val MAE: 41082.5958, Val MSE: 5224451840.3010, Val R2: 0.7346\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1031\n",
      "Val RMSE: 72681.1487, Val MAE: 39531.1185, Val MSE: 5282549371.7494, Val R2: 0.7316\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1023\n",
      "Val RMSE: 72470.3827, Val MAE: 40512.8629, Val MSE: 5251956367.8005, Val R2: 0.7332\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1046\n",
      "Val RMSE: 73121.3258, Val MAE: 40111.2791, Val MSE: 5346728293.1267, Val R2: 0.7284\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1071\n",
      "Val RMSE: 73287.0691, Val MAE: 40916.9549, Val MSE: 5370994497.9165, Val R2: 0.7271\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.0966\n",
      "Val RMSE: 69095.2494, Val MAE: 37748.0891, Val MSE: 4774153486.1921, Val R2: 0.7574\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1042\n",
      "Val RMSE: 72106.9244, Val MAE: 39394.1810, Val MSE: 5199408541.4798, Val R2: 0.7358\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1175\n",
      "Val RMSE: 77956.7417, Val MAE: 43474.4760, Val MSE: 6077253572.6962, Val R2: 0.6912\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1198\n",
      "Val RMSE: 78373.0356, Val MAE: 45743.3897, Val MSE: 6142332713.9372, Val R2: 0.6879\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1103\n",
      "Val RMSE: 76009.5368, Val MAE: 41865.5800, Val MSE: 5777449682.9762, Val R2: 0.7065\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1012\n",
      "Val RMSE: 72270.4018, Val MAE: 38907.8695, Val MSE: 5223010971.0724, Val R2: 0.7346\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1012\n",
      "Val RMSE: 70287.9785, Val MAE: 39292.1223, Val MSE: 4940399921.8780, Val R2: 0.7490\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.0955\n",
      "Val RMSE: 67837.8317, Val MAE: 39690.9029, Val MSE: 4601971407.5418, Val R2: 0.7662\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1171\n",
      "Val RMSE: 79615.8346, Val MAE: 42573.7549, Val MSE: 6338681125.4630, Val R2: 0.6780\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1118\n",
      "Val RMSE: 74879.7188, Val MAE: 43165.2821, Val MSE: 5606972293.0357, Val R2: 0.7151\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.0989\n",
      "Val RMSE: 71069.0392, Val MAE: 39169.8802, Val MSE: 5050808337.3410, Val R2: 0.7434\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1088\n",
      "Val RMSE: 75043.2378, Val MAE: 42166.4031, Val MSE: 5631487538.8862, Val R2: 0.7139\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 73648.6274, Test MAE: 42561.6300, Test MSE: 5424120311.0655, Test R2: 0.6523\n",
      "Inference Time: 2.788983858548678e-05 seconds per sample\n",
      "\n",
      "Iteration 17 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3238, Val Loss: 0.3067\n",
      "Val RMSE: 148860.1320, Val MAE: 80959.7654, Val MSE: 22159338900.6914, Val R2: -0.1258\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2792, Val Loss: 0.2757\n",
      "Val RMSE: 140380.6377, Val MAE: 86347.6283, Val MSE: 19706723434.3068, Val R2: -0.0012\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2709, Val Loss: 0.2777\n",
      "Val RMSE: 142892.1950, Val MAE: 81803.7765, Val MSE: 20418179406.0420, Val R2: -0.0374\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2643, Val Loss: 0.2782\n",
      "Val RMSE: 142495.7399, Val MAE: 85157.9789, Val MSE: 20305035897.5594, Val R2: -0.0316\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2738\n",
      "Val RMSE: 141960.0565, Val MAE: 83701.2775, Val MSE: 20152657631.5705, Val R2: -0.0239\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2594, Val Loss: 0.2718\n",
      "Val RMSE: 141555.7648, Val MAE: 82959.6145, Val MSE: 20038034562.1002, Val R2: -0.0181\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2557, Val Loss: 0.2695\n",
      "Val RMSE: 141224.9382, Val MAE: 82226.4857, Val MSE: 19944483155.5010, Val R2: -0.0133\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2767\n",
      "Val RMSE: 143650.7744, Val MAE: 79635.4971, Val MSE: 20635544992.6059, Val R2: -0.0484\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2665\n",
      "Val RMSE: 141712.4500, Val MAE: 79099.1413, Val MSE: 20082418481.1275, Val R2: -0.0203\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2649\n",
      "Val RMSE: 139877.7936, Val MAE: 81022.2442, Val MSE: 19565797153.5304, Val R2: 0.0059\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2465, Val Loss: 0.2672\n",
      "Val RMSE: 141294.0989, Val MAE: 79238.2248, Val MSE: 19964022390.2153, Val R2: -0.0143\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2465, Val Loss: 0.2811\n",
      "Val RMSE: 143903.0195, Val MAE: 79460.0871, Val MSE: 20708079033.5427, Val R2: -0.0521\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2412, Val Loss: 0.2656\n",
      "Val RMSE: 140264.1320, Val MAE: 80135.9291, Val MSE: 19674026729.5980, Val R2: 0.0004\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2434, Val Loss: 0.2534\n",
      "Val RMSE: 138043.3740, Val MAE: 75872.6894, Val MSE: 19055973103.8770, Val R2: 0.0318\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2371, Val Loss: 0.2512\n",
      "Val RMSE: 135809.7219, Val MAE: 76719.6232, Val MSE: 18444280562.8619, Val R2: 0.0629\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2321, Val Loss: 0.2513\n",
      "Val RMSE: 136123.6069, Val MAE: 75563.9234, Val MSE: 18529636363.2951, Val R2: 0.0586\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2310, Val Loss: 0.2468\n",
      "Val RMSE: 135072.3897, Val MAE: 74634.5168, Val MSE: 18244550472.4939, Val R2: 0.0731\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2286, Val Loss: 0.2555\n",
      "Val RMSE: 137093.9893, Val MAE: 74320.1650, Val MSE: 18794761901.0224, Val R2: 0.0451\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2250, Val Loss: 0.2406\n",
      "Val RMSE: 132648.9796, Val MAE: 74035.0858, Val MSE: 17595751790.6402, Val R2: 0.1060\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2196, Val Loss: 0.2356\n",
      "Val RMSE: 131267.1891, Val MAE: 71524.9502, Val MSE: 17231074938.7723, Val R2: 0.1246\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2134, Val Loss: 0.2285\n",
      "Val RMSE: 130641.2238, Val MAE: 72534.3282, Val MSE: 17067129354.8036, Val R2: 0.1329\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2050, Val Loss: 0.2306\n",
      "Val RMSE: 130640.8515, Val MAE: 73206.5759, Val MSE: 17067032069.8302, Val R2: 0.1329\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1974, Val Loss: 0.2207\n",
      "Val RMSE: 127838.1267, Val MAE: 68955.0499, Val MSE: 16342586641.5792, Val R2: 0.1697\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1921, Val Loss: 0.2275\n",
      "Val RMSE: 129659.1513, Val MAE: 70257.2333, Val MSE: 16811495507.7863, Val R2: 0.1459\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1847, Val Loss: 0.2268\n",
      "Val RMSE: 128374.4634, Val MAE: 70724.5762, Val MSE: 16480002847.3972, Val R2: 0.1627\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1791, Val Loss: 0.1856\n",
      "Val RMSE: 109121.3907, Val MAE: 62835.2544, Val MSE: 11907477909.5991, Val R2: 0.3950\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1741, Val Loss: 0.1987\n",
      "Val RMSE: 110244.4805, Val MAE: 67503.9986, Val MSE: 12153845474.0915, Val R2: 0.3825\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1686, Val Loss: 0.1689\n",
      "Val RMSE: 101653.8550, Val MAE: 58793.6358, Val MSE: 10333506240.9224, Val R2: 0.4750\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1656, Val Loss: 0.1848\n",
      "Val RMSE: 103541.9970, Val MAE: 61975.1870, Val MSE: 10720945145.0314, Val R2: 0.4553\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1712\n",
      "Val RMSE: 99562.2874, Val MAE: 60071.0698, Val MSE: 9912649078.8439, Val R2: 0.4964\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1717\n",
      "Val RMSE: 101699.1904, Val MAE: 60217.3352, Val MSE: 10342725330.9524, Val R2: 0.4745\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1492, Val Loss: 0.1613\n",
      "Val RMSE: 97211.4588, Val MAE: 58890.2836, Val MSE: 9450067714.9730, Val R2: 0.5199\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1433, Val Loss: 0.1564\n",
      "Val RMSE: 96641.4064, Val MAE: 56486.2771, Val MSE: 9339561438.1052, Val R2: 0.5255\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1578\n",
      "Val RMSE: 98557.6944, Val MAE: 55576.5458, Val MSE: 9713619122.0350, Val R2: 0.5065\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1547, Val Loss: 0.1633\n",
      "Val RMSE: 99090.9825, Val MAE: 56723.7977, Val MSE: 9819022803.8233, Val R2: 0.5011\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1476, Val Loss: 0.1581\n",
      "Val RMSE: 98363.4465, Val MAE: 55201.8169, Val MSE: 9675367600.9746, Val R2: 0.5084\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1404, Val Loss: 0.1545\n",
      "Val RMSE: 96832.2733, Val MAE: 54190.2812, Val MSE: 9376489159.6067, Val R2: 0.5236\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1338, Val Loss: 0.1690\n",
      "Val RMSE: 101365.8375, Val MAE: 57522.1322, Val MSE: 10275033002.7694, Val R2: 0.4780\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1289, Val Loss: 0.1598\n",
      "Val RMSE: 98170.1804, Val MAE: 55264.6264, Val MSE: 9637384310.3755, Val R2: 0.5104\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1223, Val Loss: 0.1528\n",
      "Val RMSE: 97712.6296, Val MAE: 54534.0746, Val MSE: 9547757988.5275, Val R2: 0.5149\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1464\n",
      "Val RMSE: 95489.1205, Val MAE: 51907.7223, Val MSE: 9118172132.6674, Val R2: 0.5367\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1486\n",
      "Val RMSE: 94819.3997, Val MAE: 52961.7230, Val MSE: 8990718558.7078, Val R2: 0.5432\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1073, Val Loss: 0.1363\n",
      "Val RMSE: 91969.2727, Val MAE: 49544.8502, Val MSE: 8458347123.0510, Val R2: 0.5703\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1546\n",
      "Val RMSE: 96016.8711, Val MAE: 52597.5572, Val MSE: 9219239533.7147, Val R2: 0.5316\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1510\n",
      "Val RMSE: 96273.2374, Val MAE: 54789.2450, Val MSE: 9268536245.6954, Val R2: 0.5291\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1683\n",
      "Val RMSE: 98985.3342, Val MAE: 58291.9881, Val MSE: 9798096395.6637, Val R2: 0.5022\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0925, Val Loss: 0.1617\n",
      "Val RMSE: 98759.4391, Val MAE: 57642.8433, Val MSE: 9753426814.5596, Val R2: 0.5045\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0889, Val Loss: 0.1513\n",
      "Val RMSE: 96663.3363, Val MAE: 53877.7235, Val MSE: 9343800588.3265, Val R2: 0.5253\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.1546\n",
      "Val RMSE: 96488.4157, Val MAE: 55687.5198, Val MSE: 9310014364.1986, Val R2: 0.5270\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0855, Val Loss: 0.1504\n",
      "Val RMSE: 95765.4580, Val MAE: 53071.6554, Val MSE: 9171022953.8695, Val R2: 0.5341\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1481\n",
      "Val RMSE: 94224.3530, Val MAE: 54356.4754, Val MSE: 8878228705.0417, Val R2: 0.5489\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0817, Val Loss: 0.1572\n",
      "Val RMSE: 96517.7161, Val MAE: 55900.5529, Val MSE: 9315669522.2543, Val R2: 0.5267\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1488\n",
      "Val RMSE: 93724.4110, Val MAE: 53832.1983, Val MSE: 8784265214.1491, Val R2: 0.5537\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1429\n",
      "Val RMSE: 91189.4965, Val MAE: 51116.6269, Val MSE: 8315524273.7572, Val R2: 0.5775\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1575\n",
      "Val RMSE: 93022.1277, Val MAE: 56856.0034, Val MSE: 8653116239.7713, Val R2: 0.5604\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1462\n",
      "Val RMSE: 89926.0678, Val MAE: 52256.6522, Val MSE: 8086697664.2134, Val R2: 0.5891\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1530\n",
      "Val RMSE: 93257.8211, Val MAE: 55197.1351, Val MSE: 8697021197.7487, Val R2: 0.5581\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1778\n",
      "Val RMSE: 96604.3016, Val MAE: 60803.8361, Val MSE: 9332391078.4799, Val R2: 0.5259\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1495\n",
      "Val RMSE: 91762.9022, Val MAE: 53231.1479, Val MSE: 8420430212.4068, Val R2: 0.5722\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.1598\n",
      "Val RMSE: 98037.3648, Val MAE: 56064.7114, Val MSE: 9611324902.1029, Val R2: 0.5117\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1739\n",
      "Val RMSE: 96172.4866, Val MAE: 58659.7641, Val MSE: 9249147186.5316, Val R2: 0.5301\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1844\n",
      "Val RMSE: 100317.3974, Val MAE: 61052.0811, Val MSE: 10063580228.4066, Val R2: 0.4887\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1733\n",
      "Val RMSE: 97134.8474, Val MAE: 58677.8382, Val MSE: 9435178574.3779, Val R2: 0.5206\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1505\n",
      "Val RMSE: 91380.9494, Val MAE: 52893.0135, Val MSE: 8350477918.8673, Val R2: 0.5757\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1594\n",
      "Val RMSE: 92092.9692, Val MAE: 56321.2791, Val MSE: 8481114974.7393, Val R2: 0.5691\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1531\n",
      "Val RMSE: 92491.9460, Val MAE: 53575.8030, Val MSE: 8554760082.9506, Val R2: 0.5654\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1736\n",
      "Val RMSE: 95214.8627, Val MAE: 59664.4218, Val MSE: 9065870079.8757, Val R2: 0.5394\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1528\n",
      "Val RMSE: 92042.1409, Val MAE: 53496.5160, Val MSE: 8471755700.7799, Val R2: 0.5696\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1711\n",
      "Val RMSE: 95569.6769, Val MAE: 59492.1713, Val MSE: 9133563143.9689, Val R2: 0.5360\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1668\n",
      "Val RMSE: 94201.2668, Val MAE: 57795.7809, Val MSE: 8873878668.3294, Val R2: 0.5492\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1819\n",
      "Val RMSE: 96544.4888, Val MAE: 61776.7115, Val MSE: 9320838314.6755, Val R2: 0.5264\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1809\n",
      "Val RMSE: 96108.9924, Val MAE: 61509.7469, Val MSE: 9236938412.9746, Val R2: 0.5307\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1905\n",
      "Val RMSE: 97849.1287, Val MAE: 62428.6893, Val MSE: 9574451992.9422, Val R2: 0.5136\n",
      "Early stopping triggered after epoch 73\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 99772.3860, Test MAE: 56216.6968, Test MSE: 9954529004.3459, Test R2: 0.3619\n",
      "Inference Time: 3.137815915621244e-05 seconds per sample\n",
      "\n",
      "Iteration 18 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3473, Val Loss: 0.2832\n",
      "Val RMSE: 141111.2147, Val MAE: 87830.2097, Val MSE: 19912374926.7710, Val R2: -0.0117\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2781, Val Loss: 0.2837\n",
      "Val RMSE: 141572.3843, Val MAE: 86727.6018, Val MSE: 20042739982.8566, Val R2: -0.0183\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2736, Val Loss: 0.2847\n",
      "Val RMSE: 142433.9010, Val MAE: 84944.2699, Val MSE: 20287416157.3868, Val R2: -0.0307\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2719, Val Loss: 0.2775\n",
      "Val RMSE: 140910.2292, Val MAE: 85817.7391, Val MSE: 19855692683.2988, Val R2: -0.0088\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2747\n",
      "Val RMSE: 140858.0744, Val MAE: 84750.3157, Val MSE: 19840997117.7013, Val R2: -0.0080\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2744\n",
      "Val RMSE: 141532.4578, Val MAE: 83642.9202, Val MSE: 20031436603.5037, Val R2: -0.0177\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2623, Val Loss: 0.2759\n",
      "Val RMSE: 142219.0186, Val MAE: 82291.6208, Val MSE: 20226249253.4141, Val R2: -0.0276\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2577, Val Loss: 0.2750\n",
      "Val RMSE: 142171.8111, Val MAE: 81279.5563, Val MSE: 20212823878.6873, Val R2: -0.0269\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.3024\n",
      "Val RMSE: 142941.9659, Val MAE: 92890.4855, Val MSE: 20432405605.1332, Val R2: -0.0381\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2585, Val Loss: 0.2676\n",
      "Val RMSE: 140200.1386, Val MAE: 82345.8552, Val MSE: 19656078872.8137, Val R2: 0.0013\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2654\n",
      "Val RMSE: 141468.0629, Val MAE: 79428.3995, Val MSE: 20013212827.5549, Val R2: -0.0168\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2512, Val Loss: 0.2686\n",
      "Val RMSE: 142072.6994, Val MAE: 79062.1298, Val MSE: 20184651911.0500, Val R2: -0.0255\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2709\n",
      "Val RMSE: 141974.6063, Val MAE: 79070.9719, Val MSE: 20156788829.9690, Val R2: -0.0241\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2512, Val Loss: 0.2669\n",
      "Val RMSE: 141255.8168, Val MAE: 79014.6900, Val MSE: 19953205786.8053, Val R2: -0.0137\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2444, Val Loss: 0.2652\n",
      "Val RMSE: 139509.5005, Val MAE: 81042.8619, Val MSE: 19462900719.8312, Val R2: 0.0112\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2439, Val Loss: 0.2628\n",
      "Val RMSE: 139807.0114, Val MAE: 79843.8980, Val MSE: 19546000437.8300, Val R2: 0.0069\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2418, Val Loss: 0.2608\n",
      "Val RMSE: 139250.6145, Val MAE: 80228.9926, Val MSE: 19390733640.9017, Val R2: 0.0148\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2626\n",
      "Val RMSE: 141985.5924, Val MAE: 76970.5492, Val MSE: 20159908438.3597, Val R2: -0.0243\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2399, Val Loss: 0.2599\n",
      "Val RMSE: 139015.1822, Val MAE: 80141.4332, Val MSE: 19325220879.7283, Val R2: 0.0182\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2395, Val Loss: 0.2596\n",
      "Val RMSE: 140195.5530, Val MAE: 78111.6025, Val MSE: 19654793086.5596, Val R2: 0.0014\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2371, Val Loss: 0.2616\n",
      "Val RMSE: 141664.6326, Val MAE: 77164.1173, Val MSE: 20068868143.6100, Val R2: -0.0196\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2373, Val Loss: 0.2627\n",
      "Val RMSE: 140119.0857, Val MAE: 79102.0724, Val MSE: 19633358182.7452, Val R2: 0.0025\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2364, Val Loss: 0.2640\n",
      "Val RMSE: 138691.7776, Val MAE: 81232.0513, Val MSE: 19235409179.3161, Val R2: 0.0227\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2310, Val Loss: 0.2499\n",
      "Val RMSE: 136144.1489, Val MAE: 73764.1021, Val MSE: 18535229279.5601, Val R2: 0.0583\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2211, Val Loss: 0.2357\n",
      "Val RMSE: 133458.8808, Val MAE: 72352.1200, Val MSE: 17811272866.4162, Val R2: 0.0951\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2098, Val Loss: 0.2469\n",
      "Val RMSE: 137947.3572, Val MAE: 75492.8778, Val MSE: 19029473350.0954, Val R2: 0.0332\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1998, Val Loss: 0.2198\n",
      "Val RMSE: 126398.0483, Val MAE: 73025.7056, Val MSE: 15976466607.1266, Val R2: 0.1883\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1954, Val Loss: 0.2179\n",
      "Val RMSE: 127195.8887, Val MAE: 69839.2879, Val MSE: 16178794101.3846, Val R2: 0.1780\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1882, Val Loss: 0.2030\n",
      "Val RMSE: 117767.3212, Val MAE: 65589.3721, Val MSE: 13869141933.5635, Val R2: 0.2954\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1773, Val Loss: 0.1977\n",
      "Val RMSE: 111130.9570, Val MAE: 66499.9037, Val MSE: 12350089604.4980, Val R2: 0.3725\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1674, Val Loss: 0.1766\n",
      "Val RMSE: 105950.1229, Val MAE: 62536.2797, Val MSE: 11225428532.6996, Val R2: 0.4297\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1861\n",
      "Val RMSE: 107021.1168, Val MAE: 61882.1108, Val MSE: 11453519439.2980, Val R2: 0.4181\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1507, Val Loss: 0.1730\n",
      "Val RMSE: 101895.6908, Val MAE: 58561.2064, Val MSE: 10382731799.5479, Val R2: 0.4725\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1473, Val Loss: 0.1719\n",
      "Val RMSE: 101715.8988, Val MAE: 58774.2228, Val MSE: 10346124068.9784, Val R2: 0.4744\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1403, Val Loss: 0.1669\n",
      "Val RMSE: 98509.0793, Val MAE: 59094.4373, Val MSE: 9704038707.7478, Val R2: 0.5070\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1351, Val Loss: 0.1604\n",
      "Val RMSE: 96082.1848, Val MAE: 55985.2240, Val MSE: 9231786237.4448, Val R2: 0.5310\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1313, Val Loss: 0.1401\n",
      "Val RMSE: 93734.3071, Val MAE: 52644.3567, Val MSE: 8786120322.6704, Val R2: 0.5536\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1225, Val Loss: 0.1387\n",
      "Val RMSE: 93487.5504, Val MAE: 51277.9083, Val MSE: 8739922076.9753, Val R2: 0.5560\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1178, Val Loss: 0.1463\n",
      "Val RMSE: 92797.1551, Val MAE: 56107.0388, Val MSE: 8611312003.1594, Val R2: 0.5625\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1141, Val Loss: 0.1294\n",
      "Val RMSE: 90965.9656, Val MAE: 47567.7887, Val MSE: 8274806904.7568, Val R2: 0.5796\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1083, Val Loss: 0.1354\n",
      "Val RMSE: 92406.1992, Val MAE: 50695.3514, Val MSE: 8538905653.9480, Val R2: 0.5662\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1042, Val Loss: 0.1280\n",
      "Val RMSE: 89741.6638, Val MAE: 48714.4356, Val MSE: 8053566219.1161, Val R2: 0.5908\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1024, Val Loss: 0.1235\n",
      "Val RMSE: 85600.5219, Val MAE: 48596.2488, Val MSE: 7327449341.1980, Val R2: 0.6277\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1246\n",
      "Val RMSE: 85423.2068, Val MAE: 47309.4232, Val MSE: 7297124268.0498, Val R2: 0.6293\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0949, Val Loss: 0.1222\n",
      "Val RMSE: 84438.5849, Val MAE: 46650.3029, Val MSE: 7129874624.0161, Val R2: 0.6378\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1321\n",
      "Val RMSE: 88073.9390, Val MAE: 48542.2290, Val MSE: 7757018722.8401, Val R2: 0.6059\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1179\n",
      "Val RMSE: 82940.8965, Val MAE: 44584.0975, Val MSE: 6879192311.6905, Val R2: 0.6505\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1312\n",
      "Val RMSE: 86087.4249, Val MAE: 48816.1460, Val MSE: 7411044726.5468, Val R2: 0.6235\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1336\n",
      "Val RMSE: 89885.4694, Val MAE: 47213.9197, Val MSE: 8079397602.2395, Val R2: 0.5895\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0844, Val Loss: 0.1357\n",
      "Val RMSE: 86043.2464, Val MAE: 46965.5609, Val MSE: 7403440254.9446, Val R2: 0.6239\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1189\n",
      "Val RMSE: 79426.2880, Val MAE: 44349.0028, Val MSE: 6308535226.1806, Val R2: 0.6795\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1253\n",
      "Val RMSE: 82479.5794, Val MAE: 47035.0003, Val MSE: 6802881021.9807, Val R2: 0.6544\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1216\n",
      "Val RMSE: 80500.7500, Val MAE: 45546.2492, Val MSE: 6480370754.5187, Val R2: 0.6708\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1343\n",
      "Val RMSE: 85742.9671, Val MAE: 48948.2027, Val MSE: 7351856404.5629, Val R2: 0.6265\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0786, Val Loss: 0.1165\n",
      "Val RMSE: 79207.6506, Val MAE: 45791.6126, Val MSE: 6273851906.7288, Val R2: 0.6812\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1192\n",
      "Val RMSE: 79292.1665, Val MAE: 47251.9636, Val MSE: 6287247671.8245, Val R2: 0.6806\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1172\n",
      "Val RMSE: 76982.0910, Val MAE: 46511.6343, Val MSE: 5926242332.4255, Val R2: 0.6989\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1284\n",
      "Val RMSE: 81915.9952, Val MAE: 46727.1019, Val MSE: 6710230275.9264, Val R2: 0.6591\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1271\n",
      "Val RMSE: 80562.6037, Val MAE: 45486.7964, Val MSE: 6490333117.8368, Val R2: 0.6703\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1090\n",
      "Val RMSE: 75089.5797, Val MAE: 42444.9575, Val MSE: 5638444978.7335, Val R2: 0.7135\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1113\n",
      "Val RMSE: 75673.4131, Val MAE: 42771.2253, Val MSE: 5726465446.6280, Val R2: 0.7091\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1077\n",
      "Val RMSE: 74418.2767, Val MAE: 42219.2863, Val MSE: 5538079905.0689, Val R2: 0.7186\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1130\n",
      "Val RMSE: 76735.8258, Val MAE: 44501.1370, Val MSE: 5888386963.7689, Val R2: 0.7008\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1196\n",
      "Val RMSE: 79471.4518, Val MAE: 46443.2088, Val MSE: 6315711648.2607, Val R2: 0.6791\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1209\n",
      "Val RMSE: 77224.6200, Val MAE: 45478.0612, Val MSE: 5963641940.2289, Val R2: 0.6970\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0653, Val Loss: 0.1229\n",
      "Val RMSE: 77933.8229, Val MAE: 47971.6340, Val MSE: 6073680752.1882, Val R2: 0.6914\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1103\n",
      "Val RMSE: 76338.2373, Val MAE: 43742.7615, Val MSE: 5827526473.2034, Val R2: 0.7039\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1094\n",
      "Val RMSE: 75393.9345, Val MAE: 42169.6176, Val MSE: 5684245355.9180, Val R2: 0.7112\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.0982\n",
      "Val RMSE: 71179.0397, Val MAE: 39063.9934, Val MSE: 5066455697.4740, Val R2: 0.7426\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1086\n",
      "Val RMSE: 74630.2990, Val MAE: 43169.2659, Val MSE: 5569681533.7266, Val R2: 0.7170\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1031\n",
      "Val RMSE: 73450.2754, Val MAE: 40892.0030, Val MSE: 5394942949.7656, Val R2: 0.7259\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1164\n",
      "Val RMSE: 76578.1742, Val MAE: 43946.3615, Val MSE: 5864216765.6556, Val R2: 0.7021\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1042\n",
      "Val RMSE: 72749.1037, Val MAE: 41569.2786, Val MSE: 5292432091.9131, Val R2: 0.7311\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1068\n",
      "Val RMSE: 73853.0211, Val MAE: 41289.0040, Val MSE: 5454268724.3899, Val R2: 0.7229\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1089\n",
      "Val RMSE: 74624.3290, Val MAE: 42069.0082, Val MSE: 5568790480.8422, Val R2: 0.7171\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1125\n",
      "Val RMSE: 74227.6087, Val MAE: 45506.5623, Val MSE: 5509737887.1275, Val R2: 0.7201\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1115\n",
      "Val RMSE: 75393.7625, Val MAE: 44408.4850, Val MSE: 5684219420.4175, Val R2: 0.7112\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1087\n",
      "Val RMSE: 75011.1369, Val MAE: 42280.4859, Val MSE: 5626670655.1209, Val R2: 0.7141\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1022\n",
      "Val RMSE: 71636.8410, Val MAE: 40589.0075, Val MSE: 5131836989.0760, Val R2: 0.7393\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1017\n",
      "Val RMSE: 71032.7348, Val MAE: 40352.7796, Val MSE: 5045649418.5127, Val R2: 0.7436\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1131\n",
      "Val RMSE: 76959.7024, Val MAE: 42315.4072, Val MSE: 5922795790.9640, Val R2: 0.6991\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1156\n",
      "Val RMSE: 77431.0019, Val MAE: 44438.4550, Val MSE: 5995560052.6379, Val R2: 0.6954\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1064\n",
      "Val RMSE: 74301.1784, Val MAE: 40484.6651, Val MSE: 5520665117.9824, Val R2: 0.7195\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1000\n",
      "Val RMSE: 71317.7267, Val MAE: 39032.4886, Val MSE: 5086218147.6882, Val R2: 0.7416\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1005\n",
      "Val RMSE: 72155.5835, Val MAE: 39733.5027, Val MSE: 5206428236.4804, Val R2: 0.7355\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1074\n",
      "Val RMSE: 74743.7095, Val MAE: 40668.4315, Val MSE: 5586622115.5562, Val R2: 0.7162\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1045\n",
      "Val RMSE: 72988.4200, Val MAE: 40753.2932, Val MSE: 5327309453.4518, Val R2: 0.7293\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1055\n",
      "Val RMSE: 72234.1665, Val MAE: 40270.3343, Val MSE: 5217774807.9195, Val R2: 0.7349\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1002\n",
      "Val RMSE: 71905.6720, Val MAE: 38383.3429, Val MSE: 5170425670.8870, Val R2: 0.7373\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.0936\n",
      "Val RMSE: 67822.3770, Val MAE: 37806.8769, Val MSE: 4599874827.4264, Val R2: 0.7663\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1015\n",
      "Val RMSE: 71912.9239, Val MAE: 39095.1998, Val MSE: 5171468621.5798, Val R2: 0.7373\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1119\n",
      "Val RMSE: 74641.9349, Val MAE: 41718.9676, Val MSE: 5571418442.6940, Val R2: 0.7169\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1083\n",
      "Val RMSE: 74357.4602, Val MAE: 40078.6941, Val MSE: 5529031889.6770, Val R2: 0.7191\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1154\n",
      "Val RMSE: 77240.9069, Val MAE: 43216.9160, Val MSE: 5966157698.6295, Val R2: 0.6969\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.0953\n",
      "Val RMSE: 68814.0002, Val MAE: 37510.5155, Val MSE: 4735366622.2492, Val R2: 0.7594\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.0933\n",
      "Val RMSE: 69727.3220, Val MAE: 37652.9365, Val MSE: 4861899437.9022, Val R2: 0.7530\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.1062\n",
      "Val RMSE: 74516.6168, Val MAE: 42700.9087, Val MSE: 5552726178.0959, Val R2: 0.7179\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1086\n",
      "Val RMSE: 75045.2256, Val MAE: 41567.2913, Val MSE: 5631785882.5930, Val R2: 0.7139\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.1005\n",
      "Val RMSE: 72968.3206, Val MAE: 38790.0461, Val MSE: 5324375808.2054, Val R2: 0.7295\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1100\n",
      "Val RMSE: 76635.0692, Val MAE: 39864.5305, Val MSE: 5872933827.1964, Val R2: 0.7016\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 70920.3088, Test MAE: 37093.6303, Test MSE: 5029690205.8837, Test R2: 0.6776\n",
      "Inference Time: 2.318760064932016e-05 seconds per sample\n",
      "\n",
      "Iteration 19 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3984, Val Loss: 0.2865\n",
      "Val RMSE: 143007.3908, Val MAE: 84324.2235, Val MSE: 20451113834.7120, Val R2: -0.0390\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2889, Val Loss: 0.2899\n",
      "Val RMSE: 144601.5839, Val MAE: 82279.7298, Val MSE: 20909618079.7992, Val R2: -0.0623\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2774, Val Loss: 0.2748\n",
      "Val RMSE: 141070.0938, Val MAE: 84243.8807, Val MSE: 19900771375.9470, Val R2: -0.0111\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2725, Val Loss: 0.2752\n",
      "Val RMSE: 141831.9026, Val MAE: 83021.8636, Val MSE: 20116288608.2912, Val R2: -0.0220\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2695, Val Loss: 0.2758\n",
      "Val RMSE: 143176.7418, Val MAE: 80635.2328, Val MSE: 20499579386.8323, Val R2: -0.0415\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2616, Val Loss: 0.2727\n",
      "Val RMSE: 141968.5142, Val MAE: 82546.5459, Val MSE: 20155059034.0805, Val R2: -0.0240\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2778\n",
      "Val RMSE: 140363.3848, Val MAE: 87723.1866, Val MSE: 19701879805.2260, Val R2: -0.0010\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2742\n",
      "Val RMSE: 142402.0978, Val MAE: 81062.8669, Val MSE: 20278357452.3400, Val R2: -0.0303\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2694\n",
      "Val RMSE: 140764.6682, Val MAE: 82230.0825, Val MSE: 19814691823.0056, Val R2: -0.0067\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2714\n",
      "Val RMSE: 142231.7509, Val MAE: 79216.9200, Val MSE: 20229870960.2007, Val R2: -0.0278\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2673\n",
      "Val RMSE: 140204.1155, Val MAE: 81536.9653, Val MSE: 19657194014.2075, Val R2: 0.0013\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2482, Val Loss: 0.2667\n",
      "Val RMSE: 139634.4327, Val MAE: 81340.8549, Val MSE: 19497774799.1407, Val R2: 0.0094\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2471, Val Loss: 0.2629\n",
      "Val RMSE: 140307.4327, Val MAE: 79024.3383, Val MSE: 19686175678.6879, Val R2: -0.0002\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2396, Val Loss: 0.2555\n",
      "Val RMSE: 137302.9850, Val MAE: 75266.0799, Val MSE: 18852109686.1483, Val R2: 0.0422\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2292, Val Loss: 0.2323\n",
      "Val RMSE: 129452.8375, Val MAE: 76396.6804, Val MSE: 16758037137.4453, Val R2: 0.1486\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2264, Val Loss: 0.2393\n",
      "Val RMSE: 131270.4505, Val MAE: 75626.2719, Val MSE: 17231931166.4089, Val R2: 0.1245\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2205, Val Loss: 0.2505\n",
      "Val RMSE: 132084.6997, Val MAE: 79949.0946, Val MSE: 17446367906.9074, Val R2: 0.1136\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2132, Val Loss: 0.2356\n",
      "Val RMSE: 131746.1246, Val MAE: 74938.1773, Val MSE: 17357041348.1060, Val R2: 0.1182\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2057, Val Loss: 0.2241\n",
      "Val RMSE: 127906.0788, Val MAE: 72459.2017, Val MSE: 16359965002.5897, Val R2: 0.1688\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2031, Val Loss: 0.2233\n",
      "Val RMSE: 126831.5669, Val MAE: 72761.5470, Val MSE: 16086246374.2125, Val R2: 0.1827\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1991, Val Loss: 0.2179\n",
      "Val RMSE: 125609.3998, Val MAE: 70325.8156, Val MSE: 15777721315.5806, Val R2: 0.1984\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1939, Val Loss: 0.2251\n",
      "Val RMSE: 129490.7923, Val MAE: 69141.2744, Val MSE: 16767865300.7494, Val R2: 0.1481\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1924, Val Loss: 0.2243\n",
      "Val RMSE: 128684.9778, Val MAE: 68938.7223, Val MSE: 16559823509.0333, Val R2: 0.1587\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1870, Val Loss: 0.2219\n",
      "Val RMSE: 127042.5185, Val MAE: 69696.8955, Val MSE: 16139801504.3693, Val R2: 0.1800\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1804, Val Loss: 0.1989\n",
      "Val RMSE: 120389.6633, Val MAE: 64860.9189, Val MSE: 14493671040.2977, Val R2: 0.2636\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1742, Val Loss: 0.1936\n",
      "Val RMSE: 112679.1135, Val MAE: 64337.7341, Val MSE: 12696582613.3966, Val R2: 0.3549\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1644, Val Loss: 0.1927\n",
      "Val RMSE: 110085.9473, Val MAE: 62675.3384, Val MSE: 12118915798.4539, Val R2: 0.3843\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1575, Val Loss: 0.1786\n",
      "Val RMSE: 103606.6240, Val MAE: 61970.7989, Val MSE: 10734332534.2014, Val R2: 0.4546\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1689\n",
      "Val RMSE: 100446.3766, Val MAE: 57508.9097, Val MSE: 10089474572.8469, Val R2: 0.4874\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1511, Val Loss: 0.1774\n",
      "Val RMSE: 103459.6499, Val MAE: 59499.7987, Val MSE: 10703899156.9413, Val R2: 0.4562\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1557\n",
      "Val RMSE: 96906.6524, Val MAE: 55152.3107, Val MSE: 9390899288.2546, Val R2: 0.5229\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1418, Val Loss: 0.1647\n",
      "Val RMSE: 98001.4000, Val MAE: 56689.7982, Val MSE: 9604274408.4798, Val R2: 0.5120\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1386, Val Loss: 0.1444\n",
      "Val RMSE: 93752.1526, Val MAE: 53178.9828, Val MSE: 8789466110.7120, Val R2: 0.5534\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1378, Val Loss: 0.1479\n",
      "Val RMSE: 95009.3922, Val MAE: 53472.7541, Val MSE: 9026784607.5371, Val R2: 0.5414\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1351, Val Loss: 0.1568\n",
      "Val RMSE: 97085.0068, Val MAE: 54804.3078, Val MSE: 9425498548.9235, Val R2: 0.5211\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1353, Val Loss: 0.1600\n",
      "Val RMSE: 94665.9423, Val MAE: 56061.5455, Val MSE: 8961640628.8005, Val R2: 0.5447\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1307, Val Loss: 0.1428\n",
      "Val RMSE: 92420.2722, Val MAE: 52737.7841, Val MSE: 8541506718.6384, Val R2: 0.5660\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1272, Val Loss: 0.1471\n",
      "Val RMSE: 93830.1199, Val MAE: 52588.4658, Val MSE: 8804091401.4510, Val R2: 0.5527\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1240, Val Loss: 0.1325\n",
      "Val RMSE: 89501.8420, Val MAE: 49576.9326, Val MSE: 8010579726.7101, Val R2: 0.5930\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1202, Val Loss: 0.1520\n",
      "Val RMSE: 95932.7179, Val MAE: 51588.3802, Val MSE: 9203086364.1386, Val R2: 0.5324\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1397\n",
      "Val RMSE: 90395.0986, Val MAE: 51089.7791, Val MSE: 8171273856.0954, Val R2: 0.5848\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1113, Val Loss: 0.1375\n",
      "Val RMSE: 88398.1240, Val MAE: 50283.0895, Val MSE: 7814228327.6913, Val R2: 0.6030\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1262\n",
      "Val RMSE: 87723.7893, Val MAE: 46548.8243, Val MSE: 7695463214.0821, Val R2: 0.6090\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1306\n",
      "Val RMSE: 88247.1365, Val MAE: 46969.2335, Val MSE: 7787557092.3704, Val R2: 0.6043\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0936, Val Loss: 0.1271\n",
      "Val RMSE: 87255.7271, Val MAE: 47828.3810, Val MSE: 7613561910.5391, Val R2: 0.6132\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1291\n",
      "Val RMSE: 87924.5468, Val MAE: 47821.0548, Val MSE: 7730725932.9590, Val R2: 0.6072\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1242\n",
      "Val RMSE: 85057.3930, Val MAE: 48723.2755, Val MSE: 7234760099.3624, Val R2: 0.6324\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0876, Val Loss: 0.1315\n",
      "Val RMSE: 88309.4779, Val MAE: 51073.5405, Val MSE: 7798563880.1589, Val R2: 0.6038\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1272\n",
      "Val RMSE: 85041.5649, Val MAE: 46715.2755, Val MSE: 7232067759.9990, Val R2: 0.6326\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0849, Val Loss: 0.1389\n",
      "Val RMSE: 88213.2077, Val MAE: 52307.1667, Val MSE: 7781570009.0290, Val R2: 0.6046\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1219\n",
      "Val RMSE: 82681.7552, Val MAE: 46356.2523, Val MSE: 6836272649.4216, Val R2: 0.6527\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0810, Val Loss: 0.1322\n",
      "Val RMSE: 86354.5717, Val MAE: 50469.3126, Val MSE: 7457112050.2936, Val R2: 0.6211\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1485\n",
      "Val RMSE: 88591.5252, Val MAE: 54315.5165, Val MSE: 7848458329.2567, Val R2: 0.6012\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1398\n",
      "Val RMSE: 88202.5063, Val MAE: 51894.4986, Val MSE: 7779682120.3491, Val R2: 0.6047\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1368\n",
      "Val RMSE: 89295.7862, Val MAE: 48986.5509, Val MSE: 7973737440.4937, Val R2: 0.5949\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0830, Val Loss: 0.1389\n",
      "Val RMSE: 86163.7295, Val MAE: 53759.7832, Val MSE: 7424188273.7795, Val R2: 0.6228\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1590\n",
      "Val RMSE: 92710.7067, Val MAE: 56258.9812, Val MSE: 8595275135.5532, Val R2: 0.5633\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1343\n",
      "Val RMSE: 85030.6259, Val MAE: 50349.1954, Val MSE: 7230207338.3675, Val R2: 0.6327\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1299\n",
      "Val RMSE: 83441.2908, Val MAE: 49015.4706, Val MSE: 6962449014.6400, Val R2: 0.6463\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1359\n",
      "Val RMSE: 85154.1192, Val MAE: 50537.5640, Val MSE: 7251224013.1169, Val R2: 0.6316\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1420\n",
      "Val RMSE: 85818.0319, Val MAE: 51996.2121, Val MSE: 7364734607.1934, Val R2: 0.6258\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1211\n",
      "Val RMSE: 81239.3371, Val MAE: 45141.9780, Val MSE: 6599829899.3889, Val R2: 0.6647\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1238\n",
      "Val RMSE: 81577.0099, Val MAE: 45897.7476, Val MSE: 6654808547.0227, Val R2: 0.6619\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0671, Val Loss: 0.1215\n",
      "Val RMSE: 79025.7546, Val MAE: 45672.0141, Val MSE: 6245069890.4319, Val R2: 0.6827\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1188\n",
      "Val RMSE: 78558.3594, Val MAE: 47469.9587, Val MSE: 6171415835.3910, Val R2: 0.6865\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.1302\n",
      "Val RMSE: 82992.5305, Val MAE: 50401.2195, Val MSE: 6887760117.5117, Val R2: 0.6501\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1239\n",
      "Val RMSE: 79643.2105, Val MAE: 47221.4639, Val MSE: 6343040983.4298, Val R2: 0.6777\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1121\n",
      "Val RMSE: 76045.1546, Val MAE: 44003.4813, Val MSE: 5782865541.3277, Val R2: 0.7062\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1132\n",
      "Val RMSE: 76402.2554, Val MAE: 43680.2653, Val MSE: 5837304624.0985, Val R2: 0.7034\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1153\n",
      "Val RMSE: 77974.7097, Val MAE: 44346.1855, Val MSE: 6080055345.1246, Val R2: 0.6911\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1095\n",
      "Val RMSE: 75047.9831, Val MAE: 41770.2841, Val MSE: 5632199762.2021, Val R2: 0.7138\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1138\n",
      "Val RMSE: 76867.1964, Val MAE: 45092.3053, Val MSE: 5908565881.2260, Val R2: 0.6998\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1193\n",
      "Val RMSE: 78475.4750, Val MAE: 45178.4240, Val MSE: 6158400181.7937, Val R2: 0.6871\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1116\n",
      "Val RMSE: 74680.0335, Val MAE: 45144.7663, Val MSE: 5577107398.6202, Val R2: 0.7166\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1266\n",
      "Val RMSE: 80656.5330, Val MAE: 48714.7922, Val MSE: 6505476318.1619, Val R2: 0.6695\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1121\n",
      "Val RMSE: 76383.7770, Val MAE: 43659.2448, Val MSE: 5834481390.9383, Val R2: 0.7036\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1161\n",
      "Val RMSE: 77330.9497, Val MAE: 43530.8546, Val MSE: 5980075788.5180, Val R2: 0.6962\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1106\n",
      "Val RMSE: 74913.9238, Val MAE: 41625.0815, Val MSE: 5612095975.7592, Val R2: 0.7149\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1176\n",
      "Val RMSE: 78916.3262, Val MAE: 44901.9512, Val MSE: 6227786537.1882, Val R2: 0.6836\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1148\n",
      "Val RMSE: 75964.1672, Val MAE: 45267.0544, Val MSE: 5770554694.2524, Val R2: 0.7068\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1219\n",
      "Val RMSE: 79709.9107, Val MAE: 45470.6979, Val MSE: 6353669869.7712, Val R2: 0.6772\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1217\n",
      "Val RMSE: 78170.4160, Val MAE: 46979.4816, Val MSE: 6110613943.0366, Val R2: 0.6895\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1145\n",
      "Val RMSE: 76186.8891, Val MAE: 42374.6219, Val MSE: 5804442073.7918, Val R2: 0.7051\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1400\n",
      "Val RMSE: 87603.5255, Val MAE: 48186.5750, Val MSE: 7674377680.5827, Val R2: 0.6101\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1139\n",
      "Val RMSE: 76809.1188, Val MAE: 45181.0083, Val MSE: 5899640736.3781, Val R2: 0.7003\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1169\n",
      "Val RMSE: 77709.3189, Val MAE: 45947.7059, Val MSE: 6038738241.6799, Val R2: 0.6932\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1143\n",
      "Val RMSE: 77358.3555, Val MAE: 45259.0537, Val MSE: 5984315168.0322, Val R2: 0.6960\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1275\n",
      "Val RMSE: 82194.2650, Val MAE: 47899.6816, Val MSE: 6755897196.3336, Val R2: 0.6568\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1250\n",
      "Val RMSE: 80009.8248, Val MAE: 44466.0469, Val MSE: 6401572063.2167, Val R2: 0.6748\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1252\n",
      "Val RMSE: 79725.2512, Val MAE: 45469.1517, Val MSE: 6356115677.9796, Val R2: 0.6771\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1200\n",
      "Val RMSE: 78680.3078, Val MAE: 43843.2873, Val MSE: 6190590837.4032, Val R2: 0.6855\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1089\n",
      "Val RMSE: 73956.1881, Val MAE: 42063.0428, Val MSE: 5469517755.3561, Val R2: 0.7221\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1407\n",
      "Val RMSE: 85307.4310, Val MAE: 50699.3517, Val MSE: 7277357775.5910, Val R2: 0.6303\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1217\n",
      "Val RMSE: 78959.8241, Val MAE: 42359.1300, Val MSE: 6234653822.7453, Val R2: 0.6832\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1257\n",
      "Val RMSE: 81100.8239, Val MAE: 46735.9162, Val MSE: 6577343642.7600, Val R2: 0.6658\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.1299\n",
      "Val RMSE: 81770.7615, Val MAE: 48246.1376, Val MSE: 6686457432.9139, Val R2: 0.6603\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1652\n",
      "Val RMSE: 98766.3314, Val MAE: 53121.0225, Val MSE: 9754788211.2079, Val R2: 0.5044\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1299\n",
      "Val RMSE: 81475.9949, Val MAE: 48136.6334, Val MSE: 6638337752.1576, Val R2: 0.6627\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1760\n",
      "Val RMSE: 109875.1431, Val MAE: 55705.2746, Val MSE: 12072547067.3114, Val R2: 0.3866\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1498\n",
      "Val RMSE: 90968.3988, Val MAE: 50615.2427, Val MSE: 8275249579.1341, Val R2: 0.5796\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74970.2735, Test MAE: 43185.5963, Test MSE: 5620541903.2074, Test R2: 0.6397\n",
      "Inference Time: 1.9817242255577676e-05 seconds per sample\n",
      "\n",
      "Iteration 20 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3829, Val Loss: 0.3096\n",
      "Val RMSE: 148627.0168, Val MAE: 82626.3992, Val MSE: 22089990128.1135, Val R2: -0.1223\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2852, Val Loss: 0.2866\n",
      "Val RMSE: 142737.9771, Val MAE: 84980.9561, Val MSE: 20374130100.7721, Val R2: -0.0351\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2764, Val Loss: 0.2844\n",
      "Val RMSE: 142037.9593, Val MAE: 85778.6447, Val MSE: 20174781878.6082, Val R2: -0.0250\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2725, Val Loss: 0.2841\n",
      "Val RMSE: 143137.7032, Val MAE: 82960.4336, Val MSE: 20488402067.0443, Val R2: -0.0409\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2654, Val Loss: 0.2816\n",
      "Val RMSE: 143667.4965, Val MAE: 81154.8711, Val MSE: 20640349546.4738, Val R2: -0.0487\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2674, Val Loss: 0.2747\n",
      "Val RMSE: 141127.3520, Val MAE: 83970.0851, Val MSE: 19916929496.4598, Val R2: -0.0119\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2760\n",
      "Val RMSE: 143445.9396, Val MAE: 80888.5544, Val MSE: 20576737577.4479, Val R2: -0.0454\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2718\n",
      "Val RMSE: 140714.9145, Val MAE: 83077.5353, Val MSE: 19800687172.5536, Val R2: -0.0060\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2583, Val Loss: 0.2883\n",
      "Val RMSE: 143242.0730, Val MAE: 88168.0112, Val MSE: 20518291469.9267, Val R2: -0.0425\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2705\n",
      "Val RMSE: 141824.5095, Val MAE: 80734.0164, Val MSE: 20114191488.2857, Val R2: -0.0219\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2706\n",
      "Val RMSE: 141921.6782, Val MAE: 82072.8954, Val MSE: 20141762736.1451, Val R2: -0.0233\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2676\n",
      "Val RMSE: 141530.8352, Val MAE: 80831.0692, Val MSE: 20030977323.1484, Val R2: -0.0177\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2500, Val Loss: 0.2686\n",
      "Val RMSE: 141415.2411, Val MAE: 80638.5683, Val MSE: 19998270413.0535, Val R2: -0.0160\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2498, Val Loss: 0.2577\n",
      "Val RMSE: 138775.4633, Val MAE: 77192.6528, Val MSE: 19258629223.8165, Val R2: 0.0215\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2459, Val Loss: 0.2558\n",
      "Val RMSE: 136818.8196, Val MAE: 77524.2541, Val MSE: 18719389392.1025, Val R2: 0.0489\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2390, Val Loss: 0.2551\n",
      "Val RMSE: 137155.2315, Val MAE: 73384.3626, Val MSE: 18811557533.0221, Val R2: 0.0443\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2326, Val Loss: 0.2620\n",
      "Val RMSE: 135607.3419, Val MAE: 77492.4498, Val MSE: 18389351170.2223, Val R2: 0.0657\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2268, Val Loss: 0.2351\n",
      "Val RMSE: 130336.0047, Val MAE: 74906.9930, Val MSE: 16987474128.4738, Val R2: 0.1369\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2392\n",
      "Val RMSE: 134091.0179, Val MAE: 75699.9620, Val MSE: 17980401085.2322, Val R2: 0.0865\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2164, Val Loss: 0.2469\n",
      "Val RMSE: 138515.0473, Val MAE: 72897.2363, Val MSE: 19186418323.4915, Val R2: 0.0252\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2498\n",
      "Val RMSE: 139770.7521, Val MAE: 75081.9039, Val MSE: 19535863132.1820, Val R2: 0.0075\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2083, Val Loss: 0.2340\n",
      "Val RMSE: 131716.4519, Val MAE: 73093.5148, Val MSE: 17349223692.8448, Val R2: 0.1185\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2101, Val Loss: 0.2437\n",
      "Val RMSE: 136763.5796, Val MAE: 71106.5955, Val MSE: 18704276692.3015, Val R2: 0.0497\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2385\n",
      "Val RMSE: 133507.7581, Val MAE: 70686.9620, Val MSE: 17824321461.1898, Val R2: 0.0944\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2042, Val Loss: 0.2381\n",
      "Val RMSE: 130827.3670, Val MAE: 70425.0317, Val MSE: 17115799966.3919, Val R2: 0.1304\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2102, Val Loss: 0.2304\n",
      "Val RMSE: 128652.3983, Val MAE: 74578.3795, Val MSE: 16551439589.2743, Val R2: 0.1591\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1896, Val Loss: 0.2172\n",
      "Val RMSE: 118158.6728, Val MAE: 70679.8122, Val MSE: 13961471953.2967, Val R2: 0.2907\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1831, Val Loss: 0.2157\n",
      "Val RMSE: 118720.5367, Val MAE: 69565.0573, Val MSE: 14094565826.1489, Val R2: 0.2839\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.1893\n",
      "Val RMSE: 105704.6352, Val MAE: 63285.2018, Val MSE: 11173469895.5985, Val R2: 0.4323\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1671, Val Loss: 0.1778\n",
      "Val RMSE: 102300.0575, Val MAE: 62181.1985, Val MSE: 10465301766.9156, Val R2: 0.4683\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1620, Val Loss: 0.1665\n",
      "Val RMSE: 99509.7233, Val MAE: 59718.4529, Val MSE: 9902185035.8887, Val R2: 0.4969\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1545, Val Loss: 0.1677\n",
      "Val RMSE: 100175.5574, Val MAE: 58699.4417, Val MSE: 10035142296.3211, Val R2: 0.4902\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1514, Val Loss: 0.1651\n",
      "Val RMSE: 99854.6407, Val MAE: 57869.4246, Val MSE: 9970949275.9042, Val R2: 0.4934\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1477, Val Loss: 0.1583\n",
      "Val RMSE: 97430.1618, Val MAE: 56486.7082, Val MSE: 9492636420.0388, Val R2: 0.5177\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1454, Val Loss: 0.1636\n",
      "Val RMSE: 98905.3654, Val MAE: 57889.3336, Val MSE: 9782271313.3576, Val R2: 0.5030\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1429, Val Loss: 0.1593\n",
      "Val RMSE: 98191.8262, Val MAE: 55249.6668, Val MSE: 9641634723.1662, Val R2: 0.5101\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1404, Val Loss: 0.1649\n",
      "Val RMSE: 96181.9685, Val MAE: 58474.6694, Val MSE: 9250971070.8766, Val R2: 0.5300\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1478\n",
      "Val RMSE: 94313.1623, Val MAE: 53808.6407, Val MSE: 8894972584.5111, Val R2: 0.5481\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1307, Val Loss: 0.1630\n",
      "Val RMSE: 98022.9448, Val MAE: 58574.7735, Val MSE: 9608497704.9636, Val R2: 0.5118\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1278, Val Loss: 0.1493\n",
      "Val RMSE: 94822.0288, Val MAE: 55561.9041, Val MSE: 8991217150.9098, Val R2: 0.5432\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1223, Val Loss: 0.1678\n",
      "Val RMSE: 97618.2166, Val MAE: 61014.1454, Val MSE: 9529316221.6656, Val R2: 0.5159\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1180, Val Loss: 0.1363\n",
      "Val RMSE: 90695.9310, Val MAE: 51397.8592, Val MSE: 8225751906.5051, Val R2: 0.5821\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1139, Val Loss: 0.1477\n",
      "Val RMSE: 93304.4045, Val MAE: 57054.8911, Val MSE: 8705711907.2607, Val R2: 0.5577\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1131, Val Loss: 0.1494\n",
      "Val RMSE: 93083.7915, Val MAE: 53206.3238, Val MSE: 8664592244.7421, Val R2: 0.5598\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1108, Val Loss: 0.1404\n",
      "Val RMSE: 90943.8731, Val MAE: 55371.5872, Val MSE: 8270788048.2268, Val R2: 0.5798\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1085, Val Loss: 0.1478\n",
      "Val RMSE: 91669.4250, Val MAE: 51487.7527, Val MSE: 8403283472.5474, Val R2: 0.5731\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1507\n",
      "Val RMSE: 93453.8377, Val MAE: 57009.8371, Val MSE: 8733619785.9007, Val R2: 0.5563\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1048, Val Loss: 0.1662\n",
      "Val RMSE: 96258.2918, Val MAE: 61337.6366, Val MSE: 9265658741.3202, Val R2: 0.5292\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1402\n",
      "Val RMSE: 88232.1365, Val MAE: 51429.4403, Val MSE: 7784909915.2449, Val R2: 0.6045\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0979, Val Loss: 0.1312\n",
      "Val RMSE: 82299.7761, Val MAE: 49404.3177, Val MSE: 6773253153.4824, Val R2: 0.6559\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1381\n",
      "Val RMSE: 88790.8501, Val MAE: 51637.8012, Val MSE: 7883815070.3330, Val R2: 0.5995\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1310\n",
      "Val RMSE: 84936.5449, Val MAE: 47571.9515, Val MSE: 7214216656.7172, Val R2: 0.6335\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1341\n",
      "Val RMSE: 86080.1404, Val MAE: 48895.4635, Val MSE: 7409790568.9057, Val R2: 0.6235\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1471\n",
      "Val RMSE: 85907.0203, Val MAE: 58198.1370, Val MSE: 7380016141.1586, Val R2: 0.6250\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0957, Val Loss: 0.1477\n",
      "Val RMSE: 86663.3079, Val MAE: 52496.0021, Val MSE: 7510528928.1924, Val R2: 0.6184\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0913, Val Loss: 0.1345\n",
      "Val RMSE: 82042.6431, Val MAE: 51591.3824, Val MSE: 6730995289.2265, Val R2: 0.6580\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0844, Val Loss: 0.1399\n",
      "Val RMSE: 84097.5491, Val MAE: 54397.2815, Val MSE: 7072397768.3333, Val R2: 0.6407\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0853, Val Loss: 0.1428\n",
      "Val RMSE: 84642.2227, Val MAE: 57011.3859, Val MSE: 7164305856.8294, Val R2: 0.6360\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1315\n",
      "Val RMSE: 80346.6300, Val MAE: 50562.6511, Val MSE: 6455580958.4373, Val R2: 0.6720\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1233\n",
      "Val RMSE: 79126.8746, Val MAE: 47805.9386, Val MSE: 6261062290.8053, Val R2: 0.6819\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1249\n",
      "Val RMSE: 79961.8828, Val MAE: 48024.2028, Val MSE: 6393902703.1130, Val R2: 0.6751\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1192\n",
      "Val RMSE: 75722.3338, Val MAE: 48160.7970, Val MSE: 5733871828.7332, Val R2: 0.7087\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1198\n",
      "Val RMSE: 77277.5105, Val MAE: 47886.4700, Val MSE: 5971813636.6654, Val R2: 0.6966\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1233\n",
      "Val RMSE: 76058.2288, Val MAE: 50234.7460, Val MSE: 5784854165.5601, Val R2: 0.7061\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1291\n",
      "Val RMSE: 79285.8040, Val MAE: 48459.9473, Val MSE: 6286238720.3326, Val R2: 0.6806\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0747, Val Loss: 0.1169\n",
      "Val RMSE: 76775.6246, Val MAE: 46166.2464, Val MSE: 5894496535.1856, Val R2: 0.7005\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1177\n",
      "Val RMSE: 73875.1793, Val MAE: 47393.3237, Val MSE: 5457542113.9276, Val R2: 0.7227\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1275\n",
      "Val RMSE: 79667.1845, Val MAE: 50384.7184, Val MSE: 6346860286.9152, Val R2: 0.6775\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1279\n",
      "Val RMSE: 78391.1033, Val MAE: 51301.9469, Val MSE: 6145165081.0597, Val R2: 0.6878\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1203\n",
      "Val RMSE: 74039.9625, Val MAE: 51019.3065, Val MSE: 5481916047.1054, Val R2: 0.7215\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1182\n",
      "Val RMSE: 74122.2576, Val MAE: 47083.7884, Val MSE: 5494109075.4844, Val R2: 0.7209\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1338\n",
      "Val RMSE: 81541.9816, Val MAE: 52584.3248, Val MSE: 6649094765.3107, Val R2: 0.6622\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1336\n",
      "Val RMSE: 79808.3810, Val MAE: 51829.9487, Val MSE: 6369377675.3334, Val R2: 0.6764\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1141\n",
      "Val RMSE: 72851.4313, Val MAE: 47492.0506, Val MSE: 5307331042.9515, Val R2: 0.7304\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1116\n",
      "Val RMSE: 71478.0637, Val MAE: 44236.1530, Val MSE: 5109113591.7712, Val R2: 0.7404\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1243\n",
      "Val RMSE: 76872.7270, Val MAE: 51759.9090, Val MSE: 5909416152.6733, Val R2: 0.6998\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1326\n",
      "Val RMSE: 81981.9412, Val MAE: 51949.0299, Val MSE: 6721038675.8840, Val R2: 0.6585\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1253\n",
      "Val RMSE: 78392.6607, Val MAE: 48354.6418, Val MSE: 6145409254.5489, Val R2: 0.6878\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1044\n",
      "Val RMSE: 71117.7263, Val MAE: 43635.9938, Val MSE: 5057730990.1565, Val R2: 0.7430\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1344\n",
      "Val RMSE: 80014.1218, Val MAE: 53566.5112, Val MSE: 6402259690.5712, Val R2: 0.6747\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1195\n",
      "Val RMSE: 73521.6127, Val MAE: 45441.1737, Val MSE: 5405427533.1197, Val R2: 0.7254\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1036\n",
      "Val RMSE: 67517.2495, Val MAE: 43489.5446, Val MSE: 4558578979.2379, Val R2: 0.7684\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1068\n",
      "Val RMSE: 69068.5486, Val MAE: 43824.6303, Val MSE: 4770464404.0140, Val R2: 0.7576\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0579, Val Loss: 0.0978\n",
      "Val RMSE: 64791.8705, Val MAE: 41064.8464, Val MSE: 4197986487.6175, Val R2: 0.7867\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1515\n",
      "Val RMSE: 82364.3251, Val MAE: 58184.9919, Val MSE: 6783882055.1388, Val R2: 0.6553\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.0962\n",
      "Val RMSE: 65147.4317, Val MAE: 41225.6909, Val MSE: 4244187855.1918, Val R2: 0.7844\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1093\n",
      "Val RMSE: 71774.5715, Val MAE: 44566.4703, Val MSE: 5151589109.4590, Val R2: 0.7383\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1077\n",
      "Val RMSE: 70853.6133, Val MAE: 44417.1504, Val MSE: 5020234521.0174, Val R2: 0.7449\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.0943\n",
      "Val RMSE: 65980.6473, Val MAE: 39249.3516, Val MSE: 4353445819.2314, Val R2: 0.7788\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1027\n",
      "Val RMSE: 66037.8114, Val MAE: 41402.9144, Val MSE: 4360992530.1687, Val R2: 0.7784\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1054\n",
      "Val RMSE: 70016.8330, Val MAE: 44640.6662, Val MSE: 4902356905.6794, Val R2: 0.7509\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1106\n",
      "Val RMSE: 71797.3141, Val MAE: 46408.4857, Val MSE: 5154854309.1124, Val R2: 0.7381\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1155\n",
      "Val RMSE: 72306.9609, Val MAE: 47491.3205, Val MSE: 5228296589.9872, Val R2: 0.7344\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1105\n",
      "Val RMSE: 71619.8927, Val MAE: 45564.0807, Val MSE: 5129409030.5474, Val R2: 0.7394\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.0954\n",
      "Val RMSE: 66571.1048, Val MAE: 41175.4919, Val MSE: 4431711995.0280, Val R2: 0.7748\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1015\n",
      "Val RMSE: 69787.3206, Val MAE: 41157.3539, Val MSE: 4870270110.7474, Val R2: 0.7526\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1015\n",
      "Val RMSE: 68433.9199, Val MAE: 40215.0657, Val MSE: 4683201397.6975, Val R2: 0.7621\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.0917\n",
      "Val RMSE: 65538.1255, Val MAE: 38288.2280, Val MSE: 4295245888.0641, Val R2: 0.7818\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1257\n",
      "Val RMSE: 77259.5205, Val MAE: 49001.8416, Val MSE: 5969033502.8195, Val R2: 0.6967\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1034\n",
      "Val RMSE: 69861.3004, Val MAE: 43319.0855, Val MSE: 4880601290.0897, Val R2: 0.7520\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69210.3958, Test MAE: 38321.0972, Test MSE: 4790078884.2624, Test R2: 0.6930\n",
      "Inference Time: 2.424309803889348e-05 seconds per sample\n",
      "\n",
      "Iteration 21 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3736, Val Loss: 0.2932\n",
      "Val RMSE: 145617.2446, Val MAE: 81561.1603, Val MSE: 21204381927.5691, Val R2: -0.0773\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2773, Val Loss: 0.2803\n",
      "Val RMSE: 142899.0272, Val MAE: 82165.1073, Val MSE: 20420131980.6938, Val R2: -0.0375\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2687, Val Loss: 0.2756\n",
      "Val RMSE: 141307.9486, Val MAE: 83733.6213, Val MSE: 19967936328.0570, Val R2: -0.0145\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2767\n",
      "Val RMSE: 142079.4197, Val MAE: 82686.3063, Val MSE: 20186561495.7473, Val R2: -0.0256\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2660, Val Loss: 0.2760\n",
      "Val RMSE: 141788.9994, Val MAE: 83072.8474, Val MSE: 20104120337.8284, Val R2: -0.0214\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2634, Val Loss: 0.2829\n",
      "Val RMSE: 140307.9566, Val MAE: 90002.3780, Val MSE: 19686322690.2102, Val R2: -0.0002\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2748\n",
      "Val RMSE: 142406.8640, Val MAE: 80706.7857, Val MSE: 20279714902.7789, Val R2: -0.0303\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2720\n",
      "Val RMSE: 141052.3744, Val MAE: 82796.2816, Val MSE: 19895772333.1260, Val R2: -0.0108\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2753\n",
      "Val RMSE: 142543.6810, Val MAE: 80360.9227, Val MSE: 20318700990.5072, Val R2: -0.0323\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2806\n",
      "Val RMSE: 144112.5148, Val MAE: 79766.1835, Val MSE: 20768416922.8035, Val R2: -0.0552\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2662\n",
      "Val RMSE: 140712.0499, Val MAE: 80872.4330, Val MSE: 19799881000.6994, Val R2: -0.0060\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2510, Val Loss: 0.2731\n",
      "Val RMSE: 141754.6336, Val MAE: 81856.2575, Val MSE: 20094376142.6761, Val R2: -0.0209\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2638\n",
      "Val RMSE: 140102.8046, Val MAE: 78089.3263, Val MSE: 19628795851.2292, Val R2: 0.0027\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2394, Val Loss: 0.2570\n",
      "Val RMSE: 136346.0339, Val MAE: 75913.7099, Val MSE: 18590240970.3893, Val R2: 0.0555\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2348, Val Loss: 0.2536\n",
      "Val RMSE: 135956.3042, Val MAE: 75893.5260, Val MSE: 18484116643.2509, Val R2: 0.0609\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2272, Val Loss: 0.2502\n",
      "Val RMSE: 135871.6308, Val MAE: 73071.3883, Val MSE: 18461100053.5974, Val R2: 0.0621\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2194, Val Loss: 0.2397\n",
      "Val RMSE: 135442.9587, Val MAE: 70959.9027, Val MSE: 18344795070.8306, Val R2: 0.0680\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2193, Val Loss: 0.2448\n",
      "Val RMSE: 132650.7597, Val MAE: 73126.4670, Val MSE: 17596224041.3040, Val R2: 0.1060\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2158, Val Loss: 0.2280\n",
      "Val RMSE: 128873.3392, Val MAE: 73299.7676, Val MSE: 16608337548.1750, Val R2: 0.1562\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2363\n",
      "Val RMSE: 128994.8039, Val MAE: 76655.1064, Val MSE: 16639659436.2469, Val R2: 0.1546\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2340\n",
      "Val RMSE: 132374.4326, Val MAE: 71333.0926, Val MSE: 17522990411.4452, Val R2: 0.1097\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1970, Val Loss: 0.2221\n",
      "Val RMSE: 125612.4376, Val MAE: 72455.8009, Val MSE: 15778484484.4566, Val R2: 0.1984\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1933, Val Loss: 0.2077\n",
      "Val RMSE: 119528.2299, Val MAE: 68672.3187, Val MSE: 14286997745.9016, Val R2: 0.2741\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1867, Val Loss: 0.2019\n",
      "Val RMSE: 115182.7527, Val MAE: 64823.1302, Val MSE: 13267066512.9382, Val R2: 0.3259\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1764, Val Loss: 0.1946\n",
      "Val RMSE: 108396.8803, Val MAE: 65374.8784, Val MSE: 11749883661.3520, Val R2: 0.4030\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1689, Val Loss: 0.1975\n",
      "Val RMSE: 110112.0618, Val MAE: 65817.9207, Val MSE: 12124666156.4606, Val R2: 0.3840\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1675, Val Loss: 0.1891\n",
      "Val RMSE: 104915.7463, Val MAE: 63240.8579, Val MSE: 11007313813.4425, Val R2: 0.4408\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1796\n",
      "Val RMSE: 100876.8588, Val MAE: 59629.2514, Val MSE: 10176140638.4436, Val R2: 0.4830\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1596, Val Loss: 0.1837\n",
      "Val RMSE: 103288.0090, Val MAE: 61600.2621, Val MSE: 10668412798.7555, Val R2: 0.4580\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1521, Val Loss: 0.1824\n",
      "Val RMSE: 102870.3250, Val MAE: 62120.9821, Val MSE: 10582303764.8670, Val R2: 0.4624\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1768\n",
      "Val RMSE: 99489.5289, Val MAE: 60459.6882, Val MSE: 9898166366.4260, Val R2: 0.4971\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1362, Val Loss: 0.1594\n",
      "Val RMSE: 95174.1402, Val MAE: 56637.8537, Val MSE: 9058116967.0535, Val R2: 0.5398\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1316, Val Loss: 0.1817\n",
      "Val RMSE: 100457.2267, Val MAE: 61808.5422, Val MSE: 10091654392.4785, Val R2: 0.4873\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1725\n",
      "Val RMSE: 100415.4355, Val MAE: 56449.6801, Val MSE: 10083259688.5128, Val R2: 0.4877\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1215, Val Loss: 0.1574\n",
      "Val RMSE: 96067.7177, Val MAE: 54637.9410, Val MSE: 9229006380.7061, Val R2: 0.5311\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1544\n",
      "Val RMSE: 95166.8823, Val MAE: 52674.2660, Val MSE: 9056735492.9248, Val R2: 0.5399\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1113, Val Loss: 0.1508\n",
      "Val RMSE: 92065.4684, Val MAE: 52818.1579, Val MSE: 8476050464.1833, Val R2: 0.5694\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1098, Val Loss: 0.1528\n",
      "Val RMSE: 94350.3000, Val MAE: 54062.3101, Val MSE: 8901979115.9256, Val R2: 0.5477\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1045, Val Loss: 0.1668\n",
      "Val RMSE: 93931.0650, Val MAE: 54457.8598, Val MSE: 8823044970.3552, Val R2: 0.5517\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1522\n",
      "Val RMSE: 94143.9585, Val MAE: 51716.3290, Val MSE: 8863084915.0044, Val R2: 0.5497\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0970, Val Loss: 0.1447\n",
      "Val RMSE: 92164.0552, Val MAE: 50528.1714, Val MSE: 8494213071.9350, Val R2: 0.5684\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0938, Val Loss: 0.1459\n",
      "Val RMSE: 90865.3792, Val MAE: 50417.5538, Val MSE: 8256517136.1138, Val R2: 0.5805\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0925, Val Loss: 0.1425\n",
      "Val RMSE: 91283.9845, Val MAE: 49515.0919, Val MSE: 8332765820.1830, Val R2: 0.5766\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1417\n",
      "Val RMSE: 91126.3868, Val MAE: 48439.2779, Val MSE: 8304018369.8939, Val R2: 0.5781\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0891, Val Loss: 0.1446\n",
      "Val RMSE: 91353.0053, Val MAE: 50732.3675, Val MSE: 8345371571.1407, Val R2: 0.5760\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0880, Val Loss: 0.1433\n",
      "Val RMSE: 90352.9627, Val MAE: 49676.9780, Val MSE: 8163657862.0922, Val R2: 0.5852\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0844, Val Loss: 0.1370\n",
      "Val RMSE: 87993.4955, Val MAE: 49215.5806, Val MSE: 7742855256.6388, Val R2: 0.6066\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0826, Val Loss: 0.1418\n",
      "Val RMSE: 89211.4835, Val MAE: 49105.9711, Val MSE: 7958688787.9421, Val R2: 0.5956\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1340\n",
      "Val RMSE: 86325.8376, Val MAE: 48914.5582, Val MSE: 7452150244.9239, Val R2: 0.6214\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1452\n",
      "Val RMSE: 87093.4400, Val MAE: 49302.6673, Val MSE: 7585267291.1991, Val R2: 0.6146\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1593\n",
      "Val RMSE: 90309.4229, Val MAE: 51462.9970, Val MSE: 8155791866.3696, Val R2: 0.5856\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0747, Val Loss: 0.1398\n",
      "Val RMSE: 87101.8724, Val MAE: 50864.6226, Val MSE: 7586736182.2359, Val R2: 0.6145\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1418\n",
      "Val RMSE: 88149.7665, Val MAE: 49652.6341, Val MSE: 7770381337.3090, Val R2: 0.6052\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1517\n",
      "Val RMSE: 90671.6858, Val MAE: 52460.1455, Val MSE: 8221354613.4177, Val R2: 0.5823\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1384\n",
      "Val RMSE: 86709.0097, Val MAE: 49542.9210, Val MSE: 7518452367.4223, Val R2: 0.6180\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1607\n",
      "Val RMSE: 92360.6443, Val MAE: 52321.3913, Val MSE: 8530488609.9925, Val R2: 0.5666\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1475\n",
      "Val RMSE: 88824.9995, Val MAE: 49996.5495, Val MSE: 7889880531.6022, Val R2: 0.5991\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0690, Val Loss: 0.1538\n",
      "Val RMSE: 89125.1197, Val MAE: 53232.1884, Val MSE: 7943286957.6774, Val R2: 0.5964\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1330\n",
      "Val RMSE: 85065.3098, Val MAE: 47532.7588, Val MSE: 7236106930.9899, Val R2: 0.6324\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1391\n",
      "Val RMSE: 84001.6687, Val MAE: 48080.4483, Val MSE: 7056280340.2795, Val R2: 0.6415\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1443\n",
      "Val RMSE: 87194.2177, Val MAE: 50673.6958, Val MSE: 7602831592.8753, Val R2: 0.6137\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1358\n",
      "Val RMSE: 83054.5875, Val MAE: 46336.3492, Val MSE: 6898064505.7380, Val R2: 0.6495\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1293\n",
      "Val RMSE: 82724.2306, Val MAE: 46830.1989, Val MSE: 6843298335.1180, Val R2: 0.6523\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.1266\n",
      "Val RMSE: 80761.5703, Val MAE: 44792.4636, Val MSE: 6522431230.4439, Val R2: 0.6686\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1415\n",
      "Val RMSE: 83277.7630, Val MAE: 48533.1841, Val MSE: 6935185809.6919, Val R2: 0.6476\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1432\n",
      "Val RMSE: 83351.1859, Val MAE: 47861.7614, Val MSE: 6947420191.0108, Val R2: 0.6470\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1336\n",
      "Val RMSE: 81575.5659, Val MAE: 47431.7042, Val MSE: 6654572945.6759, Val R2: 0.6619\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1431\n",
      "Val RMSE: 83135.9400, Val MAE: 47340.9093, Val MSE: 6911584525.9364, Val R2: 0.6488\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1318\n",
      "Val RMSE: 79280.8737, Val MAE: 45513.4658, Val MSE: 6285456940.8554, Val R2: 0.6807\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1333\n",
      "Val RMSE: 82441.1609, Val MAE: 45870.8533, Val MSE: 6796545011.3634, Val R2: 0.6547\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1265\n",
      "Val RMSE: 80520.9689, Val MAE: 46125.3979, Val MSE: 6483626431.1670, Val R2: 0.6706\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1392\n",
      "Val RMSE: 83669.7746, Val MAE: 47801.0863, Val MSE: 7000631180.0702, Val R2: 0.6443\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1330\n",
      "Val RMSE: 82215.2447, Val MAE: 45692.3358, Val MSE: 6759346460.3563, Val R2: 0.6566\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1383\n",
      "Val RMSE: 84751.4455, Val MAE: 48081.8009, Val MSE: 7182807522.2416, Val R2: 0.6351\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1278\n",
      "Val RMSE: 79708.8543, Val MAE: 44550.4314, Val MSE: 6353501459.1511, Val R2: 0.6772\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1387\n",
      "Val RMSE: 84016.2214, Val MAE: 47404.1642, Val MSE: 7058725458.0066, Val R2: 0.6414\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1373\n",
      "Val RMSE: 84355.2723, Val MAE: 47876.4034, Val MSE: 7115811970.1945, Val R2: 0.6385\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1318\n",
      "Val RMSE: 82007.3168, Val MAE: 44814.7179, Val MSE: 6725200016.5778, Val R2: 0.6583\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1309\n",
      "Val RMSE: 80890.1347, Val MAE: 46356.1123, Val MSE: 6543213887.8256, Val R2: 0.6676\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1356\n",
      "Val RMSE: 83576.8479, Val MAE: 47125.1584, Val MSE: 6985089504.9565, Val R2: 0.6451\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1286\n",
      "Val RMSE: 81275.3206, Val MAE: 43721.0999, Val MSE: 6605677738.8467, Val R2: 0.6644\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1452\n",
      "Val RMSE: 85090.0164, Val MAE: 47233.9523, Val MSE: 7240310892.3255, Val R2: 0.6321\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1305\n",
      "Val RMSE: 81287.6647, Val MAE: 46922.1953, Val MSE: 6607684435.0418, Val R2: 0.6643\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1307\n",
      "Val RMSE: 82715.8721, Val MAE: 44800.6879, Val MSE: 6841915493.4581, Val R2: 0.6524\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1269\n",
      "Val RMSE: 81188.3978, Val MAE: 47908.1122, Val MSE: 6591555940.5479, Val R2: 0.6651\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1234\n",
      "Val RMSE: 77459.5921, Val MAE: 43720.9203, Val MSE: 5999988403.9221, Val R2: 0.6952\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1241\n",
      "Val RMSE: 77866.8683, Val MAE: 43489.2506, Val MSE: 6063249171.8903, Val R2: 0.6919\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1330\n",
      "Val RMSE: 82528.4902, Val MAE: 44575.0334, Val MSE: 6810951686.7591, Val R2: 0.6540\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1275\n",
      "Val RMSE: 80010.7298, Val MAE: 44269.3060, Val MSE: 6401716875.5271, Val R2: 0.6748\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1241\n",
      "Val RMSE: 78191.5069, Val MAE: 44385.3867, Val MSE: 6113911744.5309, Val R2: 0.6894\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1288\n",
      "Val RMSE: 78983.9677, Val MAE: 44183.4214, Val MSE: 6238467158.2214, Val R2: 0.6830\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1232\n",
      "Val RMSE: 76053.8368, Val MAE: 43018.3482, Val MSE: 5784186085.8362, Val R2: 0.7061\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1270\n",
      "Val RMSE: 80343.1879, Val MAE: 43492.3155, Val MSE: 6455027842.1348, Val R2: 0.6720\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1406\n",
      "Val RMSE: 80063.2683, Val MAE: 45774.3042, Val MSE: 6410126926.7749, Val R2: 0.6743\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1319\n",
      "Val RMSE: 80772.7951, Val MAE: 45300.4578, Val MSE: 6524244431.7128, Val R2: 0.6685\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1374\n",
      "Val RMSE: 82101.6472, Val MAE: 44219.9811, Val MSE: 6740680467.9314, Val R2: 0.6575\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0422, Val Loss: 0.1228\n",
      "Val RMSE: 77391.0664, Val MAE: 43785.6660, Val MSE: 5989377154.9606, Val R2: 0.6957\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1244\n",
      "Val RMSE: 79064.8139, Val MAE: 43212.2930, Val MSE: 6251244803.9449, Val R2: 0.6824\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.1206\n",
      "Val RMSE: 76860.0045, Val MAE: 43688.9134, Val MSE: 5907460294.1347, Val R2: 0.6999\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0421, Val Loss: 0.1344\n",
      "Val RMSE: 85787.2733, Val MAE: 47601.6764, Val MSE: 7359456263.6329, Val R2: 0.6261\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 94697.4704, Test MAE: 52307.9087, Test MSE: 8967610903.2812, Test R2: 0.4252\n",
      "Inference Time: 3.196239471435547e-05 seconds per sample\n",
      "\n",
      "Iteration 22 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4041, Val Loss: 0.2971\n",
      "Val RMSE: 147933.1216, Val MAE: 80473.3772, Val MSE: 21884208477.8591, Val R2: -0.1119\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2796, Val Loss: 0.2792\n",
      "Val RMSE: 142775.8515, Val MAE: 81883.9579, Val MSE: 20384943785.4764, Val R2: -0.0357\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2737, Val Loss: 0.2751\n",
      "Val RMSE: 140457.1091, Val MAE: 85442.6548, Val MSE: 19728199483.3850, Val R2: -0.0023\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2707, Val Loss: 0.2768\n",
      "Val RMSE: 141858.8322, Val MAE: 82882.1185, Val MSE: 20123928286.1089, Val R2: -0.0224\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2674, Val Loss: 0.2765\n",
      "Val RMSE: 141712.9780, Val MAE: 83119.3055, Val MSE: 20082568122.0660, Val R2: -0.0203\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2650, Val Loss: 0.2771\n",
      "Val RMSE: 141784.8079, Val MAE: 83138.8883, Val MSE: 20102931741.6201, Val R2: -0.0214\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2654, Val Loss: 0.2740\n",
      "Val RMSE: 141478.6876, Val MAE: 84415.3696, Val MSE: 20016219051.3200, Val R2: -0.0170\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2737\n",
      "Val RMSE: 141993.9588, Val MAE: 82824.0592, Val MSE: 20162284331.5329, Val R2: -0.0244\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2585, Val Loss: 0.2727\n",
      "Val RMSE: 142096.1584, Val MAE: 81486.0901, Val MSE: 20191318231.8380, Val R2: -0.0258\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2711\n",
      "Val RMSE: 141509.8528, Val MAE: 82537.4003, Val MSE: 20025038428.9696, Val R2: -0.0174\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2821\n",
      "Val RMSE: 141309.6626, Val MAE: 88025.6029, Val MSE: 19968420750.6986, Val R2: -0.0145\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2717\n",
      "Val RMSE: 142014.8564, Val MAE: 80658.0872, Val MSE: 20168219437.1750, Val R2: -0.0247\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2674\n",
      "Val RMSE: 141158.8336, Val MAE: 81063.9869, Val MSE: 19925816313.7706, Val R2: -0.0124\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2522, Val Loss: 0.2673\n",
      "Val RMSE: 142848.0958, Val MAE: 77758.3717, Val MSE: 20405578467.9258, Val R2: -0.0367\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2665\n",
      "Val RMSE: 142453.7033, Val MAE: 78226.2645, Val MSE: 20293057588.4227, Val R2: -0.0310\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2498, Val Loss: 0.2646\n",
      "Val RMSE: 141199.7235, Val MAE: 79519.2034, Val MSE: 19937361907.3812, Val R2: -0.0129\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2472, Val Loss: 0.2647\n",
      "Val RMSE: 142012.3477, Val MAE: 78439.1188, Val MSE: 20167506913.1541, Val R2: -0.0246\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2456, Val Loss: 0.2732\n",
      "Val RMSE: 140349.5047, Val MAE: 84424.3146, Val MSE: 19697983474.5082, Val R2: -0.0008\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2436, Val Loss: 0.2624\n",
      "Val RMSE: 140774.5117, Val MAE: 79079.6278, Val MSE: 19817463132.0990, Val R2: -0.0069\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2430, Val Loss: 0.2793\n",
      "Val RMSE: 141469.7413, Val MAE: 83966.1359, Val MSE: 20013687700.1174, Val R2: -0.0168\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2461, Val Loss: 0.2634\n",
      "Val RMSE: 141563.3541, Val MAE: 78806.5443, Val MSE: 20040183237.0566, Val R2: -0.0182\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2373, Val Loss: 0.2608\n",
      "Val RMSE: 140520.1594, Val MAE: 78635.4623, Val MSE: 19745915198.2560, Val R2: -0.0032\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2386, Val Loss: 0.2598\n",
      "Val RMSE: 140688.1940, Val MAE: 77958.9668, Val MSE: 19793167929.5648, Val R2: -0.0056\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2362, Val Loss: 0.2605\n",
      "Val RMSE: 137413.8809, Val MAE: 78887.7199, Val MSE: 18882574651.7307, Val R2: 0.0406\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2301, Val Loss: 0.2486\n",
      "Val RMSE: 136851.3722, Val MAE: 74580.6070, Val MSE: 18728298084.1538, Val R2: 0.0485\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2295, Val Loss: 0.2518\n",
      "Val RMSE: 138225.1208, Val MAE: 75368.7270, Val MSE: 19106184007.0053, Val R2: 0.0293\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2256, Val Loss: 0.2520\n",
      "Val RMSE: 135093.3431, Val MAE: 73269.9254, Val MSE: 18250211338.1089, Val R2: 0.0728\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2158, Val Loss: 0.2622\n",
      "Val RMSE: 137827.8367, Val MAE: 73951.4560, Val MSE: 18996512574.6827, Val R2: 0.0349\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2149, Val Loss: 0.2347\n",
      "Val RMSE: 132329.2404, Val MAE: 71936.9977, Val MSE: 17511027876.0125, Val R2: 0.1103\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2073, Val Loss: 0.2373\n",
      "Val RMSE: 133295.8713, Val MAE: 70165.0296, Val MSE: 17767789294.0527, Val R2: 0.0973\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1985, Val Loss: 0.2327\n",
      "Val RMSE: 128345.9650, Val MAE: 75555.6029, Val MSE: 16472686740.3235, Val R2: 0.1631\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1956, Val Loss: 0.2168\n",
      "Val RMSE: 118890.6690, Val MAE: 67108.7536, Val MSE: 14134991164.2500, Val R2: 0.2819\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1911, Val Loss: 0.1936\n",
      "Val RMSE: 107026.3003, Val MAE: 66400.0935, Val MSE: 11454628946.7875, Val R2: 0.4180\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1794, Val Loss: 0.1887\n",
      "Val RMSE: 107784.1996, Val MAE: 63258.8281, Val MSE: 11617433688.3769, Val R2: 0.4098\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1682, Val Loss: 0.1894\n",
      "Val RMSE: 106208.2629, Val MAE: 62410.9843, Val MSE: 11280195098.4918, Val R2: 0.4269\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1639, Val Loss: 0.1832\n",
      "Val RMSE: 103903.1885, Val MAE: 62306.1262, Val MSE: 10795872573.3160, Val R2: 0.4515\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1609, Val Loss: 0.1772\n",
      "Val RMSE: 101472.9009, Val MAE: 60167.0874, Val MSE: 10296749608.5572, Val R2: 0.4769\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1627, Val Loss: 0.1759\n",
      "Val RMSE: 102169.2085, Val MAE: 60824.5362, Val MSE: 10438547171.8575, Val R2: 0.4697\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1710\n",
      "Val RMSE: 100557.7305, Val MAE: 58596.6022, Val MSE: 10111857161.4214, Val R2: 0.4863\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1949\n",
      "Val RMSE: 104726.4674, Val MAE: 61927.3010, Val MSE: 10967632979.3728, Val R2: 0.4428\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1650\n",
      "Val RMSE: 99126.2591, Val MAE: 58361.4536, Val MSE: 9826015249.6032, Val R2: 0.5008\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1509, Val Loss: 0.1670\n",
      "Val RMSE: 100775.7850, Val MAE: 58053.1714, Val MSE: 10155758834.1967, Val R2: 0.4840\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1433, Val Loss: 0.1653\n",
      "Val RMSE: 99941.1915, Val MAE: 56712.8990, Val MSE: 9988241757.9231, Val R2: 0.4925\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1418, Val Loss: 0.1582\n",
      "Val RMSE: 97607.1298, Val MAE: 55001.0733, Val MSE: 9527151789.6464, Val R2: 0.5160\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1376, Val Loss: 0.1536\n",
      "Val RMSE: 96532.1820, Val MAE: 53794.2838, Val MSE: 9318462168.0537, Val R2: 0.5266\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1336, Val Loss: 0.1581\n",
      "Val RMSE: 97251.7378, Val MAE: 54319.6520, Val MSE: 9457900501.0995, Val R2: 0.5195\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1407\n",
      "Val RMSE: 94070.6057, Val MAE: 50339.7111, Val MSE: 8849278856.4163, Val R2: 0.5504\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1309, Val Loss: 0.1503\n",
      "Val RMSE: 96075.5542, Val MAE: 51599.1120, Val MSE: 9230512112.1439, Val R2: 0.5310\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1239, Val Loss: 0.1344\n",
      "Val RMSE: 91485.5956, Val MAE: 48646.9078, Val MSE: 8369614193.4300, Val R2: 0.5748\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1236, Val Loss: 0.1348\n",
      "Val RMSE: 91688.7647, Val MAE: 48938.7908, Val MSE: 8406829578.6634, Val R2: 0.5729\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1359\n",
      "Val RMSE: 91916.5054, Val MAE: 49295.5013, Val MSE: 8448643956.4336, Val R2: 0.5708\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1156, Val Loss: 0.1255\n",
      "Val RMSE: 89039.6607, Val MAE: 46751.1190, Val MSE: 7928061171.7890, Val R2: 0.5972\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1107, Val Loss: 0.1296\n",
      "Val RMSE: 90926.0691, Val MAE: 48453.1147, Val MSE: 8267550047.5772, Val R2: 0.5800\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1229\n",
      "Val RMSE: 88714.1430, Val MAE: 47364.5699, Val MSE: 7870199174.7437, Val R2: 0.6001\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1045, Val Loss: 0.1300\n",
      "Val RMSE: 92145.2080, Val MAE: 47812.0497, Val MSE: 8490739351.0716, Val R2: 0.5686\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1032, Val Loss: 0.1212\n",
      "Val RMSE: 88827.2043, Val MAE: 47832.3392, Val MSE: 7890272230.0791, Val R2: 0.5991\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0993, Val Loss: 0.1310\n",
      "Val RMSE: 92135.7383, Val MAE: 49271.2438, Val MSE: 8488994267.5323, Val R2: 0.5687\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1483\n",
      "Val RMSE: 95885.4223, Val MAE: 51618.9717, Val MSE: 9194014212.5202, Val R2: 0.5329\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1315\n",
      "Val RMSE: 91672.3148, Val MAE: 48618.3259, Val MSE: 8403813300.5466, Val R2: 0.5730\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0930, Val Loss: 0.1161\n",
      "Val RMSE: 87609.7099, Val MAE: 46752.9429, Val MSE: 7675461261.4013, Val R2: 0.6100\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1208\n",
      "Val RMSE: 90012.5241, Val MAE: 45265.8860, Val MSE: 8102254497.7669, Val R2: 0.5884\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0880, Val Loss: 0.1189\n",
      "Val RMSE: 87841.7464, Val MAE: 45031.0034, Val MSE: 7716172414.5062, Val R2: 0.6080\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1233\n",
      "Val RMSE: 89195.3172, Val MAE: 47983.9506, Val MSE: 7955804607.4152, Val R2: 0.5958\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1313\n",
      "Val RMSE: 89918.9733, Val MAE: 50035.4876, Val MSE: 8085421756.0564, Val R2: 0.5892\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0841, Val Loss: 0.1287\n",
      "Val RMSE: 89251.8234, Val MAE: 48851.0797, Val MSE: 7965887983.8241, Val R2: 0.5953\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0802, Val Loss: 0.1535\n",
      "Val RMSE: 93436.2947, Val MAE: 52896.9524, Val MSE: 8730341172.1371, Val R2: 0.5564\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1733\n",
      "Val RMSE: 97176.8305, Val MAE: 57487.6347, Val MSE: 9443336395.0372, Val R2: 0.5202\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0787, Val Loss: 0.1316\n",
      "Val RMSE: 91349.4110, Val MAE: 48671.8369, Val MSE: 8344714890.7278, Val R2: 0.5760\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1934\n",
      "Val RMSE: 102633.0600, Val MAE: 59449.2380, Val MSE: 10533545001.3855, Val R2: 0.4648\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1138\n",
      "Val RMSE: 84360.5538, Val MAE: 43721.7400, Val MSE: 7116703031.8332, Val R2: 0.6384\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1344\n",
      "Val RMSE: 88019.1218, Val MAE: 48948.5573, Val MSE: 7747365798.3666, Val R2: 0.6064\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0713, Val Loss: 0.1534\n",
      "Val RMSE: 91838.8227, Val MAE: 52194.5676, Val MSE: 8434369356.1173, Val R2: 0.5715\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1409\n",
      "Val RMSE: 87809.8112, Val MAE: 49949.0894, Val MSE: 7710562941.7634, Val R2: 0.6083\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1446\n",
      "Val RMSE: 88872.5056, Val MAE: 51820.4164, Val MSE: 7898322259.0181, Val R2: 0.5987\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1793\n",
      "Val RMSE: 94959.0731, Val MAE: 55093.8404, Val MSE: 9017225569.8983, Val R2: 0.5419\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1185\n",
      "Val RMSE: 78512.6264, Val MAE: 45013.2999, Val MSE: 6164232502.4632, Val R2: 0.6868\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1374\n",
      "Val RMSE: 84630.9655, Val MAE: 49290.9968, Val MSE: 7162400326.2691, Val R2: 0.6361\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1814\n",
      "Val RMSE: 93216.9613, Val MAE: 56548.4121, Val MSE: 8689401883.1462, Val R2: 0.5585\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1376\n",
      "Val RMSE: 84417.9720, Val MAE: 50020.8658, Val MSE: 7126393990.2723, Val R2: 0.6379\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1511\n",
      "Val RMSE: 86547.1365, Val MAE: 51625.1338, Val MSE: 7490406839.0811, Val R2: 0.6194\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1364\n",
      "Val RMSE: 83395.6828, Val MAE: 51061.7343, Val MSE: 6954839913.5719, Val R2: 0.6467\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1099\n",
      "Val RMSE: 77435.6788, Val MAE: 43034.4273, Val MSE: 5996284348.7412, Val R2: 0.6954\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1116\n",
      "Val RMSE: 78451.5469, Val MAE: 43624.9790, Val MSE: 6154645210.0605, Val R2: 0.6873\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1293\n",
      "Val RMSE: 82394.1974, Val MAE: 47928.9432, Val MSE: 6788803761.2380, Val R2: 0.6551\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1186\n",
      "Val RMSE: 78766.3184, Val MAE: 45432.4893, Val MSE: 6204132919.7723, Val R2: 0.6848\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1872\n",
      "Val RMSE: 95773.5638, Val MAE: 56033.9657, Val MSE: 9172575530.2415, Val R2: 0.5340\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1274\n",
      "Val RMSE: 82917.0126, Val MAE: 47624.0983, Val MSE: 6875230981.3743, Val R2: 0.6507\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1355\n",
      "Val RMSE: 85362.5276, Val MAE: 49264.2811, Val MSE: 7286761113.6261, Val R2: 0.6298\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1367\n",
      "Val RMSE: 84434.0562, Val MAE: 48709.7496, Val MSE: 7129109838.1047, Val R2: 0.6378\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.5521\n",
      "Val RMSE: 185939.3288, Val MAE: 94258.2263, Val MSE: 34573433985.8521, Val R2: -0.7565\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1260\n",
      "Val RMSE: 82925.1520, Val MAE: 45261.2252, Val MSE: 6876580829.1375, Val R2: 0.6506\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1201\n",
      "Val RMSE: 82043.9136, Val MAE: 46016.4377, Val MSE: 6731203753.0779, Val R2: 0.6580\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1281\n",
      "Val RMSE: 82556.0195, Val MAE: 47548.2453, Val MSE: 6815496352.0834, Val R2: 0.6537\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1163\n",
      "Val RMSE: 78294.1867, Val MAE: 44497.4741, Val MSE: 6129979667.3623, Val R2: 0.6886\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1804\n",
      "Val RMSE: 92906.3667, Val MAE: 58271.5202, Val MSE: 8631592967.8574, Val R2: 0.5615\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1589\n",
      "Val RMSE: 87594.5173, Val MAE: 52153.3010, Val MSE: 7672799458.0252, Val R2: 0.6102\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1262\n",
      "Val RMSE: 81982.3807, Val MAE: 46468.5883, Val MSE: 6721110739.2361, Val R2: 0.6585\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1092\n",
      "Val RMSE: 75530.9672, Val MAE: 41539.2617, Val MSE: 5704927013.6338, Val R2: 0.7102\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1357\n",
      "Val RMSE: 83321.5286, Val MAE: 48417.8631, Val MSE: 6942477130.5452, Val R2: 0.6473\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1216\n",
      "Val RMSE: 81072.9556, Val MAE: 44993.3101, Val MSE: 6572824127.6470, Val R2: 0.6661\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74330.9790, Test MAE: 40693.1775, Test MSE: 5525094431.8169, Test R2: 0.6458\n",
      "Inference Time: 2.5885215172400843e-05 seconds per sample\n",
      "\n",
      "Iteration 23 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3732, Val Loss: 0.2998\n",
      "Val RMSE: 148243.2932, Val MAE: 80139.0133, Val MSE: 21976073975.8353, Val R2: -0.1165\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2737, Val Loss: 0.2772\n",
      "Val RMSE: 142049.1139, Val MAE: 82801.9351, Val MSE: 20177950767.4146, Val R2: -0.0252\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2670, Val Loss: 0.2768\n",
      "Val RMSE: 141957.6975, Val MAE: 82843.6320, Val MSE: 20151987884.9029, Val R2: -0.0238\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2655, Val Loss: 0.2795\n",
      "Val RMSE: 143190.2138, Val MAE: 81834.4010, Val MSE: 20503437335.1289, Val R2: -0.0417\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2665, Val Loss: 0.2776\n",
      "Val RMSE: 142276.7069, Val MAE: 82624.7419, Val MSE: 20242661326.9547, Val R2: -0.0285\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2627, Val Loss: 0.2818\n",
      "Val RMSE: 143248.1962, Val MAE: 81837.6122, Val MSE: 20520045706.1056, Val R2: -0.0425\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2607, Val Loss: 0.2804\n",
      "Val RMSE: 143472.4741, Val MAE: 80922.0112, Val MSE: 20584350815.6186, Val R2: -0.0458\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2713\n",
      "Val RMSE: 142202.1826, Val MAE: 80522.0082, Val MSE: 20221460745.3682, Val R2: -0.0274\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2600, Val Loss: 0.2739\n",
      "Val RMSE: 143220.8054, Val MAE: 79515.2546, Val MSE: 20512199095.8106, Val R2: -0.0421\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2568, Val Loss: 0.2711\n",
      "Val RMSE: 141363.2183, Val MAE: 83327.0248, Val MSE: 19983559475.6220, Val R2: -0.0153\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2721\n",
      "Val RMSE: 140742.3885, Val MAE: 84044.5031, Val MSE: 19808419916.4760, Val R2: -0.0064\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2705\n",
      "Val RMSE: 142942.9200, Val MAE: 78689.6028, Val MSE: 20432678371.8777, Val R2: -0.0381\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2682\n",
      "Val RMSE: 142369.0829, Val MAE: 79749.3031, Val MSE: 20268955752.8993, Val R2: -0.0298\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2501, Val Loss: 0.2695\n",
      "Val RMSE: 141156.0333, Val MAE: 82020.5806, Val MSE: 19925025747.9895, Val R2: -0.0123\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2485, Val Loss: 0.2672\n",
      "Val RMSE: 141823.4102, Val MAE: 80252.5961, Val MSE: 20113879673.0895, Val R2: -0.0219\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2494, Val Loss: 0.2678\n",
      "Val RMSE: 141983.3902, Val MAE: 80003.7863, Val MSE: 20159283081.2979, Val R2: -0.0242\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2465, Val Loss: 0.2679\n",
      "Val RMSE: 141491.5792, Val MAE: 79085.9418, Val MSE: 20019866991.6386, Val R2: -0.0171\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2930\n",
      "Val RMSE: 142759.3710, Val MAE: 87435.4293, Val MSE: 20380238000.0029, Val R2: -0.0354\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2485, Val Loss: 0.2629\n",
      "Val RMSE: 141031.1108, Val MAE: 79076.8966, Val MSE: 19889774209.3319, Val R2: -0.0105\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2743\n",
      "Val RMSE: 141558.5099, Val MAE: 82490.1157, Val MSE: 20038811716.1863, Val R2: -0.0181\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2416, Val Loss: 0.2644\n",
      "Val RMSE: 140804.9308, Val MAE: 80058.0706, Val MSE: 19826028538.3977, Val R2: -0.0073\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2391, Val Loss: 0.2615\n",
      "Val RMSE: 141655.4033, Val MAE: 77775.5666, Val MSE: 20066253281.9659, Val R2: -0.0195\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2323, Val Loss: 0.2576\n",
      "Val RMSE: 134410.6008, Val MAE: 79499.9623, Val MSE: 18066209612.2541, Val R2: 0.0821\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2258, Val Loss: 0.2323\n",
      "Val RMSE: 131714.9144, Val MAE: 75027.4232, Val MSE: 17348818664.9110, Val R2: 0.1186\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2136, Val Loss: 0.2457\n",
      "Val RMSE: 139124.7285, Val MAE: 71953.9462, Val MSE: 19355690075.6295, Val R2: 0.0166\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2103, Val Loss: 0.2384\n",
      "Val RMSE: 133481.3502, Val MAE: 74893.4353, Val MSE: 17817270841.4071, Val R2: 0.0948\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2506\n",
      "Val RMSE: 131670.3361, Val MAE: 78828.2041, Val MSE: 17337077417.8519, Val R2: 0.1192\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2039, Val Loss: 0.2244\n",
      "Val RMSE: 126871.9260, Val MAE: 73539.1107, Val MSE: 16096485600.6032, Val R2: 0.1822\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1986, Val Loss: 0.2242\n",
      "Val RMSE: 128357.8031, Val MAE: 70435.9438, Val MSE: 16475725608.6430, Val R2: 0.1629\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1951, Val Loss: 0.2234\n",
      "Val RMSE: 123695.8355, Val MAE: 72092.6338, Val MSE: 15300659716.8892, Val R2: 0.2226\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1873, Val Loss: 0.2091\n",
      "Val RMSE: 113714.8117, Val MAE: 72095.8980, Val MSE: 12931058396.9108, Val R2: 0.3430\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1799, Val Loss: 0.1967\n",
      "Val RMSE: 109799.4455, Val MAE: 66586.4125, Val MSE: 12055918222.6931, Val R2: 0.3875\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1762, Val Loss: 0.1945\n",
      "Val RMSE: 108412.3590, Val MAE: 66839.0295, Val MSE: 11753239590.2102, Val R2: 0.4029\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1689, Val Loss: 0.1859\n",
      "Val RMSE: 105268.5973, Val MAE: 63900.7240, Val MSE: 11081477579.4146, Val R2: 0.4370\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1621, Val Loss: 0.1792\n",
      "Val RMSE: 100380.6468, Val MAE: 65548.7101, Val MSE: 10076274243.6429, Val R2: 0.4881\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1696\n",
      "Val RMSE: 99917.0025, Val MAE: 59494.8222, Val MSE: 9983407381.6797, Val R2: 0.4928\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1632\n",
      "Val RMSE: 97890.1725, Val MAE: 58475.3159, Val MSE: 9582485864.0257, Val R2: 0.5131\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1462, Val Loss: 0.1967\n",
      "Val RMSE: 101607.9842, Val MAE: 63968.3178, Val MSE: 10324182444.4903, Val R2: 0.4755\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1422, Val Loss: 0.1493\n",
      "Val RMSE: 96341.1950, Val MAE: 52349.1983, Val MSE: 9281625850.6039, Val R2: 0.5284\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1340, Val Loss: 0.1396\n",
      "Val RMSE: 93399.7195, Val MAE: 50154.2204, Val MSE: 8723507602.4349, Val R2: 0.5568\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1280, Val Loss: 0.1359\n",
      "Val RMSE: 91642.3414, Val MAE: 50422.9490, Val MSE: 8398318742.7946, Val R2: 0.5733\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1318\n",
      "Val RMSE: 90211.2438, Val MAE: 47480.5088, Val MSE: 8138068508.7728, Val R2: 0.5865\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1159, Val Loss: 0.1212\n",
      "Val RMSE: 89318.8799, Val MAE: 46503.2952, Val MSE: 7977862312.6764, Val R2: 0.5947\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1135, Val Loss: 0.1405\n",
      "Val RMSE: 93854.9431, Val MAE: 49665.1629, Val MSE: 8808750338.2470, Val R2: 0.5525\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1098, Val Loss: 0.1205\n",
      "Val RMSE: 88152.1087, Val MAE: 50082.3202, Val MSE: 7770794274.8817, Val R2: 0.6052\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1062, Val Loss: 0.1284\n",
      "Val RMSE: 89688.4967, Val MAE: 46909.2264, Val MSE: 8044026434.2264, Val R2: 0.5913\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1028, Val Loss: 0.1134\n",
      "Val RMSE: 86225.7560, Val MAE: 43895.7886, Val MSE: 7434880992.0101, Val R2: 0.6223\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1214\n",
      "Val RMSE: 87606.0182, Val MAE: 46784.8892, Val MSE: 7674814433.4388, Val R2: 0.6101\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0981, Val Loss: 0.1161\n",
      "Val RMSE: 85551.9620, Val MAE: 47011.7165, Val MSE: 7319138194.8885, Val R2: 0.6281\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0951, Val Loss: 0.1319\n",
      "Val RMSE: 89963.9276, Val MAE: 52333.5678, Val MSE: 8093508272.6540, Val R2: 0.5888\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1156\n",
      "Val RMSE: 86178.1812, Val MAE: 45516.5231, Val MSE: 7426678909.8059, Val R2: 0.6227\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1115\n",
      "Val RMSE: 83085.0241, Val MAE: 43295.5511, Val MSE: 6903121222.9169, Val R2: 0.6493\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1202\n",
      "Val RMSE: 88335.0814, Val MAE: 43979.6896, Val MSE: 7803086599.8882, Val R2: 0.6036\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0842, Val Loss: 0.1186\n",
      "Val RMSE: 86027.6464, Val MAE: 45440.5977, Val MSE: 7400755943.0462, Val R2: 0.6240\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1267\n",
      "Val RMSE: 88773.1452, Val MAE: 46915.9174, Val MSE: 7880671313.8598, Val R2: 0.5996\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1253\n",
      "Val RMSE: 85437.1051, Val MAE: 49463.7040, Val MSE: 7299498923.7182, Val R2: 0.6291\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1147\n",
      "Val RMSE: 82456.5829, Val MAE: 45825.7051, Val MSE: 6799088057.8679, Val R2: 0.6546\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1231\n",
      "Val RMSE: 84649.0651, Val MAE: 48840.0952, Val MSE: 7165464220.8235, Val R2: 0.6359\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1104\n",
      "Val RMSE: 83584.2158, Val MAE: 42948.9119, Val MSE: 6986321134.0744, Val R2: 0.6451\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1132\n",
      "Val RMSE: 79312.4902, Val MAE: 44021.7369, Val MSE: 6290471096.0580, Val R2: 0.6804\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1157\n",
      "Val RMSE: 82551.2901, Val MAE: 44882.8951, Val MSE: 6814715500.1201, Val R2: 0.6538\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1152\n",
      "Val RMSE: 84851.1930, Val MAE: 45625.6652, Val MSE: 7199724955.7823, Val R2: 0.6342\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1125\n",
      "Val RMSE: 80719.3150, Val MAE: 44541.9758, Val MSE: 6515607806.4761, Val R2: 0.6690\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1143\n",
      "Val RMSE: 84029.7031, Val MAE: 43481.9390, Val MSE: 7060990997.7805, Val R2: 0.6413\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0664, Val Loss: 0.1047\n",
      "Val RMSE: 76990.9355, Val MAE: 44513.4415, Val MSE: 5927604145.8271, Val R2: 0.6988\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1080\n",
      "Val RMSE: 80820.8540, Val MAE: 42920.7085, Val MSE: 6532010433.3038, Val R2: 0.6681\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1139\n",
      "Val RMSE: 80598.4426, Val MAE: 42637.5126, Val MSE: 6496108945.3758, Val R2: 0.6700\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1146\n",
      "Val RMSE: 80343.5304, Val MAE: 43076.3587, Val MSE: 6455082873.5636, Val R2: 0.6720\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1533\n",
      "Val RMSE: 91209.0257, Val MAE: 50132.0264, Val MSE: 8319086360.3247, Val R2: 0.5773\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1104\n",
      "Val RMSE: 78103.3318, Val MAE: 42911.9073, Val MSE: 6100130445.0970, Val R2: 0.6901\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1085\n",
      "Val RMSE: 79973.7214, Val MAE: 42002.7685, Val MSE: 6395796109.0340, Val R2: 0.6751\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1108\n",
      "Val RMSE: 82299.9743, Val MAE: 42141.4247, Val MSE: 6773285768.6818, Val R2: 0.6559\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1068\n",
      "Val RMSE: 77920.4756, Val MAE: 42776.7880, Val MSE: 6071600513.1171, Val R2: 0.6915\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1019\n",
      "Val RMSE: 77611.8907, Val MAE: 39520.5474, Val MSE: 6023605574.6181, Val R2: 0.6940\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1128\n",
      "Val RMSE: 83695.4369, Val MAE: 42536.2481, Val MSE: 7004926164.6392, Val R2: 0.6441\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1081\n",
      "Val RMSE: 80060.2794, Val MAE: 41295.1976, Val MSE: 6409648335.6328, Val R2: 0.6743\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1105\n",
      "Val RMSE: 81819.4716, Val MAE: 41574.2823, Val MSE: 6694425939.6195, Val R2: 0.6599\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1061\n",
      "Val RMSE: 78468.7336, Val MAE: 40166.7678, Val MSE: 6157342146.3380, Val R2: 0.6872\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1066\n",
      "Val RMSE: 78973.7491, Val MAE: 41171.5755, Val MSE: 6236853042.9370, Val R2: 0.6831\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1115\n",
      "Val RMSE: 78930.0080, Val MAE: 44197.9776, Val MSE: 6229946166.2980, Val R2: 0.6835\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1109\n",
      "Val RMSE: 81335.5738, Val MAE: 42867.9403, Val MSE: 6615475569.2530, Val R2: 0.6639\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1023\n",
      "Val RMSE: 76721.2305, Val MAE: 40130.4644, Val MSE: 5886147214.4548, Val R2: 0.7009\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1027\n",
      "Val RMSE: 77727.2553, Val MAE: 40034.7366, Val MSE: 6041526216.0307, Val R2: 0.6931\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1109\n",
      "Val RMSE: 82072.6197, Val MAE: 42726.0576, Val MSE: 6735914910.5969, Val R2: 0.6578\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1108\n",
      "Val RMSE: 79792.0092, Val MAE: 43356.2363, Val MSE: 6366764730.0205, Val R2: 0.6765\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1061\n",
      "Val RMSE: 78311.5915, Val MAE: 41003.2029, Val MSE: 6132705368.8016, Val R2: 0.6884\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1052\n",
      "Val RMSE: 78401.8584, Val MAE: 40772.5337, Val MSE: 6146851398.7624, Val R2: 0.6877\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1062\n",
      "Val RMSE: 81279.0884, Val MAE: 40510.5810, Val MSE: 6606290214.1036, Val R2: 0.6644\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1123\n",
      "Val RMSE: 80939.6814, Val MAE: 41560.3109, Val MSE: 6551232020.7153, Val R2: 0.6672\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1069\n",
      "Val RMSE: 76583.3842, Val MAE: 41486.8468, Val MSE: 5865014728.9094, Val R2: 0.7020\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1196\n",
      "Val RMSE: 85597.4850, Val MAE: 41966.6782, Val MSE: 7326929437.2362, Val R2: 0.6277\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1161\n",
      "Val RMSE: 82372.2718, Val MAE: 42929.8542, Val MSE: 6785191168.4424, Val R2: 0.6553\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1107\n",
      "Val RMSE: 79527.1816, Val MAE: 41819.7005, Val MSE: 6324572618.9737, Val R2: 0.6787\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1127\n",
      "Val RMSE: 79984.9660, Val MAE: 42227.9592, Val MSE: 6397594782.9363, Val R2: 0.6750\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.1050\n",
      "Val RMSE: 77740.8576, Val MAE: 39421.3682, Val MSE: 6043640933.6959, Val R2: 0.6929\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.0954\n",
      "Val RMSE: 74000.9246, Val MAE: 38122.0691, Val MSE: 5476136845.5226, Val R2: 0.7218\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0423, Val Loss: 0.1047\n",
      "Val RMSE: 78384.5901, Val MAE: 39775.4521, Val MSE: 6144143970.9081, Val R2: 0.6878\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.1023\n",
      "Val RMSE: 76152.5558, Val MAE: 39727.1984, Val MSE: 5799211751.7058, Val R2: 0.7054\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0405, Val Loss: 0.0950\n",
      "Val RMSE: 73847.8174, Val MAE: 38339.5849, Val MSE: 5453500141.5650, Val R2: 0.7229\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0408, Val Loss: 0.0913\n",
      "Val RMSE: 71719.0715, Val MAE: 38388.8360, Val MSE: 5143625218.4539, Val R2: 0.7387\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 72068.2335, Test MAE: 39069.0069, Test MSE: 5193830272.8482, Test R2: 0.6671\n",
      "Inference Time: 2.3844572213979867e-05 seconds per sample\n",
      "\n",
      "Iteration 24 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3749, Val Loss: 0.2818\n",
      "Val RMSE: 140423.9563, Val MAE: 89121.5477, Val MSE: 19718887495.3257, Val R2: -0.0018\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2814, Val Loss: 0.2823\n",
      "Val RMSE: 142691.5494, Val MAE: 83244.1557, Val MSE: 20360878283.1403, Val R2: -0.0345\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2747, Val Loss: 0.2780\n",
      "Val RMSE: 142476.8138, Val MAE: 83060.9406, Val MSE: 20299642463.1505, Val R2: -0.0313\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2697, Val Loss: 0.2795\n",
      "Val RMSE: 143027.4186, Val MAE: 82084.2214, Val MSE: 20456842461.6116, Val R2: -0.0393\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2772\n",
      "Val RMSE: 141842.4144, Val MAE: 84066.2806, Val MSE: 20119270529.2924, Val R2: -0.0222\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2810\n",
      "Val RMSE: 143970.1503, Val MAE: 81165.9667, Val MSE: 20727404178.2046, Val R2: -0.0531\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2829\n",
      "Val RMSE: 141842.9396, Val MAE: 87776.5727, Val MSE: 20119419517.5142, Val R2: -0.0222\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2720\n",
      "Val RMSE: 142639.0329, Val MAE: 80356.5891, Val MSE: 20345893706.5795, Val R2: -0.0337\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2566, Val Loss: 0.2748\n",
      "Val RMSE: 142188.5688, Val MAE: 83317.6622, Val MSE: 20217589091.5878, Val R2: -0.0272\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2552, Val Loss: 0.2718\n",
      "Val RMSE: 142449.2418, Val MAE: 79837.4903, Val MSE: 20291786492.4352, Val R2: -0.0310\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2711\n",
      "Val RMSE: 141342.1513, Val MAE: 82329.7749, Val MSE: 19977603739.7014, Val R2: -0.0150\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2737\n",
      "Val RMSE: 143901.0669, Val MAE: 77445.1345, Val MSE: 20707517044.6671, Val R2: -0.0521\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2472, Val Loss: 0.2656\n",
      "Val RMSE: 137243.3052, Val MAE: 81319.3327, Val MSE: 18835724821.0581, Val R2: 0.0430\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2565\n",
      "Val RMSE: 136530.6177, Val MAE: 78803.5277, Val MSE: 18640609560.8507, Val R2: 0.0529\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2378, Val Loss: 0.2627\n",
      "Val RMSE: 138331.8021, Val MAE: 76536.2399, Val MSE: 19135687467.3268, Val R2: 0.0278\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2373, Val Loss: 0.2446\n",
      "Val RMSE: 133489.3800, Val MAE: 75405.5946, Val MSE: 17819414560.9223, Val R2: 0.0947\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2287, Val Loss: 0.2393\n",
      "Val RMSE: 129758.9998, Val MAE: 79133.1166, Val MSE: 16837398041.1762, Val R2: 0.1446\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2249, Val Loss: 0.2342\n",
      "Val RMSE: 132749.2049, Val MAE: 73586.6923, Val MSE: 17622351397.6241, Val R2: 0.1047\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2152, Val Loss: 0.2379\n",
      "Val RMSE: 130825.3337, Val MAE: 78259.3549, Val MSE: 17115267947.0602, Val R2: 0.1304\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2102, Val Loss: 0.2285\n",
      "Val RMSE: 131309.6628, Val MAE: 71471.3456, Val MSE: 17242227556.0302, Val R2: 0.1240\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2062, Val Loss: 0.2392\n",
      "Val RMSE: 132894.2332, Val MAE: 71317.7365, Val MSE: 17660877214.0859, Val R2: 0.1027\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2032, Val Loss: 0.2618\n",
      "Val RMSE: 142769.2548, Val MAE: 78411.4732, Val MSE: 20383060129.6767, Val R2: -0.0356\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2087, Val Loss: 0.2323\n",
      "Val RMSE: 130599.5425, Val MAE: 73290.6229, Val MSE: 17056240497.0540, Val R2: 0.1334\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2137\n",
      "Val RMSE: 124172.3677, Val MAE: 70738.6454, Val MSE: 15418776907.2167, Val R2: 0.2166\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1919, Val Loss: 0.2060\n",
      "Val RMSE: 122611.0329, Val MAE: 66489.5009, Val MSE: 15033465381.3404, Val R2: 0.2362\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1834, Val Loss: 0.2166\n",
      "Val RMSE: 116887.2882, Val MAE: 71090.7154, Val MSE: 13662638149.3715, Val R2: 0.3059\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1747, Val Loss: 0.1983\n",
      "Val RMSE: 110592.4015, Val MAE: 63358.6122, Val MSE: 12230679278.1617, Val R2: 0.3786\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1672, Val Loss: 0.2007\n",
      "Val RMSE: 105354.5693, Val MAE: 71002.8213, Val MSE: 11099585262.6863, Val R2: 0.4361\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1692, Val Loss: 0.1869\n",
      "Val RMSE: 105419.5140, Val MAE: 62160.2786, Val MSE: 11113273921.7409, Val R2: 0.4354\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1675\n",
      "Val RMSE: 98824.4848, Val MAE: 61278.2493, Val MSE: 9766278805.3165, Val R2: 0.5038\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1515, Val Loss: 0.1687\n",
      "Val RMSE: 100606.1832, Val MAE: 59595.2539, Val MSE: 10121604089.6066, Val R2: 0.4858\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1629\n",
      "Val RMSE: 98726.9702, Val MAE: 59004.0595, Val MSE: 9747014645.1732, Val R2: 0.5048\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1424, Val Loss: 0.1733\n",
      "Val RMSE: 101068.1587, Val MAE: 59312.5325, Val MSE: 10214772704.4295, Val R2: 0.4810\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1371, Val Loss: 0.1502\n",
      "Val RMSE: 95182.1239, Val MAE: 53942.3818, Val MSE: 9059636714.0620, Val R2: 0.5397\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1322, Val Loss: 0.1598\n",
      "Val RMSE: 97850.9514, Val MAE: 57635.4451, Val MSE: 9574808682.2433, Val R2: 0.5135\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1290, Val Loss: 0.1770\n",
      "Val RMSE: 101654.4554, Val MAE: 63927.2761, Val MSE: 10333628297.0273, Val R2: 0.4750\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1268, Val Loss: 0.1521\n",
      "Val RMSE: 95135.4699, Val MAE: 55111.3977, Val MSE: 9050757633.6173, Val R2: 0.5402\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1218, Val Loss: 0.1589\n",
      "Val RMSE: 96895.7817, Val MAE: 56102.4449, Val MSE: 9388792505.7051, Val R2: 0.5230\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1191, Val Loss: 0.1554\n",
      "Val RMSE: 96480.6522, Val MAE: 54343.0193, Val MSE: 9308516258.0612, Val R2: 0.5271\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1148, Val Loss: 0.1581\n",
      "Val RMSE: 96722.5688, Val MAE: 56382.0681, Val MSE: 9355255315.3309, Val R2: 0.5247\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1119, Val Loss: 0.1591\n",
      "Val RMSE: 98567.7972, Val MAE: 55050.7124, Val MSE: 9715610646.1783, Val R2: 0.5064\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1131, Val Loss: 0.1607\n",
      "Val RMSE: 97301.1360, Val MAE: 55876.9664, Val MSE: 9467511058.7728, Val R2: 0.5190\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1089, Val Loss: 0.1603\n",
      "Val RMSE: 97419.7576, Val MAE: 55539.2596, Val MSE: 9490609166.4744, Val R2: 0.5178\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1081, Val Loss: 0.1549\n",
      "Val RMSE: 97176.0683, Val MAE: 54437.6192, Val MSE: 9443188255.8679, Val R2: 0.5202\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1055, Val Loss: 0.1624\n",
      "Val RMSE: 98849.2211, Val MAE: 55465.7541, Val MSE: 9771168511.3923, Val R2: 0.5036\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1579\n",
      "Val RMSE: 97151.8387, Val MAE: 56355.0453, Val MSE: 9438479760.1169, Val R2: 0.5205\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1042, Val Loss: 0.1716\n",
      "Val RMSE: 100779.3339, Val MAE: 56776.2402, Val MSE: 10156474145.5651, Val R2: 0.4840\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1030, Val Loss: 0.1559\n",
      "Val RMSE: 96167.8785, Val MAE: 54830.3649, Val MSE: 9248260850.8313, Val R2: 0.5301\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1028, Val Loss: 0.1624\n",
      "Val RMSE: 98514.5949, Val MAE: 56701.6072, Val MSE: 9705125410.5834, Val R2: 0.5069\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0967, Val Loss: 0.1663\n",
      "Val RMSE: 99952.5870, Val MAE: 57643.0383, Val MSE: 9990519655.1219, Val R2: 0.4924\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1619\n",
      "Val RMSE: 98502.1052, Val MAE: 56569.2855, Val MSE: 9702664725.1920, Val R2: 0.5070\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1591\n",
      "Val RMSE: 96353.5629, Val MAE: 59300.4930, Val MSE: 9284009087.1016, Val R2: 0.5283\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0925, Val Loss: 0.1621\n",
      "Val RMSE: 95881.2654, Val MAE: 56338.3148, Val MSE: 9193217049.5460, Val R2: 0.5329\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0891, Val Loss: 0.1654\n",
      "Val RMSE: 97381.7198, Val MAE: 54239.0509, Val MSE: 9483199352.3791, Val R2: 0.5182\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0872, Val Loss: 0.1567\n",
      "Val RMSE: 94557.5583, Val MAE: 55804.8583, Val MSE: 8941131840.7780, Val R2: 0.5457\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1490\n",
      "Val RMSE: 89686.0697, Val MAE: 55613.4537, Val MSE: 8043591106.0705, Val R2: 0.5913\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1475\n",
      "Val RMSE: 89691.2351, Val MAE: 55094.1144, Val MSE: 8044517647.4565, Val R2: 0.5913\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1579\n",
      "Val RMSE: 90667.7886, Val MAE: 54095.5074, Val MSE: 8220647896.0143, Val R2: 0.5823\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1470\n",
      "Val RMSE: 87488.2939, Val MAE: 53190.0064, Val MSE: 7654201577.3788, Val R2: 0.6111\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1532\n",
      "Val RMSE: 89923.0664, Val MAE: 53865.6412, Val MSE: 8086157873.0888, Val R2: 0.5892\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1496\n",
      "Val RMSE: 89018.3408, Val MAE: 57421.6153, Val MSE: 7924264991.3795, Val R2: 0.5974\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1432\n",
      "Val RMSE: 87583.4336, Val MAE: 51837.2474, Val MSE: 7670857846.3456, Val R2: 0.6103\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1389\n",
      "Val RMSE: 84486.5251, Val MAE: 51982.0929, Val MSE: 7137972930.9760, Val R2: 0.6373\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1425\n",
      "Val RMSE: 85155.9250, Val MAE: 53390.1058, Val MSE: 7251531568.3700, Val R2: 0.6316\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0701, Val Loss: 0.1363\n",
      "Val RMSE: 81935.0198, Val MAE: 51810.0079, Val MSE: 6713347476.8558, Val R2: 0.6589\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.1522\n",
      "Val RMSE: 91139.0999, Val MAE: 52439.4600, Val MSE: 8306335536.4033, Val R2: 0.5780\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1328\n",
      "Val RMSE: 84358.8782, Val MAE: 49888.1336, Val MSE: 7116420324.2518, Val R2: 0.6384\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1365\n",
      "Val RMSE: 82703.0998, Val MAE: 51835.5847, Val MSE: 6839802721.2927, Val R2: 0.6525\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1385\n",
      "Val RMSE: 85789.6991, Val MAE: 50340.6652, Val MSE: 7359872475.1542, Val R2: 0.6261\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0644, Val Loss: 0.1415\n",
      "Val RMSE: 82888.4021, Val MAE: 49483.3364, Val MSE: 6870487201.3167, Val R2: 0.6509\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1354\n",
      "Val RMSE: 81881.3296, Val MAE: 49321.5516, Val MSE: 6704552134.0521, Val R2: 0.6594\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1290\n",
      "Val RMSE: 79753.0870, Val MAE: 48175.0734, Val MSE: 6360554885.2240, Val R2: 0.6768\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1375\n",
      "Val RMSE: 84024.7693, Val MAE: 49399.1764, Val MSE: 7060161859.7545, Val R2: 0.6413\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1283\n",
      "Val RMSE: 79868.3560, Val MAE: 47412.7108, Val MSE: 6378954296.5377, Val R2: 0.6759\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1411\n",
      "Val RMSE: 83218.4679, Val MAE: 50942.0335, Val MSE: 6925313396.1545, Val R2: 0.6482\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1390\n",
      "Val RMSE: 83816.8752, Val MAE: 51688.7806, Val MSE: 7025268572.4747, Val R2: 0.6431\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1422\n",
      "Val RMSE: 84360.3119, Val MAE: 52280.9471, Val MSE: 7116662215.8831, Val R2: 0.6384\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1378\n",
      "Val RMSE: 85083.3275, Val MAE: 49175.5206, Val MSE: 7239172616.8262, Val R2: 0.6322\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1376\n",
      "Val RMSE: 83005.1967, Val MAE: 48711.8068, Val MSE: 6889862686.2294, Val R2: 0.6500\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1323\n",
      "Val RMSE: 81116.2983, Val MAE: 49684.9712, Val MSE: 6579853855.6049, Val R2: 0.6657\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1273\n",
      "Val RMSE: 78436.1463, Val MAE: 46310.3558, Val MSE: 6152229040.1343, Val R2: 0.6874\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1344\n",
      "Val RMSE: 82400.5504, Val MAE: 47816.3139, Val MSE: 6789850698.5906, Val R2: 0.6550\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1331\n",
      "Val RMSE: 80019.5322, Val MAE: 48276.9526, Val MSE: 6403125537.4536, Val R2: 0.6747\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1411\n",
      "Val RMSE: 84322.9354, Val MAE: 50714.1088, Val MSE: 7110357440.8296, Val R2: 0.6387\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1345\n",
      "Val RMSE: 81141.9175, Val MAE: 48262.8832, Val MSE: 6584010781.1976, Val R2: 0.6655\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1346\n",
      "Val RMSE: 80341.3675, Val MAE: 48868.5070, Val MSE: 6454735324.0353, Val R2: 0.6721\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1358\n",
      "Val RMSE: 80893.7222, Val MAE: 50372.1237, Val MSE: 6543794294.6626, Val R2: 0.6675\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1350\n",
      "Val RMSE: 80449.9313, Val MAE: 49074.9289, Val MSE: 6472191446.9909, Val R2: 0.6712\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1337\n",
      "Val RMSE: 81357.7429, Val MAE: 47900.8440, Val MSE: 6619082333.4984, Val R2: 0.6637\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1335\n",
      "Val RMSE: 82120.9967, Val MAE: 47942.4086, Val MSE: 6743858097.0895, Val R2: 0.6574\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1342\n",
      "Val RMSE: 81096.2009, Val MAE: 49022.5549, Val MSE: 6576593798.8457, Val R2: 0.6659\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1399\n",
      "Val RMSE: 83991.5442, Val MAE: 50009.2230, Val MSE: 7054579504.7451, Val R2: 0.6416\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1382\n",
      "Val RMSE: 83151.7730, Val MAE: 47916.2534, Val MSE: 6914217346.0895, Val R2: 0.6487\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1319\n",
      "Val RMSE: 79195.5733, Val MAE: 47758.3451, Val MSE: 6271938827.9280, Val R2: 0.6813\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1385\n",
      "Val RMSE: 82251.7872, Val MAE: 50328.2613, Val MSE: 6765356504.4848, Val R2: 0.6563\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1366\n",
      "Val RMSE: 81035.0640, Val MAE: 48096.8297, Val MSE: 6566681599.0271, Val R2: 0.6664\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1423\n",
      "Val RMSE: 84464.8781, Val MAE: 48924.4446, Val MSE: 7134315635.0523, Val R2: 0.6375\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1386\n",
      "Val RMSE: 81400.9477, Val MAE: 47811.4185, Val MSE: 6626114281.8752, Val R2: 0.6634\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.1375\n",
      "Val RMSE: 83021.9663, Val MAE: 48842.3014, Val MSE: 6892646880.7015, Val R2: 0.6498\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1298\n",
      "Val RMSE: 79315.0656, Val MAE: 47853.0745, Val MSE: 6290879632.4777, Val R2: 0.6804\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 80373.8097, Test MAE: 47618.3297, Test MSE: 6459949291.2899, Test R2: 0.5859\n",
      "Inference Time: 2.2847542395958534e-05 seconds per sample\n",
      "\n",
      "Iteration 25 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3818, Val Loss: 0.2812\n",
      "Val RMSE: 140283.1505, Val MAE: 89414.6766, Val MSE: 19679362308.1993, Val R2: 0.0002\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2795, Val Loss: 0.2830\n",
      "Val RMSE: 143836.0014, Val MAE: 81582.6288, Val MSE: 20688795292.2695, Val R2: -0.0511\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2702, Val Loss: 0.2752\n",
      "Val RMSE: 141165.5980, Val MAE: 84208.9873, Val MSE: 19927726072.2715, Val R2: -0.0125\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2694, Val Loss: 0.2755\n",
      "Val RMSE: 141526.5447, Val MAE: 83945.1033, Val MSE: 20029762843.4482, Val R2: -0.0176\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2662, Val Loss: 0.2752\n",
      "Val RMSE: 142095.7204, Val MAE: 82535.9171, Val MSE: 20191193761.9721, Val R2: -0.0258\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2733\n",
      "Val RMSE: 142293.3296, Val MAE: 82393.3247, Val MSE: 20247391659.8174, Val R2: -0.0287\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2742\n",
      "Val RMSE: 141124.0392, Val MAE: 84855.2520, Val MSE: 19915994426.4084, Val R2: -0.0119\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2564, Val Loss: 0.2710\n",
      "Val RMSE: 141580.6598, Val MAE: 81948.0073, Val MSE: 20045083240.2342, Val R2: -0.0184\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2732\n",
      "Val RMSE: 142259.1525, Val MAE: 80803.2067, Val MSE: 20237666479.8308, Val R2: -0.0282\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2716\n",
      "Val RMSE: 143022.7127, Val MAE: 78936.2924, Val MSE: 20455496354.5257, Val R2: -0.0393\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2675\n",
      "Val RMSE: 140812.7798, Val MAE: 81711.4172, Val MSE: 19828238961.6657, Val R2: -0.0074\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2534, Val Loss: 0.2879\n",
      "Val RMSE: 145811.3367, Val MAE: 79320.9958, Val MSE: 21260945911.7642, Val R2: -0.0802\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2666\n",
      "Val RMSE: 142079.5950, Val MAE: 78584.7518, Val MSE: 20186611313.6241, Val R2: -0.0256\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2603\n",
      "Val RMSE: 137526.3837, Val MAE: 78820.6491, Val MSE: 18913506223.6680, Val R2: 0.0391\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2559\n",
      "Val RMSE: 137207.7425, Val MAE: 78267.8165, Val MSE: 18825964588.5812, Val R2: 0.0435\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2415, Val Loss: 0.2598\n",
      "Val RMSE: 136839.8126, Val MAE: 77364.0453, Val MSE: 18725134324.9452, Val R2: 0.0486\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2384, Val Loss: 0.2547\n",
      "Val RMSE: 135783.2084, Val MAE: 77165.3567, Val MSE: 18437079686.7943, Val R2: 0.0633\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2311, Val Loss: 0.2414\n",
      "Val RMSE: 131889.2636, Val MAE: 74902.2336, Val MSE: 17394777846.8402, Val R2: 0.1162\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2236, Val Loss: 0.2422\n",
      "Val RMSE: 134112.9674, Val MAE: 73569.8195, Val MSE: 17986288021.5360, Val R2: 0.0862\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2125, Val Loss: 0.2406\n",
      "Val RMSE: 129306.6332, Val MAE: 78293.7469, Val MSE: 16720205377.3105, Val R2: 0.1505\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2097, Val Loss: 0.2254\n",
      "Val RMSE: 128877.1003, Val MAE: 70870.4192, Val MSE: 16609306986.9389, Val R2: 0.1561\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2218\n",
      "Val RMSE: 128264.4888, Val MAE: 69711.3950, Val MSE: 16451779090.9969, Val R2: 0.1641\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2016, Val Loss: 0.2351\n",
      "Val RMSE: 130516.4233, Val MAE: 69976.9061, Val MSE: 17034536740.4854, Val R2: 0.1345\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2002, Val Loss: 0.2269\n",
      "Val RMSE: 128659.9090, Val MAE: 71299.8398, Val MSE: 16553372174.9817, Val R2: 0.1590\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1981, Val Loss: 0.2169\n",
      "Val RMSE: 120125.5060, Val MAE: 69974.9796, Val MSE: 14430137189.0015, Val R2: 0.2669\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1903, Val Loss: 0.2029\n",
      "Val RMSE: 112867.0509, Val MAE: 69173.9222, Val MSE: 12738971176.8761, Val R2: 0.3528\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1821, Val Loss: 0.1963\n",
      "Val RMSE: 109131.8002, Val MAE: 66796.7289, Val MSE: 11909749818.9105, Val R2: 0.3949\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1744, Val Loss: 0.1788\n",
      "Val RMSE: 102307.2271, Val MAE: 60561.3859, Val MSE: 10466768710.2723, Val R2: 0.4682\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1728, Val Loss: 0.1739\n",
      "Val RMSE: 99495.2238, Val MAE: 63387.4573, Val MSE: 9899299558.4622, Val R2: 0.4971\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1669, Val Loss: 0.1632\n",
      "Val RMSE: 96828.3310, Val MAE: 59109.1519, Val MSE: 9375725680.9369, Val R2: 0.5237\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1561\n",
      "Val RMSE: 96151.2299, Val MAE: 56606.4136, Val MSE: 9245059002.4040, Val R2: 0.5303\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1520, Val Loss: 0.1600\n",
      "Val RMSE: 97727.0180, Val MAE: 57261.9863, Val MSE: 9550570037.8658, Val R2: 0.5148\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1461, Val Loss: 0.1630\n",
      "Val RMSE: 98111.2559, Val MAE: 56178.0779, Val MSE: 9625818528.3185, Val R2: 0.5109\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1432, Val Loss: 0.1582\n",
      "Val RMSE: 96579.8898, Val MAE: 56849.0292, Val MSE: 9327675118.6371, Val R2: 0.5261\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1375, Val Loss: 0.1731\n",
      "Val RMSE: 100026.1835, Val MAE: 58819.9692, Val MSE: 10005237376.5529, Val R2: 0.4917\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1306, Val Loss: 0.1558\n",
      "Val RMSE: 96201.0831, Val MAE: 54479.5282, Val MSE: 9254648394.9843, Val R2: 0.5298\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1252, Val Loss: 0.1624\n",
      "Val RMSE: 97650.5892, Val MAE: 54515.7630, Val MSE: 9535637571.4218, Val R2: 0.5155\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1212, Val Loss: 0.1692\n",
      "Val RMSE: 96819.8504, Val MAE: 59237.7229, Val MSE: 9374083424.4707, Val R2: 0.5237\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1164, Val Loss: 0.1506\n",
      "Val RMSE: 92051.5414, Val MAE: 57030.1839, Val MSE: 8473486264.9293, Val R2: 0.5695\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1110, Val Loss: 0.1398\n",
      "Val RMSE: 89838.9741, Val MAE: 51608.7745, Val MSE: 8071041261.9632, Val R2: 0.5899\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1076, Val Loss: 0.1466\n",
      "Val RMSE: 92440.0186, Val MAE: 53050.5078, Val MSE: 8545157031.5442, Val R2: 0.5659\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1409\n",
      "Val RMSE: 90669.9958, Val MAE: 53480.6692, Val MSE: 8221048130.7603, Val R2: 0.5823\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1068, Val Loss: 0.1469\n",
      "Val RMSE: 91508.6534, Val MAE: 55620.0268, Val MSE: 8373833640.9749, Val R2: 0.5746\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1128, Val Loss: 0.1667\n",
      "Val RMSE: 96491.3415, Val MAE: 61583.8940, Val MSE: 9310578993.1910, Val R2: 0.5270\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1067, Val Loss: 0.1487\n",
      "Val RMSE: 93334.7725, Val MAE: 52724.9414, Val MSE: 8711379749.3467, Val R2: 0.5574\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0999, Val Loss: 0.1397\n",
      "Val RMSE: 90582.5811, Val MAE: 50271.6043, Val MSE: 8205203993.1296, Val R2: 0.5831\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1469\n",
      "Val RMSE: 92584.7861, Val MAE: 51279.8374, Val MSE: 8571942611.2131, Val R2: 0.5645\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0912, Val Loss: 0.1501\n",
      "Val RMSE: 94534.2611, Val MAE: 51723.1670, Val MSE: 8936726516.7031, Val R2: 0.5460\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0893, Val Loss: 0.1539\n",
      "Val RMSE: 96057.6918, Val MAE: 53835.0107, Val MSE: 9227080156.1398, Val R2: 0.5312\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1383\n",
      "Val RMSE: 89807.1181, Val MAE: 49796.2520, Val MSE: 8065318467.6649, Val R2: 0.5902\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0831, Val Loss: 0.1439\n",
      "Val RMSE: 91610.9364, Val MAE: 50147.5863, Val MSE: 8392563673.4974, Val R2: 0.5736\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0820, Val Loss: 0.1468\n",
      "Val RMSE: 92673.6742, Val MAE: 50363.7571, Val MSE: 8588409885.7770, Val R2: 0.5637\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1334\n",
      "Val RMSE: 84838.4379, Val MAE: 49198.7008, Val MSE: 7197560551.6868, Val R2: 0.6343\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1355\n",
      "Val RMSE: 87487.1515, Val MAE: 49360.7652, Val MSE: 7654001681.4416, Val R2: 0.6111\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1395\n",
      "Val RMSE: 89480.9433, Val MAE: 49555.1683, Val MSE: 8006839206.7322, Val R2: 0.5932\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1417\n",
      "Val RMSE: 89138.8943, Val MAE: 52287.4329, Val MSE: 7945742485.6000, Val R2: 0.5963\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1356\n",
      "Val RMSE: 83825.0458, Val MAE: 47895.5862, Val MSE: 7026638308.7179, Val R2: 0.6430\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1436\n",
      "Val RMSE: 88121.0130, Val MAE: 49026.5719, Val MSE: 7765312938.3627, Val R2: 0.6055\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1296\n",
      "Val RMSE: 85867.8244, Val MAE: 47540.6871, Val MSE: 7373283260.0764, Val R2: 0.6254\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1434\n",
      "Val RMSE: 85607.7000, Val MAE: 49103.1247, Val MSE: 7328678300.5343, Val R2: 0.6277\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1257\n",
      "Val RMSE: 80474.4457, Val MAE: 47713.7169, Val MSE: 6476136405.3466, Val R2: 0.6710\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0669, Val Loss: 0.1162\n",
      "Val RMSE: 76189.8792, Val MAE: 44112.9049, Val MSE: 5804897684.9756, Val R2: 0.7051\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1350\n",
      "Val RMSE: 80966.2992, Val MAE: 50133.4388, Val MSE: 6555541607.2832, Val R2: 0.6669\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1255\n",
      "Val RMSE: 78952.9975, Val MAE: 46228.0269, Val MSE: 6233575814.6109, Val R2: 0.6833\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1280\n",
      "Val RMSE: 79716.8794, Val MAE: 48385.7768, Val MSE: 6354780864.7019, Val R2: 0.6771\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1286\n",
      "Val RMSE: 79229.7145, Val MAE: 49560.4133, Val MSE: 6277347664.1147, Val R2: 0.6811\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1119\n",
      "Val RMSE: 74185.8070, Val MAE: 45547.1353, Val MSE: 5503533961.5558, Val R2: 0.7204\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1255\n",
      "Val RMSE: 78789.4643, Val MAE: 49580.2005, Val MSE: 6207779682.2591, Val R2: 0.6846\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1263\n",
      "Val RMSE: 77114.9806, Val MAE: 46826.1997, Val MSE: 5946720232.0324, Val R2: 0.6979\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1218\n",
      "Val RMSE: 77632.4600, Val MAE: 48209.2454, Val MSE: 6026798846.5544, Val R2: 0.6938\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1167\n",
      "Val RMSE: 76238.1532, Val MAE: 44921.0928, Val MSE: 5812255995.8396, Val R2: 0.7047\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1204\n",
      "Val RMSE: 77876.5276, Val MAE: 45600.3443, Val MSE: 6064753548.6365, Val R2: 0.6919\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1349\n",
      "Val RMSE: 83416.2469, Val MAE: 50597.0263, Val MSE: 6958270240.7809, Val R2: 0.6465\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1145\n",
      "Val RMSE: 75209.6552, Val MAE: 43862.8063, Val MSE: 5656492233.7860, Val R2: 0.7126\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1206\n",
      "Val RMSE: 76117.7329, Val MAE: 47050.1589, Val MSE: 5793909262.9745, Val R2: 0.7056\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.1125\n",
      "Val RMSE: 71800.4367, Val MAE: 46033.7162, Val MSE: 5155302715.7676, Val R2: 0.7381\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1160\n",
      "Val RMSE: 75652.6543, Val MAE: 44150.8980, Val MSE: 5723324099.3673, Val R2: 0.7092\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1105\n",
      "Val RMSE: 73016.8633, Val MAE: 42879.3697, Val MSE: 5331462323.8339, Val R2: 0.7291\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1123\n",
      "Val RMSE: 74446.6003, Val MAE: 43897.9098, Val MSE: 5542296291.6349, Val R2: 0.7184\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1213\n",
      "Val RMSE: 76083.3775, Val MAE: 45085.2559, Val MSE: 5788680326.4505, Val R2: 0.7059\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1047\n",
      "Val RMSE: 70555.2584, Val MAE: 41432.1316, Val MSE: 4978044484.3299, Val R2: 0.7471\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1012\n",
      "Val RMSE: 70460.2183, Val MAE: 40113.2857, Val MSE: 4964642367.2306, Val R2: 0.7478\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.0914\n",
      "Val RMSE: 67534.6550, Val MAE: 37733.3909, Val MSE: 4560929624.5416, Val R2: 0.7683\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.0968\n",
      "Val RMSE: 67888.8422, Val MAE: 40270.8208, Val MSE: 4608894893.1873, Val R2: 0.7658\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1120\n",
      "Val RMSE: 73819.1671, Val MAE: 42277.6636, Val MSE: 5449269434.8498, Val R2: 0.7231\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1085\n",
      "Val RMSE: 71075.5393, Val MAE: 43988.3578, Val MSE: 5051732289.4570, Val R2: 0.7433\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.0958\n",
      "Val RMSE: 66817.6801, Val MAE: 39952.2855, Val MSE: 4464602375.7359, Val R2: 0.7732\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.0972\n",
      "Val RMSE: 67448.6350, Val MAE: 41823.1026, Val MSE: 4549318361.4436, Val R2: 0.7689\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1073\n",
      "Val RMSE: 71665.5449, Val MAE: 42323.6981, Val MSE: 5135950328.9347, Val R2: 0.7391\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.1033\n",
      "Val RMSE: 69708.6569, Val MAE: 41141.3171, Val MSE: 4859296843.8910, Val R2: 0.7531\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.1103\n",
      "Val RMSE: 72797.3205, Val MAE: 42233.7703, Val MSE: 5299449872.5076, Val R2: 0.7308\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.1011\n",
      "Val RMSE: 68270.3922, Val MAE: 41607.4639, Val MSE: 4660846455.2463, Val R2: 0.7632\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0420, Val Loss: 0.0927\n",
      "Val RMSE: 67201.6397, Val MAE: 39014.6977, Val MSE: 4516060377.6694, Val R2: 0.7706\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.0979\n",
      "Val RMSE: 68935.3862, Val MAE: 39738.9587, Val MSE: 4752087474.5581, Val R2: 0.7586\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1019\n",
      "Val RMSE: 69455.7468, Val MAE: 41684.7213, Val MSE: 4824100763.5983, Val R2: 0.7549\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0421, Val Loss: 0.1014\n",
      "Val RMSE: 70315.5371, Val MAE: 39493.6606, Val MSE: 4944274763.7311, Val R2: 0.7488\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0411, Val Loss: 0.0968\n",
      "Val RMSE: 69317.5576, Val MAE: 39721.9242, Val MSE: 4804923792.2370, Val R2: 0.7559\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0401, Val Loss: 0.0938\n",
      "Val RMSE: 65832.9955, Val MAE: 39371.1241, Val MSE: 4333983292.9599, Val R2: 0.7798\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0409, Val Loss: 0.0938\n",
      "Val RMSE: 66941.8037, Val MAE: 39804.4423, Val MSE: 4481205081.3405, Val R2: 0.7723\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0404, Val Loss: 0.1005\n",
      "Val RMSE: 71173.3080, Val MAE: 39983.9523, Val MSE: 5065639771.8917, Val R2: 0.7426\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74975.2365, Test MAE: 41612.8490, Test MSE: 5621286086.7084, Test R2: 0.6397\n",
      "Inference Time: 1.932672353891226e-05 seconds per sample\n",
      "\n",
      "Iteration 26 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3723, Val Loss: 0.2773\n",
      "Val RMSE: 141214.1450, Val MAE: 84405.4153, Val MSE: 19941434740.9152, Val R2: -0.0132\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2775, Val Loss: 0.2782\n",
      "Val RMSE: 142726.6021, Val MAE: 82106.3550, Val MSE: 20370882934.4356, Val R2: -0.0350\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2714, Val Loss: 0.2790\n",
      "Val RMSE: 142999.3576, Val MAE: 81797.7436, Val MSE: 20448816279.2035, Val R2: -0.0389\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2675, Val Loss: 0.2756\n",
      "Val RMSE: 141465.2368, Val MAE: 84016.8241, Val MSE: 20012413211.3608, Val R2: -0.0168\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2807\n",
      "Val RMSE: 143615.8071, Val MAE: 81873.0362, Val MSE: 20625500049.5181, Val R2: -0.0479\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2847\n",
      "Val RMSE: 144868.0165, Val MAE: 80572.3649, Val MSE: 20986742204.5061, Val R2: -0.0663\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2782\n",
      "Val RMSE: 141778.0195, Val MAE: 85439.7128, Val MSE: 20101006823.0466, Val R2: -0.0213\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2747\n",
      "Val RMSE: 142342.9819, Val MAE: 81016.2327, Val MSE: 20261524499.9416, Val R2: -0.0294\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2806\n",
      "Val RMSE: 144583.2070, Val MAE: 79786.7274, Val MSE: 20904303746.2611, Val R2: -0.0621\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2739\n",
      "Val RMSE: 142073.6996, Val MAE: 82524.7125, Val MSE: 20184936106.6281, Val R2: -0.0255\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2679\n",
      "Val RMSE: 141303.5497, Val MAE: 80493.2591, Val MSE: 19966693160.6432, Val R2: -0.0144\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2697\n",
      "Val RMSE: 140576.3160, Val MAE: 82349.4590, Val MSE: 19761700617.4710, Val R2: -0.0040\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2500, Val Loss: 0.2707\n",
      "Val RMSE: 141899.5076, Val MAE: 80875.3708, Val MSE: 20135470249.5481, Val R2: -0.0230\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2700\n",
      "Val RMSE: 142725.1097, Val MAE: 78138.5847, Val MSE: 20370456938.3958, Val R2: -0.0349\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2470, Val Loss: 0.2682\n",
      "Val RMSE: 141166.5374, Val MAE: 80343.1226, Val MSE: 19927991284.4316, Val R2: -0.0125\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2466, Val Loss: 0.2646\n",
      "Val RMSE: 140505.2674, Val MAE: 79881.1096, Val MSE: 19741730159.7513, Val R2: -0.0030\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2634\n",
      "Val RMSE: 140477.0745, Val MAE: 79092.7352, Val MSE: 19733808452.7834, Val R2: -0.0026\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2449, Val Loss: 0.2661\n",
      "Val RMSE: 141102.1593, Val MAE: 79645.7677, Val MSE: 19909819351.9631, Val R2: -0.0115\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2407, Val Loss: 0.2666\n",
      "Val RMSE: 141773.8742, Val MAE: 78057.7944, Val MSE: 20099831393.9755, Val R2: -0.0212\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2620\n",
      "Val RMSE: 140612.9651, Val MAE: 78598.8272, Val MSE: 19772005964.8243, Val R2: -0.0045\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2437, Val Loss: 0.2770\n",
      "Val RMSE: 140774.5823, Val MAE: 83300.5124, Val MSE: 19817483019.4727, Val R2: -0.0069\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2412, Val Loss: 0.2629\n",
      "Val RMSE: 140867.2049, Val MAE: 78930.8450, Val MSE: 19843569427.2065, Val R2: -0.0082\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2394, Val Loss: 0.2740\n",
      "Val RMSE: 140476.1098, Val MAE: 82889.6361, Val MSE: 19733537434.2444, Val R2: -0.0026\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2705\n",
      "Val RMSE: 140450.5243, Val MAE: 81583.8404, Val MSE: 19726349770.5037, Val R2: -0.0022\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2351, Val Loss: 0.2570\n",
      "Val RMSE: 134738.5626, Val MAE: 79408.8231, Val MSE: 18154480261.4632, Val R2: 0.0776\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2283, Val Loss: 0.2851\n",
      "Val RMSE: 135887.0053, Val MAE: 86094.9564, Val MSE: 18465278212.2658, Val R2: 0.0618\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2315, Val Loss: 0.2565\n",
      "Val RMSE: 133174.9555, Val MAE: 79433.5585, Val MSE: 17735568765.6125, Val R2: 0.0989\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2193, Val Loss: 0.2391\n",
      "Val RMSE: 134577.4752, Val MAE: 73497.0315, Val MSE: 18111096824.5150, Val R2: 0.0798\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2068, Val Loss: 0.2171\n",
      "Val RMSE: 121205.8448, Val MAE: 71068.8042, Val MSE: 14690856814.8185, Val R2: 0.2536\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2034, Val Loss: 0.2184\n",
      "Val RMSE: 121096.8566, Val MAE: 71096.7260, Val MSE: 14664448677.1546, Val R2: 0.2550\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1879, Val Loss: 0.1983\n",
      "Val RMSE: 112722.8232, Val MAE: 64425.0348, Val MSE: 12706434861.6704, Val R2: 0.3544\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1790, Val Loss: 0.1880\n",
      "Val RMSE: 106774.6008, Val MAE: 63954.5287, Val MSE: 11400815378.8774, Val R2: 0.4208\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1681, Val Loss: 0.1899\n",
      "Val RMSE: 104436.8298, Val MAE: 62514.8611, Val MSE: 10907051423.6150, Val R2: 0.4459\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1616, Val Loss: 0.1627\n",
      "Val RMSE: 98277.1519, Val MAE: 60146.6481, Val MSE: 9658398595.1414, Val R2: 0.5093\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1588, Val Loss: 0.1672\n",
      "Val RMSE: 99118.4264, Val MAE: 59546.7283, Val MSE: 9824462442.7336, Val R2: 0.5009\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1554, Val Loss: 0.1612\n",
      "Val RMSE: 97334.6076, Val MAE: 58109.7159, Val MSE: 9474025841.9480, Val R2: 0.5187\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1472, Val Loss: 0.1742\n",
      "Val RMSE: 102956.8302, Val MAE: 59935.9096, Val MSE: 10600108894.7078, Val R2: 0.4614\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1473, Val Loss: 0.1604\n",
      "Val RMSE: 97606.6205, Val MAE: 57329.9169, Val MSE: 9527052371.5109, Val R2: 0.5160\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1477, Val Loss: 0.1580\n",
      "Val RMSE: 96954.8106, Val MAE: 57539.5045, Val MSE: 9400235298.5547, Val R2: 0.5224\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1395, Val Loss: 0.1511\n",
      "Val RMSE: 93982.7288, Val MAE: 53413.7306, Val MSE: 8832753318.1454, Val R2: 0.5512\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1292, Val Loss: 0.1526\n",
      "Val RMSE: 94704.0217, Val MAE: 53744.4720, Val MSE: 8968851732.4004, Val R2: 0.5443\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1418\n",
      "Val RMSE: 92940.2596, Val MAE: 51348.8787, Val MSE: 8637891853.9209, Val R2: 0.5611\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1200, Val Loss: 0.1378\n",
      "Val RMSE: 92806.1979, Val MAE: 50424.6336, Val MSE: 8612990370.7590, Val R2: 0.5624\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1381\n",
      "Val RMSE: 90790.4773, Val MAE: 50543.4493, Val MSE: 8242910761.1928, Val R2: 0.5812\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1472\n",
      "Val RMSE: 91800.7460, Val MAE: 51563.3038, Val MSE: 8427376968.0159, Val R2: 0.5718\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1030, Val Loss: 0.1315\n",
      "Val RMSE: 89080.1590, Val MAE: 48365.1331, Val MSE: 7935274719.4865, Val R2: 0.5968\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0992, Val Loss: 0.1282\n",
      "Val RMSE: 90087.9631, Val MAE: 47622.0354, Val MSE: 8115841102.1159, Val R2: 0.5877\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0948, Val Loss: 0.1650\n",
      "Val RMSE: 95483.4498, Val MAE: 54329.8104, Val MSE: 9117089194.0043, Val R2: 0.5368\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1398\n",
      "Val RMSE: 85928.3534, Val MAE: 50672.0265, Val MSE: 7383681917.9668, Val R2: 0.6249\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0891, Val Loss: 0.1194\n",
      "Val RMSE: 84119.8910, Val MAE: 46297.1750, Val MSE: 7076156066.2244, Val R2: 0.6405\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0870, Val Loss: 0.1369\n",
      "Val RMSE: 87751.9879, Val MAE: 50591.1234, Val MSE: 7700411374.8563, Val R2: 0.6088\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1679\n",
      "Val RMSE: 95568.4087, Val MAE: 57980.2987, Val MSE: 9133320734.7823, Val R2: 0.5360\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.2321\n",
      "Val RMSE: 122793.8917, Val MAE: 69469.4250, Val MSE: 15078339840.9825, Val R2: 0.2339\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1314\n",
      "Val RMSE: 83142.4937, Val MAE: 49266.6266, Val MSE: 6912674264.8037, Val R2: 0.6488\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1693\n",
      "Val RMSE: 94411.4918, Val MAE: 58144.2957, Val MSE: 8913529790.5001, Val R2: 0.5471\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1300\n",
      "Val RMSE: 79563.9132, Val MAE: 50894.5313, Val MSE: 6330416288.9763, Val R2: 0.6784\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1585\n",
      "Val RMSE: 91722.5629, Val MAE: 56759.3624, Val MSE: 8413028553.9506, Val R2: 0.5726\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1165\n",
      "Val RMSE: 76269.0871, Val MAE: 45539.5755, Val MSE: 5816973641.7794, Val R2: 0.7045\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0690, Val Loss: 0.2489\n",
      "Val RMSE: 123144.3659, Val MAE: 74883.2844, Val MSE: 15164534852.6375, Val R2: 0.2295\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1404\n",
      "Val RMSE: 83896.6299, Val MAE: 54028.6734, Val MSE: 7038644510.5547, Val R2: 0.6424\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1652\n",
      "Val RMSE: 91080.9553, Val MAE: 60047.8484, Val MSE: 8295740419.7297, Val R2: 0.5785\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1304\n",
      "Val RMSE: 81674.0255, Val MAE: 51168.5118, Val MSE: 6670646446.0013, Val R2: 0.6611\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1208\n",
      "Val RMSE: 78513.3060, Val MAE: 46662.2663, Val MSE: 6164339221.8278, Val R2: 0.6868\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.4459\n",
      "Val RMSE: 188567.3537, Val MAE: 102246.2689, Val MSE: 35557646884.2954, Val R2: -0.8066\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1221\n",
      "Val RMSE: 78133.1665, Val MAE: 47289.1701, Val MSE: 6104791709.3470, Val R2: 0.6898\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1024\n",
      "Val RMSE: 71149.8544, Val MAE: 42989.9702, Val MSE: 5062301784.1696, Val R2: 0.7428\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1011\n",
      "Val RMSE: 70618.2376, Val MAE: 41915.0501, Val MSE: 4986935481.1940, Val R2: 0.7466\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.2083\n",
      "Val RMSE: 105407.7272, Val MAE: 67044.6841, Val MSE: 11110788961.0669, Val R2: 0.4355\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1488\n",
      "Val RMSE: 87709.6339, Val MAE: 53767.4223, Val MSE: 7692979885.4120, Val R2: 0.6091\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1082\n",
      "Val RMSE: 74769.4718, Val MAE: 43662.8124, Val MSE: 5590473913.1152, Val R2: 0.7160\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1032\n",
      "Val RMSE: 71978.3211, Val MAE: 42263.6256, Val MSE: 5180878706.4475, Val R2: 0.7368\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.0976\n",
      "Val RMSE: 69994.4902, Val MAE: 40456.5184, Val MSE: 4899228662.4356, Val R2: 0.7511\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1014\n",
      "Val RMSE: 69857.9412, Val MAE: 42806.1101, Val MSE: 4880131947.2874, Val R2: 0.7521\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.0915\n",
      "Val RMSE: 67008.3947, Val MAE: 39630.9057, Val MSE: 4490124961.7904, Val R2: 0.7719\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1248\n",
      "Val RMSE: 79265.4711, Val MAE: 47380.2144, Val MSE: 6283014909.7618, Val R2: 0.6808\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.0972\n",
      "Val RMSE: 69188.8979, Val MAE: 39818.6034, Val MSE: 4787103591.9706, Val R2: 0.7568\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1408\n",
      "Val RMSE: 85317.6920, Val MAE: 51384.5901, Val MSE: 7279108563.0428, Val R2: 0.6302\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1038\n",
      "Val RMSE: 71955.2650, Val MAE: 42186.3086, Val MSE: 5177560166.1224, Val R2: 0.7369\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.0902\n",
      "Val RMSE: 68307.7186, Val MAE: 37476.8174, Val MSE: 4665944418.0206, Val R2: 0.7629\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.0922\n",
      "Val RMSE: 67405.2501, Val MAE: 37751.2777, Val MSE: 4543467740.7193, Val R2: 0.7692\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.0920\n",
      "Val RMSE: 67342.3744, Val MAE: 37901.1842, Val MSE: 4534995393.8428, Val R2: 0.7696\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.0935\n",
      "Val RMSE: 67288.8624, Val MAE: 38534.8674, Val MSE: 4527791009.6992, Val R2: 0.7700\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.0912\n",
      "Val RMSE: 66766.6496, Val MAE: 38797.7129, Val MSE: 4457785499.3653, Val R2: 0.7735\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.0957\n",
      "Val RMSE: 70102.5422, Val MAE: 40167.4121, Val MSE: 4914366418.8176, Val R2: 0.7503\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.1033\n",
      "Val RMSE: 73476.7240, Val MAE: 41091.5151, Val MSE: 5398828977.1122, Val R2: 0.7257\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.0891\n",
      "Val RMSE: 66340.2124, Val MAE: 38457.5495, Val MSE: 4401023784.2236, Val R2: 0.7764\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.0975\n",
      "Val RMSE: 71557.2166, Val MAE: 40995.2086, Val MSE: 5120435248.5117, Val R2: 0.7398\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0420, Val Loss: 0.0899\n",
      "Val RMSE: 66849.8727, Val MAE: 37125.7295, Val MSE: 4468905478.0537, Val R2: 0.7730\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0408, Val Loss: 0.0856\n",
      "Val RMSE: 65751.1843, Val MAE: 37535.6028, Val MSE: 4323218239.6034, Val R2: 0.7804\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.0869\n",
      "Val RMSE: 65758.1521, Val MAE: 36202.6455, Val MSE: 4324134572.1354, Val R2: 0.7803\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0409, Val Loss: 0.0940\n",
      "Val RMSE: 67765.4522, Val MAE: 38184.5295, Val MSE: 4592156506.6127, Val R2: 0.7667\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0395, Val Loss: 0.0889\n",
      "Val RMSE: 68276.0539, Val MAE: 37282.6187, Val MSE: 4661619533.2082, Val R2: 0.7632\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0396, Val Loss: 0.0902\n",
      "Val RMSE: 69482.4074, Val MAE: 37724.5379, Val MSE: 4827804939.1890, Val R2: 0.7547\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0397, Val Loss: 0.0892\n",
      "Val RMSE: 67855.1884, Val MAE: 38031.2153, Val MSE: 4604326586.6455, Val R2: 0.7661\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0385, Val Loss: 0.0855\n",
      "Val RMSE: 64560.7563, Val MAE: 36939.3560, Val MSE: 4168091258.7838, Val R2: 0.7882\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0388, Val Loss: 0.0821\n",
      "Val RMSE: 64281.3071, Val MAE: 35151.0981, Val MSE: 4132086441.2476, Val R2: 0.7901\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0389, Val Loss: 0.0926\n",
      "Val RMSE: 67158.3886, Val MAE: 37963.2151, Val MSE: 4510249165.3066, Val R2: 0.7709\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0399, Val Loss: 0.0839\n",
      "Val RMSE: 65872.3864, Val MAE: 35984.0916, Val MSE: 4339171289.8221, Val R2: 0.7795\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0375, Val Loss: 0.0870\n",
      "Val RMSE: 67719.9040, Val MAE: 37422.7816, Val MSE: 4585985396.8641, Val R2: 0.7670\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0363, Val Loss: 0.0857\n",
      "Val RMSE: 65775.1289, Val MAE: 36693.1366, Val MSE: 4326367587.4957, Val R2: 0.7802\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 63838.3376, Test MAE: 35696.2141, Test MSE: 4075333342.3295, Test R2: 0.7388\n",
      "Inference Time: 1.8989122830904448e-05 seconds per sample\n",
      "\n",
      "Iteration 27 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3465, Val Loss: 0.2828\n",
      "Val RMSE: 143287.1733, Val MAE: 82142.2787, Val MSE: 20531214030.0196, Val R2: -0.0431\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2763, Val Loss: 0.2751\n",
      "Val RMSE: 141303.1267, Val MAE: 83896.9172, Val MSE: 19966573606.5560, Val R2: -0.0144\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2780\n",
      "Val RMSE: 143188.0899, Val MAE: 81653.6890, Val MSE: 20502829081.8448, Val R2: -0.0417\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2652, Val Loss: 0.2756\n",
      "Val RMSE: 141707.0600, Val MAE: 83951.4645, Val MSE: 20080890858.4234, Val R2: -0.0202\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2768\n",
      "Val RMSE: 141933.2871, Val MAE: 83139.1792, Val MSE: 20145058000.5436, Val R2: -0.0235\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2752\n",
      "Val RMSE: 142345.7219, Val MAE: 82936.6493, Val MSE: 20262304552.9632, Val R2: -0.0295\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2715\n",
      "Val RMSE: 141249.6865, Val MAE: 82665.0266, Val MSE: 19951473928.4320, Val R2: -0.0137\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2714\n",
      "Val RMSE: 142118.3922, Val MAE: 81244.4606, Val MSE: 20197637395.7862, Val R2: -0.0262\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2708\n",
      "Val RMSE: 141100.2318, Val MAE: 82884.1606, Val MSE: 19909275424.3799, Val R2: -0.0115\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2694\n",
      "Val RMSE: 141892.7533, Val MAE: 80269.8482, Val MSE: 20133553438.0159, Val R2: -0.0229\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2649\n",
      "Val RMSE: 141334.0970, Val MAE: 79245.6441, Val MSE: 19975326961.1727, Val R2: -0.0149\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2515, Val Loss: 0.2661\n",
      "Val RMSE: 142979.9411, Val MAE: 77832.2864, Val MSE: 20443263560.6472, Val R2: -0.0386\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2492, Val Loss: 0.2653\n",
      "Val RMSE: 140083.0776, Val MAE: 81063.4339, Val MSE: 19623268631.1851, Val R2: 0.0030\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2671\n",
      "Val RMSE: 140945.8966, Val MAE: 79746.9859, Val MSE: 19865745758.6550, Val R2: -0.0093\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2699\n",
      "Val RMSE: 141935.2390, Val MAE: 80974.0015, Val MSE: 20145612077.6039, Val R2: -0.0235\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2466, Val Loss: 0.2684\n",
      "Val RMSE: 141344.0241, Val MAE: 79250.8537, Val MSE: 19978133153.1063, Val R2: -0.0150\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2350, Val Loss: 0.2739\n",
      "Val RMSE: 133524.7237, Val MAE: 85330.1304, Val MSE: 17828851851.5388, Val R2: 0.0942\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2213, Val Loss: 0.2494\n",
      "Val RMSE: 130009.1625, Val MAE: 79704.3335, Val MSE: 16902382340.8511, Val R2: 0.1413\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2142, Val Loss: 0.2295\n",
      "Val RMSE: 129120.4644, Val MAE: 74204.6580, Val MSE: 16672094337.8481, Val R2: 0.1530\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2060, Val Loss: 0.2327\n",
      "Val RMSE: 132674.0284, Val MAE: 71171.4951, Val MSE: 17602397823.8358, Val R2: 0.1057\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2316\n",
      "Val RMSE: 130067.3387, Val MAE: 72369.7520, Val MSE: 16917512594.6028, Val R2: 0.1405\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2025, Val Loss: 0.2283\n",
      "Val RMSE: 128249.0580, Val MAE: 73202.7342, Val MSE: 16447820883.9698, Val R2: 0.1643\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1947, Val Loss: 0.2198\n",
      "Val RMSE: 125952.8488, Val MAE: 72422.6248, Val MSE: 15864120128.0012, Val R2: 0.1940\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2086\n",
      "Val RMSE: 117046.9979, Val MAE: 70550.9377, Val MSE: 13699999712.2729, Val R2: 0.3040\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1862, Val Loss: 0.2075\n",
      "Val RMSE: 117442.8835, Val MAE: 67772.2145, Val MSE: 13792830885.0925, Val R2: 0.2992\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1825, Val Loss: 0.2130\n",
      "Val RMSE: 117990.4753, Val MAE: 70793.0571, Val MSE: 13921752261.4498, Val R2: 0.2927\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1777, Val Loss: 0.1894\n",
      "Val RMSE: 110360.3575, Val MAE: 63548.3315, Val MSE: 12179408497.2910, Val R2: 0.3812\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1796\n",
      "Val RMSE: 105058.7235, Val MAE: 62389.9455, Val MSE: 11037335383.0226, Val R2: 0.4392\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1654, Val Loss: 0.1755\n",
      "Val RMSE: 102206.8176, Val MAE: 63553.2756, Val MSE: 10446233564.1002, Val R2: 0.4693\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1642, Val Loss: 0.1805\n",
      "Val RMSE: 103238.4077, Val MAE: 62543.8169, Val MSE: 10658168824.3857, Val R2: 0.4585\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1608, Val Loss: 0.1682\n",
      "Val RMSE: 101462.2150, Val MAE: 59453.7920, Val MSE: 10294581063.5765, Val R2: 0.4770\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1589, Val Loss: 0.1631\n",
      "Val RMSE: 98989.4276, Val MAE: 58796.3921, Val MSE: 9798906776.4870, Val R2: 0.5022\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1564, Val Loss: 0.1605\n",
      "Val RMSE: 98204.0290, Val MAE: 57981.1046, Val MSE: 9644031305.6188, Val R2: 0.5100\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1521, Val Loss: 0.1550\n",
      "Val RMSE: 97233.2862, Val MAE: 56975.7805, Val MSE: 9454311950.6534, Val R2: 0.5197\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1513, Val Loss: 0.1527\n",
      "Val RMSE: 96957.7355, Val MAE: 55182.5525, Val MSE: 9400802479.9498, Val R2: 0.5224\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1527, Val Loss: 0.1573\n",
      "Val RMSE: 97713.7511, Val MAE: 54936.6290, Val MSE: 9547977151.2341, Val R2: 0.5149\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1481, Val Loss: 0.1507\n",
      "Val RMSE: 95424.5715, Val MAE: 53852.7244, Val MSE: 9105848844.8121, Val R2: 0.5374\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1463, Val Loss: 0.1485\n",
      "Val RMSE: 94644.3097, Val MAE: 54387.4282, Val MSE: 8957545356.0417, Val R2: 0.5449\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1423, Val Loss: 0.1480\n",
      "Val RMSE: 94674.9891, Val MAE: 54470.0993, Val MSE: 8963353565.3081, Val R2: 0.5446\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1496\n",
      "Val RMSE: 96138.9913, Val MAE: 53100.6929, Val MSE: 9242705645.5728, Val R2: 0.5304\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1459\n",
      "Val RMSE: 95047.8453, Val MAE: 51644.4531, Val MSE: 9034092901.9399, Val R2: 0.5410\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1338, Val Loss: 0.1401\n",
      "Val RMSE: 92548.9024, Val MAE: 50011.2942, Val MSE: 8565299336.1434, Val R2: 0.5648\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1282, Val Loss: 0.1415\n",
      "Val RMSE: 93801.8908, Val MAE: 50386.2933, Val MSE: 8798794725.9446, Val R2: 0.5530\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1298, Val Loss: 0.1327\n",
      "Val RMSE: 92775.2796, Val MAE: 48126.8211, Val MSE: 8607252499.9122, Val R2: 0.5627\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1225, Val Loss: 0.1221\n",
      "Val RMSE: 87897.1776, Val MAE: 49196.0658, Val MSE: 7725913822.6847, Val R2: 0.6075\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1137, Val Loss: 0.1102\n",
      "Val RMSE: 82887.9894, Val MAE: 44147.4697, Val MSE: 6870418790.9697, Val R2: 0.6509\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1118, Val Loss: 0.1225\n",
      "Val RMSE: 88649.5499, Val MAE: 48140.0148, Val MSE: 7858742694.6003, Val R2: 0.6007\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1286\n",
      "Val RMSE: 87720.6983, Val MAE: 50091.2488, Val MSE: 7694920908.7347, Val R2: 0.6090\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1115\n",
      "Val RMSE: 80987.2636, Val MAE: 46019.5824, Val MSE: 6558936871.6363, Val R2: 0.6668\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1192\n",
      "Val RMSE: 87846.7846, Val MAE: 46369.9229, Val MSE: 7717057563.5930, Val R2: 0.6079\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1114\n",
      "Val RMSE: 83408.2474, Val MAE: 44430.6814, Val MSE: 6956935742.3415, Val R2: 0.6465\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1062\n",
      "Val RMSE: 79004.5870, Val MAE: 43645.6170, Val MSE: 6241724759.2961, Val R2: 0.6829\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0905, Val Loss: 0.1064\n",
      "Val RMSE: 80421.8797, Val MAE: 40488.8207, Val MSE: 6467678733.2283, Val R2: 0.6714\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1203\n",
      "Val RMSE: 79852.4806, Val MAE: 48298.7351, Val MSE: 6376418662.1931, Val R2: 0.6760\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1061\n",
      "Val RMSE: 76903.3930, Val MAE: 41865.0494, Val MSE: 5914131853.0823, Val R2: 0.6995\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.0989\n",
      "Val RMSE: 74412.1980, Val MAE: 39644.3924, Val MSE: 5537175210.0423, Val R2: 0.7187\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.0987\n",
      "Val RMSE: 72433.2314, Val MAE: 39087.3753, Val MSE: 5246573011.6370, Val R2: 0.7334\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1088\n",
      "Val RMSE: 77316.7988, Val MAE: 42278.3307, Val MSE: 5977887383.6534, Val R2: 0.6963\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0744, Val Loss: 0.1065\n",
      "Val RMSE: 76827.9216, Val MAE: 40603.0740, Val MSE: 5902529538.2066, Val R2: 0.7001\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0746, Val Loss: 0.1132\n",
      "Val RMSE: 78674.4792, Val MAE: 40840.2567, Val MSE: 6189673679.9424, Val R2: 0.6855\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.0989\n",
      "Val RMSE: 71571.3697, Val MAE: 41612.8958, Val MSE: 5122460955.5992, Val R2: 0.7397\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.0952\n",
      "Val RMSE: 72352.1393, Val MAE: 39542.4206, Val MSE: 5234832054.6511, Val R2: 0.7340\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0701, Val Loss: 0.1017\n",
      "Val RMSE: 73207.3470, Val MAE: 38935.8252, Val MSE: 5359315657.9585, Val R2: 0.7277\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.0946\n",
      "Val RMSE: 69617.6489, Val MAE: 40177.3170, Val MSE: 4846617037.1255, Val R2: 0.7538\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1071\n",
      "Val RMSE: 73162.8204, Val MAE: 41443.5163, Val MSE: 5352798283.8742, Val R2: 0.7280\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.0916\n",
      "Val RMSE: 69263.4217, Val MAE: 39463.0189, Val MSE: 4797421578.8886, Val R2: 0.7563\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0671, Val Loss: 0.1011\n",
      "Val RMSE: 71729.8137, Val MAE: 41209.7595, Val MSE: 5145166180.4918, Val R2: 0.7386\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1060\n",
      "Val RMSE: 74679.4435, Val MAE: 42263.9400, Val MSE: 5577019279.4511, Val R2: 0.7167\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.0906\n",
      "Val RMSE: 68821.3657, Val MAE: 37647.6973, Val MSE: 4736380377.0976, Val R2: 0.7594\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1047\n",
      "Val RMSE: 73163.6402, Val MAE: 40752.6953, Val MSE: 5352918252.8112, Val R2: 0.7280\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1013\n",
      "Val RMSE: 73736.0794, Val MAE: 40244.9959, Val MSE: 5437009411.4167, Val R2: 0.7238\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.0840\n",
      "Val RMSE: 67090.1942, Val MAE: 36428.7927, Val MSE: 4501094157.9303, Val R2: 0.7713\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.0984\n",
      "Val RMSE: 71401.9230, Val MAE: 38834.2559, Val MSE: 5098234601.5191, Val R2: 0.7410\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1030\n",
      "Val RMSE: 74525.7544, Val MAE: 38933.1042, Val MSE: 5554088064.2140, Val R2: 0.7178\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1000\n",
      "Val RMSE: 73493.1723, Val MAE: 39011.3847, Val MSE: 5401246381.1544, Val R2: 0.7256\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.0992\n",
      "Val RMSE: 70723.9935, Val MAE: 40609.3874, Val MSE: 5001883258.1941, Val R2: 0.7459\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.0923\n",
      "Val RMSE: 70395.7664, Val MAE: 38512.9249, Val MSE: 4955563924.4393, Val R2: 0.7482\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1002\n",
      "Val RMSE: 72470.4400, Val MAE: 39790.3854, Val MSE: 5251964674.5964, Val R2: 0.7332\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.0999\n",
      "Val RMSE: 72850.2637, Val MAE: 38809.1832, Val MSE: 5307160922.7174, Val R2: 0.7304\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1016\n",
      "Val RMSE: 74258.9007, Val MAE: 38259.2030, Val MSE: 5514384340.2166, Val R2: 0.7198\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.0916\n",
      "Val RMSE: 69562.4656, Val MAE: 38450.3555, Val MSE: 4838936621.9740, Val R2: 0.7542\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1045\n",
      "Val RMSE: 75484.5658, Val MAE: 41128.5615, Val MSE: 5697919673.5390, Val R2: 0.7105\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1109\n",
      "Val RMSE: 75977.4458, Val MAE: 41185.7617, Val MSE: 5772572268.4355, Val R2: 0.7067\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1061\n",
      "Val RMSE: 75223.3325, Val MAE: 39728.3905, Val MSE: 5658549753.2845, Val R2: 0.7125\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.0856\n",
      "Val RMSE: 68146.2155, Val MAE: 37060.2031, Val MSE: 4643906688.2042, Val R2: 0.7641\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1010\n",
      "Val RMSE: 73817.4492, Val MAE: 40027.0825, Val MSE: 5449015804.9085, Val R2: 0.7232\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.0977\n",
      "Val RMSE: 72135.0287, Val MAE: 39290.5118, Val MSE: 5203462366.9864, Val R2: 0.7356\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.0906\n",
      "Val RMSE: 70406.2709, Val MAE: 38001.1576, Val MSE: 4957042982.0561, Val R2: 0.7482\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.0995\n",
      "Val RMSE: 71669.5425, Val MAE: 39798.9354, Val MSE: 5136523323.5872, Val R2: 0.7390\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.0935\n",
      "Val RMSE: 71828.9203, Val MAE: 37959.5013, Val MSE: 5159393788.2578, Val R2: 0.7379\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1036\n",
      "Val RMSE: 75039.1028, Val MAE: 41355.3468, Val MSE: 5630866945.3026, Val R2: 0.7139\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.0964\n",
      "Val RMSE: 72206.5672, Val MAE: 38016.3835, Val MSE: 5213788348.2986, Val R2: 0.7351\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.0982\n",
      "Val RMSE: 73583.6709, Val MAE: 37712.3678, Val MSE: 5414556628.1130, Val R2: 0.7249\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1005\n",
      "Val RMSE: 74719.2580, Val MAE: 38290.5188, Val MSE: 5582967512.9544, Val R2: 0.7164\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.1063\n",
      "Val RMSE: 76185.8632, Val MAE: 39022.6101, Val MSE: 5804285749.4043, Val R2: 0.7051\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0420, Val Loss: 0.1073\n",
      "Val RMSE: 78094.7830, Val MAE: 39346.3632, Val MSE: 6098795129.6293, Val R2: 0.6901\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.0971\n",
      "Val RMSE: 73333.8173, Val MAE: 37374.6783, Val MSE: 5377848754.9216, Val R2: 0.7268\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.0978\n",
      "Val RMSE: 73229.5413, Val MAE: 39781.4231, Val MSE: 5362565717.4191, Val R2: 0.7275\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0418, Val Loss: 0.0993\n",
      "Val RMSE: 75049.2526, Val MAE: 36527.9361, Val MSE: 5632390313.4840, Val R2: 0.7138\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0411, Val Loss: 0.0993\n",
      "Val RMSE: 74291.9468, Val MAE: 39109.4680, Val MSE: 5519293357.6157, Val R2: 0.7196\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 80626.9570, Test MAE: 41422.4288, Test MSE: 6500706188.8609, Test R2: 0.5833\n",
      "Inference Time: 2.63061156639686e-05 seconds per sample\n",
      "\n",
      "Iteration 28 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3605, Val Loss: 0.2765\n",
      "Val RMSE: 140526.5006, Val MAE: 86341.5035, Val MSE: 19747697358.3007, Val R2: -0.0033\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2816, Val Loss: 0.2772\n",
      "Val RMSE: 142301.8666, Val MAE: 82528.4012, Val MSE: 20249821250.9026, Val R2: -0.0288\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2736, Val Loss: 0.2749\n",
      "Val RMSE: 141243.0500, Val MAE: 83923.8649, Val MSE: 19949599179.0890, Val R2: -0.0136\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2694, Val Loss: 0.2769\n",
      "Val RMSE: 142303.4814, Val MAE: 82374.0782, Val MSE: 20250280820.1894, Val R2: -0.0288\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2669, Val Loss: 0.2757\n",
      "Val RMSE: 142128.1650, Val MAE: 82751.0593, Val MSE: 20200415285.3941, Val R2: -0.0263\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2629, Val Loss: 0.2810\n",
      "Val RMSE: 141939.4411, Val MAE: 87149.1121, Val MSE: 20146804952.6596, Val R2: -0.0236\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2740\n",
      "Val RMSE: 141149.3058, Val MAE: 84178.4657, Val MSE: 19923126524.0086, Val R2: -0.0122\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2819\n",
      "Val RMSE: 141622.2973, Val MAE: 87939.0746, Val MSE: 20056875081.2027, Val R2: -0.0190\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2777\n",
      "Val RMSE: 140349.0421, Val MAE: 87379.5756, Val MSE: 19697853617.7831, Val R2: -0.0008\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2562, Val Loss: 0.2764\n",
      "Val RMSE: 141527.7360, Val MAE: 84892.6057, Val MSE: 20030100057.9979, Val R2: -0.0177\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2734\n",
      "Val RMSE: 140862.4616, Val MAE: 83648.8579, Val MSE: 19842233095.7821, Val R2: -0.0081\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2519, Val Loss: 0.2704\n",
      "Val RMSE: 140020.8789, Val MAE: 83052.9756, Val MSE: 19605846531.1647, Val R2: 0.0039\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2665\n",
      "Val RMSE: 141929.0806, Val MAE: 78555.9755, Val MSE: 20143863907.0358, Val R2: -0.0234\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2475, Val Loss: 0.2688\n",
      "Val RMSE: 138863.6436, Val MAE: 84442.6112, Val MSE: 19283111524.6619, Val R2: 0.0203\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2421, Val Loss: 0.2573\n",
      "Val RMSE: 139206.2090, Val MAE: 73618.8765, Val MSE: 19378368612.6259, Val R2: 0.0155\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2329, Val Loss: 0.2400\n",
      "Val RMSE: 132240.3707, Val MAE: 75685.1854, Val MSE: 17487515646.9542, Val R2: 0.1115\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2213, Val Loss: 0.2321\n",
      "Val RMSE: 129715.8953, Val MAE: 76022.5562, Val MSE: 16826213500.5279, Val R2: 0.1451\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2217, Val Loss: 0.2448\n",
      "Val RMSE: 131424.8427, Val MAE: 78994.0397, Val MSE: 17272489291.0812, Val R2: 0.1224\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2135, Val Loss: 0.2323\n",
      "Val RMSE: 130358.3687, Val MAE: 73928.7310, Val MSE: 16993304301.2458, Val R2: 0.1366\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2071, Val Loss: 0.2216\n",
      "Val RMSE: 126794.3810, Val MAE: 72194.4905, Val MSE: 16076815063.9740, Val R2: 0.1832\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2045, Val Loss: 0.2224\n",
      "Val RMSE: 127923.0785, Val MAE: 70801.7184, Val MSE: 16364314025.3130, Val R2: 0.1686\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2018, Val Loss: 0.2324\n",
      "Val RMSE: 130798.6493, Val MAE: 70094.7237, Val MSE: 17108286649.5726, Val R2: 0.1308\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2046, Val Loss: 0.2220\n",
      "Val RMSE: 126419.6600, Val MAE: 71737.3380, Val MSE: 15981930433.0706, Val R2: 0.1880\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2012, Val Loss: 0.2331\n",
      "Val RMSE: 127555.7423, Val MAE: 75054.2124, Val MSE: 16270467395.0508, Val R2: 0.1734\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1985, Val Loss: 0.2207\n",
      "Val RMSE: 125512.5634, Val MAE: 70272.5942, Val MSE: 15753403576.5060, Val R2: 0.1996\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1963, Val Loss: 0.2135\n",
      "Val RMSE: 119202.0380, Val MAE: 70204.7221, Val MSE: 14209125857.3342, Val R2: 0.2781\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2135\n",
      "Val RMSE: 117858.3576, Val MAE: 67582.4449, Val MSE: 13890592452.9723, Val R2: 0.2943\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1848, Val Loss: 0.2082\n",
      "Val RMSE: 117307.6767, Val MAE: 65608.6744, Val MSE: 13761091024.3905, Val R2: 0.3008\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1791, Val Loss: 0.1871\n",
      "Val RMSE: 103181.4762, Val MAE: 65462.4186, Val MSE: 10646417031.1292, Val R2: 0.4591\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1717, Val Loss: 0.1760\n",
      "Val RMSE: 101586.7981, Val MAE: 60743.6072, Val MSE: 10319877554.9058, Val R2: 0.4757\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1653, Val Loss: 0.1814\n",
      "Val RMSE: 102865.3084, Val MAE: 60882.5931, Val MSE: 10581271664.6519, Val R2: 0.4624\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1618, Val Loss: 0.1854\n",
      "Val RMSE: 105714.5065, Val MAE: 62210.1017, Val MSE: 11175556884.2048, Val R2: 0.4322\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1583, Val Loss: 0.1698\n",
      "Val RMSE: 100773.0325, Val MAE: 59193.3914, Val MSE: 10155204086.0399, Val R2: 0.4841\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1583, Val Loss: 0.1620\n",
      "Val RMSE: 97282.7819, Val MAE: 58366.6817, Val MSE: 9463939654.0877, Val R2: 0.5192\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1569, Val Loss: 0.1589\n",
      "Val RMSE: 97650.7134, Val MAE: 56108.4212, Val MSE: 9535661823.2348, Val R2: 0.5155\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1530, Val Loss: 0.1596\n",
      "Val RMSE: 98636.1139, Val MAE: 56579.1115, Val MSE: 9729082962.6950, Val R2: 0.5057\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1528, Val Loss: 0.1601\n",
      "Val RMSE: 97319.0300, Val MAE: 56847.8183, Val MSE: 9470993593.9398, Val R2: 0.5188\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1454, Val Loss: 0.1596\n",
      "Val RMSE: 97397.9306, Val MAE: 56481.5585, Val MSE: 9486356889.0338, Val R2: 0.5180\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1577\n",
      "Val RMSE: 97069.6311, Val MAE: 57094.6685, Val MSE: 9422513286.5898, Val R2: 0.5213\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1423, Val Loss: 0.1569\n",
      "Val RMSE: 95441.5736, Val MAE: 55515.0999, Val MSE: 9109093978.5590, Val R2: 0.5372\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1397, Val Loss: 0.1474\n",
      "Val RMSE: 95084.5172, Val MAE: 54092.7663, Val MSE: 9041065406.9708, Val R2: 0.5407\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1355, Val Loss: 0.1518\n",
      "Val RMSE: 95544.1485, Val MAE: 54745.1641, Val MSE: 9128684305.2360, Val R2: 0.5362\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1347, Val Loss: 0.1561\n",
      "Val RMSE: 95326.4468, Val MAE: 54608.1196, Val MSE: 9087131453.6312, Val R2: 0.5383\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1314, Val Loss: 0.1359\n",
      "Val RMSE: 90798.4492, Val MAE: 50214.6950, Val MSE: 8244358368.1798, Val R2: 0.5811\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1263, Val Loss: 0.1367\n",
      "Val RMSE: 89943.1756, Val MAE: 51581.2920, Val MSE: 8089774828.5772, Val R2: 0.5890\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1200, Val Loss: 0.1463\n",
      "Val RMSE: 93536.9667, Val MAE: 51045.1864, Val MSE: 8749164138.2364, Val R2: 0.5555\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1117, Val Loss: 0.1394\n",
      "Val RMSE: 93324.8376, Val MAE: 49957.8309, Val MSE: 8709525310.0931, Val R2: 0.5575\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1408\n",
      "Val RMSE: 91631.0578, Val MAE: 47386.3090, Val MSE: 8396250762.0730, Val R2: 0.5734\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1459\n",
      "Val RMSE: 92664.1651, Val MAE: 52024.5528, Val MSE: 8586647495.4988, Val R2: 0.5637\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1150, Val Loss: 0.1389\n",
      "Val RMSE: 90255.7255, Val MAE: 53144.5219, Val MSE: 8146095986.8495, Val R2: 0.5861\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1156, Val Loss: 0.1386\n",
      "Val RMSE: 91129.8476, Val MAE: 49429.9951, Val MSE: 8304649115.6212, Val R2: 0.5781\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1094, Val Loss: 0.1357\n",
      "Val RMSE: 90757.9129, Val MAE: 49301.9674, Val MSE: 8236998762.9350, Val R2: 0.5815\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1394\n",
      "Val RMSE: 91640.2052, Val MAE: 48447.9695, Val MSE: 8397927202.2080, Val R2: 0.5733\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1382\n",
      "Val RMSE: 92196.3310, Val MAE: 47192.4569, Val MSE: 8500163445.7172, Val R2: 0.5681\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1361\n",
      "Val RMSE: 90507.0399, Val MAE: 48006.3873, Val MSE: 8191524274.6604, Val R2: 0.5838\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1425\n",
      "Val RMSE: 91044.6106, Val MAE: 48795.2545, Val MSE: 8289121125.7946, Val R2: 0.5789\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1327\n",
      "Val RMSE: 86899.6526, Val MAE: 47544.8598, Val MSE: 7551549622.7605, Val R2: 0.6163\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1385\n",
      "Val RMSE: 89332.7943, Val MAE: 46549.2015, Val MSE: 7980348132.3474, Val R2: 0.5945\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1452\n",
      "Val RMSE: 90677.2691, Val MAE: 49939.8659, Val MSE: 8222367138.1834, Val R2: 0.5823\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1350\n",
      "Val RMSE: 87703.6158, Val MAE: 46150.6008, Val MSE: 7691924225.7505, Val R2: 0.6092\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1360\n",
      "Val RMSE: 86846.9450, Val MAE: 46010.7265, Val MSE: 7542391848.5910, Val R2: 0.6168\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1320\n",
      "Val RMSE: 83552.4260, Val MAE: 45067.0147, Val MSE: 6981007897.5076, Val R2: 0.6453\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1479\n",
      "Val RMSE: 86684.7429, Val MAE: 50742.1049, Val MSE: 7514244649.6170, Val R2: 0.6182\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1449\n",
      "Val RMSE: 90192.3613, Val MAE: 50924.4737, Val MSE: 8134662029.3982, Val R2: 0.5867\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1250\n",
      "Val RMSE: 80500.6096, Val MAE: 45521.8685, Val MSE: 6480348151.1740, Val R2: 0.6708\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1310\n",
      "Val RMSE: 80403.1757, Val MAE: 44976.5299, Val MSE: 6464670655.5457, Val R2: 0.6716\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1283\n",
      "Val RMSE: 83259.4119, Val MAE: 45591.2625, Val MSE: 6932129675.0764, Val R2: 0.6478\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1286\n",
      "Val RMSE: 79431.8038, Val MAE: 44136.3224, Val MSE: 6309411451.2785, Val R2: 0.6794\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1283\n",
      "Val RMSE: 80848.8268, Val MAE: 47353.8127, Val MSE: 6536532788.7355, Val R2: 0.6679\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1294\n",
      "Val RMSE: 79256.9105, Val MAE: 45189.7956, Val MSE: 6281657861.8524, Val R2: 0.6809\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1251\n",
      "Val RMSE: 77999.6169, Val MAE: 44311.0049, Val MSE: 6083940238.8996, Val R2: 0.6909\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1171\n",
      "Val RMSE: 75448.5514, Val MAE: 42550.0012, Val MSE: 5692483904.8348, Val R2: 0.7108\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1186\n",
      "Val RMSE: 74692.4400, Val MAE: 43147.0708, Val MSE: 5578960598.5824, Val R2: 0.7166\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1263\n",
      "Val RMSE: 79043.2866, Val MAE: 43016.7175, Val MSE: 6247841157.3211, Val R2: 0.6826\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1229\n",
      "Val RMSE: 77930.6109, Val MAE: 43023.3743, Val MSE: 6073180110.2106, Val R2: 0.6914\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1189\n",
      "Val RMSE: 76078.8558, Val MAE: 41673.3998, Val MSE: 5787992300.5683, Val R2: 0.7059\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1252\n",
      "Val RMSE: 79455.4842, Val MAE: 43882.2325, Val MSE: 6313173968.7971, Val R2: 0.6793\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1306\n",
      "Val RMSE: 79756.2303, Val MAE: 43388.5307, Val MSE: 6361056275.4253, Val R2: 0.6768\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1182\n",
      "Val RMSE: 75091.0313, Val MAE: 42407.1162, Val MSE: 5638662984.0761, Val R2: 0.7135\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1378\n",
      "Val RMSE: 81162.6360, Val MAE: 46278.4400, Val MSE: 6587373480.4416, Val R2: 0.6653\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1248\n",
      "Val RMSE: 79050.6985, Val MAE: 44226.1817, Val MSE: 6249012926.9119, Val R2: 0.6825\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1299\n",
      "Val RMSE: 80734.5954, Val MAE: 44375.6616, Val MSE: 6518074894.3596, Val R2: 0.6688\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1256\n",
      "Val RMSE: 77397.4922, Val MAE: 44487.2443, Val MSE: 5990371799.4148, Val R2: 0.6957\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1227\n",
      "Val RMSE: 77287.9595, Val MAE: 43180.0554, Val MSE: 5973428687.7129, Val R2: 0.6965\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1249\n",
      "Val RMSE: 78788.0970, Val MAE: 45107.9802, Val MSE: 6207564232.5293, Val R2: 0.6846\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1294\n",
      "Val RMSE: 81984.4923, Val MAE: 44856.1092, Val MSE: 6721456975.4392, Val R2: 0.6585\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1286\n",
      "Val RMSE: 82152.0963, Val MAE: 44161.1066, Val MSE: 6748966921.3290, Val R2: 0.6571\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1375\n",
      "Val RMSE: 85026.5269, Val MAE: 44534.3897, Val MSE: 7229510273.2069, Val R2: 0.6327\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1236\n",
      "Val RMSE: 77284.9518, Val MAE: 42373.0294, Val MSE: 5972963775.2399, Val R2: 0.6965\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1300\n",
      "Val RMSE: 82922.0504, Val MAE: 45029.5406, Val MSE: 6876066435.2605, Val R2: 0.6507\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1237\n",
      "Val RMSE: 78432.1921, Val MAE: 43768.9750, Val MSE: 6151608750.1894, Val R2: 0.6875\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1328\n",
      "Val RMSE: 80598.4830, Val MAE: 43760.9315, Val MSE: 6496115454.0381, Val R2: 0.6700\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1176\n",
      "Val RMSE: 74966.6848, Val MAE: 40732.9596, Val MSE: 5620003837.0118, Val R2: 0.7145\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1238\n",
      "Val RMSE: 81392.4660, Val MAE: 41824.9537, Val MSE: 6624733520.3693, Val R2: 0.6634\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1321\n",
      "Val RMSE: 82949.3220, Val MAE: 44632.0207, Val MSE: 6880590013.5646, Val R2: 0.6504\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1282\n",
      "Val RMSE: 80040.9362, Val MAE: 43200.5840, Val MSE: 6406551460.5947, Val R2: 0.6745\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1512\n",
      "Val RMSE: 83344.9306, Val MAE: 45167.8841, Val MSE: 6946377464.5985, Val R2: 0.6471\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.1377\n",
      "Val RMSE: 84670.4835, Val MAE: 45016.2490, Val MSE: 7169090780.0956, Val R2: 0.6358\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1278\n",
      "Val RMSE: 80917.6239, Val MAE: 42738.8327, Val MSE: 6547661864.8020, Val R2: 0.6673\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1245\n",
      "Val RMSE: 79559.7281, Val MAE: 43790.3569, Val MSE: 6329750335.6879, Val R2: 0.6784\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 87851.5667, Test MAE: 48560.5123, Test MSE: 7717897777.8447, Test R2: 0.5053\n",
      "Inference Time: 2.6318660149207483e-05 seconds per sample\n",
      "\n",
      "Iteration 29 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.2940, Val Loss: 0.2787\n",
      "Val RMSE: 142784.3415, Val MAE: 82230.1046, Val MSE: 20387368185.5772, Val R2: -0.0358\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2778\n",
      "Val RMSE: 143050.7063, Val MAE: 81246.5227, Val MSE: 20463504572.0166, Val R2: -0.0397\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2625, Val Loss: 0.2889\n",
      "Val RMSE: 146412.6210, Val MAE: 79060.0852, Val MSE: 21436655594.0004, Val R2: -0.0891\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2619, Val Loss: 0.2740\n",
      "Val RMSE: 140616.7453, Val MAE: 85587.9515, Val MSE: 19773069071.2959, Val R2: -0.0046\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2725\n",
      "Val RMSE: 141179.1295, Val MAE: 83333.8180, Val MSE: 19931546599.0965, Val R2: -0.0126\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2566, Val Loss: 0.2737\n",
      "Val RMSE: 142098.3788, Val MAE: 83140.5011, Val MSE: 20191949249.4594, Val R2: -0.0259\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2740\n",
      "Val RMSE: 139910.0788, Val MAE: 86158.3727, Val MSE: 19574830143.1601, Val R2: 0.0055\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2717\n",
      "Val RMSE: 140356.4768, Val MAE: 83071.2906, Val MSE: 19699940581.0439, Val R2: -0.0009\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2520, Val Loss: 0.2836\n",
      "Val RMSE: 139740.3044, Val MAE: 89300.9575, Val MSE: 19527352667.9789, Val R2: 0.0079\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2765\n",
      "Val RMSE: 140369.8702, Val MAE: 85466.8699, Val MSE: 19703700457.4712, Val R2: -0.0011\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2455, Val Loss: 0.2655\n",
      "Val RMSE: 139511.9592, Val MAE: 81746.2642, Val MSE: 19463586748.6804, Val R2: 0.0111\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2435, Val Loss: 0.2628\n",
      "Val RMSE: 139378.5650, Val MAE: 80984.2680, Val MSE: 19426384369.2080, Val R2: 0.0130\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2422, Val Loss: 0.2646\n",
      "Val RMSE: 140986.4623, Val MAE: 78738.8087, Val MSE: 19877182558.7350, Val R2: -0.0099\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2404, Val Loss: 0.2627\n",
      "Val RMSE: 141428.9740, Val MAE: 77773.4247, Val MSE: 20002154695.8498, Val R2: -0.0162\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2399, Val Loss: 0.2598\n",
      "Val RMSE: 139089.3212, Val MAE: 80436.4763, Val MSE: 19345839258.8761, Val R2: 0.0171\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2382, Val Loss: 0.2631\n",
      "Val RMSE: 139776.7340, Val MAE: 80120.0671, Val MSE: 19537535358.6641, Val R2: 0.0074\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2673\n",
      "Val RMSE: 139406.2920, Val MAE: 82604.4528, Val MSE: 19434114253.9679, Val R2: 0.0126\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2387, Val Loss: 0.2603\n",
      "Val RMSE: 139915.5294, Val MAE: 79065.5600, Val MSE: 19576355376.9379, Val R2: 0.0054\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2378, Val Loss: 0.2616\n",
      "Val RMSE: 139494.1783, Val MAE: 80358.2519, Val MSE: 19458625769.6530, Val R2: 0.0114\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2367, Val Loss: 0.2585\n",
      "Val RMSE: 138599.3978, Val MAE: 79093.8998, Val MSE: 19209793073.3982, Val R2: 0.0240\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2263, Val Loss: 0.2387\n",
      "Val RMSE: 132879.8404, Val MAE: 72545.5855, Val MSE: 17657051972.3309, Val R2: 0.1029\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2543\n",
      "Val RMSE: 140031.7999, Val MAE: 78608.8397, Val MSE: 19608904983.2708, Val R2: 0.0037\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2120, Val Loss: 0.2308\n",
      "Val RMSE: 128169.5663, Val MAE: 75605.2067, Val MSE: 16427437729.6277, Val R2: 0.1654\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2551\n",
      "Val RMSE: 129933.0938, Val MAE: 83888.8250, Val MSE: 16882608866.0278, Val R2: 0.1423\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2100, Val Loss: 0.2294\n",
      "Val RMSE: 127685.2609, Val MAE: 76711.6827, Val MSE: 16303525842.5765, Val R2: 0.1717\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2049, Val Loss: 0.2543\n",
      "Val RMSE: 140078.9039, Val MAE: 79393.8613, Val MSE: 19622099309.4728, Val R2: 0.0031\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2019, Val Loss: 0.2395\n",
      "Val RMSE: 134153.0284, Val MAE: 76898.3766, Val MSE: 17997035042.0955, Val R2: 0.0856\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1993, Val Loss: 0.2211\n",
      "Val RMSE: 127195.6830, Val MAE: 71843.6178, Val MSE: 16178741775.2365, Val R2: 0.1780\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2023, Val Loss: 0.2234\n",
      "Val RMSE: 129452.0074, Val MAE: 70323.4389, Val MSE: 16757822218.3668, Val R2: 0.1486\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1976, Val Loss: 0.2199\n",
      "Val RMSE: 126596.3903, Val MAE: 72687.5244, Val MSE: 16026646041.1457, Val R2: 0.1857\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1909, Val Loss: 0.2177\n",
      "Val RMSE: 125133.4628, Val MAE: 69969.3126, Val MSE: 15658383511.0794, Val R2: 0.2045\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1852, Val Loss: 0.1964\n",
      "Val RMSE: 112036.7324, Val MAE: 65845.8611, Val MSE: 12552229405.8311, Val R2: 0.3623\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1759, Val Loss: 0.1846\n",
      "Val RMSE: 106124.0742, Val MAE: 64261.7394, Val MSE: 11262319116.2024, Val R2: 0.4278\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1675, Val Loss: 0.1879\n",
      "Val RMSE: 105350.2557, Val MAE: 66988.6536, Val MSE: 11098676368.2914, Val R2: 0.4361\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1643, Val Loss: 0.1852\n",
      "Val RMSE: 104577.1961, Val MAE: 64961.3662, Val MSE: 10936389943.3829, Val R2: 0.4444\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1597, Val Loss: 0.1640\n",
      "Val RMSE: 98541.6135, Val MAE: 57948.3038, Val MSE: 9710449581.9175, Val R2: 0.5066\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1556, Val Loss: 0.1781\n",
      "Val RMSE: 102415.3269, Val MAE: 62464.9501, Val MSE: 10488899185.7846, Val R2: 0.4671\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1927, Val Loss: 0.2518\n",
      "Val RMSE: 130755.2930, Val MAE: 83633.0093, Val MSE: 17096946648.7646, Val R2: 0.1314\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1912, Val Loss: 0.1826\n",
      "Val RMSE: 109592.0279, Val MAE: 61444.0182, Val MSE: 12010412590.0724, Val R2: 0.3898\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1717\n",
      "Val RMSE: 100489.9535, Val MAE: 59963.0624, Val MSE: 10098230749.2994, Val R2: 0.4869\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1647, Val Loss: 0.1637\n",
      "Val RMSE: 101076.4548, Val MAE: 58246.0217, Val MSE: 10216449721.4197, Val R2: 0.4809\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1575, Val Loss: 0.1625\n",
      "Val RMSE: 98455.5421, Val MAE: 57653.9924, Val MSE: 9693493767.7849, Val R2: 0.5075\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1532, Val Loss: 0.1609\n",
      "Val RMSE: 98383.5596, Val MAE: 57471.9268, Val MSE: 9679324807.3325, Val R2: 0.5082\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1501, Val Loss: 0.1600\n",
      "Val RMSE: 95860.1634, Val MAE: 58220.2057, Val MSE: 9189170921.8027, Val R2: 0.5331\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1462, Val Loss: 0.1751\n",
      "Val RMSE: 97811.1122, Val MAE: 60993.6011, Val MSE: 9567013674.1455, Val R2: 0.5139\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1413, Val Loss: 0.1495\n",
      "Val RMSE: 93873.3477, Val MAE: 53549.5808, Val MSE: 8812205412.2286, Val R2: 0.5523\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1535\n",
      "Val RMSE: 96153.8266, Val MAE: 54685.6279, Val MSE: 9245558378.3357, Val R2: 0.5303\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1357, Val Loss: 0.1424\n",
      "Val RMSE: 93992.8461, Val MAE: 51504.4511, Val MSE: 8834655114.0781, Val R2: 0.5511\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1431\n",
      "Val RMSE: 93786.7340, Val MAE: 55673.5168, Val MSE: 8795951473.6537, Val R2: 0.5531\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1264, Val Loss: 0.1361\n",
      "Val RMSE: 92781.5780, Val MAE: 49352.1087, Val MSE: 8608421222.2956, Val R2: 0.5626\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1214, Val Loss: 0.1263\n",
      "Val RMSE: 90217.4883, Val MAE: 47001.4912, Val MSE: 8139195194.5214, Val R2: 0.5865\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1349\n",
      "Val RMSE: 90812.3387, Val MAE: 53528.1201, Val MSE: 8246880855.4923, Val R2: 0.5810\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1232\n",
      "Val RMSE: 87392.0343, Val MAE: 49029.3825, Val MSE: 7637367666.7271, Val R2: 0.6120\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1143\n",
      "Val RMSE: 85432.6354, Val MAE: 46456.3525, Val MSE: 7298735198.2036, Val R2: 0.6292\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1213\n",
      "Val RMSE: 87856.9479, Val MAE: 49857.2645, Val MSE: 7718843291.2461, Val R2: 0.6078\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1032, Val Loss: 0.1157\n",
      "Val RMSE: 87540.5538, Val MAE: 49819.5580, Val MSE: 7663348551.7939, Val R2: 0.6107\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0951, Val Loss: 0.1091\n",
      "Val RMSE: 84388.7471, Val MAE: 43412.1353, Val MSE: 7121460637.2780, Val R2: 0.6382\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1170\n",
      "Val RMSE: 87289.8910, Val MAE: 45410.6925, Val MSE: 7619525064.6011, Val R2: 0.6129\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1129\n",
      "Val RMSE: 85150.4590, Val MAE: 47329.3791, Val MSE: 7250600666.7194, Val R2: 0.6316\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0858, Val Loss: 0.1027\n",
      "Val RMSE: 81832.4475, Val MAE: 41355.3600, Val MSE: 6696549467.2511, Val R2: 0.6598\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0849, Val Loss: 0.1155\n",
      "Val RMSE: 85542.9124, Val MAE: 44240.0783, Val MSE: 7317589862.1511, Val R2: 0.6282\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1113\n",
      "Val RMSE: 84440.7765, Val MAE: 44834.6132, Val MSE: 7130244735.2578, Val R2: 0.6377\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1047\n",
      "Val RMSE: 80317.9184, Val MAE: 41992.0421, Val MSE: 6450968019.8050, Val R2: 0.6723\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1141\n",
      "Val RMSE: 82724.4459, Val MAE: 44410.6817, Val MSE: 6843333953.6672, Val R2: 0.6523\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1227\n",
      "Val RMSE: 84386.6209, Val MAE: 47025.9030, Val MSE: 7121101792.8984, Val R2: 0.6382\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1145\n",
      "Val RMSE: 83213.2732, Val MAE: 45522.6886, Val MSE: 6924448840.5641, Val R2: 0.6482\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1021\n",
      "Val RMSE: 75385.4146, Val MAE: 40720.8353, Val MSE: 5682960739.7094, Val R2: 0.7113\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1104\n",
      "Val RMSE: 80144.0106, Val MAE: 44392.4449, Val MSE: 6423062429.6183, Val R2: 0.6737\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1022\n",
      "Val RMSE: 77068.8136, Val MAE: 43227.6076, Val MSE: 5939602032.9480, Val R2: 0.6982\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1059\n",
      "Val RMSE: 76044.7549, Val MAE: 41345.0825, Val MSE: 5782804754.9384, Val R2: 0.7062\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1030\n",
      "Val RMSE: 76510.0623, Val MAE: 41030.6231, Val MSE: 5853789633.3117, Val R2: 0.7026\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1023\n",
      "Val RMSE: 75388.8911, Val MAE: 40626.7729, Val MSE: 5683484908.5420, Val R2: 0.7112\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1091\n",
      "Val RMSE: 76741.5072, Val MAE: 44377.4343, Val MSE: 5889258933.1974, Val R2: 0.7008\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1008\n",
      "Val RMSE: 76553.0023, Val MAE: 38637.5267, Val MSE: 5860362157.1149, Val R2: 0.7023\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1051\n",
      "Val RMSE: 76954.4601, Val MAE: 42015.4087, Val MSE: 5921988928.1021, Val R2: 0.6991\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1048\n",
      "Val RMSE: 75101.3321, Val MAE: 42821.3864, Val MSE: 5640210084.6050, Val R2: 0.7134\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.0981\n",
      "Val RMSE: 73822.7449, Val MAE: 39634.0752, Val MSE: 5449797670.6542, Val R2: 0.7231\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.0998\n",
      "Val RMSE: 74017.7694, Val MAE: 39189.9870, Val MSE: 5478630190.8531, Val R2: 0.7217\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.0984\n",
      "Val RMSE: 73862.5839, Val MAE: 39080.4094, Val MSE: 5455681303.0459, Val R2: 0.7228\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0590, Val Loss: 0.1074\n",
      "Val RMSE: 77157.6702, Val MAE: 41985.5511, Val MSE: 5953306063.2263, Val R2: 0.6975\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1036\n",
      "Val RMSE: 76140.2201, Val MAE: 42989.3519, Val MSE: 5797333111.7603, Val R2: 0.7055\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0579, Val Loss: 0.1023\n",
      "Val RMSE: 73389.3974, Val MAE: 44243.3620, Val MSE: 5386003646.1295, Val R2: 0.7264\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.0962\n",
      "Val RMSE: 73460.5872, Val MAE: 37287.7523, Val MSE: 5396457870.7709, Val R2: 0.7258\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1050\n",
      "Val RMSE: 77418.0452, Val MAE: 40549.0735, Val MSE: 5993553730.2474, Val R2: 0.6955\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1146\n",
      "Val RMSE: 78626.7009, Val MAE: 43746.5334, Val MSE: 6182158090.2875, Val R2: 0.6859\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1013\n",
      "Val RMSE: 74171.5855, Val MAE: 38678.0645, Val MSE: 5501424093.8127, Val R2: 0.7205\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1051\n",
      "Val RMSE: 76133.0822, Val MAE: 41311.1305, Val MSE: 5796246211.1041, Val R2: 0.7055\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.0992\n",
      "Val RMSE: 75257.0155, Val MAE: 38099.2883, Val MSE: 5663618384.5201, Val R2: 0.7123\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.0941\n",
      "Val RMSE: 72668.2536, Val MAE: 36878.0404, Val MSE: 5280675088.1952, Val R2: 0.7317\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.0872\n",
      "Val RMSE: 69780.2178, Val MAE: 37097.1955, Val MSE: 4869278792.7100, Val R2: 0.7526\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0943\n",
      "Val RMSE: 71170.4069, Val MAE: 39593.8121, Val MSE: 5065226820.5488, Val R2: 0.7427\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1012\n",
      "Val RMSE: 72666.8809, Val MAE: 42368.4492, Val MSE: 5280475584.1399, Val R2: 0.7317\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.0957\n",
      "Val RMSE: 71152.6171, Val MAE: 38711.5078, Val MSE: 5062694918.7799, Val R2: 0.7428\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.0975\n",
      "Val RMSE: 73052.9290, Val MAE: 38316.1467, Val MSE: 5336730437.4485, Val R2: 0.7289\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.0974\n",
      "Val RMSE: 72898.1980, Val MAE: 41872.1515, Val MSE: 5314147266.5207, Val R2: 0.7300\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.0882\n",
      "Val RMSE: 69365.8192, Val MAE: 37974.7952, Val MSE: 4811616871.4896, Val R2: 0.7555\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.0962\n",
      "Val RMSE: 71101.3359, Val MAE: 40943.7422, Val MSE: 5055399971.0375, Val R2: 0.7432\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.0975\n",
      "Val RMSE: 71612.4991, Val MAE: 41880.9713, Val MSE: 5128350029.6415, Val R2: 0.7394\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.0882\n",
      "Val RMSE: 68621.9148, Val MAE: 39222.2538, Val MSE: 4708967187.2328, Val R2: 0.7608\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.0869\n",
      "Val RMSE: 68386.1146, Val MAE: 37350.3626, Val MSE: 4676660666.9000, Val R2: 0.7624\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83418.4118, Test MAE: 43689.1879, Test MSE: 6958631420.4492, Test R2: 0.5539\n",
      "Inference Time: 2.1217969747690054e-05 seconds per sample\n",
      "\n",
      "Iteration 30 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3657, Val Loss: 0.3045\n",
      "Val RMSE: 147899.1518, Val MAE: 81929.3616, Val MSE: 21874159114.0739, Val R2: -0.1113\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2781, Val Loss: 0.2762\n",
      "Val RMSE: 140790.3356, Val MAE: 85703.1785, Val MSE: 19821918590.1634, Val R2: -0.0071\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2756\n",
      "Val RMSE: 141408.8960, Val MAE: 83782.8561, Val MSE: 19996475854.9656, Val R2: -0.0159\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2753\n",
      "Val RMSE: 140426.4181, Val MAE: 86211.0700, Val MSE: 19719578901.8422, Val R2: -0.0019\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2627, Val Loss: 0.2805\n",
      "Val RMSE: 140988.7936, Val MAE: 87738.0840, Val MSE: 19877839932.7292, Val R2: -0.0099\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2720\n",
      "Val RMSE: 141573.9694, Val MAE: 82596.5252, Val MSE: 20043188817.0141, Val R2: -0.0183\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2600, Val Loss: 0.2699\n",
      "Val RMSE: 140891.9722, Val MAE: 82832.3774, Val MSE: 19850547831.9769, Val R2: -0.0085\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2713\n",
      "Val RMSE: 142507.1924, Val MAE: 81235.5766, Val MSE: 20308299897.9836, Val R2: -0.0318\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2703\n",
      "Val RMSE: 141308.5276, Val MAE: 82187.7862, Val MSE: 19968099974.4644, Val R2: -0.0145\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2569, Val Loss: 0.2766\n",
      "Val RMSE: 140849.7523, Val MAE: 85847.8788, Val MSE: 19838652736.0462, Val R2: -0.0079\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2706\n",
      "Val RMSE: 141179.0960, Val MAE: 81776.4466, Val MSE: 19931537134.7818, Val R2: -0.0126\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2650\n",
      "Val RMSE: 140810.4721, Val MAE: 78580.2581, Val MSE: 19827589043.4431, Val R2: -0.0074\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2637\n",
      "Val RMSE: 138361.3610, Val MAE: 76932.1212, Val MSE: 19143866228.2834, Val R2: 0.0274\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2536\n",
      "Val RMSE: 136341.9705, Val MAE: 77894.3352, Val MSE: 18589132916.7893, Val R2: 0.0556\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2394, Val Loss: 0.2506\n",
      "Val RMSE: 135764.6287, Val MAE: 77179.3822, Val MSE: 18432034401.3304, Val R2: 0.0635\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2361, Val Loss: 0.2488\n",
      "Val RMSE: 134980.1879, Val MAE: 78030.9670, Val MSE: 18219651119.0059, Val R2: 0.0743\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2350, Val Loss: 0.2480\n",
      "Val RMSE: 132757.8971, Val MAE: 77864.9190, Val MSE: 17624659237.1270, Val R2: 0.1046\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2286, Val Loss: 0.2441\n",
      "Val RMSE: 133418.1142, Val MAE: 75996.7755, Val MSE: 17800393185.7899, Val R2: 0.0956\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2252, Val Loss: 0.2403\n",
      "Val RMSE: 131015.0883, Val MAE: 76626.1417, Val MSE: 17164953373.8450, Val R2: 0.1279\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2249, Val Loss: 0.2482\n",
      "Val RMSE: 132051.1743, Val MAE: 81072.9613, Val MSE: 17437512643.8241, Val R2: 0.1141\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2202, Val Loss: 0.2428\n",
      "Val RMSE: 135361.9790, Val MAE: 75504.3565, Val MSE: 18322865366.8162, Val R2: 0.0691\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2221, Val Loss: 0.2429\n",
      "Val RMSE: 134220.2080, Val MAE: 76594.5607, Val MSE: 18015064228.2892, Val R2: 0.0847\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2149, Val Loss: 0.2443\n",
      "Val RMSE: 137384.0463, Val MAE: 72766.8515, Val MSE: 18874376189.7151, Val R2: 0.0411\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2119, Val Loss: 0.2304\n",
      "Val RMSE: 128790.1668, Val MAE: 74596.0495, Val MSE: 16586907077.2502, Val R2: 0.1573\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2312\n",
      "Val RMSE: 129559.0565, Val MAE: 75386.6023, Val MSE: 16785549119.3702, Val R2: 0.1472\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2045, Val Loss: 0.2290\n",
      "Val RMSE: 130730.8995, Val MAE: 72083.0036, Val MSE: 17090568080.8472, Val R2: 0.1317\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2030, Val Loss: 0.2375\n",
      "Val RMSE: 134916.0517, Val MAE: 72694.9440, Val MSE: 18202341013.7629, Val R2: 0.0752\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2000, Val Loss: 0.2367\n",
      "Val RMSE: 133869.2390, Val MAE: 74699.3462, Val MSE: 17920973160.8262, Val R2: 0.0895\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1971, Val Loss: 0.2275\n",
      "Val RMSE: 129676.1902, Val MAE: 73158.4156, Val MSE: 16815914310.0120, Val R2: 0.1456\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1971, Val Loss: 0.2388\n",
      "Val RMSE: 134993.9293, Val MAE: 73874.5030, Val MSE: 18223360945.3708, Val R2: 0.0741\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1969, Val Loss: 0.2404\n",
      "Val RMSE: 134265.9795, Val MAE: 73435.2349, Val MSE: 18027353238.8586, Val R2: 0.0841\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1957, Val Loss: 0.2188\n",
      "Val RMSE: 127066.8953, Val MAE: 68445.3076, Val MSE: 16145995887.9961, Val R2: 0.1797\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1903, Val Loss: 0.2079\n",
      "Val RMSE: 119361.1392, Val MAE: 67454.6756, Val MSE: 14247081561.2574, Val R2: 0.2762\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1830, Val Loss: 0.2074\n",
      "Val RMSE: 111055.9305, Val MAE: 68049.1056, Val MSE: 12333419692.3936, Val R2: 0.3734\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1751, Val Loss: 0.1872\n",
      "Val RMSE: 106126.0656, Val MAE: 65836.8195, Val MSE: 11262741805.4394, Val R2: 0.4278\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1687, Val Loss: 0.2052\n",
      "Val RMSE: 111825.2201, Val MAE: 68945.6939, Val MSE: 12504879853.9100, Val R2: 0.3647\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1595, Val Loss: 0.1932\n",
      "Val RMSE: 106599.2304, Val MAE: 66724.7543, Val MSE: 11363395930.1581, Val R2: 0.4227\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1562, Val Loss: 0.1701\n",
      "Val RMSE: 100900.3489, Val MAE: 60791.9335, Val MSE: 10180880406.8771, Val R2: 0.4827\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1535, Val Loss: 0.1727\n",
      "Val RMSE: 102063.1996, Val MAE: 60035.8398, Val MSE: 10416896715.9445, Val R2: 0.4708\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1456, Val Loss: 0.1826\n",
      "Val RMSE: 102003.1765, Val MAE: 61646.6452, Val MSE: 10404648012.9016, Val R2: 0.4714\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1435, Val Loss: 0.1861\n",
      "Val RMSE: 103058.8554, Val MAE: 65064.5113, Val MSE: 10621127670.0067, Val R2: 0.4604\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1377, Val Loss: 0.1678\n",
      "Val RMSE: 99730.9799, Val MAE: 58949.5278, Val MSE: 9946268344.8299, Val R2: 0.4947\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1296, Val Loss: 0.1655\n",
      "Val RMSE: 100379.9942, Val MAE: 57240.2357, Val MSE: 10076143236.3854, Val R2: 0.4881\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1626\n",
      "Val RMSE: 99492.5763, Val MAE: 56875.8587, Val MSE: 9898772743.7459, Val R2: 0.4971\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1200, Val Loss: 0.1680\n",
      "Val RMSE: 101162.5596, Val MAE: 59424.6244, Val MSE: 10233863468.7428, Val R2: 0.4801\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1182, Val Loss: 0.1590\n",
      "Val RMSE: 98035.8691, Val MAE: 55426.2999, Val MSE: 9611031630.1199, Val R2: 0.5117\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1142, Val Loss: 0.1571\n",
      "Val RMSE: 97213.3476, Val MAE: 56231.7287, Val MSE: 9450434958.8030, Val R2: 0.5199\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1112, Val Loss: 0.1557\n",
      "Val RMSE: 96337.5039, Val MAE: 56643.9158, Val MSE: 9280914648.2885, Val R2: 0.5285\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1504\n",
      "Val RMSE: 95857.0654, Val MAE: 51893.7301, Val MSE: 9188576980.7550, Val R2: 0.5332\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1650\n",
      "Val RMSE: 100027.1358, Val MAE: 57344.9730, Val MSE: 10005427901.7720, Val R2: 0.4917\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1052, Val Loss: 0.1825\n",
      "Val RMSE: 103276.9878, Val MAE: 57897.8192, Val MSE: 10666136219.0119, Val R2: 0.4581\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1612\n",
      "Val RMSE: 97946.5366, Val MAE: 55196.7718, Val MSE: 9593524028.3960, Val R2: 0.5126\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0991, Val Loss: 0.1566\n",
      "Val RMSE: 97208.3346, Val MAE: 54237.1926, Val MSE: 9449460324.0398, Val R2: 0.5199\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1494\n",
      "Val RMSE: 94941.5681, Val MAE: 53069.6478, Val MSE: 9013901345.3626, Val R2: 0.5420\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1515\n",
      "Val RMSE: 95314.1544, Val MAE: 53356.9327, Val MSE: 9084788029.3744, Val R2: 0.5384\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1443\n",
      "Val RMSE: 92919.8836, Val MAE: 52675.7684, Val MSE: 8634104772.5851, Val R2: 0.5613\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1510\n",
      "Val RMSE: 95552.4905, Val MAE: 55217.0929, Val MSE: 9130278435.9331, Val R2: 0.5361\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1609\n",
      "Val RMSE: 98929.2986, Val MAE: 55026.6682, Val MSE: 9787006128.0196, Val R2: 0.5028\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0885, Val Loss: 0.1483\n",
      "Val RMSE: 92393.2467, Val MAE: 51775.1875, Val MSE: 8536512035.9743, Val R2: 0.5663\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1463\n",
      "Val RMSE: 91811.3545, Val MAE: 53069.7483, Val MSE: 8429324823.3684, Val R2: 0.5717\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1458\n",
      "Val RMSE: 89369.2337, Val MAE: 52505.7379, Val MSE: 7986859923.6757, Val R2: 0.5942\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1434\n",
      "Val RMSE: 92444.3563, Val MAE: 51895.3477, Val MSE: 8545959007.6223, Val R2: 0.5658\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1445\n",
      "Val RMSE: 91366.9456, Val MAE: 51510.2432, Val MSE: 8347918755.0461, Val R2: 0.5759\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1323\n",
      "Val RMSE: 82868.7741, Val MAE: 49201.2728, Val MSE: 6867233714.7616, Val R2: 0.6511\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1371\n",
      "Val RMSE: 87019.9611, Val MAE: 50921.0772, Val MSE: 7572473635.7864, Val R2: 0.6153\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1322\n",
      "Val RMSE: 82278.8107, Val MAE: 49006.7316, Val MSE: 6769802694.1829, Val R2: 0.6561\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1282\n",
      "Val RMSE: 81489.0148, Val MAE: 47182.9476, Val MSE: 6640459528.2914, Val R2: 0.6626\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1284\n",
      "Val RMSE: 80203.8713, Val MAE: 47091.8140, Val MSE: 6432660970.6229, Val R2: 0.6732\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1285\n",
      "Val RMSE: 79555.9223, Val MAE: 50580.5621, Val MSE: 6329144777.3937, Val R2: 0.6784\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1416\n",
      "Val RMSE: 82873.2376, Val MAE: 53467.6022, Val MSE: 6867973514.8213, Val R2: 0.6511\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1185\n",
      "Val RMSE: 75287.5391, Val MAE: 46910.0667, Val MSE: 5668213538.6543, Val R2: 0.7120\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1441\n",
      "Val RMSE: 83921.4511, Val MAE: 53588.7101, Val MSE: 7042809949.9421, Val R2: 0.6422\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1358\n",
      "Val RMSE: 83904.2941, Val MAE: 51000.5243, Val MSE: 7039930563.2500, Val R2: 0.6423\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1389\n",
      "Val RMSE: 80887.6873, Val MAE: 51270.8206, Val MSE: 6542817956.2253, Val R2: 0.6676\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1350\n",
      "Val RMSE: 81562.7566, Val MAE: 52111.0073, Val MSE: 6652483265.4779, Val R2: 0.6620\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1223\n",
      "Val RMSE: 75208.9252, Val MAE: 46535.2277, Val MSE: 5656382424.0987, Val R2: 0.7126\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1024\n",
      "Val RMSE: 69658.8492, Val MAE: 42030.1432, Val MSE: 4852355270.4472, Val R2: 0.7535\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1232\n",
      "Val RMSE: 78630.8202, Val MAE: 46239.9675, Val MSE: 6182805881.1955, Val R2: 0.6859\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.1199\n",
      "Val RMSE: 75737.3918, Val MAE: 46630.7167, Val MSE: 5736152514.6044, Val R2: 0.7086\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1266\n",
      "Val RMSE: 80136.6120, Val MAE: 48829.3132, Val MSE: 6421876586.5355, Val R2: 0.6737\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1321\n",
      "Val RMSE: 78538.5403, Val MAE: 50684.8173, Val MSE: 6168302311.3660, Val R2: 0.6866\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1224\n",
      "Val RMSE: 77124.6639, Val MAE: 47860.9201, Val MSE: 5948213780.1806, Val R2: 0.6978\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1286\n",
      "Val RMSE: 78816.5139, Val MAE: 48686.4088, Val MSE: 6212042864.9786, Val R2: 0.6844\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1046\n",
      "Val RMSE: 72838.0915, Val MAE: 41467.2578, Val MSE: 5305387577.1078, Val R2: 0.7305\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1147\n",
      "Val RMSE: 76895.5071, Val MAE: 44063.4525, Val MSE: 5912919011.2133, Val R2: 0.6996\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1115\n",
      "Val RMSE: 76103.2557, Val MAE: 42365.3380, Val MSE: 5791705526.0917, Val R2: 0.7057\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1150\n",
      "Val RMSE: 74859.9323, Val MAE: 44834.1091, Val MSE: 5604009469.5170, Val R2: 0.7153\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1190\n",
      "Val RMSE: 78601.4569, Val MAE: 46478.9910, Val MSE: 6178189025.2451, Val R2: 0.6861\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1084\n",
      "Val RMSE: 75698.4137, Val MAE: 43890.7230, Val MSE: 5730249832.6105, Val R2: 0.7089\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1212\n",
      "Val RMSE: 80330.2381, Val MAE: 45915.4903, Val MSE: 6452947150.0848, Val R2: 0.6721\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.1145\n",
      "Val RMSE: 78107.9630, Val MAE: 44538.8288, Val MSE: 6100853878.6600, Val R2: 0.6900\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1240\n",
      "Val RMSE: 80500.8946, Val MAE: 48268.4371, Val MSE: 6480394026.3745, Val R2: 0.6708\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1266\n",
      "Val RMSE: 80314.7670, Val MAE: 50089.5282, Val MSE: 6450461796.7135, Val R2: 0.6723\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1137\n",
      "Val RMSE: 78806.2343, Val MAE: 42973.3273, Val MSE: 6210422566.0378, Val R2: 0.6845\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1033\n",
      "Val RMSE: 74284.3902, Val MAE: 40661.7629, Val MSE: 5518170626.2560, Val R2: 0.7196\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1151\n",
      "Val RMSE: 79463.6297, Val MAE: 44177.7454, Val MSE: 6314468438.7583, Val R2: 0.6792\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1241\n",
      "Val RMSE: 83115.5594, Val MAE: 46285.4653, Val MSE: 6908196220.0446, Val R2: 0.6490\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1146\n",
      "Val RMSE: 80041.7447, Val MAE: 43630.1886, Val MSE: 6406680887.1354, Val R2: 0.6745\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1100\n",
      "Val RMSE: 75870.3333, Val MAE: 43452.4060, Val MSE: 5756307468.8024, Val R2: 0.7075\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1214\n",
      "Val RMSE: 79157.0813, Val MAE: 46755.3368, Val MSE: 6265843524.6815, Val R2: 0.6817\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83473.3300, Test MAE: 45228.2841, Test MSE: 6967796818.1952, Test R2: 0.5534\n",
      "Inference Time: 2.0790833693284254e-05 seconds per sample\n",
      "\n",
      "Iteration 31 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3605, Val Loss: 0.2902\n",
      "Val RMSE: 146478.4436, Val MAE: 80235.3554, Val MSE: 21455934441.6747, Val R2: -0.0901\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2706, Val Loss: 0.2749\n",
      "Val RMSE: 141004.7690, Val MAE: 84466.8172, Val MSE: 19882344875.5158, Val R2: -0.0101\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2671, Val Loss: 0.2744\n",
      "Val RMSE: 141183.0166, Val MAE: 83976.1641, Val MSE: 19932644171.0702, Val R2: -0.0127\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2747\n",
      "Val RMSE: 141333.6429, Val MAE: 84463.2508, Val MSE: 19975198627.8441, Val R2: -0.0149\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2629, Val Loss: 0.2755\n",
      "Val RMSE: 142260.3928, Val MAE: 81951.1200, Val MSE: 20238019353.6043, Val R2: -0.0282\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2725\n",
      "Val RMSE: 141716.6044, Val MAE: 82850.2896, Val MSE: 20083595962.9309, Val R2: -0.0204\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2746\n",
      "Val RMSE: 141082.8576, Val MAE: 84374.8032, Val MSE: 19904372707.0082, Val R2: -0.0113\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2574, Val Loss: 0.2744\n",
      "Val RMSE: 142267.9538, Val MAE: 81689.9988, Val MSE: 20240170674.7681, Val R2: -0.0283\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2727\n",
      "Val RMSE: 141908.6195, Val MAE: 82416.7528, Val MSE: 20138056276.8900, Val R2: -0.0231\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2722\n",
      "Val RMSE: 141504.3157, Val MAE: 82465.6418, Val MSE: 20023471373.7470, Val R2: -0.0173\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2734\n",
      "Val RMSE: 143689.0958, Val MAE: 78487.7934, Val MSE: 20646556261.2692, Val R2: -0.0490\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2709\n",
      "Val RMSE: 141618.4436, Val MAE: 80729.4036, Val MSE: 20055783566.9630, Val R2: -0.0190\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2652\n",
      "Val RMSE: 141264.4750, Val MAE: 79202.1409, Val MSE: 19955651886.4058, Val R2: -0.0139\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2667\n",
      "Val RMSE: 141559.8293, Val MAE: 79503.5008, Val MSE: 20039185275.0205, Val R2: -0.0181\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2466, Val Loss: 0.2630\n",
      "Val RMSE: 142301.1632, Val MAE: 77786.5681, Val MSE: 20249621037.9826, Val R2: -0.0288\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2712\n",
      "Val RMSE: 144688.6199, Val MAE: 76839.3760, Val MSE: 20934796742.7969, Val R2: -0.0636\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2459, Val Loss: 0.2656\n",
      "Val RMSE: 142308.6844, Val MAE: 78430.9413, Val MSE: 20251761660.3412, Val R2: -0.0289\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2411, Val Loss: 0.2664\n",
      "Val RMSE: 142169.5078, Val MAE: 78927.6324, Val MSE: 20212168961.7851, Val R2: -0.0269\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2382, Val Loss: 0.2758\n",
      "Val RMSE: 140569.0125, Val MAE: 84490.5770, Val MSE: 19759647275.3900, Val R2: -0.0039\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2680\n",
      "Val RMSE: 140548.6441, Val MAE: 81511.8231, Val MSE: 19753921357.8945, Val R2: -0.0036\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2787\n",
      "Val RMSE: 140514.5933, Val MAE: 85171.3076, Val MSE: 19744350925.0221, Val R2: -0.0031\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2382, Val Loss: 0.2620\n",
      "Val RMSE: 141308.4579, Val MAE: 78016.9704, Val MSE: 19968080277.9683, Val R2: -0.0145\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2381, Val Loss: 0.2615\n",
      "Val RMSE: 141061.5799, Val MAE: 78298.3113, Val MSE: 19898369325.3243, Val R2: -0.0110\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2342, Val Loss: 0.2435\n",
      "Val RMSE: 133158.3100, Val MAE: 75887.3351, Val MSE: 17731135509.6754, Val R2: 0.0991\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2223, Val Loss: 0.2319\n",
      "Val RMSE: 130202.2689, Val MAE: 73161.6634, Val MSE: 16952630819.5131, Val R2: 0.1387\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2184, Val Loss: 0.2463\n",
      "Val RMSE: 136261.9541, Val MAE: 75689.4347, Val MSE: 18567320147.2145, Val R2: 0.0567\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2099, Val Loss: 0.2324\n",
      "Val RMSE: 130925.9348, Val MAE: 73629.0683, Val MSE: 17141600409.1444, Val R2: 0.1291\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2062, Val Loss: 0.2233\n",
      "Val RMSE: 128761.6633, Val MAE: 71117.9267, Val MSE: 16579565925.8951, Val R2: 0.1577\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2034, Val Loss: 0.2356\n",
      "Val RMSE: 133027.7565, Val MAE: 70673.4938, Val MSE: 17696384008.4844, Val R2: 0.1009\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2252\n",
      "Val RMSE: 128983.0412, Val MAE: 69219.7720, Val MSE: 16636624926.5138, Val R2: 0.1548\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1979, Val Loss: 0.2243\n",
      "Val RMSE: 128536.8700, Val MAE: 69656.9716, Val MSE: 16521726945.0293, Val R2: 0.1606\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1944, Val Loss: 0.2205\n",
      "Val RMSE: 124507.5511, Val MAE: 67703.5128, Val MSE: 15502130286.0143, Val R2: 0.2124\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1863, Val Loss: 0.2059\n",
      "Val RMSE: 116273.9706, Val MAE: 66300.6343, Val MSE: 13519636228.7876, Val R2: 0.3131\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1809, Val Loss: 0.1968\n",
      "Val RMSE: 111683.0994, Val MAE: 66465.5418, Val MSE: 12473114684.8299, Val R2: 0.3663\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1734, Val Loss: 0.1769\n",
      "Val RMSE: 101654.5443, Val MAE: 62234.5256, Val MSE: 10333646383.8940, Val R2: 0.4750\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1699, Val Loss: 0.1860\n",
      "Val RMSE: 105374.7381, Val MAE: 62694.0904, Val MSE: 11103835434.6483, Val R2: 0.4359\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1664, Val Loss: 0.1770\n",
      "Val RMSE: 102617.0469, Val MAE: 62426.0960, Val MSE: 10530258319.3791, Val R2: 0.4650\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1844\n",
      "Val RMSE: 105035.6822, Val MAE: 60503.3574, Val MSE: 11032494544.9713, Val R2: 0.4395\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1595, Val Loss: 0.1734\n",
      "Val RMSE: 102616.3874, Val MAE: 59542.4815, Val MSE: 10530122954.7130, Val R2: 0.4650\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1565, Val Loss: 0.1706\n",
      "Val RMSE: 101938.4610, Val MAE: 57555.0233, Val MSE: 10391449832.6860, Val R2: 0.4720\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1546, Val Loss: 0.1595\n",
      "Val RMSE: 97545.7555, Val MAE: 56849.1169, Val MSE: 9515174406.7037, Val R2: 0.5166\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1574, Val Loss: 0.1707\n",
      "Val RMSE: 101306.5654, Val MAE: 59667.6748, Val MSE: 10263020185.5765, Val R2: 0.4786\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1535, Val Loss: 0.1556\n",
      "Val RMSE: 97063.0766, Val MAE: 55321.1987, Val MSE: 9421240842.2446, Val R2: 0.5213\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1492, Val Loss: 0.1524\n",
      "Val RMSE: 96401.3941, Val MAE: 54484.6249, Val MSE: 9293228783.5787, Val R2: 0.5278\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1495, Val Loss: 0.1616\n",
      "Val RMSE: 98953.2680, Val MAE: 57629.3558, Val MSE: 9791749244.7692, Val R2: 0.5025\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1449, Val Loss: 0.1573\n",
      "Val RMSE: 98399.9159, Val MAE: 54571.5758, Val MSE: 9682543458.9144, Val R2: 0.5081\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1421, Val Loss: 0.1606\n",
      "Val RMSE: 99345.7423, Val MAE: 54113.9424, Val MSE: 9869576513.0575, Val R2: 0.4986\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1392, Val Loss: 0.1676\n",
      "Val RMSE: 101285.7886, Val MAE: 55407.6627, Val MSE: 10258810966.9282, Val R2: 0.4788\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1496\n",
      "Val RMSE: 94365.4846, Val MAE: 54957.1173, Val MSE: 8904844686.0287, Val R2: 0.5476\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1356, Val Loss: 0.1557\n",
      "Val RMSE: 97477.8201, Val MAE: 53278.5375, Val MSE: 9501925408.6221, Val R2: 0.5172\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1640\n",
      "Val RMSE: 98508.6897, Val MAE: 53386.1350, Val MSE: 9703961953.9361, Val R2: 0.5070\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1295, Val Loss: 0.1474\n",
      "Val RMSE: 94615.3980, Val MAE: 52506.3505, Val MSE: 8952073538.6161, Val R2: 0.5452\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1237, Val Loss: 0.1458\n",
      "Val RMSE: 94079.6375, Val MAE: 51791.7006, Val MSE: 8850978187.5307, Val R2: 0.5503\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1256, Val Loss: 0.1437\n",
      "Val RMSE: 92048.6076, Val MAE: 50238.8505, Val MSE: 8472946158.4418, Val R2: 0.5695\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1455\n",
      "Val RMSE: 94516.7866, Val MAE: 50491.9642, Val MSE: 8933422950.9428, Val R2: 0.5461\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1104, Val Loss: 0.1416\n",
      "Val RMSE: 93359.9893, Val MAE: 48686.3552, Val MSE: 8716087597.4674, Val R2: 0.5572\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1417\n",
      "Val RMSE: 92409.1271, Val MAE: 48930.6464, Val MSE: 8539446763.4495, Val R2: 0.5661\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1394\n",
      "Val RMSE: 92314.4298, Val MAE: 49502.3024, Val MSE: 8521953956.5925, Val R2: 0.5670\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1305\n",
      "Val RMSE: 89693.1500, Val MAE: 47830.3072, Val MSE: 8044861165.8140, Val R2: 0.5913\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1488\n",
      "Val RMSE: 95988.1189, Val MAE: 49557.8523, Val MSE: 9213718976.2777, Val R2: 0.5319\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1005, Val Loss: 0.1288\n",
      "Val RMSE: 88967.6480, Val MAE: 46786.7835, Val MSE: 7915242388.3464, Val R2: 0.5979\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1284\n",
      "Val RMSE: 88144.1796, Val MAE: 44305.1179, Val MSE: 7769396403.8887, Val R2: 0.6053\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0916, Val Loss: 0.1324\n",
      "Val RMSE: 88593.8619, Val MAE: 46432.8251, Val MSE: 7848872372.4203, Val R2: 0.6012\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1300\n",
      "Val RMSE: 87821.5892, Val MAE: 45142.7318, Val MSE: 7712631531.5562, Val R2: 0.6081\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1249\n",
      "Val RMSE: 85849.1926, Val MAE: 44862.1247, Val MSE: 7370083877.7001, Val R2: 0.6256\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1324\n",
      "Val RMSE: 88580.2568, Val MAE: 45722.2590, Val MSE: 7846461891.9364, Val R2: 0.6014\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1197\n",
      "Val RMSE: 83582.9420, Val MAE: 44527.8898, Val MSE: 6986108187.0674, Val R2: 0.6451\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.1216\n",
      "Val RMSE: 83524.2698, Val MAE: 44291.3280, Val MSE: 6976303638.3802, Val R2: 0.6456\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1204\n",
      "Val RMSE: 83675.8662, Val MAE: 44077.0438, Val MSE: 7001650589.2685, Val R2: 0.6443\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1224\n",
      "Val RMSE: 82939.4209, Val MAE: 43344.8421, Val MSE: 6878947547.1467, Val R2: 0.6505\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1138\n",
      "Val RMSE: 80915.5639, Val MAE: 41696.2111, Val MSE: 6547328473.6437, Val R2: 0.6674\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1217\n",
      "Val RMSE: 82826.8670, Val MAE: 44313.3854, Val MSE: 6860289904.0716, Val R2: 0.6515\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1189\n",
      "Val RMSE: 81752.4320, Val MAE: 42339.2169, Val MSE: 6683460142.3366, Val R2: 0.6604\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1220\n",
      "Val RMSE: 84600.8949, Val MAE: 42639.6513, Val MSE: 7157311416.8853, Val R2: 0.6364\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1180\n",
      "Val RMSE: 80547.7161, Val MAE: 42871.4366, Val MSE: 6487934563.9450, Val R2: 0.6704\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0755, Val Loss: 0.1183\n",
      "Val RMSE: 82143.4794, Val MAE: 42936.0974, Val MSE: 6747551211.0269, Val R2: 0.6572\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1224\n",
      "Val RMSE: 83069.7059, Val MAE: 43303.7956, Val MSE: 6900576046.5864, Val R2: 0.6494\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1160\n",
      "Val RMSE: 81406.0415, Val MAE: 41204.3162, Val MSE: 6626943585.8701, Val R2: 0.6633\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1198\n",
      "Val RMSE: 83082.6648, Val MAE: 42576.2850, Val MSE: 6902729190.1488, Val R2: 0.6493\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1265\n",
      "Val RMSE: 87695.6417, Val MAE: 44427.4669, Val MSE: 7690525578.4140, Val R2: 0.6093\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.1208\n",
      "Val RMSE: 83809.9403, Val MAE: 42405.0788, Val MSE: 7024106090.7320, Val R2: 0.6431\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1326\n",
      "Val RMSE: 86979.0081, Val MAE: 44242.7532, Val MSE: 7565347856.3028, Val R2: 0.6156\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1247\n",
      "Val RMSE: 83587.0287, Val MAE: 44901.1233, Val MSE: 6986791367.1013, Val R2: 0.6450\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1193\n",
      "Val RMSE: 82310.3816, Val MAE: 42260.4260, Val MSE: 6774998921.3551, Val R2: 0.6558\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1195\n",
      "Val RMSE: 81616.9364, Val MAE: 42798.8798, Val MSE: 6661324299.5642, Val R2: 0.6616\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1191\n",
      "Val RMSE: 81267.1865, Val MAE: 42074.2378, Val MSE: 6604355602.0106, Val R2: 0.6645\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1149\n",
      "Val RMSE: 79676.3609, Val MAE: 41079.5581, Val MSE: 6348322493.0236, Val R2: 0.6775\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0626, Val Loss: 0.1113\n",
      "Val RMSE: 78078.4947, Val MAE: 39914.3751, Val MSE: 6096251338.2924, Val R2: 0.6903\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1213\n",
      "Val RMSE: 81417.7510, Val MAE: 43445.5888, Val MSE: 6628850180.4545, Val R2: 0.6632\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1141\n",
      "Val RMSE: 78575.6695, Val MAE: 41292.2052, Val MSE: 6174135839.8065, Val R2: 0.6863\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1247\n",
      "Val RMSE: 83782.5780, Val MAE: 42739.2552, Val MSE: 7019520371.3566, Val R2: 0.6434\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1189\n",
      "Val RMSE: 80694.8926, Val MAE: 42063.8629, Val MSE: 6511665699.1542, Val R2: 0.6692\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1215\n",
      "Val RMSE: 82127.2206, Val MAE: 42110.0091, Val MSE: 6744880369.4517, Val R2: 0.6573\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1219\n",
      "Val RMSE: 79681.3571, Val MAE: 43257.9070, Val MSE: 6349118661.6816, Val R2: 0.6774\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1160\n",
      "Val RMSE: 79419.3192, Val MAE: 41350.1910, Val MSE: 6307428260.8185, Val R2: 0.6795\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.1158\n",
      "Val RMSE: 79468.8682, Val MAE: 40609.1262, Val MSE: 6315301014.7662, Val R2: 0.6791\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1212\n",
      "Val RMSE: 80188.3760, Val MAE: 41271.1467, Val MSE: 6430175648.2417, Val R2: 0.6733\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.1217\n",
      "Val RMSE: 79151.8013, Val MAE: 44155.6776, Val MSE: 6265007644.0327, Val R2: 0.6817\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1296\n",
      "Val RMSE: 83560.5921, Val MAE: 43496.4710, Val MSE: 6982372552.5057, Val R2: 0.6453\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.1226\n",
      "Val RMSE: 80567.3014, Val MAE: 43059.7012, Val MSE: 6491090058.9374, Val R2: 0.6702\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83072.0963, Test MAE: 43869.7356, Test MSE: 6900973177.7005, Test R2: 0.5576\n",
      "Inference Time: 2.1956553825965294e-05 seconds per sample\n",
      "\n",
      "Iteration 32 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3243, Val Loss: 0.2878\n",
      "Val RMSE: 145225.2718, Val MAE: 80421.2604, Val MSE: 21090379577.0209, Val R2: -0.0715\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2708, Val Loss: 0.2752\n",
      "Val RMSE: 140259.2323, Val MAE: 85913.6218, Val MSE: 19672652234.9668, Val R2: 0.0005\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2692, Val Loss: 0.2753\n",
      "Val RMSE: 140807.5625, Val MAE: 84554.8204, Val MSE: 19826769649.3386, Val R2: -0.0073\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2819\n",
      "Val RMSE: 143430.1967, Val MAE: 81487.3960, Val MSE: 20572221335.2380, Val R2: -0.0452\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2650, Val Loss: 0.2760\n",
      "Val RMSE: 140964.4200, Val MAE: 84500.5917, Val MSE: 19870967714.9374, Val R2: -0.0096\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2598, Val Loss: 0.2731\n",
      "Val RMSE: 140974.7679, Val MAE: 84399.0742, Val MSE: 19873885180.0830, Val R2: -0.0097\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2788\n",
      "Val RMSE: 141130.7369, Val MAE: 86209.5073, Val MSE: 19917884888.6236, Val R2: -0.0120\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2801\n",
      "Val RMSE: 141190.0739, Val MAE: 87200.2661, Val MSE: 19934636966.1015, Val R2: -0.0128\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2858\n",
      "Val RMSE: 142024.3020, Val MAE: 86825.0503, Val MSE: 20170902370.4422, Val R2: -0.0248\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2681\n",
      "Val RMSE: 140628.5397, Val MAE: 81340.7456, Val MSE: 19776386173.4061, Val R2: -0.0048\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2504, Val Loss: 0.2868\n",
      "Val RMSE: 145353.3555, Val MAE: 79083.0592, Val MSE: 21127597941.6541, Val R2: -0.0734\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2673\n",
      "Val RMSE: 139356.5503, Val MAE: 82537.8949, Val MSE: 19420248122.2311, Val R2: 0.0133\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2857\n",
      "Val RMSE: 145632.9771, Val MAE: 78828.0056, Val MSE: 21208964029.0317, Val R2: -0.0775\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2477, Val Loss: 0.2708\n",
      "Val RMSE: 140452.1941, Val MAE: 82216.9244, Val MSE: 19726818822.4092, Val R2: -0.0022\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2644\n",
      "Val RMSE: 139754.9987, Val MAE: 80857.2300, Val MSE: 19531459663.1496, Val R2: 0.0077\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2428, Val Loss: 0.2731\n",
      "Val RMSE: 140948.3219, Val MAE: 81981.1320, Val MSE: 19866429452.0272, Val R2: -0.0093\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2436, Val Loss: 0.2660\n",
      "Val RMSE: 139843.5592, Val MAE: 81452.2386, Val MSE: 19556221042.8956, Val R2: 0.0064\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2631\n",
      "Val RMSE: 140323.1713, Val MAE: 78212.9247, Val MSE: 19690592407.3472, Val R2: -0.0004\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2271, Val Loss: 0.2492\n",
      "Val RMSE: 131885.9236, Val MAE: 80031.0622, Val MSE: 17393896840.1045, Val R2: 0.1163\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2292, Val Loss: 0.2426\n",
      "Val RMSE: 135271.7761, Val MAE: 73472.6457, Val MSE: 18298453418.5853, Val R2: 0.0703\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2164, Val Loss: 0.2627\n",
      "Val RMSE: 134379.9967, Val MAE: 74490.8972, Val MSE: 18057983516.2324, Val R2: 0.0825\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2245, Val Loss: 0.2386\n",
      "Val RMSE: 130939.4698, Val MAE: 77768.3210, Val MSE: 17145144752.0268, Val R2: 0.1289\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2190, Val Loss: 0.2365\n",
      "Val RMSE: 133197.3470, Val MAE: 72627.1991, Val MSE: 17741533235.2553, Val R2: 0.0986\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2137, Val Loss: 0.2371\n",
      "Val RMSE: 132960.4819, Val MAE: 74010.7417, Val MSE: 17678489747.4301, Val R2: 0.1018\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2293\n",
      "Val RMSE: 131043.5115, Val MAE: 70619.4179, Val MSE: 17172401900.1329, Val R2: 0.1275\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2002, Val Loss: 0.2280\n",
      "Val RMSE: 127186.1716, Val MAE: 71258.1412, Val MSE: 16176322258.1509, Val R2: 0.1781\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1897, Val Loss: 0.2206\n",
      "Val RMSE: 123149.6608, Val MAE: 69546.0887, Val MSE: 15165838962.4118, Val R2: 0.2295\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1819, Val Loss: 0.2272\n",
      "Val RMSE: 122445.0507, Val MAE: 68313.5665, Val MSE: 14992790435.0049, Val R2: 0.2383\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1994\n",
      "Val RMSE: 111304.1363, Val MAE: 64629.2258, Val MSE: 12388610749.1907, Val R2: 0.3706\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1636, Val Loss: 0.1746\n",
      "Val RMSE: 101923.8221, Val MAE: 60948.4851, Val MSE: 10388465516.5153, Val R2: 0.4722\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1609, Val Loss: 0.1747\n",
      "Val RMSE: 102409.8991, Val MAE: 60172.8905, Val MSE: 10487787431.7882, Val R2: 0.4672\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1522, Val Loss: 0.1706\n",
      "Val RMSE: 101559.3403, Val MAE: 58070.7693, Val MSE: 10314299601.7331, Val R2: 0.4760\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1715\n",
      "Val RMSE: 102987.7257, Val MAE: 56984.6527, Val MSE: 10606471654.4792, Val R2: 0.4611\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1586, Val Loss: 0.1663\n",
      "Val RMSE: 101922.5317, Val MAE: 57397.1164, Val MSE: 10388202466.7580, Val R2: 0.4722\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1536, Val Loss: 0.1457\n",
      "Val RMSE: 94635.2884, Val MAE: 52890.2037, Val MSE: 8955837804.6318, Val R2: 0.5450\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1487, Val Loss: 0.1692\n",
      "Val RMSE: 100828.2108, Val MAE: 55840.7179, Val MSE: 10166328093.4159, Val R2: 0.4835\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1441, Val Loss: 0.1530\n",
      "Val RMSE: 97165.0390, Val MAE: 51905.8075, Val MSE: 9441044802.8288, Val R2: 0.5203\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1374, Val Loss: 0.1407\n",
      "Val RMSE: 92887.8165, Val MAE: 51169.6756, Val MSE: 8628146455.0057, Val R2: 0.5616\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1362, Val Loss: 0.1518\n",
      "Val RMSE: 97985.9129, Val MAE: 51841.2737, Val MSE: 9601239117.6393, Val R2: 0.5122\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1339, Val Loss: 0.1264\n",
      "Val RMSE: 89470.9961, Val MAE: 47003.1529, Val MSE: 8005059139.0274, Val R2: 0.5933\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1299, Val Loss: 0.1259\n",
      "Val RMSE: 89722.1604, Val MAE: 46557.9085, Val MSE: 8050066065.8846, Val R2: 0.5910\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1216, Val Loss: 0.1276\n",
      "Val RMSE: 90585.1047, Val MAE: 47080.8779, Val MSE: 8205661187.4406, Val R2: 0.5831\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1172, Val Loss: 0.1260\n",
      "Val RMSE: 90619.2525, Val MAE: 46657.7781, Val MSE: 8211848922.4975, Val R2: 0.5828\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1118, Val Loss: 0.1343\n",
      "Val RMSE: 90618.6322, Val MAE: 51774.0052, Val MSE: 8211736502.2093, Val R2: 0.5828\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1090, Val Loss: 0.1207\n",
      "Val RMSE: 88523.1156, Val MAE: 45992.3349, Val MSE: 7836341995.0840, Val R2: 0.6019\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1025, Val Loss: 0.1254\n",
      "Val RMSE: 90210.3328, Val MAE: 47866.1303, Val MSE: 8137904144.1735, Val R2: 0.5865\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0998, Val Loss: 0.1181\n",
      "Val RMSE: 88598.3455, Val MAE: 45045.9368, Val MSE: 7849666826.3930, Val R2: 0.6012\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0972, Val Loss: 0.1310\n",
      "Val RMSE: 89860.5075, Val MAE: 46364.7381, Val MSE: 8074910808.4860, Val R2: 0.5897\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1194\n",
      "Val RMSE: 87828.4275, Val MAE: 46212.9864, Val MSE: 7713832670.0605, Val R2: 0.6081\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0913, Val Loss: 0.1211\n",
      "Val RMSE: 87990.2139, Val MAE: 46141.0702, Val MSE: 7742277735.4605, Val R2: 0.6066\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0906, Val Loss: 0.1170\n",
      "Val RMSE: 87087.5555, Val MAE: 43059.9445, Val MSE: 7584242327.2592, Val R2: 0.6147\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1069\n",
      "Val RMSE: 81235.3213, Val MAE: 42314.1430, Val MSE: 6599177430.6187, Val R2: 0.6647\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0872, Val Loss: 0.1133\n",
      "Val RMSE: 83896.9100, Val MAE: 42375.4146, Val MSE: 7038691511.8306, Val R2: 0.6424\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0845, Val Loss: 0.1098\n",
      "Val RMSE: 82726.8468, Val MAE: 42064.1468, Val MSE: 6843731182.7645, Val R2: 0.6523\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0833, Val Loss: 0.1112\n",
      "Val RMSE: 80506.7521, Val MAE: 44752.5178, Val MSE: 6481337128.8267, Val R2: 0.6707\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1129\n",
      "Val RMSE: 78774.4318, Val MAE: 45397.6340, Val MSE: 6205411105.9746, Val R2: 0.6847\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0805, Val Loss: 0.0980\n",
      "Val RMSE: 72452.2200, Val MAE: 39363.3577, Val MSE: 5249324187.3942, Val R2: 0.7333\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1069\n",
      "Val RMSE: 74473.0056, Val MAE: 41093.1844, Val MSE: 5546228561.3889, Val R2: 0.7182\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.0956\n",
      "Val RMSE: 72677.8511, Val MAE: 39380.5351, Val MSE: 5282070045.7551, Val R2: 0.7316\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1061\n",
      "Val RMSE: 73556.1675, Val MAE: 41589.2118, Val MSE: 5410509770.9476, Val R2: 0.7251\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1138\n",
      "Val RMSE: 76611.6963, Val MAE: 46041.7765, Val MSE: 5869352003.8589, Val R2: 0.7018\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1029\n",
      "Val RMSE: 74555.7170, Val MAE: 41071.2408, Val MSE: 5558554937.6613, Val R2: 0.7176\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1007\n",
      "Val RMSE: 72519.0845, Val MAE: 41836.2095, Val MSE: 5259017617.5313, Val R2: 0.7328\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1088\n",
      "Val RMSE: 77860.9492, Val MAE: 40363.6582, Val MSE: 6062327413.9474, Val R2: 0.6920\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1067\n",
      "Val RMSE: 77348.0503, Val MAE: 42364.8064, Val MSE: 5982720879.8045, Val R2: 0.6960\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1059\n",
      "Val RMSE: 74634.9835, Val MAE: 41923.0357, Val MSE: 5570380768.1676, Val R2: 0.7170\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.0990\n",
      "Val RMSE: 73207.7121, Val MAE: 38549.7372, Val MSE: 5359369109.6465, Val R2: 0.7277\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1000\n",
      "Val RMSE: 74026.5987, Val MAE: 39929.2910, Val MSE: 5479937309.8136, Val R2: 0.7216\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1004\n",
      "Val RMSE: 74276.9306, Val MAE: 39650.9450, Val MSE: 5517062422.4823, Val R2: 0.7197\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.0989\n",
      "Val RMSE: 75520.0927, Val MAE: 38134.2661, Val MSE: 5703284399.7404, Val R2: 0.7102\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.0968\n",
      "Val RMSE: 73391.6076, Val MAE: 38962.8747, Val MSE: 5386328072.7706, Val R2: 0.7263\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.0976\n",
      "Val RMSE: 71129.2537, Val MAE: 40913.2348, Val MSE: 5059370727.4335, Val R2: 0.7430\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.0908\n",
      "Val RMSE: 69884.5372, Val MAE: 38124.0806, Val MSE: 4883848539.3919, Val R2: 0.7519\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0568, Val Loss: 0.0973\n",
      "Val RMSE: 74323.4745, Val MAE: 38961.6223, Val MSE: 5523978861.5394, Val R2: 0.7193\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.0963\n",
      "Val RMSE: 73990.3067, Val MAE: 37680.1275, Val MSE: 5474565480.6427, Val R2: 0.7219\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1187\n",
      "Val RMSE: 82354.1891, Val MAE: 43939.3926, Val MSE: 6782212464.1905, Val R2: 0.6554\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0786, Val Loss: 0.0946\n",
      "Val RMSE: 70281.1239, Val MAE: 40890.7035, Val MSE: 4939436381.6278, Val R2: 0.7490\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.0862\n",
      "Val RMSE: 65685.6800, Val MAE: 39452.7656, Val MSE: 4314608563.5344, Val R2: 0.7808\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.0848\n",
      "Val RMSE: 66133.2371, Val MAE: 36617.9286, Val MSE: 4373605048.7564, Val R2: 0.7778\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.0789\n",
      "Val RMSE: 64685.4952, Val MAE: 35472.9258, Val MSE: 4184213285.2957, Val R2: 0.7874\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.0763\n",
      "Val RMSE: 63028.7450, Val MAE: 35146.4940, Val MSE: 3972622701.6667, Val R2: 0.7982\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.0785\n",
      "Val RMSE: 63834.5027, Val MAE: 34632.1585, Val MSE: 4074843734.6281, Val R2: 0.7930\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.0883\n",
      "Val RMSE: 68462.1308, Val MAE: 35402.3907, Val MSE: 4687063354.2916, Val R2: 0.7619\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.0850\n",
      "Val RMSE: 65716.2332, Val MAE: 37066.5583, Val MSE: 4318623306.7268, Val R2: 0.7806\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.0789\n",
      "Val RMSE: 64903.0545, Val MAE: 35483.5439, Val MSE: 4212406488.0306, Val R2: 0.7860\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.0763\n",
      "Val RMSE: 65688.2391, Val MAE: 33823.1647, Val MSE: 4314944760.6182, Val R2: 0.7808\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.0717\n",
      "Val RMSE: 60918.1930, Val MAE: 33509.0704, Val MSE: 3711026233.4982, Val R2: 0.8115\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.0852\n",
      "Val RMSE: 69158.2385, Val MAE: 34843.2282, Val MSE: 4782861958.4972, Val R2: 0.7570\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.0855\n",
      "Val RMSE: 68353.8469, Val MAE: 36299.4956, Val MSE: 4672248392.5644, Val R2: 0.7626\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.0800\n",
      "Val RMSE: 67547.0384, Val MAE: 34417.6642, Val MSE: 4562602396.8784, Val R2: 0.7682\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.0795\n",
      "Val RMSE: 65369.8763, Val MAE: 34492.6907, Val MSE: 4273220725.8686, Val R2: 0.7829\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.0840\n",
      "Val RMSE: 68481.7234, Val MAE: 35818.5584, Val MSE: 4689746440.6699, Val R2: 0.7617\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.0864\n",
      "Val RMSE: 71585.5662, Val MAE: 36054.0345, Val MSE: 5124493285.6800, Val R2: 0.7396\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.0764\n",
      "Val RMSE: 64529.2909, Val MAE: 33913.7814, Val MSE: 4164029382.3429, Val R2: 0.7884\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.0808\n",
      "Val RMSE: 67205.8916, Val MAE: 35222.0166, Val MSE: 4516631867.5038, Val R2: 0.7705\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.0819\n",
      "Val RMSE: 66684.5747, Val MAE: 36873.0508, Val MSE: 4446832500.7259, Val R2: 0.7741\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.0795\n",
      "Val RMSE: 68366.0892, Val MAE: 33810.4660, Val MSE: 4673922147.3647, Val R2: 0.7625\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.0795\n",
      "Val RMSE: 64234.1354, Val MAE: 35103.3329, Val MSE: 4126024156.5642, Val R2: 0.7904\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.0858\n",
      "Val RMSE: 71871.2409, Val MAE: 36279.9435, Val MSE: 5165475275.0961, Val R2: 0.7376\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0425, Val Loss: 0.0801\n",
      "Val RMSE: 66771.4538, Val MAE: 35301.1121, Val MSE: 4458427046.7249, Val R2: 0.7735\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 62502.1967, Test MAE: 34006.6455, Test MSE: 3906524595.3312, Test R2: 0.7496\n",
      "Inference Time: 2.165974103487455e-05 seconds per sample\n",
      "\n",
      "Iteration 33 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3666, Val Loss: 0.2854\n",
      "Val RMSE: 143755.8193, Val MAE: 81931.8308, Val MSE: 20665735569.4331, Val R2: -0.0499\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2745, Val Loss: 0.2781\n",
      "Val RMSE: 142476.5285, Val MAE: 82216.9108, Val MSE: 20299561163.4478, Val R2: -0.0313\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2699, Val Loss: 0.2756\n",
      "Val RMSE: 141568.9395, Val MAE: 83420.1639, Val MSE: 20041764623.1836, Val R2: -0.0182\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2756\n",
      "Val RMSE: 142163.3946, Val MAE: 82595.7200, Val MSE: 20210430778.0108, Val R2: -0.0268\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2629, Val Loss: 0.2782\n",
      "Val RMSE: 141910.6046, Val MAE: 85262.3784, Val MSE: 20138619703.1688, Val R2: -0.0232\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2759\n",
      "Val RMSE: 144189.8951, Val MAE: 78264.0760, Val MSE: 20790725845.3884, Val R2: -0.0563\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2710\n",
      "Val RMSE: 142378.5663, Val MAE: 79544.4369, Val MSE: 20271656151.5897, Val R2: -0.0299\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2662\n",
      "Val RMSE: 140562.9643, Val MAE: 80773.1098, Val MSE: 19757946938.9510, Val R2: -0.0038\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2688\n",
      "Val RMSE: 141866.1334, Val MAE: 78753.6874, Val MSE: 20125999799.1013, Val R2: -0.0225\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2835\n",
      "Val RMSE: 145965.4006, Val MAE: 77879.2627, Val MSE: 21305898171.1969, Val R2: -0.0825\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2512, Val Loss: 0.2664\n",
      "Val RMSE: 141169.5543, Val MAE: 80086.9993, Val MSE: 19928843069.2497, Val R2: -0.0125\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2496, Val Loss: 0.2698\n",
      "Val RMSE: 142996.0312, Val MAE: 77590.3929, Val MSE: 20447864936.4222, Val R2: -0.0389\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2477, Val Loss: 0.2627\n",
      "Val RMSE: 140415.3951, Val MAE: 79314.7223, Val MSE: 19716483186.9456, Val R2: -0.0017\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2550\n",
      "Val RMSE: 137696.2372, Val MAE: 77343.6796, Val MSE: 18960253737.7568, Val R2: 0.0367\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2337, Val Loss: 0.2502\n",
      "Val RMSE: 135073.7587, Val MAE: 73567.9983, Val MSE: 18244920288.0249, Val R2: 0.0730\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2331, Val Loss: 0.2488\n",
      "Val RMSE: 134495.9116, Val MAE: 77204.2624, Val MSE: 18089150227.8426, Val R2: 0.0810\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2287, Val Loss: 0.2375\n",
      "Val RMSE: 132721.8716, Val MAE: 74930.9182, Val MSE: 17615095198.5375, Val R2: 0.1050\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2280, Val Loss: 0.2389\n",
      "Val RMSE: 133358.1156, Val MAE: 73055.8569, Val MSE: 17784386994.7351, Val R2: 0.0964\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2218, Val Loss: 0.2473\n",
      "Val RMSE: 130889.4777, Val MAE: 77988.1965, Val MSE: 17132055361.2658, Val R2: 0.1296\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2330\n",
      "Val RMSE: 128948.5984, Val MAE: 76639.4211, Val MSE: 16627741027.2058, Val R2: 0.1552\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2375\n",
      "Val RMSE: 132150.1964, Val MAE: 74254.2412, Val MSE: 17463674397.6923, Val R2: 0.1127\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2131, Val Loss: 0.2098\n",
      "Val RMSE: 121111.8653, Val MAE: 69071.3829, Val MSE: 14668083912.6668, Val R2: 0.2548\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2007, Val Loss: 0.2289\n",
      "Val RMSE: 126018.6346, Val MAE: 73517.3208, Val MSE: 15880696270.8476, Val R2: 0.1932\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1989, Val Loss: 0.2361\n",
      "Val RMSE: 132315.0720, Val MAE: 71620.4162, Val MSE: 17507278287.9820, Val R2: 0.1105\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2011, Val Loss: 0.2214\n",
      "Val RMSE: 124443.0747, Val MAE: 69549.2777, Val MSE: 15486078849.5476, Val R2: 0.2132\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1912, Val Loss: 0.2086\n",
      "Val RMSE: 116313.6846, Val MAE: 69607.7887, Val MSE: 13528873231.7946, Val R2: 0.3126\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1849, Val Loss: 0.1960\n",
      "Val RMSE: 110589.7379, Val MAE: 63618.2734, Val MSE: 12230090129.0552, Val R2: 0.3786\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1772, Val Loss: 0.1875\n",
      "Val RMSE: 107288.6479, Val MAE: 63865.2723, Val MSE: 11510853964.9770, Val R2: 0.4152\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1732, Val Loss: 0.2000\n",
      "Val RMSE: 110725.8670, Val MAE: 64420.1194, Val MSE: 12260217627.0801, Val R2: 0.3771\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1704, Val Loss: 0.1805\n",
      "Val RMSE: 103365.6712, Val MAE: 61144.1843, Val MSE: 10684461976.6842, Val R2: 0.4572\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1696, Val Loss: 0.1763\n",
      "Val RMSE: 100883.2714, Val MAE: 59880.4532, Val MSE: 10177434452.8547, Val R2: 0.4829\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1640, Val Loss: 0.1744\n",
      "Val RMSE: 101556.1056, Val MAE: 59548.2012, Val MSE: 10313642576.4653, Val R2: 0.4760\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1613, Val Loss: 0.1708\n",
      "Val RMSE: 99864.7662, Val MAE: 61296.9940, Val MSE: 9972971525.1127, Val R2: 0.4933\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1599, Val Loss: 0.1818\n",
      "Val RMSE: 102995.1650, Val MAE: 60005.0386, Val MSE: 10608004023.0355, Val R2: 0.4610\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1557, Val Loss: 0.1676\n",
      "Val RMSE: 98867.5088, Val MAE: 58831.5655, Val MSE: 9774784291.6994, Val R2: 0.5034\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1525, Val Loss: 0.1658\n",
      "Val RMSE: 99490.3150, Val MAE: 59002.1819, Val MSE: 9898322787.5217, Val R2: 0.4971\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1563, Val Loss: 0.1583\n",
      "Val RMSE: 96979.8130, Val MAE: 56055.7126, Val MSE: 9405084124.3598, Val R2: 0.5222\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1518, Val Loss: 0.1701\n",
      "Val RMSE: 98321.0099, Val MAE: 60366.5142, Val MSE: 9667020983.2925, Val R2: 0.5089\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1443, Val Loss: 0.1651\n",
      "Val RMSE: 98388.7600, Val MAE: 57730.8281, Val MSE: 9680348085.1343, Val R2: 0.5082\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1637\n",
      "Val RMSE: 97727.9719, Val MAE: 57462.7608, Val MSE: 9550756496.9932, Val R2: 0.5148\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1584\n",
      "Val RMSE: 96415.4584, Val MAE: 56049.0749, Val MSE: 9295940622.0601, Val R2: 0.5277\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1380, Val Loss: 0.1491\n",
      "Val RMSE: 93727.5947, Val MAE: 54723.2648, Val MSE: 8784862009.9171, Val R2: 0.5537\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1332, Val Loss: 0.1598\n",
      "Val RMSE: 95905.3459, Val MAE: 56504.0733, Val MSE: 9197835367.7026, Val R2: 0.5327\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1368, Val Loss: 0.1577\n",
      "Val RMSE: 95676.1774, Val MAE: 56706.4449, Val MSE: 9153930921.0657, Val R2: 0.5349\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1322, Val Loss: 0.1673\n",
      "Val RMSE: 97698.7363, Val MAE: 58581.4125, Val MSE: 9545043071.1986, Val R2: 0.5151\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1263, Val Loss: 0.2081\n",
      "Val RMSE: 102981.0088, Val MAE: 66685.0592, Val MSE: 10605088183.3568, Val R2: 0.4612\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1982\n",
      "Val RMSE: 101526.4807, Val MAE: 66037.4041, Val MSE: 10307626276.4806, Val R2: 0.4763\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1218, Val Loss: 0.1684\n",
      "Val RMSE: 95915.0601, Val MAE: 61059.4378, Val MSE: 9199698758.2992, Val R2: 0.5326\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1166, Val Loss: 0.1566\n",
      "Val RMSE: 94867.4076, Val MAE: 57767.4709, Val MSE: 8999825017.3972, Val R2: 0.5428\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1165, Val Loss: 0.2141\n",
      "Val RMSE: 105104.2701, Val MAE: 71976.5643, Val MSE: 11046907600.3476, Val R2: 0.4387\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1148, Val Loss: 0.1569\n",
      "Val RMSE: 95080.8992, Val MAE: 57611.8449, Val MSE: 9040377383.2219, Val R2: 0.5407\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1765\n",
      "Val RMSE: 99046.7671, Val MAE: 66191.1987, Val MSE: 9810262080.9894, Val R2: 0.5016\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1130, Val Loss: 0.1811\n",
      "Val RMSE: 99328.4688, Val MAE: 66349.3925, Val MSE: 9866144715.8593, Val R2: 0.4987\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1117, Val Loss: 0.1641\n",
      "Val RMSE: 96048.6915, Val MAE: 61508.0830, Val MSE: 9225351132.0444, Val R2: 0.5313\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1110, Val Loss: 0.1770\n",
      "Val RMSE: 99603.9341, Val MAE: 63698.1066, Val MSE: 9920943678.7208, Val R2: 0.4960\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1088, Val Loss: 0.1736\n",
      "Val RMSE: 99899.2114, Val MAE: 64102.8013, Val MSE: 9979852445.3349, Val R2: 0.4930\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1109, Val Loss: 0.1690\n",
      "Val RMSE: 97929.4903, Val MAE: 61502.9397, Val MSE: 9590185063.1593, Val R2: 0.5128\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1099, Val Loss: 0.1977\n",
      "Val RMSE: 102686.2274, Val MAE: 70832.1806, Val MSE: 10544461301.4293, Val R2: 0.4643\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1084, Val Loss: 0.1645\n",
      "Val RMSE: 97674.0926, Val MAE: 60669.7426, Val MSE: 9540228358.8726, Val R2: 0.5153\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1078, Val Loss: 0.1624\n",
      "Val RMSE: 95711.8340, Val MAE: 61651.7118, Val MSE: 9160755169.5816, Val R2: 0.5346\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1796\n",
      "Val RMSE: 99453.0554, Val MAE: 65533.5365, Val MSE: 9890910227.6466, Val R2: 0.4975\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1059, Val Loss: 0.1663\n",
      "Val RMSE: 96553.8234, Val MAE: 63498.1230, Val MSE: 9322640814.9619, Val R2: 0.5264\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1658\n",
      "Val RMSE: 96650.5261, Val MAE: 61607.9763, Val MSE: 9341324191.3947, Val R2: 0.5254\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1011, Val Loss: 0.1553\n",
      "Val RMSE: 94369.4199, Val MAE: 58933.9251, Val MSE: 8905587408.7198, Val R2: 0.5475\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1681\n",
      "Val RMSE: 96556.0694, Val MAE: 62943.6875, Val MSE: 9323074547.2990, Val R2: 0.5263\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1002, Val Loss: 0.1584\n",
      "Val RMSE: 94674.9859, Val MAE: 59500.8716, Val MSE: 8963352960.2750, Val R2: 0.5446\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1646\n",
      "Val RMSE: 96350.3350, Val MAE: 61466.1790, Val MSE: 9283387047.8263, Val R2: 0.5283\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0914, Val Loss: 0.1640\n",
      "Val RMSE: 97107.4216, Val MAE: 58784.6774, Val MSE: 9429851337.6973, Val R2: 0.5209\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0905, Val Loss: 0.1673\n",
      "Val RMSE: 96071.2677, Val MAE: 62389.0610, Val MSE: 9229688469.0346, Val R2: 0.5311\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0900, Val Loss: 0.1542\n",
      "Val RMSE: 93421.7971, Val MAE: 57209.2582, Val MSE: 8727632164.0974, Val R2: 0.5566\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0908, Val Loss: 0.1621\n",
      "Val RMSE: 94973.9756, Val MAE: 57778.1547, Val MSE: 9020056033.2161, Val R2: 0.5417\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0862, Val Loss: 0.1745\n",
      "Val RMSE: 97852.2031, Val MAE: 63054.0748, Val MSE: 9575053644.9021, Val R2: 0.5135\n",
      "Early stopping triggered after epoch 72\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 102932.3586, Test MAE: 60450.2391, Test MSE: 10595070439.5002, Test R2: 0.3208\n",
      "Inference Time: 2.1538954514723557e-05 seconds per sample\n",
      "\n",
      "Iteration 34 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3686, Val Loss: 0.2763\n",
      "Val RMSE: 140463.3739, Val MAE: 86746.3204, Val MSE: 19729959397.5777, Val R2: -0.0024\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2785, Val Loss: 0.2781\n",
      "Val RMSE: 142822.4305, Val MAE: 82101.9475, Val MSE: 20398246645.9181, Val R2: -0.0364\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2704, Val Loss: 0.2769\n",
      "Val RMSE: 142238.4536, Val MAE: 82622.6547, Val MSE: 20231777685.9661, Val R2: -0.0279\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2669, Val Loss: 0.2759\n",
      "Val RMSE: 141299.4712, Val MAE: 83905.7277, Val MSE: 19965540572.0617, Val R2: -0.0144\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2644, Val Loss: 0.2745\n",
      "Val RMSE: 140548.5301, Val MAE: 84710.4112, Val MSE: 19753889300.0374, Val R2: -0.0036\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2617, Val Loss: 0.2773\n",
      "Val RMSE: 142995.3853, Val MAE: 80615.6651, Val MSE: 20447680204.8346, Val R2: -0.0389\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2587, Val Loss: 0.2762\n",
      "Val RMSE: 141099.3427, Val MAE: 84777.0091, Val MSE: 19909024520.6171, Val R2: -0.0115\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2564, Val Loss: 0.2703\n",
      "Val RMSE: 140117.4853, Val MAE: 84216.7027, Val MSE: 19632909684.2241, Val R2: 0.0025\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2683\n",
      "Val RMSE: 142637.4501, Val MAE: 78131.6177, Val MSE: 20345442156.8669, Val R2: -0.0337\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2654\n",
      "Val RMSE: 141910.4838, Val MAE: 78256.6721, Val MSE: 20138585420.8125, Val R2: -0.0232\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2512, Val Loss: 0.2775\n",
      "Val RMSE: 140253.6869, Val MAE: 86647.5183, Val MSE: 19671096695.8412, Val R2: 0.0006\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2504, Val Loss: 0.2601\n",
      "Val RMSE: 139875.3137, Val MAE: 77896.3077, Val MSE: 19565103386.0433, Val R2: 0.0060\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2557\n",
      "Val RMSE: 137934.2081, Val MAE: 74621.7439, Val MSE: 19025845776.5604, Val R2: 0.0334\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2343, Val Loss: 0.2347\n",
      "Val RMSE: 133164.3936, Val MAE: 72376.9673, Val MSE: 17732755727.8560, Val R2: 0.0991\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2215, Val Loss: 0.2367\n",
      "Val RMSE: 131966.1325, Val MAE: 73168.6307, Val MSE: 17415060127.0823, Val R2: 0.1152\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2173, Val Loss: 0.2230\n",
      "Val RMSE: 128395.2325, Val MAE: 71419.4609, Val MSE: 16485335718.8398, Val R2: 0.1624\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2132, Val Loss: 0.2336\n",
      "Val RMSE: 129771.9498, Val MAE: 77273.9007, Val MSE: 16840758965.3609, Val R2: 0.1444\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2115, Val Loss: 0.2334\n",
      "Val RMSE: 131199.6327, Val MAE: 74239.7583, Val MSE: 17213343613.5053, Val R2: 0.1255\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2399\n",
      "Val RMSE: 134199.3920, Val MAE: 73862.3652, Val MSE: 18009476818.9621, Val R2: 0.0850\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2112, Val Loss: 0.2305\n",
      "Val RMSE: 130192.4937, Val MAE: 73264.8116, Val MSE: 16950085427.5253, Val R2: 0.1388\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2017, Val Loss: 0.2314\n",
      "Val RMSE: 130047.9677, Val MAE: 71928.7933, Val MSE: 16912473914.8951, Val R2: 0.1407\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2000, Val Loss: 0.2260\n",
      "Val RMSE: 124841.1126, Val MAE: 73479.1412, Val MSE: 15585303390.6385, Val R2: 0.2082\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1983, Val Loss: 0.2409\n",
      "Val RMSE: 129964.2569, Val MAE: 73602.5580, Val MSE: 16890708059.3304, Val R2: 0.1418\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1962, Val Loss: 0.2301\n",
      "Val RMSE: 126096.6277, Val MAE: 70662.5325, Val MSE: 15900359529.7284, Val R2: 0.1922\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1860, Val Loss: 0.2069\n",
      "Val RMSE: 112792.4542, Val MAE: 68914.1538, Val MSE: 12722137714.1208, Val R2: 0.3536\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1815, Val Loss: 0.2083\n",
      "Val RMSE: 111317.6319, Val MAE: 66268.6848, Val MSE: 12391615178.1797, Val R2: 0.3704\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1778, Val Loss: 0.2057\n",
      "Val RMSE: 112853.4573, Val MAE: 65950.3417, Val MSE: 12735902813.3689, Val R2: 0.3529\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1737, Val Loss: 0.1897\n",
      "Val RMSE: 104916.0874, Val MAE: 65401.6817, Val MSE: 11007385400.9701, Val R2: 0.4408\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1725, Val Loss: 0.2068\n",
      "Val RMSE: 108137.2387, Val MAE: 64857.3963, Val MSE: 11693662395.6860, Val R2: 0.4059\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1678, Val Loss: 0.1748\n",
      "Val RMSE: 100581.9539, Val MAE: 61980.0795, Val MSE: 10116729457.7834, Val R2: 0.4860\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1667, Val Loss: 0.1858\n",
      "Val RMSE: 104840.4234, Val MAE: 63865.0625, Val MSE: 10991514387.9357, Val R2: 0.4416\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1613, Val Loss: 0.1782\n",
      "Val RMSE: 101261.6451, Val MAE: 61362.4631, Val MSE: 10253920766.2057, Val R2: 0.4790\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1571, Val Loss: 0.1756\n",
      "Val RMSE: 101084.5279, Val MAE: 59493.9178, Val MSE: 10218081785.0985, Val R2: 0.4809\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1569, Val Loss: 0.1611\n",
      "Val RMSE: 97713.2931, Val MAE: 57050.0671, Val MSE: 9547887639.0814, Val R2: 0.5149\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1518, Val Loss: 0.1545\n",
      "Val RMSE: 95954.9489, Val MAE: 55440.1186, Val MSE: 9207352219.8070, Val R2: 0.5322\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1475, Val Loss: 0.1572\n",
      "Val RMSE: 96159.0454, Val MAE: 57630.0796, Val MSE: 9246562018.8178, Val R2: 0.5302\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1477, Val Loss: 0.1514\n",
      "Val RMSE: 94939.2476, Val MAE: 53803.5346, Val MSE: 9013460737.6638, Val R2: 0.5421\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1422, Val Loss: 0.1643\n",
      "Val RMSE: 96469.8840, Val MAE: 58890.0060, Val MSE: 9306438510.0270, Val R2: 0.5272\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1358, Val Loss: 0.1576\n",
      "Val RMSE: 94500.0007, Val MAE: 56631.6845, Val MSE: 8930250131.6191, Val R2: 0.5463\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1315, Val Loss: 0.1633\n",
      "Val RMSE: 95141.6071, Val MAE: 58981.8490, Val MSE: 9051925407.9431, Val R2: 0.5401\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1279, Val Loss: 0.1413\n",
      "Val RMSE: 92251.3844, Val MAE: 50936.8822, Val MSE: 8510317927.5798, Val R2: 0.5676\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1298, Val Loss: 0.1645\n",
      "Val RMSE: 95923.0085, Val MAE: 59775.3891, Val MSE: 9201223553.6184, Val R2: 0.5325\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1229, Val Loss: 0.1805\n",
      "Val RMSE: 98205.7017, Val MAE: 63113.4110, Val MSE: 9644359843.7882, Val R2: 0.5100\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1187, Val Loss: 0.1699\n",
      "Val RMSE: 96114.9945, Val MAE: 59127.6272, Val MSE: 9238092175.0035, Val R2: 0.5306\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1176, Val Loss: 0.1505\n",
      "Val RMSE: 92780.2822, Val MAE: 54793.6020, Val MSE: 8608180756.4532, Val R2: 0.5627\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1158, Val Loss: 0.1340\n",
      "Val RMSE: 89629.9899, Val MAE: 51037.8127, Val MSE: 8033535088.7750, Val R2: 0.5918\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1147, Val Loss: 0.1354\n",
      "Val RMSE: 89682.9472, Val MAE: 51039.5292, Val MSE: 8043031015.9965, Val R2: 0.5914\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1102, Val Loss: 0.1571\n",
      "Val RMSE: 95404.0266, Val MAE: 56357.6219, Val MSE: 9101928299.3338, Val R2: 0.5376\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1113, Val Loss: 0.1961\n",
      "Val RMSE: 101621.9072, Val MAE: 62259.1315, Val MSE: 10327012016.6292, Val R2: 0.4753\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1527\n",
      "Val RMSE: 93109.4681, Val MAE: 54806.0028, Val MSE: 8669373040.9334, Val R2: 0.5595\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1117, Val Loss: 0.1322\n",
      "Val RMSE: 88132.8120, Val MAE: 50780.3912, Val MSE: 7767392549.9260, Val R2: 0.6054\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1055, Val Loss: 0.1506\n",
      "Val RMSE: 92663.4393, Val MAE: 56936.4508, Val MSE: 8586512991.9006, Val R2: 0.5638\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1418\n",
      "Val RMSE: 90782.6134, Val MAE: 53526.4869, Val MSE: 8241482886.8610, Val R2: 0.5813\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1005, Val Loss: 0.1311\n",
      "Val RMSE: 89379.2274, Val MAE: 48644.9170, Val MSE: 7988646298.6395, Val R2: 0.5941\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1314\n",
      "Val RMSE: 88490.2128, Val MAE: 51606.1625, Val MSE: 7830517756.4187, Val R2: 0.6022\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1456\n",
      "Val RMSE: 92198.6733, Val MAE: 53798.7420, Val MSE: 8500595366.7275, Val R2: 0.5681\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0962, Val Loss: 0.1305\n",
      "Val RMSE: 88801.0359, Val MAE: 48960.4838, Val MSE: 7885623977.9204, Val R2: 0.5994\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0963, Val Loss: 0.1427\n",
      "Val RMSE: 91342.0290, Val MAE: 55363.5912, Val MSE: 8343366267.3873, Val R2: 0.5761\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1345\n",
      "Val RMSE: 89337.4654, Val MAE: 52505.3018, Val MSE: 7981182722.1488, Val R2: 0.5945\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0913, Val Loss: 0.1360\n",
      "Val RMSE: 89921.6465, Val MAE: 50408.9760, Val MSE: 8085902507.3408, Val R2: 0.5892\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0911, Val Loss: 0.1339\n",
      "Val RMSE: 90129.4533, Val MAE: 49484.2216, Val MSE: 8123318354.2378, Val R2: 0.5873\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1327\n",
      "Val RMSE: 88739.1235, Val MAE: 50629.4298, Val MSE: 7874632038.6697, Val R2: 0.5999\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.1494\n",
      "Val RMSE: 92370.8880, Val MAE: 55480.4168, Val MSE: 8532380946.4401, Val R2: 0.5665\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1387\n",
      "Val RMSE: 91373.2161, Val MAE: 50963.1424, Val MSE: 8349064620.7535, Val R2: 0.5758\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1324\n",
      "Val RMSE: 87866.1070, Val MAE: 50548.6868, Val MSE: 7720452764.3551, Val R2: 0.6078\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0855, Val Loss: 0.1383\n",
      "Val RMSE: 91072.7465, Val MAE: 50983.8904, Val MSE: 8294245146.5785, Val R2: 0.5786\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0851, Val Loss: 0.1312\n",
      "Val RMSE: 86253.1739, Val MAE: 51045.6023, Val MSE: 7439610010.0367, Val R2: 0.6220\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1353\n",
      "Val RMSE: 87774.2514, Val MAE: 50308.8119, Val MSE: 7704319217.0099, Val R2: 0.6086\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1252\n",
      "Val RMSE: 84256.5262, Val MAE: 45168.5631, Val MSE: 7099162210.8537, Val R2: 0.6393\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0786, Val Loss: 0.1361\n",
      "Val RMSE: 85622.2164, Val MAE: 51540.0358, Val MSE: 7331163937.0869, Val R2: 0.6275\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1242\n",
      "Val RMSE: 82752.2246, Val MAE: 45657.4049, Val MSE: 6847930684.4178, Val R2: 0.6521\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1387\n",
      "Val RMSE: 88533.9729, Val MAE: 51602.2416, Val MSE: 7838264358.8149, Val R2: 0.6018\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0760, Val Loss: 0.1411\n",
      "Val RMSE: 88457.8817, Val MAE: 52439.1985, Val MSE: 7824796830.4364, Val R2: 0.6025\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1270\n",
      "Val RMSE: 82090.0602, Val MAE: 48927.5926, Val MSE: 6738777976.8074, Val R2: 0.6576\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1418\n",
      "Val RMSE: 85070.1597, Val MAE: 53936.1541, Val MSE: 7236932076.2272, Val R2: 0.6323\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0744, Val Loss: 0.1335\n",
      "Val RMSE: 83270.7294, Val MAE: 50841.2914, Val MSE: 6934014376.4785, Val R2: 0.6477\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1362\n",
      "Val RMSE: 84659.2407, Val MAE: 51845.0179, Val MSE: 7167187042.2030, Val R2: 0.6359\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1220\n",
      "Val RMSE: 79757.4438, Val MAE: 46643.4635, Val MSE: 6361249843.4854, Val R2: 0.6768\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1376\n",
      "Val RMSE: 83708.3299, Val MAE: 51767.6536, Val MSE: 7007084488.7210, Val R2: 0.6440\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1206\n",
      "Val RMSE: 78640.5270, Val MAE: 48076.6691, Val MSE: 6184332488.8440, Val R2: 0.6858\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0671, Val Loss: 0.1395\n",
      "Val RMSE: 84443.2753, Val MAE: 52695.2695, Val MSE: 7130666735.9394, Val R2: 0.6377\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1283\n",
      "Val RMSE: 79008.4783, Val MAE: 50055.3687, Val MSE: 6242339641.7068, Val R2: 0.6828\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0653, Val Loss: 0.1325\n",
      "Val RMSE: 81657.4793, Val MAE: 50782.1414, Val MSE: 6667943924.0917, Val R2: 0.6612\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1351\n",
      "Val RMSE: 81169.3187, Val MAE: 51831.9641, Val MSE: 6588458302.1487, Val R2: 0.6653\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1333\n",
      "Val RMSE: 82067.7720, Val MAE: 51459.9300, Val MSE: 6735119198.5005, Val R2: 0.6578\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1411\n",
      "Val RMSE: 84345.6310, Val MAE: 53172.1628, Val MSE: 7114185466.2535, Val R2: 0.6386\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1328\n",
      "Val RMSE: 80905.7229, Val MAE: 51204.8021, Val MSE: 6545735995.5256, Val R2: 0.6674\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0644, Val Loss: 0.1241\n",
      "Val RMSE: 80403.1455, Val MAE: 45947.2847, Val MSE: 6464665806.1524, Val R2: 0.6716\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0626, Val Loss: 0.1290\n",
      "Val RMSE: 80959.5824, Val MAE: 50168.8721, Val MSE: 6554453978.1467, Val R2: 0.6670\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1346\n",
      "Val RMSE: 82603.1683, Val MAE: 51998.9401, Val MSE: 6823283408.7018, Val R2: 0.6533\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1346\n",
      "Val RMSE: 83932.0705, Val MAE: 50080.9078, Val MSE: 7044592461.2762, Val R2: 0.6421\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0589, Val Loss: 0.1318\n",
      "Val RMSE: 81349.7131, Val MAE: 50145.7865, Val MSE: 6617775827.6001, Val R2: 0.6638\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1336\n",
      "Val RMSE: 82506.5959, Val MAE: 50355.2112, Val MSE: 6807338359.9593, Val R2: 0.6541\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1320\n",
      "Val RMSE: 82105.0968, Val MAE: 50246.8824, Val MSE: 6741246922.4091, Val R2: 0.6575\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1338\n",
      "Val RMSE: 83966.4401, Val MAE: 50808.3563, Val MSE: 7050363070.2264, Val R2: 0.6418\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1369\n",
      "Val RMSE: 83325.8603, Val MAE: 52585.1187, Val MSE: 6943198986.7006, Val R2: 0.6472\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1464\n",
      "Val RMSE: 86619.5032, Val MAE: 54910.2033, Val MSE: 7502938341.1490, Val R2: 0.6188\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1247\n",
      "Val RMSE: 79169.5190, Val MAE: 49645.3641, Val MSE: 6267812740.7841, Val R2: 0.6816\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1429\n",
      "Val RMSE: 86174.3278, Val MAE: 54100.8201, Val MSE: 7426014772.9951, Val R2: 0.6227\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1274\n",
      "Val RMSE: 81013.7577, Val MAE: 48188.3945, Val MSE: 6563228935.4953, Val R2: 0.6665\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 88699.7537, Test MAE: 54525.8105, Test MSE: 7867646310.4825, Test R2: 0.4957\n",
      "Inference Time: 2.941450705895057e-05 seconds per sample\n",
      "\n",
      "Iteration 35 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3723, Val Loss: 0.2834\n",
      "Val RMSE: 142404.4772, Val MAE: 84425.4588, Val MSE: 20279035136.1671, Val R2: -0.0303\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2789, Val Loss: 0.2796\n",
      "Val RMSE: 143092.8865, Val MAE: 81681.8877, Val MSE: 20475574170.5153, Val R2: -0.0403\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2724, Val Loss: 0.2749\n",
      "Val RMSE: 141108.4530, Val MAE: 84372.2634, Val MSE: 19911595503.6107, Val R2: -0.0116\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2683, Val Loss: 0.2744\n",
      "Val RMSE: 142388.3027, Val MAE: 82193.5950, Val MSE: 20274428756.9010, Val R2: -0.0301\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2656, Val Loss: 0.2888\n",
      "Val RMSE: 144437.9062, Val MAE: 82248.7275, Val MSE: 20862308755.6294, Val R2: -0.0599\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2588, Val Loss: 0.2768\n",
      "Val RMSE: 141639.0513, Val MAE: 85080.7750, Val MSE: 20061620843.3642, Val R2: -0.0193\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2767\n",
      "Val RMSE: 143193.5811, Val MAE: 80748.0926, Val MSE: 20504401672.8785, Val R2: -0.0418\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2552, Val Loss: 0.2855\n",
      "Val RMSE: 144171.0042, Val MAE: 81447.2167, Val MSE: 20785278457.0527, Val R2: -0.0560\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2732\n",
      "Val RMSE: 140821.1690, Val MAE: 84629.3833, Val MSE: 19830601632.5315, Val R2: -0.0075\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2759\n",
      "Val RMSE: 140457.7845, Val MAE: 86342.5339, Val MSE: 19728389240.0477, Val R2: -0.0023\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2508, Val Loss: 0.2672\n",
      "Val RMSE: 141277.2964, Val MAE: 79956.4978, Val MSE: 19959274476.0932, Val R2: -0.0141\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2645\n",
      "Val RMSE: 139827.6384, Val MAE: 81587.4464, Val MSE: 19551768473.0356, Val R2: 0.0066\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2470, Val Loss: 0.2838\n",
      "Val RMSE: 140716.2887, Val MAE: 87965.8352, Val MSE: 19801073907.2600, Val R2: -0.0060\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2622\n",
      "Val RMSE: 141031.2192, Val MAE: 78731.8419, Val MSE: 19889804788.1609, Val R2: -0.0105\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2618\n",
      "Val RMSE: 140424.5296, Val MAE: 79098.4425, Val MSE: 19719048510.3616, Val R2: -0.0019\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2415, Val Loss: 0.2631\n",
      "Val RMSE: 139435.3840, Val MAE: 81014.7644, Val MSE: 19442226301.5047, Val R2: 0.0122\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2328, Val Loss: 0.2443\n",
      "Val RMSE: 134595.9998, Val MAE: 74190.0943, Val MSE: 18116083165.6236, Val R2: 0.0796\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2291, Val Loss: 0.2478\n",
      "Val RMSE: 130531.0884, Val MAE: 80408.3432, Val MSE: 17038365040.5854, Val R2: 0.1343\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2218, Val Loss: 0.2351\n",
      "Val RMSE: 130320.7762, Val MAE: 76894.9227, Val MSE: 16983504706.8081, Val R2: 0.1371\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2110, Val Loss: 0.2470\n",
      "Val RMSE: 138036.9043, Val MAE: 77909.7122, Val MSE: 19054186953.9530, Val R2: 0.0319\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2079, Val Loss: 0.2582\n",
      "Val RMSE: 141225.5069, Val MAE: 78843.5066, Val MSE: 19944643810.1105, Val R2: -0.0133\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2060, Val Loss: 0.2316\n",
      "Val RMSE: 130523.1359, Val MAE: 73451.1085, Val MSE: 17036289016.9378, Val R2: 0.1344\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1958, Val Loss: 0.2202\n",
      "Val RMSE: 128038.0296, Val MAE: 69650.5135, Val MSE: 16393737013.7801, Val R2: 0.1671\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1898, Val Loss: 0.2225\n",
      "Val RMSE: 123040.0446, Val MAE: 71894.8455, Val MSE: 15138852585.7060, Val R2: 0.2309\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1800, Val Loss: 0.2027\n",
      "Val RMSE: 116144.2568, Val MAE: 67397.4057, Val MSE: 13489488378.5330, Val R2: 0.3146\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1745, Val Loss: 0.1826\n",
      "Val RMSE: 105518.7020, Val MAE: 63136.5713, Val MSE: 11134196463.2045, Val R2: 0.4343\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1674, Val Loss: 0.1754\n",
      "Val RMSE: 103199.9514, Val MAE: 61543.2601, Val MSE: 10650229975.8827, Val R2: 0.4589\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1613, Val Loss: 0.1645\n",
      "Val RMSE: 99463.0583, Val MAE: 59918.4778, Val MSE: 9892899961.5515, Val R2: 0.4974\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1586, Val Loss: 0.1524\n",
      "Val RMSE: 96838.0095, Val MAE: 55390.6859, Val MSE: 9377600084.5742, Val R2: 0.5236\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1537, Val Loss: 0.1508\n",
      "Val RMSE: 96458.3065, Val MAE: 55245.7487, Val MSE: 9304204898.5733, Val R2: 0.5273\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1521, Val Loss: 0.1508\n",
      "Val RMSE: 95131.6964, Val MAE: 55337.5499, Val MSE: 9050039667.2743, Val R2: 0.5402\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1472, Val Loss: 0.1476\n",
      "Val RMSE: 94350.0045, Val MAE: 53534.1801, Val MSE: 8901923342.1952, Val R2: 0.5477\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1525, Val Loss: 0.1601\n",
      "Val RMSE: 96994.8483, Val MAE: 59151.2284, Val MSE: 9408000599.2847, Val R2: 0.5220\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1525, Val Loss: 0.1496\n",
      "Val RMSE: 94572.7911, Val MAE: 55432.3263, Val MSE: 8944012815.5321, Val R2: 0.5456\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1452, Val Loss: 0.1496\n",
      "Val RMSE: 94732.3336, Val MAE: 53135.1583, Val MSE: 8974215026.2519, Val R2: 0.5441\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1410, Val Loss: 0.2202\n",
      "Val RMSE: 105364.0565, Val MAE: 65664.8236, Val MSE: 11101584394.1420, Val R2: 0.4360\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1380, Val Loss: 0.1382\n",
      "Val RMSE: 91862.7644, Val MAE: 50974.4957, Val MSE: 8438767491.5160, Val R2: 0.5713\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1299, Val Loss: 0.1427\n",
      "Val RMSE: 92291.8955, Val MAE: 51379.0865, Val MSE: 8517793982.5787, Val R2: 0.5672\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1486\n",
      "Val RMSE: 92036.5564, Val MAE: 51823.4764, Val MSE: 8470727705.6363, Val R2: 0.5696\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1219, Val Loss: 0.1486\n",
      "Val RMSE: 93841.0621, Val MAE: 52808.7736, Val MSE: 8806144929.9425, Val R2: 0.5526\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1562\n",
      "Val RMSE: 97124.2004, Val MAE: 53021.5779, Val MSE: 9433110311.5832, Val R2: 0.5207\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1578\n",
      "Val RMSE: 96581.4919, Val MAE: 54583.5135, Val MSE: 9327984583.1685, Val R2: 0.5261\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1508\n",
      "Val RMSE: 95419.8965, Val MAE: 53519.8593, Val MSE: 9104956647.5677, Val R2: 0.5374\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1020, Val Loss: 0.1491\n",
      "Val RMSE: 94665.2794, Val MAE: 54200.4994, Val MSE: 8961515132.6079, Val R2: 0.5447\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1662\n",
      "Val RMSE: 98285.7312, Val MAE: 56455.6725, Val MSE: 9660084952.2132, Val R2: 0.5092\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1416\n",
      "Val RMSE: 92523.8658, Val MAE: 48900.7682, Val MSE: 8560665741.9997, Val R2: 0.5651\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1496\n",
      "Val RMSE: 92619.4352, Val MAE: 51854.9295, Val MSE: 8578359785.6866, Val R2: 0.5642\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0926, Val Loss: 0.1512\n",
      "Val RMSE: 95138.1597, Val MAE: 52470.0133, Val MSE: 9051269434.6380, Val R2: 0.5401\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1877\n",
      "Val RMSE: 100339.3778, Val MAE: 57603.1952, Val MSE: 10067990734.3258, Val R2: 0.4885\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1792\n",
      "Val RMSE: 100971.2521, Val MAE: 57118.7893, Val MSE: 10195193747.0522, Val R2: 0.4820\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0870, Val Loss: 0.1274\n",
      "Val RMSE: 82884.3521, Val MAE: 45382.0077, Val MSE: 6869815831.0250, Val R2: 0.6510\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1396\n",
      "Val RMSE: 86739.8291, Val MAE: 49322.2572, Val MSE: 7523797959.1793, Val R2: 0.6177\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0841, Val Loss: 0.1620\n",
      "Val RMSE: 94575.3384, Val MAE: 54658.9543, Val MSE: 8944494638.6558, Val R2: 0.5456\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0810, Val Loss: 0.1369\n",
      "Val RMSE: 89462.4257, Val MAE: 46313.7452, Val MSE: 8003525613.7065, Val R2: 0.5934\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1450\n",
      "Val RMSE: 89499.2391, Val MAE: 51029.9319, Val MSE: 8010113790.7943, Val R2: 0.5930\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0799, Val Loss: 0.1480\n",
      "Val RMSE: 87746.2343, Val MAE: 52461.6022, Val MSE: 7699401625.8576, Val R2: 0.6088\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0773, Val Loss: 0.1973\n",
      "Val RMSE: 99686.8672, Val MAE: 60129.6709, Val MSE: 9937471491.7049, Val R2: 0.4951\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0755, Val Loss: 0.1284\n",
      "Val RMSE: 84349.2461, Val MAE: 45914.6050, Val MSE: 7114795314.6367, Val R2: 0.6385\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1249\n",
      "Val RMSE: 80196.1930, Val MAE: 44241.9039, Val MSE: 6431429368.5214, Val R2: 0.6732\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1522\n",
      "Val RMSE: 86756.7667, Val MAE: 50461.7905, Val MSE: 7526736572.2206, Val R2: 0.6176\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1291\n",
      "Val RMSE: 81681.6806, Val MAE: 44920.0801, Val MSE: 6671896951.4623, Val R2: 0.6610\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.1181\n",
      "Val RMSE: 77526.9938, Val MAE: 42482.2755, Val MSE: 6010434761.2848, Val R2: 0.6946\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1421\n",
      "Val RMSE: 85127.7332, Val MAE: 49696.2700, Val MSE: 7246730962.9182, Val R2: 0.6318\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1200\n",
      "Val RMSE: 76822.9271, Val MAE: 42586.5118, Val MSE: 5901762121.4826, Val R2: 0.7002\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1395\n",
      "Val RMSE: 81577.6724, Val MAE: 49418.3406, Val MSE: 6654916626.7299, Val R2: 0.6619\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.3193\n",
      "Val RMSE: 122861.6125, Val MAE: 77402.0429, Val MSE: 15094975818.6747, Val R2: 0.2331\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1398\n",
      "Val RMSE: 84010.5422, Val MAE: 49790.0429, Val MSE: 7057771206.7305, Val R2: 0.6414\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1183\n",
      "Val RMSE: 77814.3476, Val MAE: 42801.5935, Val MSE: 6055072696.2321, Val R2: 0.6924\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1313\n",
      "Val RMSE: 83301.5933, Val MAE: 45009.8877, Val MSE: 6939155438.8907, Val R2: 0.6474\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1216\n",
      "Val RMSE: 78269.8565, Val MAE: 43648.2977, Val MSE: 6126170444.0072, Val R2: 0.6888\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1202\n",
      "Val RMSE: 77423.7211, Val MAE: 43282.3560, Val MSE: 5994432584.2681, Val R2: 0.6954\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1198\n",
      "Val RMSE: 76770.9305, Val MAE: 44967.1616, Val MSE: 5893775776.7880, Val R2: 0.7006\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1115\n",
      "Val RMSE: 72765.5783, Val MAE: 41341.5748, Val MSE: 5294829387.9916, Val R2: 0.7310\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1211\n",
      "Val RMSE: 72295.4163, Val MAE: 43166.5297, Val MSE: 5226627225.0065, Val R2: 0.7345\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.1158\n",
      "Val RMSE: 74069.6965, Val MAE: 43279.7499, Val MSE: 5486319932.4083, Val R2: 0.7213\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1198\n",
      "Val RMSE: 75277.1834, Val MAE: 41877.5795, Val MSE: 5666654347.5352, Val R2: 0.7121\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1717\n",
      "Val RMSE: 87836.9990, Val MAE: 53405.3900, Val MSE: 7715338398.6451, Val R2: 0.6080\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1250\n",
      "Val RMSE: 75407.8757, Val MAE: 44440.5406, Val MSE: 5686347724.8110, Val R2: 0.7111\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.3477\n",
      "Val RMSE: 152063.0269, Val MAE: 83399.5852, Val MSE: 23123164140.4631, Val R2: -0.1748\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1061\n",
      "Val RMSE: 68717.6086, Val MAE: 42254.5957, Val MSE: 4722109725.0934, Val R2: 0.7601\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1142\n",
      "Val RMSE: 73462.0527, Val MAE: 41963.1246, Val MSE: 5396673184.7106, Val R2: 0.7258\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1101\n",
      "Val RMSE: 71852.5288, Val MAE: 40998.2173, Val MSE: 5162785888.5147, Val R2: 0.7377\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1242\n",
      "Val RMSE: 75495.3211, Val MAE: 43604.1724, Val MSE: 5699543506.9954, Val R2: 0.7104\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1099\n",
      "Val RMSE: 70593.7826, Val MAE: 42070.8998, Val MSE: 4983482135.7210, Val R2: 0.7468\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1195\n",
      "Val RMSE: 72152.6812, Val MAE: 43578.3726, Val MSE: 5206009407.3525, Val R2: 0.7355\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1150\n",
      "Val RMSE: 74337.7482, Val MAE: 42016.7199, Val MSE: 5526100813.2090, Val R2: 0.7192\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1153\n",
      "Val RMSE: 73728.0724, Val MAE: 42169.5071, Val MSE: 5435828661.4018, Val R2: 0.7238\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1263\n",
      "Val RMSE: 78393.8289, Val MAE: 47923.1945, Val MSE: 6145592406.5982, Val R2: 0.6878\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1048\n",
      "Val RMSE: 69079.8596, Val MAE: 40433.2816, Val MSE: 4772027004.7957, Val R2: 0.7576\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1517\n",
      "Val RMSE: 87634.0957, Val MAE: 49986.9976, Val MSE: 7679734727.9287, Val R2: 0.6098\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1126\n",
      "Val RMSE: 71550.6206, Val MAE: 43235.2693, Val MSE: 5119491314.6168, Val R2: 0.7399\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1192\n",
      "Val RMSE: 74890.9067, Val MAE: 44526.7018, Val MSE: 5608647911.7628, Val R2: 0.7150\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1142\n",
      "Val RMSE: 71824.5987, Val MAE: 40629.6966, Val MSE: 5158772981.5938, Val R2: 0.7379\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1157\n",
      "Val RMSE: 72580.9879, Val MAE: 44056.4498, Val MSE: 5267999809.6088, Val R2: 0.7324\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1122\n",
      "Val RMSE: 73418.4050, Val MAE: 39426.7714, Val MSE: 5390262189.4134, Val R2: 0.7261\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1263\n",
      "Val RMSE: 79709.5459, Val MAE: 45752.4192, Val MSE: 6353611714.0391, Val R2: 0.6772\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1055\n",
      "Val RMSE: 69133.4914, Val MAE: 40474.7271, Val MSE: 4779439637.9538, Val R2: 0.7572\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1086\n",
      "Val RMSE: 71524.6292, Val MAE: 40293.1132, Val MSE: 5115772575.4143, Val R2: 0.7401\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1159\n",
      "Val RMSE: 75613.6438, Val MAE: 40836.7604, Val MSE: 5717423123.9148, Val R2: 0.7095\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1162\n",
      "Val RMSE: 75704.5156, Val MAE: 44244.8587, Val MSE: 5731173680.2963, Val R2: 0.7088\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 81827.0341, Test MAE: 43012.9576, Test MSE: 6695663511.1821, Test R2: 0.5708\n",
      "Inference Time: 2.240588114811824e-05 seconds per sample\n",
      "\n",
      "Iteration 36 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3682, Val Loss: 0.2830\n",
      "Val RMSE: 141656.7444, Val MAE: 86221.8741, Val MSE: 20066633237.5888, Val R2: -0.0195\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2808, Val Loss: 0.2885\n",
      "Val RMSE: 144133.9260, Val MAE: 82724.3992, Val MSE: 20774588636.4737, Val R2: -0.0555\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2746, Val Loss: 0.2751\n",
      "Val RMSE: 141676.6875, Val MAE: 83343.9777, Val MSE: 20072283770.9339, Val R2: -0.0198\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2689, Val Loss: 0.2745\n",
      "Val RMSE: 141617.1028, Val MAE: 83144.5839, Val MSE: 20055403818.3588, Val R2: -0.0189\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2650, Val Loss: 0.2791\n",
      "Val RMSE: 142626.4758, Val MAE: 81971.8852, Val MSE: 20342311611.4607, Val R2: -0.0335\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2627, Val Loss: 0.2821\n",
      "Val RMSE: 144569.9221, Val MAE: 79709.1023, Val MSE: 20900462364.3235, Val R2: -0.0619\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2781\n",
      "Val RMSE: 141623.0386, Val MAE: 82891.3768, Val MSE: 20057085052.4326, Val R2: -0.0190\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2755\n",
      "Val RMSE: 141061.8885, Val MAE: 84687.3594, Val MSE: 19898456393.8007, Val R2: -0.0110\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2726\n",
      "Val RMSE: 140835.2726, Val MAE: 83119.4743, Val MSE: 19834573996.4146, Val R2: -0.0077\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2768\n",
      "Val RMSE: 144033.4949, Val MAE: 78380.9478, Val MSE: 20745647645.2741, Val R2: -0.0540\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2481, Val Loss: 0.2699\n",
      "Val RMSE: 142367.9902, Val MAE: 78422.6186, Val MSE: 20268644639.9238, Val R2: -0.0298\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2453, Val Loss: 0.2724\n",
      "Val RMSE: 139885.8762, Val MAE: 83829.7889, Val MSE: 19568058352.4757, Val R2: 0.0058\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2438, Val Loss: 0.2651\n",
      "Val RMSE: 140132.1477, Val MAE: 81011.2281, Val MSE: 19637018806.9814, Val R2: 0.0023\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2418, Val Loss: 0.2758\n",
      "Val RMSE: 139630.4133, Val MAE: 85532.4431, Val MSE: 19496652325.5834, Val R2: 0.0094\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2414, Val Loss: 0.2627\n",
      "Val RMSE: 140782.9957, Val MAE: 78530.7625, Val MSE: 19819851879.1610, Val R2: -0.0070\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2384, Val Loss: 0.2601\n",
      "Val RMSE: 140282.5581, Val MAE: 78542.6060, Val MSE: 19679196115.9548, Val R2: 0.0002\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2371, Val Loss: 0.2625\n",
      "Val RMSE: 141129.4470, Val MAE: 77988.6225, Val MSE: 19917520802.9235, Val R2: -0.0119\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2386, Val Loss: 0.2609\n",
      "Val RMSE: 139077.4624, Val MAE: 80128.0016, Val MSE: 19342540537.2982, Val R2: 0.0173\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2404, Val Loss: 0.2638\n",
      "Val RMSE: 139262.5855, Val MAE: 80837.3169, Val MSE: 19394067707.6326, Val R2: 0.0147\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2369, Val Loss: 0.2601\n",
      "Val RMSE: 140064.3216, Val MAE: 78963.5635, Val MSE: 19618014193.6814, Val R2: 0.0033\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2366, Val Loss: 0.2602\n",
      "Val RMSE: 139124.6818, Val MAE: 79977.8154, Val MSE: 19355677091.4331, Val R2: 0.0166\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2345, Val Loss: 0.2492\n",
      "Val RMSE: 135669.7157, Val MAE: 77204.3443, Val MSE: 18406271744.5966, Val R2: 0.0648\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2277, Val Loss: 0.2510\n",
      "Val RMSE: 134945.8635, Val MAE: 78139.2308, Val MSE: 18210386074.3451, Val R2: 0.0748\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2281, Val Loss: 0.2571\n",
      "Val RMSE: 137805.4239, Val MAE: 76182.4046, Val MSE: 18990334852.7931, Val R2: 0.0352\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2307, Val Loss: 0.2472\n",
      "Val RMSE: 135152.5299, Val MAE: 73857.5473, Val MSE: 18266206340.9648, Val R2: 0.0720\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2374\n",
      "Val RMSE: 131769.4643, Val MAE: 72967.9490, Val MSE: 17363191716.7947, Val R2: 0.1178\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2102, Val Loss: 0.2264\n",
      "Val RMSE: 128154.0575, Val MAE: 73581.7249, Val MSE: 16423462453.5069, Val R2: 0.1656\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2064, Val Loss: 0.2251\n",
      "Val RMSE: 130540.9420, Val MAE: 69749.9761, Val MSE: 17040937541.0251, Val R2: 0.1342\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2255\n",
      "Val RMSE: 129219.8616, Val MAE: 71126.6474, Val MSE: 16697772637.9635, Val R2: 0.1516\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2031, Val Loss: 0.2309\n",
      "Val RMSE: 130681.1857, Val MAE: 73873.4897, Val MSE: 17077572288.9215, Val R2: 0.1324\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2011, Val Loss: 0.2296\n",
      "Val RMSE: 130206.6382, Val MAE: 72393.1892, Val MSE: 16953768631.7631, Val R2: 0.1386\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1971, Val Loss: 0.2196\n",
      "Val RMSE: 126172.1500, Val MAE: 70634.2048, Val MSE: 15919411426.1594, Val R2: 0.1912\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1950, Val Loss: 0.2244\n",
      "Val RMSE: 128074.9800, Val MAE: 69412.8007, Val MSE: 16403200508.7655, Val R2: 0.1666\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1858, Val Loss: 0.1921\n",
      "Val RMSE: 111496.6731, Val MAE: 64197.2752, Val MSE: 12431508110.4692, Val R2: 0.3684\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1755, Val Loss: 0.1913\n",
      "Val RMSE: 108796.7073, Val MAE: 63002.1117, Val MSE: 11836723530.0024, Val R2: 0.3986\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1685, Val Loss: 0.1886\n",
      "Val RMSE: 107155.2835, Val MAE: 62621.4867, Val MSE: 11482254781.9999, Val R2: 0.4166\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1688, Val Loss: 0.1897\n",
      "Val RMSE: 106840.1394, Val MAE: 62927.7142, Val MSE: 11414815394.1827, Val R2: 0.4201\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1605, Val Loss: 0.1840\n",
      "Val RMSE: 105015.7392, Val MAE: 63429.1588, Val MSE: 11028305474.9786, Val R2: 0.4397\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1545, Val Loss: 0.1806\n",
      "Val RMSE: 102876.9150, Val MAE: 60658.4786, Val MSE: 10583659646.4993, Val R2: 0.4623\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1534, Val Loss: 0.1687\n",
      "Val RMSE: 100389.6113, Val MAE: 59075.2947, Val MSE: 10078074049.3179, Val R2: 0.4880\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1508, Val Loss: 0.1648\n",
      "Val RMSE: 98641.0377, Val MAE: 58300.9328, Val MSE: 9730054311.8055, Val R2: 0.5057\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1449, Val Loss: 0.1669\n",
      "Val RMSE: 99095.8959, Val MAE: 59524.8639, Val MSE: 9819996581.5657, Val R2: 0.5011\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1440, Val Loss: 0.1701\n",
      "Val RMSE: 99800.9088, Val MAE: 59300.4262, Val MSE: 9960221391.4989, Val R2: 0.4940\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1421, Val Loss: 0.1762\n",
      "Val RMSE: 101435.9785, Val MAE: 59712.6146, Val MSE: 10289257730.9193, Val R2: 0.4772\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1364, Val Loss: 0.1639\n",
      "Val RMSE: 99260.8219, Val MAE: 58683.1370, Val MSE: 9852710767.5900, Val R2: 0.4994\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1347, Val Loss: 0.1561\n",
      "Val RMSE: 97262.1995, Val MAE: 56208.4299, Val MSE: 9459935457.9564, Val R2: 0.5194\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1292, Val Loss: 0.1616\n",
      "Val RMSE: 98784.5488, Val MAE: 57386.5838, Val MSE: 9758387091.4536, Val R2: 0.5042\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1224, Val Loss: 0.1464\n",
      "Val RMSE: 96548.8468, Val MAE: 52514.4290, Val MSE: 9321679819.9187, Val R2: 0.5264\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1161, Val Loss: 0.1487\n",
      "Val RMSE: 94177.1429, Val MAE: 56094.8427, Val MSE: 8869334250.0508, Val R2: 0.5494\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1444\n",
      "Val RMSE: 93412.1886, Val MAE: 52183.2504, Val MSE: 8725836981.4593, Val R2: 0.5567\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1115, Val Loss: 0.1570\n",
      "Val RMSE: 95202.0871, Val MAE: 57091.0706, Val MSE: 9063437396.6706, Val R2: 0.5395\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1057, Val Loss: 0.1372\n",
      "Val RMSE: 91084.2263, Val MAE: 52053.1003, Val MSE: 8296336277.0818, Val R2: 0.5785\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1522\n",
      "Val RMSE: 95300.3583, Val MAE: 53770.9547, Val MSE: 9082158300.5614, Val R2: 0.5386\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0998, Val Loss: 0.1407\n",
      "Val RMSE: 91300.4303, Val MAE: 52387.5582, Val MSE: 8335768572.2868, Val R2: 0.5765\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0971, Val Loss: 0.1681\n",
      "Val RMSE: 96683.1310, Val MAE: 60777.9727, Val MSE: 9347627818.5877, Val R2: 0.5251\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0969, Val Loss: 0.1371\n",
      "Val RMSE: 90977.2111, Val MAE: 50882.6373, Val MSE: 8276852944.4717, Val R2: 0.5795\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0958, Val Loss: 0.1683\n",
      "Val RMSE: 97086.9599, Val MAE: 59438.2031, Val MSE: 9425877784.4235, Val R2: 0.5211\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1487\n",
      "Val RMSE: 95158.8521, Val MAE: 55453.8247, Val MSE: 9055207130.5913, Val R2: 0.5399\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1892\n",
      "Val RMSE: 101237.1952, Val MAE: 63020.2852, Val MSE: 10248969691.3314, Val R2: 0.4793\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0870, Val Loss: 0.1582\n",
      "Val RMSE: 96584.9148, Val MAE: 57297.5817, Val MSE: 9328645758.2359, Val R2: 0.5260\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1629\n",
      "Val RMSE: 96725.6692, Val MAE: 57793.8584, Val MSE: 9355855072.9855, Val R2: 0.5247\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.2473\n",
      "Val RMSE: 113520.5992, Val MAE: 75056.4739, Val MSE: 12886926431.7206, Val R2: 0.3453\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0841, Val Loss: 0.2332\n",
      "Val RMSE: 107036.1796, Val MAE: 67548.1422, Val MSE: 11456743749.8706, Val R2: 0.4179\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.2395\n",
      "Val RMSE: 108849.1417, Val MAE: 70242.8772, Val MSE: 11848135649.8419, Val R2: 0.3980\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.4930\n",
      "Val RMSE: 161729.6620, Val MAE: 108884.0115, Val MSE: 26156483578.8788, Val R2: -0.3289\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.2196\n",
      "Val RMSE: 107333.3333, Val MAE: 67304.6855, Val MSE: 11520444431.4277, Val R2: 0.4147\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.2334\n",
      "Val RMSE: 108647.3445, Val MAE: 67175.1529, Val MSE: 11804245475.8125, Val R2: 0.4003\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1345\n",
      "Val RMSE: 88390.4476, Val MAE: 49539.4246, Val MSE: 7812871219.7812, Val R2: 0.6031\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1305\n",
      "Val RMSE: 87449.7743, Val MAE: 47439.4992, Val MSE: 7647463021.7993, Val R2: 0.6115\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.2002\n",
      "Val RMSE: 100447.9830, Val MAE: 61794.5475, Val MSE: 10089797291.1305, Val R2: 0.4874\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0724, Val Loss: 0.1935\n",
      "Val RMSE: 94175.1398, Val MAE: 58332.4645, Val MSE: 8868956961.1030, Val R2: 0.5494\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1451\n",
      "Val RMSE: 90438.3917, Val MAE: 51253.2880, Val MSE: 8179102685.3667, Val R2: 0.5844\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1415\n",
      "Val RMSE: 89768.8364, Val MAE: 50002.4031, Val MSE: 8058443982.7180, Val R2: 0.5906\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1406\n",
      "Val RMSE: 87945.1870, Val MAE: 50112.1809, Val MSE: 7734355908.2484, Val R2: 0.6070\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.2217\n",
      "Val RMSE: 102072.1699, Val MAE: 66473.9757, Val MSE: 10418727864.8321, Val R2: 0.4707\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0637, Val Loss: 0.1318\n",
      "Val RMSE: 84034.0679, Val MAE: 48314.4268, Val MSE: 7061724561.8315, Val R2: 0.6412\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1304\n",
      "Val RMSE: 86671.1188, Val MAE: 47385.0644, Val MSE: 7511882830.5767, Val R2: 0.6183\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0653, Val Loss: 0.1402\n",
      "Val RMSE: 87910.9513, Val MAE: 51000.0896, Val MSE: 7728335362.5354, Val R2: 0.6074\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1229\n",
      "Val RMSE: 82525.7296, Val MAE: 45089.4001, Val MSE: 6810496048.7601, Val R2: 0.6540\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1630\n",
      "Val RMSE: 92735.7723, Val MAE: 57642.3037, Val MSE: 8599923454.8949, Val R2: 0.5631\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1551\n",
      "Val RMSE: 90357.8319, Val MAE: 54246.7540, Val MSE: 8164537776.7870, Val R2: 0.5852\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1438\n",
      "Val RMSE: 88065.9665, Val MAE: 52895.1022, Val MSE: 7755614459.4352, Val R2: 0.6060\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1505\n",
      "Val RMSE: 88610.2321, Val MAE: 53974.9268, Val MSE: 7851773231.9914, Val R2: 0.6011\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1427\n",
      "Val RMSE: 85460.7843, Val MAE: 53302.5931, Val MSE: 7303545651.4920, Val R2: 0.6289\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1593\n",
      "Val RMSE: 90429.4120, Val MAE: 53934.5901, Val MSE: 8177478561.1116, Val R2: 0.5845\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.2759\n",
      "Val RMSE: 116894.6721, Val MAE: 78203.7005, Val MSE: 13664364373.3776, Val R2: 0.3058\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1303\n",
      "Val RMSE: 85701.3505, Val MAE: 47716.8850, Val MSE: 7344721477.3104, Val R2: 0.6268\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1396\n",
      "Val RMSE: 88348.9522, Val MAE: 50237.3123, Val MSE: 7805537356.3131, Val R2: 0.6034\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1626\n",
      "Val RMSE: 91154.9962, Val MAE: 55706.9619, Val MSE: 8309233335.2868, Val R2: 0.5778\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1349\n",
      "Val RMSE: 87003.1886, Val MAE: 48833.0280, Val MSE: 7569554825.3310, Val R2: 0.6154\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1322\n",
      "Val RMSE: 83394.2823, Val MAE: 47587.0816, Val MSE: 6954606322.6622, Val R2: 0.6467\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1455\n",
      "Val RMSE: 86621.8939, Val MAE: 51433.1529, Val MSE: 7503352511.0539, Val R2: 0.6188\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1582\n",
      "Val RMSE: 87432.7381, Val MAE: 54353.4199, Val MSE: 7644483689.9332, Val R2: 0.6116\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1345\n",
      "Val RMSE: 83190.8630, Val MAE: 49422.2445, Val MSE: 6920719694.8914, Val R2: 0.6484\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1365\n",
      "Val RMSE: 83872.2632, Val MAE: 49138.6455, Val MSE: 7034556539.7803, Val R2: 0.6426\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1361\n",
      "Val RMSE: 83382.4429, Val MAE: 48006.1459, Val MSE: 6952631781.1794, Val R2: 0.6468\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1374\n",
      "Val RMSE: 81243.8086, Val MAE: 50010.7777, Val MSE: 6600556434.3233, Val R2: 0.6647\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1257\n",
      "Val RMSE: 83752.8090, Val MAE: 45682.4613, Val MSE: 7014533017.9281, Val R2: 0.6436\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1374\n",
      "Val RMSE: 84413.2422, Val MAE: 49213.5887, Val MSE: 7125595465.3931, Val R2: 0.6380\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1256\n",
      "Val RMSE: 80965.7049, Val MAE: 46320.3504, Val MSE: 6555445368.6006, Val R2: 0.6669\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 81051.0419, Test MAE: 43727.7453, Test MSE: 6569271396.4388, Test R2: 0.5789\n",
      "Inference Time: 3.117154194758488e-05 seconds per sample\n",
      "\n",
      "Iteration 37 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3758, Val Loss: 0.3015\n",
      "Val RMSE: 147917.5149, Val MAE: 81055.3780, Val MSE: 21879591211.7797, Val R2: -0.1116\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2760, Val Loss: 0.2799\n",
      "Val RMSE: 143165.7683, Val MAE: 81898.1570, Val MSE: 20496437221.1271, Val R2: -0.0413\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2672, Val Loss: 0.2768\n",
      "Val RMSE: 142120.6914, Val MAE: 82729.6929, Val MSE: 20198290919.1508, Val R2: -0.0262\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2759\n",
      "Val RMSE: 141514.7547, Val MAE: 84097.2039, Val MSE: 20026425785.7186, Val R2: -0.0175\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2633, Val Loss: 0.2815\n",
      "Val RMSE: 141354.3672, Val MAE: 88035.1004, Val MSE: 19981057124.5902, Val R2: -0.0152\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2623, Val Loss: 0.2723\n",
      "Val RMSE: 140833.4412, Val MAE: 84688.3490, Val MSE: 19834058154.5992, Val R2: -0.0077\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2706\n",
      "Val RMSE: 140688.6613, Val MAE: 83427.2384, Val MSE: 19793299422.4549, Val R2: -0.0056\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2715\n",
      "Val RMSE: 141512.5393, Val MAE: 82732.6271, Val MSE: 20025798786.6826, Val R2: -0.0174\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2692\n",
      "Val RMSE: 142443.1923, Val MAE: 78747.7576, Val MSE: 20290063029.5535, Val R2: -0.0309\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2574, Val Loss: 0.2798\n",
      "Val RMSE: 144396.0076, Val MAE: 78568.7504, Val MSE: 20850207021.6794, Val R2: -0.0593\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2520, Val Loss: 0.2644\n",
      "Val RMSE: 137510.3423, Val MAE: 81862.0297, Val MSE: 18909094227.5038, Val R2: 0.0393\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2428, Val Loss: 0.2551\n",
      "Val RMSE: 137804.9128, Val MAE: 76340.8187, Val MSE: 18990193990.5377, Val R2: 0.0352\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2538\n",
      "Val RMSE: 136720.7446, Val MAE: 76453.6212, Val MSE: 18692562000.0587, Val R2: 0.0503\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2589\n",
      "Val RMSE: 138524.2229, Val MAE: 73812.6291, Val MSE: 19188960320.0511, Val R2: 0.0251\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2361, Val Loss: 0.2442\n",
      "Val RMSE: 130202.0022, Val MAE: 77898.7858, Val MSE: 16952561372.3506, Val R2: 0.1387\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2250, Val Loss: 0.2301\n",
      "Val RMSE: 130927.5734, Val MAE: 73193.2597, Val MSE: 17142029470.0521, Val R2: 0.1291\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2205, Val Loss: 0.2410\n",
      "Val RMSE: 133344.1127, Val MAE: 74767.8151, Val MSE: 17780652396.6194, Val R2: 0.0966\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2203, Val Loss: 0.2398\n",
      "Val RMSE: 132067.7671, Val MAE: 76370.1044, Val MSE: 17441895104.0859, Val R2: 0.1138\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2081, Val Loss: 0.2488\n",
      "Val RMSE: 138328.6713, Val MAE: 75785.8253, Val MSE: 19134821300.7850, Val R2: 0.0278\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2041, Val Loss: 0.2315\n",
      "Val RMSE: 130254.2109, Val MAE: 71698.6660, Val MSE: 16966159469.6661, Val R2: 0.1380\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1956, Val Loss: 0.2343\n",
      "Val RMSE: 129437.2937, Val MAE: 72514.6281, Val MSE: 16754013007.9249, Val R2: 0.1488\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1905, Val Loss: 0.2554\n",
      "Val RMSE: 135748.9590, Val MAE: 73251.8320, Val MSE: 18427779866.3632, Val R2: 0.0638\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1905, Val Loss: 0.2081\n",
      "Val RMSE: 116614.7265, Val MAE: 69939.4186, Val MSE: 13598994425.8852, Val R2: 0.3091\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1795, Val Loss: 0.2082\n",
      "Val RMSE: 118705.1780, Val MAE: 66582.8844, Val MSE: 14090919289.3783, Val R2: 0.2841\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1953\n",
      "Val RMSE: 110289.2096, Val MAE: 63805.5314, Val MSE: 12163709748.0421, Val R2: 0.3820\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1883\n",
      "Val RMSE: 107991.3373, Val MAE: 62247.6308, Val MSE: 11662128939.6104, Val R2: 0.4075\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1642, Val Loss: 0.1828\n",
      "Val RMSE: 104648.4340, Val MAE: 61281.9443, Val MSE: 10951294746.3818, Val R2: 0.4436\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1574, Val Loss: 0.1829\n",
      "Val RMSE: 104732.7130, Val MAE: 60208.4531, Val MSE: 10968941178.6490, Val R2: 0.4427\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1560, Val Loss: 0.1645\n",
      "Val RMSE: 98039.5226, Val MAE: 59227.4056, Val MSE: 9611747985.5822, Val R2: 0.5117\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1519, Val Loss: 0.1596\n",
      "Val RMSE: 96688.1818, Val MAE: 57154.3320, Val MSE: 9348604491.6212, Val R2: 0.5250\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1467, Val Loss: 0.1513\n",
      "Val RMSE: 94439.0617, Val MAE: 56992.6139, Val MSE: 8918736373.8537, Val R2: 0.5469\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1408, Val Loss: 0.1443\n",
      "Val RMSE: 93248.6809, Val MAE: 52460.5253, Val MSE: 8695316494.5204, Val R2: 0.5582\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1387, Val Loss: 0.1414\n",
      "Val RMSE: 93399.3255, Val MAE: 51533.0122, Val MSE: 8723434000.2880, Val R2: 0.5568\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1347, Val Loss: 0.1264\n",
      "Val RMSE: 87874.4993, Val MAE: 49808.8092, Val MSE: 7721927630.1972, Val R2: 0.6077\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1290, Val Loss: 0.1303\n",
      "Val RMSE: 90858.6881, Val MAE: 48526.1647, Val MSE: 8255301210.5400, Val R2: 0.5806\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1261, Val Loss: 0.1404\n",
      "Val RMSE: 93153.7308, Val MAE: 51208.8276, Val MSE: 8677617565.8556, Val R2: 0.5591\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1214, Val Loss: 0.1214\n",
      "Val RMSE: 87326.2003, Val MAE: 46954.0134, Val MSE: 7625865263.8287, Val R2: 0.6126\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1179, Val Loss: 0.1315\n",
      "Val RMSE: 88936.3157, Val MAE: 49646.9222, Val MSE: 7909668256.0375, Val R2: 0.5981\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1154, Val Loss: 0.1398\n",
      "Val RMSE: 91605.3193, Val MAE: 49951.7069, Val MSE: 8391534529.5278, Val R2: 0.5737\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1113, Val Loss: 0.1329\n",
      "Val RMSE: 90758.4744, Val MAE: 48704.2774, Val MSE: 8237100676.3087, Val R2: 0.5815\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1101, Val Loss: 0.1117\n",
      "Val RMSE: 85803.5246, Val MAE: 44407.4339, Val MSE: 7362244839.3844, Val R2: 0.6260\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1044, Val Loss: 0.1048\n",
      "Val RMSE: 82635.1228, Val MAE: 41922.4363, Val MSE: 6828563523.2987, Val R2: 0.6531\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1053\n",
      "Val RMSE: 82987.0365, Val MAE: 42435.2790, Val MSE: 6886848228.6074, Val R2: 0.6501\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1011, Val Loss: 0.1085\n",
      "Val RMSE: 82252.5544, Val MAE: 43152.6204, Val MSE: 6765482699.3600, Val R2: 0.6563\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0982, Val Loss: 0.0947\n",
      "Val RMSE: 76363.3660, Val MAE: 38553.8873, Val MSE: 5831363667.4321, Val R2: 0.7037\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0949, Val Loss: 0.0967\n",
      "Val RMSE: 76362.0517, Val MAE: 39311.1056, Val MSE: 5831162946.2257, Val R2: 0.7037\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1091\n",
      "Val RMSE: 79032.8240, Val MAE: 44401.3008, Val MSE: 6246187277.0277, Val R2: 0.6827\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.0981\n",
      "Val RMSE: 75833.3429, Val MAE: 39343.1959, Val MSE: 5750695902.7606, Val R2: 0.7078\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0896, Val Loss: 0.0974\n",
      "Val RMSE: 75120.9060, Val MAE: 41554.4840, Val MSE: 5643150512.7804, Val R2: 0.7133\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0851, Val Loss: 0.0988\n",
      "Val RMSE: 74739.4180, Val MAE: 40520.0505, Val MSE: 5585980604.1676, Val R2: 0.7162\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.0909\n",
      "Val RMSE: 72768.6150, Val MAE: 36632.0473, Val MSE: 5295271333.0270, Val R2: 0.7310\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0830, Val Loss: 0.0888\n",
      "Val RMSE: 69366.7379, Val MAE: 36352.5899, Val MSE: 4811744326.5075, Val R2: 0.7555\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0805, Val Loss: 0.0895\n",
      "Val RMSE: 70883.9701, Val MAE: 40191.0183, Val MSE: 5024537214.1066, Val R2: 0.7447\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.0840\n",
      "Val RMSE: 68861.7307, Val MAE: 36016.8730, Val MSE: 4741937954.7226, Val R2: 0.7591\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.0816\n",
      "Val RMSE: 65760.9787, Val MAE: 36318.5126, Val MSE: 4324506320.6606, Val R2: 0.7803\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.0873\n",
      "Val RMSE: 68030.0684, Val MAE: 35676.0276, Val MSE: 4628090203.4151, Val R2: 0.7649\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.0990\n",
      "Val RMSE: 71417.8667, Val MAE: 42234.4198, Val MSE: 5100511678.8720, Val R2: 0.7409\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0737, Val Loss: 0.0901\n",
      "Val RMSE: 67673.4487, Val MAE: 39648.6365, Val MSE: 4579695662.8903, Val R2: 0.7673\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.0943\n",
      "Val RMSE: 76205.9378, Val MAE: 38745.2752, Val MSE: 5807344963.4339, Val R2: 0.7050\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.0907\n",
      "Val RMSE: 70255.2474, Val MAE: 37763.4834, Val MSE: 4935799780.5144, Val R2: 0.7492\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.0875\n",
      "Val RMSE: 68665.7794, Val MAE: 38241.7025, Val MSE: 4714989261.4756, Val R2: 0.7604\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.0890\n",
      "Val RMSE: 70081.8925, Val MAE: 36532.6141, Val MSE: 4911471649.8802, Val R2: 0.7505\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.0830\n",
      "Val RMSE: 66178.4833, Val MAE: 35834.0742, Val MSE: 4379591650.5723, Val R2: 0.7775\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.0867\n",
      "Val RMSE: 69275.8316, Val MAE: 36355.6641, Val MSE: 4799140847.7272, Val R2: 0.7562\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.0934\n",
      "Val RMSE: 69061.6947, Val MAE: 40753.3333, Val MSE: 4769517678.9676, Val R2: 0.7577\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.0792\n",
      "Val RMSE: 64568.4775, Val MAE: 34223.3975, Val MSE: 4169088283.0782, Val R2: 0.7882\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.0843\n",
      "Val RMSE: 67454.6049, Val MAE: 34643.4006, Val MSE: 4550123725.4828, Val R2: 0.7688\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.0847\n",
      "Val RMSE: 67336.8558, Val MAE: 35687.0230, Val MSE: 4534252143.3861, Val R2: 0.7696\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0637, Val Loss: 0.0891\n",
      "Val RMSE: 70505.5295, Val MAE: 34735.2068, Val MSE: 4971029693.3796, Val R2: 0.7474\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.0842\n",
      "Val RMSE: 68209.0533, Val MAE: 34874.8250, Val MSE: 4652474958.3181, Val R2: 0.7636\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.0820\n",
      "Val RMSE: 67094.9696, Val MAE: 34366.2929, Val MSE: 4501734948.3679, Val R2: 0.7713\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.0813\n",
      "Val RMSE: 65896.9850, Val MAE: 33896.6640, Val MSE: 4342412637.3763, Val R2: 0.7794\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.0775\n",
      "Val RMSE: 63907.5283, Val MAE: 32916.1865, Val MSE: 4084172171.4742, Val R2: 0.7925\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.0840\n",
      "Val RMSE: 66428.1089, Val MAE: 36207.8230, Val MSE: 4412693657.8124, Val R2: 0.7758\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.0738\n",
      "Val RMSE: 63102.5573, Val MAE: 31085.6490, Val MSE: 3981932741.2962, Val R2: 0.7977\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.0865\n",
      "Val RMSE: 67132.9734, Val MAE: 37406.0518, Val MSE: 4506836113.3850, Val R2: 0.7710\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.0803\n",
      "Val RMSE: 64515.7187, Val MAE: 35364.7528, Val MSE: 4162277955.0399, Val R2: 0.7885\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.0815\n",
      "Val RMSE: 66456.9773, Val MAE: 33804.1183, Val MSE: 4416529837.8389, Val R2: 0.7756\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0841\n",
      "Val RMSE: 67891.3683, Val MAE: 34909.3450, Val MSE: 4609237883.9412, Val R2: 0.7658\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.0845\n",
      "Val RMSE: 66457.4526, Val MAE: 34694.1819, Val MSE: 4416593001.7428, Val R2: 0.7756\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.0813\n",
      "Val RMSE: 63926.6340, Val MAE: 36436.2135, Val MSE: 4086614537.5944, Val R2: 0.7924\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.0828\n",
      "Val RMSE: 67360.1020, Val MAE: 34787.5846, Val MSE: 4537383341.1901, Val R2: 0.7695\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.0758\n",
      "Val RMSE: 63350.4262, Val MAE: 31484.4791, Val MSE: 4013276493.5425, Val R2: 0.7961\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.0779\n",
      "Val RMSE: 64335.7038, Val MAE: 33912.3626, Val MSE: 4139082787.8597, Val R2: 0.7897\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.0766\n",
      "Val RMSE: 64137.6086, Val MAE: 33216.8410, Val MSE: 4113632831.5829, Val R2: 0.7910\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.0795\n",
      "Val RMSE: 65080.4157, Val MAE: 33019.9171, Val MSE: 4235460510.1185, Val R2: 0.7848\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.0791\n",
      "Val RMSE: 66346.5938, Val MAE: 32171.5780, Val MSE: 4401870505.6837, Val R2: 0.7764\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.0809\n",
      "Val RMSE: 65397.9472, Val MAE: 34864.4850, Val MSE: 4276891504.4350, Val R2: 0.7827\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.0765\n",
      "Val RMSE: 64346.8946, Val MAE: 32332.4108, Val MSE: 4140522845.1530, Val R2: 0.7896\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.0769\n",
      "Val RMSE: 63002.0453, Val MAE: 32454.3315, Val MSE: 3969257716.4935, Val R2: 0.7983\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.0803\n",
      "Val RMSE: 65669.4133, Val MAE: 33852.7206, Val MSE: 4312471846.9713, Val R2: 0.7809\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.0844\n",
      "Val RMSE: 66691.2519, Val MAE: 35697.8524, Val MSE: 4447723081.2038, Val R2: 0.7740\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.0830\n",
      "Val RMSE: 66521.1317, Val MAE: 34324.4771, Val MSE: 4425060960.0913, Val R2: 0.7752\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.0841\n",
      "Val RMSE: 67236.4582, Val MAE: 36121.7434, Val MSE: 4520741305.3787, Val R2: 0.7703\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.0789\n",
      "Val RMSE: 65692.1069, Val MAE: 33280.9037, Val MSE: 4315452913.2948, Val R2: 0.7807\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.0901\n",
      "Val RMSE: 72878.3837, Val MAE: 35172.1373, Val MSE: 5311258809.4866, Val R2: 0.7302\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.0859\n",
      "Val RMSE: 67970.1011, Val MAE: 35736.3824, Val MSE: 4619934642.5835, Val R2: 0.7653\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.0842\n",
      "Val RMSE: 66500.9894, Val MAE: 36932.8671, Val MSE: 4422381594.2052, Val R2: 0.7753\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.0851\n",
      "Val RMSE: 67527.7253, Val MAE: 35441.9430, Val MSE: 4559993683.0634, Val R2: 0.7683\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.0899\n",
      "Val RMSE: 70353.5557, Val MAE: 35692.1291, Val MSE: 4949622794.7527, Val R2: 0.7485\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 62045.2561, Test MAE: 31095.4486, Test MSE: 3849613803.0166, Test R2: 0.7532\n",
      "Inference Time: 1.8297818990854116e-05 seconds per sample\n",
      "\n",
      "Iteration 38 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3626, Val Loss: 0.2826\n",
      "Val RMSE: 140789.2110, Val MAE: 88492.4001, Val MSE: 19821601921.6990, Val R2: -0.0071\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2854, Val Loss: 0.2899\n",
      "Val RMSE: 144513.7085, Val MAE: 82499.5309, Val MSE: 20884211937.5230, Val R2: -0.0610\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2760, Val Loss: 0.2774\n",
      "Val RMSE: 142470.4216, Val MAE: 82770.9600, Val MSE: 20297821034.2113, Val R2: -0.0313\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2718, Val Loss: 0.2761\n",
      "Val RMSE: 141468.4982, Val MAE: 83758.5179, Val MSE: 20013335971.5406, Val R2: -0.0168\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2771\n",
      "Val RMSE: 141933.9588, Val MAE: 83187.9383, Val MSE: 20145248656.5861, Val R2: -0.0235\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2665, Val Loss: 0.2821\n",
      "Val RMSE: 144167.6496, Val MAE: 80382.5179, Val MSE: 20784311198.7281, Val R2: -0.0560\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2720\n",
      "Val RMSE: 141604.1907, Val MAE: 81805.1534, Val MSE: 20051746809.8940, Val R2: -0.0188\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2584, Val Loss: 0.2749\n",
      "Val RMSE: 140460.3517, Val MAE: 86230.2269, Val MSE: 19729110391.1808, Val R2: -0.0024\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2670\n",
      "Val RMSE: 141433.4109, Val MAE: 79840.9083, Val MSE: 20003409711.4003, Val R2: -0.0163\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2685\n",
      "Val RMSE: 139478.9555, Val MAE: 84168.7692, Val MSE: 19454379033.0028, Val R2: 0.0116\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2802\n",
      "Val RMSE: 145376.0554, Val MAE: 77642.6757, Val MSE: 21134197471.6107, Val R2: -0.0738\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2681\n",
      "Val RMSE: 139635.2475, Val MAE: 83441.5589, Val MSE: 19498002357.6560, Val R2: 0.0094\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2488, Val Loss: 0.2642\n",
      "Val RMSE: 139659.0565, Val MAE: 81352.9702, Val MSE: 19504652065.9567, Val R2: 0.0090\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2721\n",
      "Val RMSE: 139477.5173, Val MAE: 86326.6752, Val MSE: 19453977839.0333, Val R2: 0.0116\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2472, Val Loss: 0.2643\n",
      "Val RMSE: 142839.7137, Val MAE: 76909.2113, Val MSE: 20403183798.2415, Val R2: -0.0366\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2434, Val Loss: 0.2628\n",
      "Val RMSE: 139800.0319, Val MAE: 80882.4260, Val MSE: 19544048925.5319, Val R2: 0.0070\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2404, Val Loss: 0.2735\n",
      "Val RMSE: 145109.3583, Val MAE: 76801.1934, Val MSE: 21056725871.3972, Val R2: -0.0698\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2622\n",
      "Val RMSE: 139758.7750, Val MAE: 80271.7632, Val MSE: 19532515188.2859, Val R2: 0.0076\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2416, Val Loss: 0.2509\n",
      "Val RMSE: 136252.0678, Val MAE: 75928.4205, Val MSE: 18564625973.4248, Val R2: 0.0568\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2322, Val Loss: 0.2497\n",
      "Val RMSE: 134927.2538, Val MAE: 74669.4510, Val MSE: 18205363813.3196, Val R2: 0.0751\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2180, Val Loss: 0.2323\n",
      "Val RMSE: 131829.0085, Val MAE: 74308.6416, Val MSE: 17378887477.5812, Val R2: 0.1170\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2096, Val Loss: 0.2437\n",
      "Val RMSE: 135584.5833, Val MAE: 73679.5151, Val MSE: 18383179220.0546, Val R2: 0.0660\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2030, Val Loss: 0.2282\n",
      "Val RMSE: 128853.8090, Val MAE: 73099.1381, Val MSE: 16603304085.7574, Val R2: 0.1564\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1990, Val Loss: 0.2253\n",
      "Val RMSE: 127752.3329, Val MAE: 73189.0017, Val MSE: 16320658568.7257, Val R2: 0.1708\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1989, Val Loss: 0.2228\n",
      "Val RMSE: 123580.1816, Val MAE: 67930.1626, Val MSE: 15272061275.6117, Val R2: 0.2241\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1821, Val Loss: 0.2123\n",
      "Val RMSE: 119372.4825, Val MAE: 66347.2051, Val MSE: 14249789584.8649, Val R2: 0.2760\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1738, Val Loss: 0.1835\n",
      "Val RMSE: 104598.0051, Val MAE: 61467.5419, Val MSE: 10940742668.7600, Val R2: 0.4441\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1683, Val Loss: 0.1815\n",
      "Val RMSE: 102289.2149, Val MAE: 62840.6052, Val MSE: 10463083493.6397, Val R2: 0.4684\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1623, Val Loss: 0.1557\n",
      "Val RMSE: 96175.3555, Val MAE: 56951.5677, Val MSE: 9249698999.6409, Val R2: 0.5301\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1637\n",
      "Val RMSE: 97619.3920, Val MAE: 60241.2963, Val MSE: 9529545701.1684, Val R2: 0.5158\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1516, Val Loss: 0.1606\n",
      "Val RMSE: 98100.5591, Val MAE: 56647.2791, Val MSE: 9623719691.8783, Val R2: 0.5111\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1459, Val Loss: 0.1672\n",
      "Val RMSE: 101452.3297, Val MAE: 58516.8031, Val MSE: 10292575210.7665, Val R2: 0.4771\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1414, Val Loss: 0.1646\n",
      "Val RMSE: 99711.6854, Val MAE: 57541.2676, Val MSE: 9942420199.6887, Val R2: 0.4949\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1359, Val Loss: 0.1558\n",
      "Val RMSE: 96855.5602, Val MAE: 54579.7059, Val MSE: 9380999548.8944, Val R2: 0.5234\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1316, Val Loss: 0.1608\n",
      "Val RMSE: 97439.5220, Val MAE: 57100.8906, Val MSE: 9494460442.0825, Val R2: 0.5176\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1253, Val Loss: 0.1529\n",
      "Val RMSE: 96184.7438, Val MAE: 55049.1803, Val MSE: 9251504935.9930, Val R2: 0.5300\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1184, Val Loss: 0.1438\n",
      "Val RMSE: 92863.3185, Val MAE: 51342.2756, Val MSE: 8623595931.1752, Val R2: 0.5619\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1168, Val Loss: 0.1483\n",
      "Val RMSE: 93761.7012, Val MAE: 52823.8457, Val MSE: 8791256620.1514, Val R2: 0.5533\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1127, Val Loss: 0.1510\n",
      "Val RMSE: 93629.4322, Val MAE: 55076.6660, Val MSE: 8766470569.6078, Val R2: 0.5546\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1534\n",
      "Val RMSE: 95478.8599, Val MAE: 56213.9084, Val MSE: 9116212692.2144, Val R2: 0.5368\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1051, Val Loss: 0.1573\n",
      "Val RMSE: 95684.0478, Val MAE: 57194.2006, Val MSE: 9155437012.5597, Val R2: 0.5348\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1016, Val Loss: 0.1544\n",
      "Val RMSE: 96313.1472, Val MAE: 54589.9177, Val MSE: 9276222315.8390, Val R2: 0.5287\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0983, Val Loss: 0.1502\n",
      "Val RMSE: 94766.3716, Val MAE: 55328.2086, Val MSE: 8980665188.8516, Val R2: 0.5437\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0952, Val Loss: 0.1452\n",
      "Val RMSE: 93049.9302, Val MAE: 53071.0362, Val MSE: 8658289503.6101, Val R2: 0.5601\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0926, Val Loss: 0.1504\n",
      "Val RMSE: 94954.6466, Val MAE: 53578.4648, Val MSE: 9016384911.6935, Val R2: 0.5419\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0905, Val Loss: 0.1384\n",
      "Val RMSE: 89659.3967, Val MAE: 49995.9672, Val MSE: 8038807420.5681, Val R2: 0.5916\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0881, Val Loss: 0.1472\n",
      "Val RMSE: 92298.1131, Val MAE: 53188.3533, Val MSE: 8518941690.8963, Val R2: 0.5672\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1450\n",
      "Val RMSE: 92233.8489, Val MAE: 51701.8926, Val MSE: 8507082877.8604, Val R2: 0.5678\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1591\n",
      "Val RMSE: 95448.5568, Val MAE: 56069.4044, Val MSE: 9110426989.4012, Val R2: 0.5371\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0858, Val Loss: 0.1463\n",
      "Val RMSE: 92287.5876, Val MAE: 51301.8985, Val MSE: 8516998821.2621, Val R2: 0.5673\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1503\n",
      "Val RMSE: 91156.3642, Val MAE: 54143.2831, Val MSE: 8309482733.9838, Val R2: 0.5778\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1469\n",
      "Val RMSE: 91949.1109, Val MAE: 51715.6101, Val MSE: 8454638989.5783, Val R2: 0.5705\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1424\n",
      "Val RMSE: 87547.3670, Val MAE: 51487.1617, Val MSE: 7664541468.1064, Val R2: 0.6106\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0760, Val Loss: 0.1471\n",
      "Val RMSE: 88798.5721, Val MAE: 52087.2738, Val MSE: 7885186403.9651, Val R2: 0.5994\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.1615\n",
      "Val RMSE: 93724.9155, Val MAE: 56972.0537, Val MSE: 8784359786.4865, Val R2: 0.5537\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1393\n",
      "Val RMSE: 86560.4151, Val MAE: 50264.9135, Val MSE: 7492705461.3651, Val R2: 0.6193\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1470\n",
      "Val RMSE: 90046.8754, Val MAE: 50935.6006, Val MSE: 8108439764.4593, Val R2: 0.5880\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1467\n",
      "Val RMSE: 89537.1098, Val MAE: 51076.1263, Val MSE: 8016894027.9391, Val R2: 0.5927\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1524\n",
      "Val RMSE: 90823.5061, Val MAE: 53228.9685, Val MSE: 8248909263.8603, Val R2: 0.5809\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1364\n",
      "Val RMSE: 83061.2086, Val MAE: 48975.2450, Val MSE: 6899164378.6740, Val R2: 0.6495\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0702, Val Loss: 0.1296\n",
      "Val RMSE: 80782.7508, Val MAE: 47838.8112, Val MSE: 6525852828.2893, Val R2: 0.6684\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1394\n",
      "Val RMSE: 81156.5844, Val MAE: 48774.2850, Val MSE: 6586391193.7660, Val R2: 0.6654\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1504\n",
      "Val RMSE: 88488.4886, Val MAE: 52925.2792, Val MSE: 7830212613.5260, Val R2: 0.6022\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1385\n",
      "Val RMSE: 83333.6248, Val MAE: 49621.3079, Val MSE: 6944493015.6042, Val R2: 0.6472\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.1511\n",
      "Val RMSE: 88301.5284, Val MAE: 54370.1791, Val MSE: 7797159923.8548, Val R2: 0.6039\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1374\n",
      "Val RMSE: 84619.6779, Val MAE: 49130.3077, Val MSE: 7160489879.5989, Val R2: 0.6362\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1323\n",
      "Val RMSE: 81183.8701, Val MAE: 48915.4371, Val MSE: 6590820760.7912, Val R2: 0.6651\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1475\n",
      "Val RMSE: 86964.4637, Val MAE: 51590.6515, Val MSE: 7562817948.9442, Val R2: 0.6158\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1500\n",
      "Val RMSE: 84796.5597, Val MAE: 51314.5672, Val MSE: 7190456533.2728, Val R2: 0.6347\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1366\n",
      "Val RMSE: 82485.1464, Val MAE: 50604.5332, Val MSE: 6803799370.6197, Val R2: 0.6543\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1407\n",
      "Val RMSE: 88542.1509, Val MAE: 50001.2454, Val MSE: 7839712478.0495, Val R2: 0.6017\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1316\n",
      "Val RMSE: 79655.7886, Val MAE: 48088.9428, Val MSE: 6345044662.8877, Val R2: 0.6776\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1468\n",
      "Val RMSE: 86654.8954, Val MAE: 50550.4586, Val MSE: 7509070897.8601, Val R2: 0.6185\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1376\n",
      "Val RMSE: 83940.3868, Val MAE: 48965.8738, Val MSE: 7045988528.0443, Val R2: 0.6420\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1360\n",
      "Val RMSE: 81583.2491, Val MAE: 49074.2589, Val MSE: 6655826529.9682, Val R2: 0.6618\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1402\n",
      "Val RMSE: 85221.5021, Val MAE: 48790.4982, Val MSE: 7262704414.2521, Val R2: 0.6310\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1338\n",
      "Val RMSE: 82727.7002, Val MAE: 47265.8813, Val MSE: 6843872387.4351, Val R2: 0.6523\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1636\n",
      "Val RMSE: 90124.2659, Val MAE: 53816.1626, Val MSE: 8122383310.0902, Val R2: 0.5873\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1414\n",
      "Val RMSE: 86158.9334, Val MAE: 48995.4907, Val MSE: 7423361801.7582, Val R2: 0.6228\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1429\n",
      "Val RMSE: 87208.5275, Val MAE: 48840.5624, Val MSE: 7605327271.3619, Val R2: 0.6136\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1336\n",
      "Val RMSE: 82885.9785, Val MAE: 46486.4714, Val MSE: 6870085434.1944, Val R2: 0.6510\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1312\n",
      "Val RMSE: 82440.5623, Val MAE: 46068.5083, Val MSE: 6796446317.1967, Val R2: 0.6547\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1316\n",
      "Val RMSE: 82844.6508, Val MAE: 46633.0742, Val MSE: 6863236162.7799, Val R2: 0.6513\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1302\n",
      "Val RMSE: 82011.1189, Val MAE: 46125.1637, Val MSE: 6725823615.8152, Val R2: 0.6583\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1447\n",
      "Val RMSE: 83341.7719, Val MAE: 49415.0887, Val MSE: 6945850942.9119, Val R2: 0.6471\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1359\n",
      "Val RMSE: 83253.9493, Val MAE: 46462.1666, Val MSE: 6931220076.8337, Val R2: 0.6479\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1634\n",
      "Val RMSE: 87634.2510, Val MAE: 52264.5346, Val MSE: 7679761953.4339, Val R2: 0.6098\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.1403\n",
      "Val RMSE: 87652.1909, Val MAE: 47228.0783, Val MSE: 7682906566.4164, Val R2: 0.6097\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1307\n",
      "Val RMSE: 80940.5610, Val MAE: 46191.7809, Val MSE: 6551374415.5907, Val R2: 0.6671\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1157\n",
      "Val RMSE: 73665.7990, Val MAE: 44435.3870, Val MSE: 5426649944.7789, Val R2: 0.7243\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1351\n",
      "Val RMSE: 82881.1548, Val MAE: 46002.7572, Val MSE: 6869285818.7086, Val R2: 0.6510\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1339\n",
      "Val RMSE: 81953.6200, Val MAE: 45688.5201, Val MSE: 6716395837.1996, Val R2: 0.6588\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1355\n",
      "Val RMSE: 83110.1921, Val MAE: 47155.5170, Val MSE: 6907304028.0329, Val R2: 0.6491\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.1293\n",
      "Val RMSE: 81899.7677, Val MAE: 45045.7726, Val MSE: 6707571949.6900, Val R2: 0.6592\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1403\n",
      "Val RMSE: 84147.9647, Val MAE: 49809.4935, Val MSE: 7080879965.5160, Val R2: 0.6402\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1304\n",
      "Val RMSE: 80490.8370, Val MAE: 46674.0859, Val MSE: 6478774833.1313, Val R2: 0.6708\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.1357\n",
      "Val RMSE: 82667.2190, Val MAE: 45839.4994, Val MSE: 6833869089.7768, Val R2: 0.6528\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1336\n",
      "Val RMSE: 81899.5154, Val MAE: 46805.8587, Val MSE: 6707530629.8521, Val R2: 0.6592\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.1356\n",
      "Val RMSE: 84123.3638, Val MAE: 47454.6988, Val MSE: 7076740341.8886, Val R2: 0.6405\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1448\n",
      "Val RMSE: 84095.5600, Val MAE: 47331.2860, Val MSE: 7072063219.2295, Val R2: 0.6407\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 81238.0895, Test MAE: 46334.4315, Test MSE: 6599627181.8888, Test R2: 0.5770\n",
      "Inference Time: 2.0508656134972205e-05 seconds per sample\n",
      "\n",
      "Iteration 39 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3130, Val Loss: 0.2830\n",
      "Val RMSE: 144120.8435, Val MAE: 81171.4477, Val MSE: 20770817521.4011, Val R2: -0.0553\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2741, Val Loss: 0.2750\n",
      "Val RMSE: 140925.7601, Val MAE: 84347.4023, Val MSE: 19860069865.7385, Val R2: -0.0090\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2695, Val Loss: 0.2761\n",
      "Val RMSE: 141852.2523, Val MAE: 82943.3985, Val MSE: 20122061488.9145, Val R2: -0.0223\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2631, Val Loss: 0.2752\n",
      "Val RMSE: 142101.5284, Val MAE: 82446.1733, Val MSE: 20192844383.0797, Val R2: -0.0259\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2661, Val Loss: 0.2746\n",
      "Val RMSE: 142598.1721, Val MAE: 81033.5912, Val MSE: 20334238680.5576, Val R2: -0.0331\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2766\n",
      "Val RMSE: 142696.2577, Val MAE: 83154.9362, Val MSE: 20362221951.5428, Val R2: -0.0345\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2772\n",
      "Val RMSE: 141344.2442, Val MAE: 84829.1893, Val MSE: 19978195363.3904, Val R2: -0.0150\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2788\n",
      "Val RMSE: 141154.0830, Val MAE: 86532.3667, Val MSE: 19924475151.7940, Val R2: -0.0123\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2555, Val Loss: 0.2737\n",
      "Val RMSE: 141237.1094, Val MAE: 83125.6413, Val MSE: 19947921066.5807, Val R2: -0.0135\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2557, Val Loss: 0.2689\n",
      "Val RMSE: 141229.5224, Val MAE: 81007.7453, Val MSE: 19945778006.1748, Val R2: -0.0134\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2708\n",
      "Val RMSE: 142190.8402, Val MAE: 79249.9791, Val MSE: 20218235027.8300, Val R2: -0.0272\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2508, Val Loss: 0.2651\n",
      "Val RMSE: 140182.4958, Val MAE: 81841.6550, Val MSE: 19651132125.2059, Val R2: 0.0016\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2507, Val Loss: 0.2654\n",
      "Val RMSE: 139176.3244, Val MAE: 82163.2494, Val MSE: 19370049286.9868, Val R2: 0.0159\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2450, Val Loss: 0.2648\n",
      "Val RMSE: 139186.8845, Val MAE: 82564.6264, Val MSE: 19372988805.8701, Val R2: 0.0157\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2937\n",
      "Val RMSE: 146161.1824, Val MAE: 80205.2189, Val MSE: 21363091243.8595, Val R2: -0.0854\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2619\n",
      "Val RMSE: 141374.9448, Val MAE: 78236.3006, Val MSE: 19986875026.0412, Val R2: -0.0155\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2411, Val Loss: 0.2617\n",
      "Val RMSE: 139669.7590, Val MAE: 80390.5018, Val MSE: 19507641581.8407, Val R2: 0.0089\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2408, Val Loss: 0.2593\n",
      "Val RMSE: 138987.0745, Val MAE: 80420.5893, Val MSE: 19317406866.0183, Val R2: 0.0186\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2389, Val Loss: 0.2756\n",
      "Val RMSE: 139594.9936, Val MAE: 84981.1585, Val MSE: 19486762243.3742, Val R2: 0.0099\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2376, Val Loss: 0.2616\n",
      "Val RMSE: 141421.9203, Val MAE: 77307.6873, Val MSE: 20000159543.2888, Val R2: -0.0161\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2403, Val Loss: 0.2591\n",
      "Val RMSE: 140410.1039, Val MAE: 78165.8035, Val MSE: 19714997282.2102, Val R2: -0.0016\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2376, Val Loss: 0.2589\n",
      "Val RMSE: 139351.5503, Val MAE: 79430.3904, Val MSE: 19418854584.6096, Val R2: 0.0134\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2353, Val Loss: 0.2590\n",
      "Val RMSE: 140986.6071, Val MAE: 77345.8723, Val MSE: 19877223374.4108, Val R2: -0.0099\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2386, Val Loss: 0.2669\n",
      "Val RMSE: 142020.4494, Val MAE: 77928.4447, Val MSE: 20169808057.2880, Val R2: -0.0248\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2397, Val Loss: 0.2572\n",
      "Val RMSE: 138558.8780, Val MAE: 79673.9424, Val MSE: 19198562672.2907, Val R2: 0.0246\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2383, Val Loss: 0.2734\n",
      "Val RMSE: 138295.8085, Val MAE: 84748.2780, Val MSE: 19125730647.4819, Val R2: 0.0283\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2256, Val Loss: 0.2348\n",
      "Val RMSE: 133015.2997, Val MAE: 72280.6111, Val MSE: 17693069950.4378, Val R2: 0.1011\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2105, Val Loss: 0.2305\n",
      "Val RMSE: 133351.2000, Val MAE: 69735.5003, Val MSE: 17782542543.0353, Val R2: 0.0965\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2064, Val Loss: 0.2272\n",
      "Val RMSE: 130524.6046, Val MAE: 69898.1630, Val MSE: 17036672418.8564, Val R2: 0.1344\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2009, Val Loss: 0.2388\n",
      "Val RMSE: 134000.5874, Val MAE: 74218.0955, Val MSE: 17956157421.7476, Val R2: 0.0877\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1998, Val Loss: 0.2260\n",
      "Val RMSE: 130879.2187, Val MAE: 70850.4273, Val MSE: 17129369889.6718, Val R2: 0.1297\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1985, Val Loss: 0.2296\n",
      "Val RMSE: 130114.1703, Val MAE: 72606.2873, Val MSE: 16929697308.8415, Val R2: 0.1399\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1949, Val Loss: 0.2234\n",
      "Val RMSE: 128987.7033, Val MAE: 70489.7238, Val MSE: 16637827600.0422, Val R2: 0.1547\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1919, Val Loss: 0.2202\n",
      "Val RMSE: 127751.3766, Val MAE: 69903.5162, Val MSE: 16320414212.4901, Val R2: 0.1708\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1854, Val Loss: 0.2441\n",
      "Val RMSE: 125966.7665, Val MAE: 70955.5401, Val MSE: 15867626258.1937, Val R2: 0.1938\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.2038, Val Loss: 0.2201\n",
      "Val RMSE: 126398.3487, Val MAE: 69269.8817, Val MSE: 15976542553.2538, Val R2: 0.1883\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1838, Val Loss: 0.2002\n",
      "Val RMSE: 111512.5924, Val MAE: 65582.4506, Val MSE: 12435058257.1287, Val R2: 0.3682\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.1822\n",
      "Val RMSE: 104324.1296, Val MAE: 62936.0133, Val MSE: 10883524018.3734, Val R2: 0.4470\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1664, Val Loss: 0.1766\n",
      "Val RMSE: 103409.0819, Val MAE: 61400.4614, Val MSE: 10693438210.6908, Val R2: 0.4567\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1640, Val Loss: 0.1693\n",
      "Val RMSE: 102142.1614, Val MAE: 59268.4629, Val MSE: 10433021137.1106, Val R2: 0.4699\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1569, Val Loss: 0.1756\n",
      "Val RMSE: 103362.6394, Val MAE: 57970.1484, Val MSE: 10683835222.0750, Val R2: 0.4572\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1545, Val Loss: 0.1600\n",
      "Val RMSE: 97587.3442, Val MAE: 58305.1803, Val MSE: 9523289752.2769, Val R2: 0.5162\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1476, Val Loss: 0.1552\n",
      "Val RMSE: 96256.9365, Val MAE: 57086.4734, Val MSE: 9265397833.9074, Val R2: 0.5293\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1457, Val Loss: 0.1655\n",
      "Val RMSE: 99593.7785, Val MAE: 56563.6343, Val MSE: 9918920723.4945, Val R2: 0.4961\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1439, Val Loss: 0.1636\n",
      "Val RMSE: 98246.4246, Val MAE: 56115.6455, Val MSE: 9652359938.9259, Val R2: 0.5096\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1423, Val Loss: 0.1489\n",
      "Val RMSE: 94644.6694, Val MAE: 53723.3591, Val MSE: 8957613444.4242, Val R2: 0.5449\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1434\n",
      "Val RMSE: 91517.5506, Val MAE: 53099.4902, Val MSE: 8375462065.9828, Val R2: 0.5745\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1256, Val Loss: 0.1540\n",
      "Val RMSE: 94529.0685, Val MAE: 53246.9300, Val MSE: 8935744792.1097, Val R2: 0.5460\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1195, Val Loss: 0.1526\n",
      "Val RMSE: 93414.8669, Val MAE: 54142.3495, Val MSE: 8726337349.4298, Val R2: 0.5566\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1120, Val Loss: 0.1283\n",
      "Val RMSE: 86736.8853, Val MAE: 48411.2536, Val MSE: 7523287272.7198, Val R2: 0.6178\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1081, Val Loss: 0.1420\n",
      "Val RMSE: 91501.4168, Val MAE: 50757.1685, Val MSE: 8372509271.5811, Val R2: 0.5746\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1547\n",
      "Val RMSE: 93810.2581, Val MAE: 53954.6912, Val MSE: 8800364530.5367, Val R2: 0.5529\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1376\n",
      "Val RMSE: 89616.8553, Val MAE: 51140.2028, Val MSE: 8031180755.4359, Val R2: 0.5920\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0958, Val Loss: 0.1342\n",
      "Val RMSE: 88177.8452, Val MAE: 49308.5254, Val MSE: 7775332377.1209, Val R2: 0.6050\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1263\n",
      "Val RMSE: 84510.0548, Val MAE: 47367.4951, Val MSE: 7141949359.6659, Val R2: 0.6371\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1603\n",
      "Val RMSE: 93618.4659, Val MAE: 55172.5897, Val MSE: 8764417160.4515, Val R2: 0.5547\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1420\n",
      "Val RMSE: 88263.6355, Val MAE: 51587.0768, Val MSE: 7790469358.0337, Val R2: 0.6042\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1456\n",
      "Val RMSE: 89501.9100, Val MAE: 50439.8953, Val MSE: 8010591900.7203, Val R2: 0.5930\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1364\n",
      "Val RMSE: 85199.0682, Val MAE: 51541.9913, Val MSE: 7258881220.1983, Val R2: 0.6312\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1347\n",
      "Val RMSE: 83949.8405, Val MAE: 48896.5537, Val MSE: 7047575715.4554, Val R2: 0.6419\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1478\n",
      "Val RMSE: 88569.9045, Val MAE: 53315.9820, Val MSE: 7844627978.6155, Val R2: 0.6014\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1562\n",
      "Val RMSE: 98875.9613, Val MAE: 51665.5863, Val MSE: 9776455720.5620, Val R2: 0.5033\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1485\n",
      "Val RMSE: 92901.7137, Val MAE: 49074.2872, Val MSE: 8630728414.1201, Val R2: 0.5615\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0763, Val Loss: 0.1430\n",
      "Val RMSE: 85616.3290, Val MAE: 49118.6092, Val MSE: 7330155787.5898, Val R2: 0.6276\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1433\n",
      "Val RMSE: 89865.6972, Val MAE: 49437.1015, Val MSE: 8075843535.2623, Val R2: 0.5897\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1347\n",
      "Val RMSE: 84530.1099, Val MAE: 48539.5985, Val MSE: 7145339477.3756, Val R2: 0.6370\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0702, Val Loss: 0.1311\n",
      "Val RMSE: 82493.0995, Val MAE: 47452.3189, Val MSE: 6805111460.4098, Val R2: 0.6543\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1318\n",
      "Val RMSE: 81449.5472, Val MAE: 47492.4325, Val MSE: 6634028740.3368, Val R2: 0.6629\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1311\n",
      "Val RMSE: 81432.5977, Val MAE: 48264.2969, Val MSE: 6631267963.5422, Val R2: 0.6631\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1205\n",
      "Val RMSE: 77808.8781, Val MAE: 46641.5185, Val MSE: 6054221510.4364, Val R2: 0.6924\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1277\n",
      "Val RMSE: 78488.5197, Val MAE: 45720.5416, Val MSE: 6160447721.4281, Val R2: 0.6870\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1211\n",
      "Val RMSE: 76851.4134, Val MAE: 47528.4749, Val MSE: 5906139741.7232, Val R2: 0.6999\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1373\n",
      "Val RMSE: 85418.3916, Val MAE: 50782.4094, Val MSE: 7296301631.1412, Val R2: 0.6293\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0611, Val Loss: 0.1297\n",
      "Val RMSE: 82270.8402, Val MAE: 45643.4176, Val MSE: 6768491144.0749, Val R2: 0.6561\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1310\n",
      "Val RMSE: 81953.3246, Val MAE: 44891.6333, Val MSE: 6716347416.5361, Val R2: 0.6588\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1279\n",
      "Val RMSE: 79437.0589, Val MAE: 45152.5268, Val MSE: 6310246324.8020, Val R2: 0.6794\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1366\n",
      "Val RMSE: 83078.2050, Val MAE: 48993.0068, Val MSE: 6901988149.2365, Val R2: 0.6493\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1353\n",
      "Val RMSE: 81156.2607, Val MAE: 52292.0349, Val MSE: 6586338643.2586, Val R2: 0.6654\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1279\n",
      "Val RMSE: 83677.0937, Val MAE: 46480.4793, Val MSE: 7001856004.0213, Val R2: 0.6443\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1367\n",
      "Val RMSE: 86614.4882, Val MAE: 48517.3754, Val MSE: 7502069558.5899, Val R2: 0.6188\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1256\n",
      "Val RMSE: 80644.8095, Val MAE: 45475.6808, Val MSE: 6503585305.8324, Val R2: 0.6696\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1200\n",
      "Val RMSE: 77211.0297, Val MAE: 45139.4283, Val MSE: 5961543112.8203, Val R2: 0.6971\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1268\n",
      "Val RMSE: 80347.1605, Val MAE: 46685.6484, Val MSE: 6455666194.2083, Val R2: 0.6720\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1262\n",
      "Val RMSE: 81808.6331, Val MAE: 45473.9266, Val MSE: 6692652457.7130, Val R2: 0.6600\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1292\n",
      "Val RMSE: 78909.4444, Val MAE: 44431.8990, Val MSE: 6226700417.3314, Val R2: 0.6836\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1321\n",
      "Val RMSE: 82203.3934, Val MAE: 45593.9109, Val MSE: 6757397887.6866, Val R2: 0.6567\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1231\n",
      "Val RMSE: 79490.8362, Val MAE: 45350.0999, Val MSE: 6318793036.4378, Val R2: 0.6790\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1371\n",
      "Val RMSE: 85829.9990, Val MAE: 45204.7272, Val MSE: 7366788730.2604, Val R2: 0.6257\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1296\n",
      "Val RMSE: 79732.0323, Val MAE: 44707.3971, Val MSE: 6357196974.6337, Val R2: 0.6770\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1343\n",
      "Val RMSE: 81105.0492, Val MAE: 49927.5892, Val MSE: 6578029012.0313, Val R2: 0.6658\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1283\n",
      "Val RMSE: 77978.3881, Val MAE: 47635.5228, Val MSE: 6080629007.6012, Val R2: 0.6911\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1222\n",
      "Val RMSE: 78060.3869, Val MAE: 43231.5912, Val MSE: 6093424004.1067, Val R2: 0.6904\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1196\n",
      "Val RMSE: 74379.3873, Val MAE: 42829.2946, Val MSE: 5532293255.0188, Val R2: 0.7189\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1300\n",
      "Val RMSE: 79104.0981, Val MAE: 44462.3787, Val MSE: 6257458339.7879, Val R2: 0.6821\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1237\n",
      "Val RMSE: 77641.2533, Val MAE: 46632.5809, Val MSE: 6028164218.9146, Val R2: 0.6937\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1135\n",
      "Val RMSE: 73272.5857, Val MAE: 43571.6139, Val MSE: 5368871818.4628, Val R2: 0.7272\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1254\n",
      "Val RMSE: 76855.4335, Val MAE: 44252.8952, Val MSE: 5906757655.2061, Val R2: 0.6999\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1147\n",
      "Val RMSE: 72023.5181, Val MAE: 42509.1185, Val MSE: 5187387153.8325, Val R2: 0.7364\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1156\n",
      "Val RMSE: 76455.9989, Val MAE: 43077.4515, Val MSE: 5845519767.8028, Val R2: 0.7030\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1291\n",
      "Val RMSE: 80170.9031, Val MAE: 44772.0619, Val MSE: 6427373696.3307, Val R2: 0.6734\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 85276.4996, Test MAE: 48063.0678, Test MSE: 7272081386.5550, Test R2: 0.5339\n",
      "Inference Time: 2.1716154538668117e-05 seconds per sample\n",
      "\n",
      "Iteration 40 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3930, Val Loss: 0.3082\n",
      "Val RMSE: 148316.2178, Val MAE: 82634.6058, Val MSE: 21997700465.2658, Val R2: -0.1176\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2835, Val Loss: 0.2900\n",
      "Val RMSE: 143829.9229, Val MAE: 83970.3665, Val MSE: 20687046734.6340, Val R2: -0.0510\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2801, Val Loss: 0.2848\n",
      "Val RMSE: 142329.2498, Val MAE: 85211.5140, Val MSE: 20257615360.6413, Val R2: -0.0292\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2772\n",
      "Val RMSE: 142221.1954, Val MAE: 82731.5896, Val MSE: 20226868434.3842, Val R2: -0.0277\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2671, Val Loss: 0.2747\n",
      "Val RMSE: 140867.4797, Val MAE: 85475.0139, Val MSE: 19843646840.9830, Val R2: -0.0082\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2641, Val Loss: 0.2785\n",
      "Val RMSE: 141860.9235, Val MAE: 85555.6634, Val MSE: 20124521616.3109, Val R2: -0.0225\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2637, Val Loss: 0.2818\n",
      "Val RMSE: 142120.2643, Val MAE: 86662.6517, Val MSE: 20198169528.2602, Val R2: -0.0262\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2782\n",
      "Val RMSE: 142188.6788, Val MAE: 82001.4807, Val MSE: 20217620390.2538, Val R2: -0.0272\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2831\n",
      "Val RMSE: 143705.3822, Val MAE: 84487.7640, Val MSE: 20651236873.0323, Val R2: -0.0492\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2773\n",
      "Val RMSE: 141315.6367, Val MAE: 85027.9060, Val MSE: 19970109171.7920, Val R2: -0.0146\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2735\n",
      "Val RMSE: 142407.8186, Val MAE: 82526.3257, Val MSE: 20279986794.7215, Val R2: -0.0304\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2752\n",
      "Val RMSE: 142582.2643, Val MAE: 76882.2125, Val MSE: 20329702105.3372, Val R2: -0.0329\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2477, Val Loss: 0.2556\n",
      "Val RMSE: 135906.7090, Val MAE: 80582.9593, Val MSE: 18470633554.9459, Val R2: 0.0616\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2466, Val Loss: 0.2542\n",
      "Val RMSE: 136968.1136, Val MAE: 76460.7193, Val MSE: 18760264140.2188, Val R2: 0.0469\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2395, Val Loss: 0.2484\n",
      "Val RMSE: 134603.0850, Val MAE: 75068.5113, Val MSE: 18117990498.9854, Val R2: 0.0795\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2313, Val Loss: 0.2487\n",
      "Val RMSE: 133037.0481, Val MAE: 79044.0638, Val MSE: 17698856163.6158, Val R2: 0.1008\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2247, Val Loss: 0.2355\n",
      "Val RMSE: 131946.8862, Val MAE: 72798.4988, Val MSE: 17409980780.8418, Val R2: 0.1155\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2209, Val Loss: 0.2273\n",
      "Val RMSE: 130219.7414, Val MAE: 69859.4650, Val MSE: 16957181059.4842, Val R2: 0.1385\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2409\n",
      "Val RMSE: 128634.2897, Val MAE: 79246.9903, Val MSE: 16546780486.2241, Val R2: 0.1593\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2106, Val Loss: 0.2316\n",
      "Val RMSE: 130121.4782, Val MAE: 71429.9794, Val MSE: 16931599093.2772, Val R2: 0.1398\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2037, Val Loss: 0.2417\n",
      "Val RMSE: 131246.8467, Val MAE: 76609.7029, Val MSE: 17225734778.7189, Val R2: 0.1248\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2030, Val Loss: 0.2273\n",
      "Val RMSE: 127458.7927, Val MAE: 74021.9905, Val MSE: 16245743842.0538, Val R2: 0.1746\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2069, Val Loss: 0.2264\n",
      "Val RMSE: 129340.6289, Val MAE: 71327.4425, Val MSE: 16728998285.2632, Val R2: 0.1501\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1988, Val Loss: 0.2285\n",
      "Val RMSE: 128028.6297, Val MAE: 73471.6338, Val MSE: 16391330023.2970, Val R2: 0.1672\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1980, Val Loss: 0.2230\n",
      "Val RMSE: 127274.0054, Val MAE: 70625.3263, Val MSE: 16198672462.2680, Val R2: 0.1770\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1946, Val Loss: 0.2056\n",
      "Val RMSE: 117323.9778, Val MAE: 68452.8768, Val MSE: 13764915778.5038, Val R2: 0.3007\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1972, Val Loss: 0.2140\n",
      "Val RMSE: 118443.0236, Val MAE: 70365.2002, Val MSE: 14028749842.7792, Val R2: 0.2873\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1852, Val Loss: 0.2147\n",
      "Val RMSE: 117652.6647, Val MAE: 69132.3903, Val MSE: 13842149502.8798, Val R2: 0.2967\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1789, Val Loss: 0.1917\n",
      "Val RMSE: 107729.3524, Val MAE: 66544.2857, Val MSE: 11605613377.5673, Val R2: 0.4104\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1751, Val Loss: 0.1872\n",
      "Val RMSE: 106402.8506, Val MAE: 62991.6082, Val MSE: 11321566613.3418, Val R2: 0.4248\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1704, Val Loss: 0.1976\n",
      "Val RMSE: 107712.1135, Val MAE: 64188.6109, Val MSE: 11601899385.1585, Val R2: 0.4106\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1636, Val Loss: 0.1997\n",
      "Val RMSE: 107353.4535, Val MAE: 63747.8897, Val MSE: 11524763973.5377, Val R2: 0.4145\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1681, Val Loss: 0.1807\n",
      "Val RMSE: 105861.8867, Val MAE: 60922.4829, Val MSE: 11206739059.7362, Val R2: 0.4306\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1582, Val Loss: 0.1633\n",
      "Val RMSE: 100428.0748, Val MAE: 56211.2690, Val MSE: 10085798207.3507, Val R2: 0.4876\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1531, Val Loss: 0.1608\n",
      "Val RMSE: 97961.3728, Val MAE: 57201.1480, Val MSE: 9596430560.5594, Val R2: 0.5124\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1515, Val Loss: 0.1631\n",
      "Val RMSE: 99377.5657, Val MAE: 58448.1734, Val MSE: 9875900566.9730, Val R2: 0.4982\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1502, Val Loss: 0.1570\n",
      "Val RMSE: 97115.7243, Val MAE: 56841.8366, Val MSE: 9431463898.0225, Val R2: 0.5208\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1485, Val Loss: 0.1580\n",
      "Val RMSE: 96289.8594, Val MAE: 58463.2793, Val MSE: 9271737013.8240, Val R2: 0.5289\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1447, Val Loss: 0.1645\n",
      "Val RMSE: 100922.6683, Val MAE: 58216.4076, Val MSE: 10185384978.6484, Val R2: 0.4825\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1402, Val Loss: 0.1485\n",
      "Val RMSE: 95085.0756, Val MAE: 53860.9432, Val MSE: 9041171601.4750, Val R2: 0.5407\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1353, Val Loss: 0.1525\n",
      "Val RMSE: 95243.5747, Val MAE: 54336.0726, Val MSE: 9071338518.1240, Val R2: 0.5391\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1351, Val Loss: 0.1564\n",
      "Val RMSE: 97549.7584, Val MAE: 54529.8145, Val MSE: 9515955360.6438, Val R2: 0.5165\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1293, Val Loss: 0.1491\n",
      "Val RMSE: 94469.8525, Val MAE: 50655.9607, Val MSE: 8924553028.3829, Val R2: 0.5466\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1222, Val Loss: 0.1423\n",
      "Val RMSE: 94046.4148, Val MAE: 51028.6917, Val MSE: 8844728136.0192, Val R2: 0.5506\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1293\n",
      "Val RMSE: 91265.8791, Val MAE: 47491.4865, Val MSE: 8329460687.4482, Val R2: 0.5768\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1088, Val Loss: 0.1372\n",
      "Val RMSE: 91720.4046, Val MAE: 49555.5855, Val MSE: 8412632619.9307, Val R2: 0.5726\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1363\n",
      "Val RMSE: 92258.5581, Val MAE: 48849.2170, Val MSE: 8511641545.8956, Val R2: 0.5676\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1047, Val Loss: 0.1491\n",
      "Val RMSE: 92415.3116, Val MAE: 56390.0692, Val MSE: 8540589810.7473, Val R2: 0.5661\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1000, Val Loss: 0.1315\n",
      "Val RMSE: 91213.3103, Val MAE: 47457.2889, Val MSE: 8319867979.2045, Val R2: 0.5773\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1289\n",
      "Val RMSE: 90337.5853, Val MAE: 47926.8296, Val MSE: 8160879319.9990, Val R2: 0.5854\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1251\n",
      "Val RMSE: 88054.0439, Val MAE: 45515.5327, Val MSE: 7753514641.2395, Val R2: 0.6061\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1401\n",
      "Val RMSE: 91023.8698, Val MAE: 47994.5263, Val MSE: 8285344873.3849, Val R2: 0.5791\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1365\n",
      "Val RMSE: 89821.4601, Val MAE: 50613.3526, Val MSE: 8067894692.1539, Val R2: 0.5901\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0861, Val Loss: 0.1304\n",
      "Val RMSE: 88874.1283, Val MAE: 47399.5395, Val MSE: 7898610687.6052, Val R2: 0.5987\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1509\n",
      "Val RMSE: 92523.6198, Val MAE: 49225.3999, Val MSE: 8560620217.5331, Val R2: 0.5651\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1285\n",
      "Val RMSE: 86990.1558, Val MAE: 47569.0985, Val MSE: 7567287202.9597, Val R2: 0.6155\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1311\n",
      "Val RMSE: 88523.4243, Val MAE: 47457.6699, Val MSE: 7836396648.6211, Val R2: 0.6019\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1274\n",
      "Val RMSE: 85026.9260, Val MAE: 46472.6473, Val MSE: 7229578150.4490, Val R2: 0.6327\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1190\n",
      "Val RMSE: 83639.0436, Val MAE: 47176.6318, Val MSE: 6995489610.9739, Val R2: 0.6446\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0773, Val Loss: 0.1152\n",
      "Val RMSE: 80821.7172, Val MAE: 45247.0730, Val MSE: 6532149963.2314, Val R2: 0.6681\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1198\n",
      "Val RMSE: 82064.9139, Val MAE: 45509.1119, Val MSE: 6734650093.7684, Val R2: 0.6578\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1219\n",
      "Val RMSE: 84428.2818, Val MAE: 43922.9385, Val MSE: 7128134767.2401, Val R2: 0.6378\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1253\n",
      "Val RMSE: 84771.9340, Val MAE: 43256.3157, Val MSE: 7186280795.9264, Val R2: 0.6349\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0718, Val Loss: 0.1178\n",
      "Val RMSE: 79119.1445, Val MAE: 43305.7584, Val MSE: 6259839031.2525, Val R2: 0.6820\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1392\n",
      "Val RMSE: 88314.1553, Val MAE: 46805.8759, Val MSE: 7799390023.2984, Val R2: 0.6037\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1237\n",
      "Val RMSE: 81194.0126, Val MAE: 42296.2107, Val MSE: 6592467684.3136, Val R2: 0.6651\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1097\n",
      "Val RMSE: 77083.7174, Val MAE: 40460.2699, Val MSE: 5941899487.7297, Val R2: 0.6981\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1098\n",
      "Val RMSE: 75536.9172, Val MAE: 42291.0187, Val MSE: 5705825865.3738, Val R2: 0.7101\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1230\n",
      "Val RMSE: 82893.8587, Val MAE: 43020.7925, Val MSE: 6871391815.7436, Val R2: 0.6509\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1067\n",
      "Val RMSE: 75606.3266, Val MAE: 42265.6366, Val MSE: 5716316623.9342, Val R2: 0.7096\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1092\n",
      "Val RMSE: 75692.4049, Val MAE: 43280.2390, Val MSE: 5729340154.9788, Val R2: 0.7089\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1182\n",
      "Val RMSE: 79951.2946, Val MAE: 43321.5865, Val MSE: 6392209500.8855, Val R2: 0.6752\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.0995\n",
      "Val RMSE: 70505.5575, Val MAE: 40904.7130, Val MSE: 4971033640.4114, Val R2: 0.7474\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0590, Val Loss: 0.1218\n",
      "Val RMSE: 77205.6552, Val MAE: 42789.3002, Val MSE: 5960713198.8082, Val R2: 0.6972\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1295\n",
      "Val RMSE: 85974.6052, Val MAE: 45706.7734, Val MSE: 7391632741.9401, Val R2: 0.6245\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1117\n",
      "Val RMSE: 76004.0025, Val MAE: 39617.9111, Val MSE: 5776608389.8656, Val R2: 0.7065\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1135\n",
      "Val RMSE: 73037.0811, Val MAE: 40602.6399, Val MSE: 5334415213.6453, Val R2: 0.7290\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1059\n",
      "Val RMSE: 70864.5625, Val MAE: 40126.8183, Val MSE: 5021786224.8421, Val R2: 0.7449\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1107\n",
      "Val RMSE: 75793.8480, Val MAE: 40655.1535, Val MSE: 5744707388.0205, Val R2: 0.7081\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.0912\n",
      "Val RMSE: 66922.6667, Val MAE: 37055.6747, Val MSE: 4478643320.3853, Val R2: 0.7725\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.0998\n",
      "Val RMSE: 69172.3579, Val MAE: 37545.4706, Val MSE: 4784815094.6003, Val R2: 0.7569\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1092\n",
      "Val RMSE: 72699.7046, Val MAE: 40711.2558, Val MSE: 5285247047.7831, Val R2: 0.7315\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1120\n",
      "Val RMSE: 74744.2708, Val MAE: 39803.2423, Val MSE: 5586706013.7668, Val R2: 0.7162\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1036\n",
      "Val RMSE: 70769.2768, Val MAE: 39074.4601, Val MSE: 5008290533.4915, Val R2: 0.7455\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1079\n",
      "Val RMSE: 72484.7173, Val MAE: 38768.8536, Val MSE: 5254034241.0518, Val R2: 0.7331\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1086\n",
      "Val RMSE: 70325.4337, Val MAE: 39658.6692, Val MSE: 4945666630.9013, Val R2: 0.7487\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1235\n",
      "Val RMSE: 77480.1349, Val MAE: 42085.1317, Val MSE: 6003171301.8825, Val R2: 0.6950\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1085\n",
      "Val RMSE: 71368.0179, Val MAE: 39346.9076, Val MSE: 5093393976.2702, Val R2: 0.7412\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1181\n",
      "Val RMSE: 73825.3773, Val MAE: 41388.0529, Val MSE: 5450186338.7878, Val R2: 0.7231\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1181\n",
      "Val RMSE: 77201.4609, Val MAE: 41169.7215, Val MSE: 5960065570.7789, Val R2: 0.6972\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1076\n",
      "Val RMSE: 74109.5398, Val MAE: 38153.9344, Val MSE: 5492223883.8372, Val R2: 0.7210\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1125\n",
      "Val RMSE: 76614.7629, Val MAE: 40909.7637, Val MSE: 5869821899.8372, Val R2: 0.7018\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1154\n",
      "Val RMSE: 75750.5875, Val MAE: 41207.5885, Val MSE: 5738151510.4973, Val R2: 0.7085\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1082\n",
      "Val RMSE: 75906.0158, Val MAE: 39961.3965, Val MSE: 5761723227.1136, Val R2: 0.7073\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1121\n",
      "Val RMSE: 76865.5210, Val MAE: 40514.9758, Val MSE: 5908308315.9980, Val R2: 0.6998\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1110\n",
      "Val RMSE: 74920.5295, Val MAE: 40763.5821, Val MSE: 5613085738.5695, Val R2: 0.7148\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.0907\n",
      "Val RMSE: 66615.9759, Val MAE: 35803.4712, Val MSE: 4437688241.8062, Val R2: 0.7745\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1085\n",
      "Val RMSE: 76266.5516, Val MAE: 39663.8945, Val MSE: 5816586891.5735, Val R2: 0.7045\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1111\n",
      "Val RMSE: 74793.3854, Val MAE: 41436.8220, Val MSE: 5594050500.9609, Val R2: 0.7158\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1058\n",
      "Val RMSE: 72228.5922, Val MAE: 40340.2025, Val MSE: 5216969524.8959, Val R2: 0.7349\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 80076.4514, Test MAE: 38110.3439, Test MSE: 6412238065.3418, Test R2: 0.5890\n",
      "Inference Time: 1.8632045158973106e-05 seconds per sample\n",
      "\n",
      "Iteration 41 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3533, Val Loss: 0.2811\n",
      "Val RMSE: 143715.6509, Val MAE: 81479.7214, Val MSE: 20654188315.4384, Val R2: -0.0494\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2755\n",
      "Val RMSE: 141484.1431, Val MAE: 83603.8708, Val MSE: 20017762759.3808, Val R2: -0.0170\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2697, Val Loss: 0.2781\n",
      "Val RMSE: 142701.8346, Val MAE: 82035.7249, Val MSE: 20363813585.6708, Val R2: -0.0346\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2751\n",
      "Val RMSE: 141174.3012, Val MAE: 84098.8368, Val MSE: 19930183329.8946, Val R2: -0.0126\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2664, Val Loss: 0.2752\n",
      "Val RMSE: 141388.6435, Val MAE: 83996.7005, Val MSE: 19990748512.2748, Val R2: -0.0157\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2656, Val Loss: 0.2746\n",
      "Val RMSE: 140895.4467, Val MAE: 84842.7595, Val MSE: 19851526913.5101, Val R2: -0.0086\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2624, Val Loss: 0.2766\n",
      "Val RMSE: 142056.0829, Val MAE: 82432.4253, Val MSE: 20179930685.9609, Val R2: -0.0253\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2868\n",
      "Val RMSE: 144519.0912, Val MAE: 80845.4890, Val MSE: 20885767710.6288, Val R2: -0.0611\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2706\n",
      "Val RMSE: 141811.6669, Val MAE: 81308.8458, Val MSE: 20110548880.9580, Val R2: -0.0217\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2682\n",
      "Val RMSE: 140239.2975, Val MAE: 83402.0093, Val MSE: 19667060571.1258, Val R2: 0.0008\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2553, Val Loss: 0.2780\n",
      "Val RMSE: 142115.8884, Val MAE: 84235.1349, Val MSE: 20196925748.5852, Val R2: -0.0261\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2677\n",
      "Val RMSE: 140211.6039, Val MAE: 82589.6086, Val MSE: 19659293854.6192, Val R2: 0.0012\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2510, Val Loss: 0.2804\n",
      "Val RMSE: 142662.2384, Val MAE: 83826.4032, Val MSE: 20352514268.6629, Val R2: -0.0340\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2673\n",
      "Val RMSE: 140889.5894, Val MAE: 79805.1275, Val MSE: 19849876395.3534, Val R2: -0.0085\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2633\n",
      "Val RMSE: 140764.9492, Val MAE: 79075.4720, Val MSE: 19814770929.2533, Val R2: -0.0067\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2428, Val Loss: 0.2532\n",
      "Val RMSE: 136688.2103, Val MAE: 77566.2634, Val MSE: 18683666837.0426, Val R2: 0.0508\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2337, Val Loss: 0.2511\n",
      "Val RMSE: 132585.5324, Val MAE: 77501.4520, Val MSE: 17578923415.0249, Val R2: 0.1069\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2220, Val Loss: 0.2331\n",
      "Val RMSE: 129622.6396, Val MAE: 76931.5080, Val MSE: 16802028686.3220, Val R2: 0.1464\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2186, Val Loss: 0.2343\n",
      "Val RMSE: 131991.8842, Val MAE: 72413.8437, Val MSE: 17421857499.4238, Val R2: 0.1149\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2129, Val Loss: 0.2270\n",
      "Val RMSE: 129901.3831, Val MAE: 71276.4593, Val MSE: 16874369338.6121, Val R2: 0.1427\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2102, Val Loss: 0.2235\n",
      "Val RMSE: 128364.0090, Val MAE: 71351.6847, Val MSE: 16477318809.8993, Val R2: 0.1628\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2146, Val Loss: 0.2365\n",
      "Val RMSE: 130616.6506, Val MAE: 76444.7247, Val MSE: 17060709414.9721, Val R2: 0.1332\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2086, Val Loss: 0.2269\n",
      "Val RMSE: 129710.4987, Val MAE: 72048.3590, Val MSE: 16824813469.5073, Val R2: 0.1452\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2052, Val Loss: 0.2215\n",
      "Val RMSE: 128057.0066, Val MAE: 69686.1678, Val MSE: 16398596942.0324, Val R2: 0.1668\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2066, Val Loss: 0.2440\n",
      "Val RMSE: 135578.5747, Val MAE: 74034.6881, Val MSE: 18381549917.4468, Val R2: 0.0661\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2087, Val Loss: 0.2211\n",
      "Val RMSE: 126391.3049, Val MAE: 70545.1751, Val MSE: 15974761950.8647, Val R2: 0.1884\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2018, Val Loss: 0.2355\n",
      "Val RMSE: 129114.5684, Val MAE: 71779.2678, Val MSE: 16670571783.4702, Val R2: 0.1530\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2222\n",
      "Val RMSE: 123728.2481, Val MAE: 68942.0547, Val MSE: 15308679376.3595, Val R2: 0.2222\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1982, Val Loss: 0.2315\n",
      "Val RMSE: 125069.4960, Val MAE: 70942.6834, Val MSE: 15642378836.1340, Val R2: 0.2053\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1872, Val Loss: 0.1951\n",
      "Val RMSE: 109637.6243, Val MAE: 63470.5577, Val MSE: 12020408671.3875, Val R2: 0.3893\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1800, Val Loss: 0.1862\n",
      "Val RMSE: 104811.8312, Val MAE: 62002.0981, Val MSE: 10985519960.1812, Val R2: 0.4419\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1742, Val Loss: 0.1844\n",
      "Val RMSE: 102984.3749, Val MAE: 62442.8544, Val MSE: 10605781463.3716, Val R2: 0.4612\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1737, Val Loss: 0.1798\n",
      "Val RMSE: 102577.9973, Val MAE: 62598.8252, Val MSE: 10522245530.1483, Val R2: 0.4654\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1681, Val Loss: 0.1653\n",
      "Val RMSE: 99888.9352, Val MAE: 58532.5764, Val MSE: 9977799376.4159, Val R2: 0.4931\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1655, Val Loss: 0.1742\n",
      "Val RMSE: 103731.7146, Val MAE: 58981.2864, Val MSE: 10760268609.5376, Val R2: 0.4533\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1630, Val Loss: 0.1823\n",
      "Val RMSE: 103984.2388, Val MAE: 60536.3950, Val MSE: 10812721910.2261, Val R2: 0.4506\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1616, Val Loss: 0.1648\n",
      "Val RMSE: 99929.6303, Val MAE: 55768.0490, Val MSE: 9985931015.2447, Val R2: 0.4927\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1586, Val Loss: 0.1611\n",
      "Val RMSE: 98736.6611, Val MAE: 55535.8027, Val MSE: 9748928249.2821, Val R2: 0.5047\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1578, Val Loss: 0.1595\n",
      "Val RMSE: 96606.9178, Val MAE: 57668.4537, Val MSE: 9332896563.5434, Val R2: 0.5258\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1563, Val Loss: 0.1653\n",
      "Val RMSE: 99564.9494, Val MAE: 58240.2015, Val MSE: 9913179147.0003, Val R2: 0.4963\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1521, Val Loss: 0.1516\n",
      "Val RMSE: 95552.1329, Val MAE: 55525.5245, Val MSE: 9130210110.9755, Val R2: 0.5361\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1491, Val Loss: 0.1469\n",
      "Val RMSE: 94710.5729, Val MAE: 54162.4856, Val MSE: 8970092627.0303, Val R2: 0.5443\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1499, Val Loss: 0.1369\n",
      "Val RMSE: 90692.1868, Val MAE: 52827.5214, Val MSE: 8225072747.8013, Val R2: 0.5821\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1448, Val Loss: 0.1433\n",
      "Val RMSE: 93851.6869, Val MAE: 52646.6846, Val MSE: 8808139138.6292, Val R2: 0.5525\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1454, Val Loss: 0.1580\n",
      "Val RMSE: 97894.2011, Val MAE: 57992.4718, Val MSE: 9583274611.7852, Val R2: 0.5131\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1420, Val Loss: 0.1533\n",
      "Val RMSE: 96233.2050, Val MAE: 55495.1991, Val MSE: 9260829751.9191, Val R2: 0.5295\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1398, Val Loss: 0.1507\n",
      "Val RMSE: 95011.0817, Val MAE: 53878.6438, Val MSE: 9027105638.1773, Val R2: 0.5414\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1388, Val Loss: 0.1422\n",
      "Val RMSE: 93664.8947, Val MAE: 52204.1387, Val MSE: 8773112490.9223, Val R2: 0.5543\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1366, Val Loss: 0.1385\n",
      "Val RMSE: 90663.9987, Val MAE: 51966.3401, Val MSE: 8219960665.3951, Val R2: 0.5824\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1382, Val Loss: 0.1373\n",
      "Val RMSE: 91249.1867, Val MAE: 50749.7068, Val MSE: 8326414071.7042, Val R2: 0.5770\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1351, Val Loss: 0.1353\n",
      "Val RMSE: 90899.9852, Val MAE: 50015.8575, Val MSE: 8262807309.3551, Val R2: 0.5802\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1275, Val Loss: 0.1635\n",
      "Val RMSE: 95249.1589, Val MAE: 52876.5975, Val MSE: 9072402272.7085, Val R2: 0.5391\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1257, Val Loss: 0.1318\n",
      "Val RMSE: 91175.4318, Val MAE: 48401.2699, Val MSE: 8312959369.7461, Val R2: 0.5776\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1193, Val Loss: 0.1176\n",
      "Val RMSE: 86406.2324, Val MAE: 45602.8807, Val MSE: 7466036996.2008, Val R2: 0.6207\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1154, Val Loss: 0.1154\n",
      "Val RMSE: 86125.8624, Val MAE: 45157.5736, Val MSE: 7417664167.8472, Val R2: 0.6231\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1125, Val Loss: 0.1148\n",
      "Val RMSE: 85834.3742, Val MAE: 45903.6417, Val MSE: 7367539787.4840, Val R2: 0.6257\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1178\n",
      "Val RMSE: 86502.5973, Val MAE: 46201.2339, Val MSE: 7482699346.9094, Val R2: 0.6198\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1091, Val Loss: 0.1133\n",
      "Val RMSE: 85326.7958, Val MAE: 44946.0725, Val MSE: 7280662085.1663, Val R2: 0.6301\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1094, Val Loss: 0.1134\n",
      "Val RMSE: 84940.7021, Val MAE: 45156.0103, Val MSE: 7214922880.9298, Val R2: 0.6334\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1084, Val Loss: 0.1142\n",
      "Val RMSE: 86049.1029, Val MAE: 44258.7012, Val MSE: 7404448116.7144, Val R2: 0.6238\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1046, Val Loss: 0.1232\n",
      "Val RMSE: 88721.1387, Val MAE: 45448.4119, Val MSE: 7871440460.6756, Val R2: 0.6001\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1033, Val Loss: 0.1075\n",
      "Val RMSE: 84133.6226, Val MAE: 41959.3010, Val MSE: 7078466444.6197, Val R2: 0.6404\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1053, Val Loss: 0.1287\n",
      "Val RMSE: 89505.8052, Val MAE: 46608.7361, Val MSE: 8011289164.9595, Val R2: 0.5930\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1026, Val Loss: 0.1121\n",
      "Val RMSE: 86350.4949, Val MAE: 44831.9921, Val MSE: 7456407974.9796, Val R2: 0.6212\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1126\n",
      "Val RMSE: 86158.2882, Val MAE: 43640.9327, Val MSE: 7423250617.8458, Val R2: 0.6229\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1140\n",
      "Val RMSE: 86881.6983, Val MAE: 42648.4028, Val MSE: 7548429502.0696, Val R2: 0.6165\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0991, Val Loss: 0.1226\n",
      "Val RMSE: 88431.2857, Val MAE: 46175.9037, Val MSE: 7820092290.8300, Val R2: 0.6027\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1290\n",
      "Val RMSE: 89570.7946, Val MAE: 44456.4894, Val MSE: 8022927239.5985, Val R2: 0.5924\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0976, Val Loss: 0.1128\n",
      "Val RMSE: 85197.3569, Val MAE: 43094.0689, Val MSE: 7258589629.0618, Val R2: 0.6312\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1195\n",
      "Val RMSE: 86410.8764, Val MAE: 43236.1949, Val MSE: 7466839563.0917, Val R2: 0.6206\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1177\n",
      "Val RMSE: 88632.2980, Val MAE: 44657.3965, Val MSE: 7855684243.3449, Val R2: 0.6009\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1255\n",
      "Val RMSE: 87657.7846, Val MAE: 44483.8165, Val MSE: 7683887200.7664, Val R2: 0.6096\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0911, Val Loss: 0.1131\n",
      "Val RMSE: 86169.7543, Val MAE: 42665.8374, Val MSE: 7425226550.5057, Val R2: 0.6228\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1100\n",
      "Val RMSE: 85846.5433, Val MAE: 42182.4614, Val MSE: 7369628997.9917, Val R2: 0.6256\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0845, Val Loss: 0.1166\n",
      "Val RMSE: 87043.6726, Val MAE: 43212.9021, Val MSE: 7576600945.3990, Val R2: 0.6151\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1187\n",
      "Val RMSE: 86989.2656, Val MAE: 42785.6291, Val MSE: 7567132336.5725, Val R2: 0.6155\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1154\n",
      "Val RMSE: 86355.3127, Val MAE: 41858.9283, Val MSE: 7457240032.4547, Val R2: 0.6211\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0790, Val Loss: 0.1144\n",
      "Val RMSE: 81542.7717, Val MAE: 42489.8243, Val MSE: 6649223612.6612, Val R2: 0.6622\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0783, Val Loss: 0.1235\n",
      "Val RMSE: 84502.0612, Val MAE: 44751.0005, Val MSE: 7140598340.8572, Val R2: 0.6372\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0790, Val Loss: 0.1067\n",
      "Val RMSE: 78635.4751, Val MAE: 40529.8441, Val MSE: 6183537946.4077, Val R2: 0.6858\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0749, Val Loss: 0.1090\n",
      "Val RMSE: 76139.5599, Val MAE: 40352.9134, Val MSE: 5797232582.5408, Val R2: 0.7055\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1208\n",
      "Val RMSE: 83179.4114, Val MAE: 43353.3235, Val MSE: 6918814473.8999, Val R2: 0.6485\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1181\n",
      "Val RMSE: 81267.5539, Val MAE: 42689.7767, Val MSE: 6604415322.5077, Val R2: 0.6645\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1089\n",
      "Val RMSE: 76778.1724, Val MAE: 40741.7592, Val MSE: 5894887757.2973, Val R2: 0.7005\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1169\n",
      "Val RMSE: 78258.3841, Val MAE: 44040.4860, Val MSE: 6124374676.2582, Val R2: 0.6888\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0691, Val Loss: 0.1135\n",
      "Val RMSE: 77035.5629, Val MAE: 41897.8512, Val MSE: 5934477946.0449, Val R2: 0.6985\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1097\n",
      "Val RMSE: 76831.6609, Val MAE: 41505.0146, Val MSE: 5903104119.4372, Val R2: 0.7001\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1019\n",
      "Val RMSE: 72808.0426, Val MAE: 38828.9612, Val MSE: 5301011071.8324, Val R2: 0.7307\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.0954\n",
      "Val RMSE: 69929.3453, Val MAE: 38555.9109, Val MSE: 4890113338.8655, Val R2: 0.7516\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1092\n",
      "Val RMSE: 75001.9211, Val MAE: 42116.8673, Val MSE: 5625288161.7720, Val R2: 0.7142\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.0978\n",
      "Val RMSE: 71090.4338, Val MAE: 38386.3159, Val MSE: 5053849781.2817, Val R2: 0.7432\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1044\n",
      "Val RMSE: 74596.3220, Val MAE: 39670.5399, Val MSE: 5564611258.6340, Val R2: 0.7173\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1094\n",
      "Val RMSE: 73841.6418, Val MAE: 41884.2632, Val MSE: 5452588062.5914, Val R2: 0.7230\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1022\n",
      "Val RMSE: 74224.7592, Val MAE: 38982.2457, Val MSE: 5509314882.2587, Val R2: 0.7201\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.0953\n",
      "Val RMSE: 69908.7050, Val MAE: 37472.7063, Val MSE: 4887227037.3704, Val R2: 0.7517\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.0935\n",
      "Val RMSE: 69908.7599, Val MAE: 37266.5521, Val MSE: 4887234710.8940, Val R2: 0.7517\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.0924\n",
      "Val RMSE: 70082.0106, Val MAE: 36242.0831, Val MSE: 4911488211.6305, Val R2: 0.7505\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1002\n",
      "Val RMSE: 73133.2646, Val MAE: 39844.3256, Val MSE: 5348474395.5653, Val R2: 0.7283\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.0983\n",
      "Val RMSE: 71324.0226, Val MAE: 39456.1321, Val MSE: 5087116198.5322, Val R2: 0.7415\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.0963\n",
      "Val RMSE: 70323.9919, Val MAE: 36842.1839, Val MSE: 4945463833.5144, Val R2: 0.7487\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75129.3272, Test MAE: 38375.8412, Test MSE: 5644415810.8265, Test R2: 0.6382\n",
      "Inference Time: 1.7614401303804838e-05 seconds per sample\n",
      "\n",
      "Iteration 42 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3690, Val Loss: 0.2829\n",
      "Val RMSE: 140952.3394, Val MAE: 88141.8689, Val MSE: 19867561970.6218, Val R2: -0.0094\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2805, Val Loss: 0.2879\n",
      "Val RMSE: 143559.8585, Val MAE: 83718.0895, Val MSE: 20609432975.6727, Val R2: -0.0471\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2758, Val Loss: 0.2770\n",
      "Val RMSE: 141521.5269, Val MAE: 84043.8510, Val MSE: 20028342563.8674, Val R2: -0.0176\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2681, Val Loss: 0.2753\n",
      "Val RMSE: 141947.4798, Val MAE: 82772.6177, Val MSE: 20149087010.7522, Val R2: -0.0237\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2748\n",
      "Val RMSE: 141254.9435, Val MAE: 84623.2077, Val MSE: 19952959075.4332, Val R2: -0.0137\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2734\n",
      "Val RMSE: 141381.6770, Val MAE: 83101.7451, Val MSE: 19988778586.1133, Val R2: -0.0156\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2553, Val Loss: 0.2783\n",
      "Val RMSE: 141552.3831, Val MAE: 85735.2254, Val MSE: 20037077163.9463, Val R2: -0.0180\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2668\n",
      "Val RMSE: 141016.1694, Val MAE: 80130.1553, Val MSE: 19885560033.5311, Val R2: -0.0103\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2725\n",
      "Val RMSE: 140935.3888, Val MAE: 83217.4538, Val MSE: 19862783821.5964, Val R2: -0.0092\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2720\n",
      "Val RMSE: 141177.7568, Val MAE: 81894.3857, Val MSE: 19931159024.6081, Val R2: -0.0126\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2642\n",
      "Val RMSE: 141176.6343, Val MAE: 78811.3935, Val MSE: 19930842078.8023, Val R2: -0.0126\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2652\n",
      "Val RMSE: 139370.4825, Val MAE: 82388.7997, Val MSE: 19424131400.2720, Val R2: 0.0131\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2501, Val Loss: 0.2616\n",
      "Val RMSE: 140082.0742, Val MAE: 78358.9567, Val MSE: 19622987514.9312, Val R2: 0.0030\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2396, Val Loss: 0.2516\n",
      "Val RMSE: 134737.2632, Val MAE: 77838.7530, Val MSE: 18154130093.9549, Val R2: 0.0777\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2314, Val Loss: 0.2567\n",
      "Val RMSE: 135678.2790, Val MAE: 77359.4057, Val MSE: 18408595388.1676, Val R2: 0.0647\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2284, Val Loss: 0.2474\n",
      "Val RMSE: 132405.3347, Val MAE: 76543.4710, Val MSE: 17531172659.3525, Val R2: 0.1093\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2149, Val Loss: 0.2504\n",
      "Val RMSE: 137861.3225, Val MAE: 76182.2836, Val MSE: 19005744241.0023, Val R2: 0.0344\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2264\n",
      "Val RMSE: 129749.8707, Val MAE: 72572.2006, Val MSE: 16835028947.8161, Val R2: 0.1447\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2270\n",
      "Val RMSE: 129642.5025, Val MAE: 70923.0554, Val MSE: 16807178445.9730, Val R2: 0.1461\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.1963, Val Loss: 0.2321\n",
      "Val RMSE: 129748.6897, Val MAE: 69169.7175, Val MSE: 16834722476.1651, Val R2: 0.1447\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1933, Val Loss: 0.2248\n",
      "Val RMSE: 126847.4813, Val MAE: 70268.5372, Val MSE: 16090283514.4751, Val R2: 0.1825\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1894, Val Loss: 0.2131\n",
      "Val RMSE: 123695.8110, Val MAE: 68232.2784, Val MSE: 15300653665.1937, Val R2: 0.2226\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1808, Val Loss: 0.1916\n",
      "Val RMSE: 110835.9168, Val MAE: 64316.9488, Val MSE: 12284600455.0417, Val R2: 0.3759\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1721, Val Loss: 0.1709\n",
      "Val RMSE: 102855.9234, Val MAE: 60282.3954, Val MSE: 10579340975.6253, Val R2: 0.4625\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1695\n",
      "Val RMSE: 101444.9147, Val MAE: 60979.3547, Val MSE: 10291070712.4268, Val R2: 0.4771\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1726\n",
      "Val RMSE: 102709.9124, Val MAE: 59398.6658, Val MSE: 10549326109.7783, Val R2: 0.4640\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1553, Val Loss: 0.1677\n",
      "Val RMSE: 100530.3783, Val MAE: 58393.5578, Val MSE: 10106356962.7233, Val R2: 0.4865\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1635\n",
      "Val RMSE: 100018.7167, Val MAE: 57828.1898, Val MSE: 10003743697.4201, Val R2: 0.4917\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1593, Val Loss: 0.1527\n",
      "Val RMSE: 96704.8927, Val MAE: 54707.2094, Val MSE: 9351836264.3363, Val R2: 0.5249\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1568, Val Loss: 0.1549\n",
      "Val RMSE: 97426.8479, Val MAE: 55537.5253, Val MSE: 9491990682.9830, Val R2: 0.5177\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1515, Val Loss: 0.1533\n",
      "Val RMSE: 96617.1477, Val MAE: 53542.7766, Val MSE: 9334873220.8839, Val R2: 0.5257\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1467, Val Loss: 0.1496\n",
      "Val RMSE: 95494.8861, Val MAE: 53265.4787, Val MSE: 9119273266.6798, Val R2: 0.5367\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1522\n",
      "Val RMSE: 94365.8168, Val MAE: 53972.5992, Val MSE: 8904907379.7186, Val R2: 0.5476\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1295, Val Loss: 0.1352\n",
      "Val RMSE: 90712.7746, Val MAE: 49276.4268, Val MSE: 8228807482.1687, Val R2: 0.5819\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1256, Val Loss: 0.1400\n",
      "Val RMSE: 92949.1313, Val MAE: 49537.4504, Val MSE: 8639541018.4264, Val R2: 0.5611\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1203, Val Loss: 0.1333\n",
      "Val RMSE: 90923.5373, Val MAE: 47695.6805, Val MSE: 8267089633.2480, Val R2: 0.5800\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1164, Val Loss: 0.1357\n",
      "Val RMSE: 91535.1163, Val MAE: 48881.8830, Val MSE: 8378677510.6758, Val R2: 0.5743\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1412\n",
      "Val RMSE: 92184.9636, Val MAE: 51179.1314, Val MSE: 8498067508.4881, Val R2: 0.5682\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1123, Val Loss: 0.1393\n",
      "Val RMSE: 93127.3098, Val MAE: 49679.0229, Val MSE: 8672695831.6931, Val R2: 0.5594\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1108, Val Loss: 0.1404\n",
      "Val RMSE: 94050.2025, Val MAE: 48897.9683, Val MSE: 8845440599.5093, Val R2: 0.5506\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1089, Val Loss: 0.1382\n",
      "Val RMSE: 92948.6790, Val MAE: 47545.9078, Val MSE: 8639456935.4793, Val R2: 0.5611\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1058, Val Loss: 0.1428\n",
      "Val RMSE: 93955.1576, Val MAE: 50589.1187, Val MSE: 8827571637.9323, Val R2: 0.5515\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1418\n",
      "Val RMSE: 93064.9132, Val MAE: 50499.5260, Val MSE: 8661078073.2312, Val R2: 0.5600\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1008, Val Loss: 0.1343\n",
      "Val RMSE: 91666.2851, Val MAE: 47418.0035, Val MSE: 8402707815.6425, Val R2: 0.5731\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0959, Val Loss: 0.1458\n",
      "Val RMSE: 95033.2772, Val MAE: 50733.6784, Val MSE: 9031323784.0937, Val R2: 0.5412\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1356\n",
      "Val RMSE: 91925.8685, Val MAE: 49047.3229, Val MSE: 8450365292.0991, Val R2: 0.5707\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0934, Val Loss: 0.1346\n",
      "Val RMSE: 91959.7475, Val MAE: 47905.6266, Val MSE: 8456595162.9137, Val R2: 0.5704\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1338\n",
      "Val RMSE: 90169.5663, Val MAE: 50265.3937, Val MSE: 8130550686.8753, Val R2: 0.5869\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0875, Val Loss: 0.1326\n",
      "Val RMSE: 90740.0562, Val MAE: 49237.5717, Val MSE: 8233757802.0284, Val R2: 0.5817\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1353\n",
      "Val RMSE: 90200.9555, Val MAE: 51102.2596, Val MSE: 8136212381.0925, Val R2: 0.5866\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.1470\n",
      "Val RMSE: 92744.5928, Val MAE: 54267.9287, Val MSE: 8601559489.3904, Val R2: 0.5630\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1379\n",
      "Val RMSE: 89893.4237, Val MAE: 52035.7435, Val MSE: 8080827616.9016, Val R2: 0.5894\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1538\n",
      "Val RMSE: 92189.0962, Val MAE: 53842.7556, Val MSE: 8498829451.3491, Val R2: 0.5682\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0773, Val Loss: 0.1332\n",
      "Val RMSE: 88840.0656, Val MAE: 49155.6041, Val MSE: 7892557255.0864, Val R2: 0.5990\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1313\n",
      "Val RMSE: 86329.3138, Val MAE: 48491.3999, Val MSE: 7452750417.6574, Val R2: 0.6214\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1283\n",
      "Val RMSE: 82498.8497, Val MAE: 48885.8806, Val MSE: 6806060197.1881, Val R2: 0.6542\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0741, Val Loss: 0.1322\n",
      "Val RMSE: 85872.4767, Val MAE: 48417.5895, Val MSE: 7374082253.7154, Val R2: 0.6254\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1268\n",
      "Val RMSE: 84525.4615, Val MAE: 48254.2963, Val MSE: 7144553634.7844, Val R2: 0.6370\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1392\n",
      "Val RMSE: 87477.3344, Val MAE: 51415.1479, Val MSE: 7652284035.5417, Val R2: 0.6112\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0701, Val Loss: 0.1268\n",
      "Val RMSE: 83130.4109, Val MAE: 45909.1750, Val MSE: 6910665223.6573, Val R2: 0.6489\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1263\n",
      "Val RMSE: 82173.1194, Val MAE: 48546.7721, Val MSE: 6752421555.2231, Val R2: 0.6569\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1319\n",
      "Val RMSE: 82159.9159, Val MAE: 48802.3696, Val MSE: 6750251775.0075, Val R2: 0.6570\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.1166\n",
      "Val RMSE: 78033.3000, Val MAE: 43554.3089, Val MSE: 6089195910.2442, Val R2: 0.6906\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1275\n",
      "Val RMSE: 81899.9543, Val MAE: 47626.2032, Val MSE: 6707602509.7451, Val R2: 0.6592\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1116\n",
      "Val RMSE: 77640.7282, Val MAE: 43684.0676, Val MSE: 6028082669.1498, Val R2: 0.6937\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1142\n",
      "Val RMSE: 77193.4236, Val MAE: 45539.5072, Val MSE: 5958824645.4441, Val R2: 0.6973\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1216\n",
      "Val RMSE: 80959.7832, Val MAE: 46785.8565, Val MSE: 6554486495.1670, Val R2: 0.6670\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1124\n",
      "Val RMSE: 76878.7467, Val MAE: 43926.0898, Val MSE: 5910341690.5560, Val R2: 0.6997\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1209\n",
      "Val RMSE: 79305.5507, Val MAE: 45839.0716, Val MSE: 6289370378.9774, Val R2: 0.6805\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1107\n",
      "Val RMSE: 76669.8483, Val MAE: 44290.6509, Val MSE: 5878265641.5642, Val R2: 0.7013\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1100\n",
      "Val RMSE: 77937.0769, Val MAE: 41291.9438, Val MSE: 6074187954.9317, Val R2: 0.6914\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1150\n",
      "Val RMSE: 77773.2586, Val MAE: 45499.6035, Val MSE: 6048679759.6902, Val R2: 0.6927\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1118\n",
      "Val RMSE: 76883.3777, Val MAE: 43760.2859, Val MSE: 5911053759.5679, Val R2: 0.6997\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1173\n",
      "Val RMSE: 78859.0761, Val MAE: 44542.4522, Val MSE: 6218753890.2987, Val R2: 0.6840\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0568, Val Loss: 0.1103\n",
      "Val RMSE: 75679.3169, Val MAE: 44339.4526, Val MSE: 5727359007.1078, Val R2: 0.7090\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1175\n",
      "Val RMSE: 78243.9708, Val MAE: 45530.6288, Val MSE: 6122118970.1709, Val R2: 0.6890\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1116\n",
      "Val RMSE: 79683.3588, Val MAE: 41021.4376, Val MSE: 6349437663.5355, Val R2: 0.6774\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1090\n",
      "Val RMSE: 76638.1414, Val MAE: 43448.8658, Val MSE: 5873404720.0942, Val R2: 0.7016\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1080\n",
      "Val RMSE: 76295.7732, Val MAE: 41953.5059, Val MSE: 5821045006.5050, Val R2: 0.7043\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1135\n",
      "Val RMSE: 77830.3117, Val MAE: 43941.7956, Val MSE: 6057557414.0904, Val R2: 0.6922\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1137\n",
      "Val RMSE: 76696.9882, Val MAE: 45438.2128, Val MSE: 5882428005.5425, Val R2: 0.7011\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1139\n",
      "Val RMSE: 77805.9787, Val MAE: 43814.3811, Val MSE: 6053770317.9778, Val R2: 0.6924\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1017\n",
      "Val RMSE: 74827.0112, Val MAE: 39223.7654, Val MSE: 5599081611.1808, Val R2: 0.7155\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1119\n",
      "Val RMSE: 75897.8760, Val MAE: 44136.6488, Val MSE: 5760487579.1301, Val R2: 0.7073\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1028\n",
      "Val RMSE: 74564.9733, Val MAE: 39683.9023, Val MSE: 5559935246.8173, Val R2: 0.7175\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1126\n",
      "Val RMSE: 77557.8132, Val MAE: 43003.0501, Val MSE: 6015214387.9762, Val R2: 0.6944\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1148\n",
      "Val RMSE: 76221.6296, Val MAE: 45763.9744, Val MSE: 5809736826.4528, Val R2: 0.7048\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1076\n",
      "Val RMSE: 75230.1572, Val MAE: 42336.2115, Val MSE: 5659576553.4538, Val R2: 0.7125\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1088\n",
      "Val RMSE: 75608.5981, Val MAE: 42500.9844, Val MSE: 5716660111.0651, Val R2: 0.7096\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1075\n",
      "Val RMSE: 77211.4725, Val MAE: 40783.7125, Val MSE: 5961611483.2178, Val R2: 0.6971\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.0951\n",
      "Val RMSE: 72247.0595, Val MAE: 37959.4792, Val MSE: 5219637601.7503, Val R2: 0.7348\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.1148\n",
      "Val RMSE: 77329.9084, Val MAE: 44049.6855, Val MSE: 5979914728.6974, Val R2: 0.6962\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1124\n",
      "Val RMSE: 77146.7349, Val MAE: 43106.1375, Val MSE: 5951618700.2210, Val R2: 0.6976\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.1139\n",
      "Val RMSE: 78971.7788, Val MAE: 43825.9713, Val MSE: 6236541854.4754, Val R2: 0.6831\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0435, Val Loss: 0.1065\n",
      "Val RMSE: 76848.1975, Val MAE: 39893.7417, Val MSE: 5905645458.0084, Val R2: 0.7000\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1133\n",
      "Val RMSE: 78734.9455, Val MAE: 42046.1031, Val MSE: 6199191641.4822, Val R2: 0.6850\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.1077\n",
      "Val RMSE: 76404.8125, Val MAE: 41807.3011, Val MSE: 5837695373.8053, Val R2: 0.7034\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1154\n",
      "Val RMSE: 80331.9534, Val MAE: 42497.8117, Val MSE: 6453222740.8213, Val R2: 0.6721\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.1140\n",
      "Val RMSE: 80296.3338, Val MAE: 40892.5261, Val MSE: 6447501218.5449, Val R2: 0.6724\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0425, Val Loss: 0.1112\n",
      "Val RMSE: 79556.6051, Val MAE: 41774.2581, Val MSE: 6329253407.5984, Val R2: 0.6784\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 73330.0320, Test MAE: 40684.2885, Test MSE: 5377293592.3837, Test R2: 0.6553\n",
      "Inference Time: 2.162782962505634e-05 seconds per sample\n",
      "\n",
      "Iteration 43 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3783, Val Loss: 0.2830\n",
      "Val RMSE: 142600.4552, Val MAE: 83725.0665, Val MSE: 20334889811.2930, Val R2: -0.0331\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2807, Val Loss: 0.2776\n",
      "Val RMSE: 142384.2560, Val MAE: 82699.1055, Val MSE: 20273276360.8941, Val R2: -0.0300\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2768\n",
      "Val RMSE: 142013.1495, Val MAE: 82860.9073, Val MSE: 20167734638.1224, Val R2: -0.0246\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2703, Val Loss: 0.2771\n",
      "Val RMSE: 142509.7733, Val MAE: 82323.7965, Val MSE: 20309035483.7755, Val R2: -0.0318\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2773\n",
      "Val RMSE: 141245.1823, Val MAE: 85901.3984, Val MSE: 19950201520.3190, Val R2: -0.0136\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2777\n",
      "Val RMSE: 142829.8881, Val MAE: 81658.8583, Val MSE: 20400376924.9300, Val R2: -0.0365\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2715\n",
      "Val RMSE: 141611.7457, Val MAE: 82014.5884, Val MSE: 20053886534.0745, Val R2: -0.0189\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2583, Val Loss: 0.2776\n",
      "Val RMSE: 141457.1265, Val MAE: 85295.2272, Val MSE: 20010118632.2532, Val R2: -0.0166\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2759\n",
      "Val RMSE: 141086.3972, Val MAE: 85387.9654, Val MSE: 19905371485.1520, Val R2: -0.0113\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2727\n",
      "Val RMSE: 140876.5619, Val MAE: 84130.5011, Val MSE: 19846205680.3885, Val R2: -0.0083\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2509, Val Loss: 0.2655\n",
      "Val RMSE: 140345.1053, Val MAE: 81159.1443, Val MSE: 19696748577.1418, Val R2: -0.0007\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2651\n",
      "Val RMSE: 141837.0601, Val MAE: 77406.7891, Val MSE: 20117751606.9107, Val R2: -0.0221\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2460, Val Loss: 0.2570\n",
      "Val RMSE: 135813.5389, Val MAE: 80103.7575, Val MSE: 18445317336.4123, Val R2: 0.0629\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2532\n",
      "Val RMSE: 135546.6695, Val MAE: 77587.0835, Val MSE: 18372899624.4738, Val R2: 0.0665\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2369, Val Loss: 0.2544\n",
      "Val RMSE: 136472.6450, Val MAE: 76647.1119, Val MSE: 18624782829.3791, Val R2: 0.0537\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2300, Val Loss: 0.2551\n",
      "Val RMSE: 132485.0938, Val MAE: 79321.0968, Val MSE: 17552300089.8955, Val R2: 0.1082\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2259, Val Loss: 0.2315\n",
      "Val RMSE: 130244.6790, Val MAE: 75202.2945, Val MSE: 16963676398.0209, Val R2: 0.1381\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2188, Val Loss: 0.2314\n",
      "Val RMSE: 129952.2577, Val MAE: 74121.9811, Val MSE: 16887589275.2957, Val R2: 0.1420\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2171, Val Loss: 0.2386\n",
      "Val RMSE: 132714.6997, Val MAE: 74522.3830, Val MSE: 17613191521.3440, Val R2: 0.1051\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2139, Val Loss: 0.2291\n",
      "Val RMSE: 128250.6613, Val MAE: 76228.9367, Val MSE: 16448232132.6103, Val R2: 0.1643\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2308\n",
      "Val RMSE: 130041.8439, Val MAE: 73712.1263, Val MSE: 16910881167.0878, Val R2: 0.1408\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2151, Val Loss: 0.2339\n",
      "Val RMSE: 132405.8633, Val MAE: 70910.4598, Val MSE: 17531312641.8941, Val R2: 0.1093\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2192, Val Loss: 0.2403\n",
      "Val RMSE: 130520.2062, Val MAE: 76075.1691, Val MSE: 17035524238.0290, Val R2: 0.1345\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2185, Val Loss: 0.2367\n",
      "Val RMSE: 130224.5820, Val MAE: 76443.8462, Val MSE: 16958441755.7151, Val R2: 0.1384\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2143, Val Loss: 0.2309\n",
      "Val RMSE: 130420.9988, Val MAE: 72964.5617, Val MSE: 17009636919.3420, Val R2: 0.1358\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2122, Val Loss: 0.2355\n",
      "Val RMSE: 130034.8921, Val MAE: 75559.1234, Val MSE: 16909073160.8261, Val R2: 0.1409\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2109, Val Loss: 0.2250\n",
      "Val RMSE: 129015.3877, Val MAE: 71396.5053, Val MSE: 16644970263.1688, Val R2: 0.1543\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2064, Val Loss: 0.2220\n",
      "Val RMSE: 127788.3122, Val MAE: 72040.4579, Val MSE: 16329852726.3873, Val R2: 0.1703\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2051, Val Loss: 0.2291\n",
      "Val RMSE: 130108.2981, Val MAE: 71003.9967, Val MSE: 16928169228.9490, Val R2: 0.1399\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2038, Val Loss: 0.2193\n",
      "Val RMSE: 127489.9729, Val MAE: 68071.8759, Val MSE: 16253693183.9657, Val R2: 0.1742\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2007, Val Loss: 0.2277\n",
      "Val RMSE: 130355.1941, Val MAE: 70410.9965, Val MSE: 16992476625.6313, Val R2: 0.1367\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1960, Val Loss: 0.2267\n",
      "Val RMSE: 128820.9099, Val MAE: 69555.4894, Val MSE: 16594826833.4790, Val R2: 0.1569\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1863, Val Loss: 0.2243\n",
      "Val RMSE: 121578.3667, Val MAE: 67307.4210, Val MSE: 14781299257.7000, Val R2: 0.2490\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1826, Val Loss: 0.2201\n",
      "Val RMSE: 123661.0736, Val MAE: 69129.7536, Val MSE: 15292061115.8848, Val R2: 0.2231\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1751, Val Loss: 0.1875\n",
      "Val RMSE: 105363.4498, Val MAE: 63789.3928, Val MSE: 11101456550.8799, Val R2: 0.4360\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1656, Val Loss: 0.1815\n",
      "Val RMSE: 105075.7231, Val MAE: 61999.2046, Val MSE: 11040907575.1485, Val R2: 0.4391\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1614, Val Loss: 0.1722\n",
      "Val RMSE: 102169.0976, Val MAE: 61603.4065, Val MSE: 10438524509.9163, Val R2: 0.4697\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1589, Val Loss: 0.1598\n",
      "Val RMSE: 98017.3133, Val MAE: 55983.2060, Val MSE: 9607393715.6044, Val R2: 0.5119\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1539, Val Loss: 0.1614\n",
      "Val RMSE: 98088.6191, Val MAE: 57182.4296, Val MSE: 9621377193.3480, Val R2: 0.5112\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1538, Val Loss: 0.1588\n",
      "Val RMSE: 98095.2956, Val MAE: 57687.0858, Val MSE: 9622687023.7163, Val R2: 0.5111\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1505, Val Loss: 0.1605\n",
      "Val RMSE: 98429.1924, Val MAE: 56161.7676, Val MSE: 9688305917.9039, Val R2: 0.5078\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1475, Val Loss: 0.1599\n",
      "Val RMSE: 97804.5335, Val MAE: 55590.5559, Val MSE: 9565726771.5112, Val R2: 0.5140\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1452, Val Loss: 0.1558\n",
      "Val RMSE: 97188.6990, Val MAE: 53974.2708, Val MSE: 9445643212.8658, Val R2: 0.5201\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1414, Val Loss: 0.1509\n",
      "Val RMSE: 95276.4331, Val MAE: 54529.4499, Val MSE: 9077598700.6418, Val R2: 0.5388\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1378, Val Loss: 0.1424\n",
      "Val RMSE: 92612.9839, Val MAE: 53358.7100, Val MSE: 8577164795.8809, Val R2: 0.5642\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1355, Val Loss: 0.1512\n",
      "Val RMSE: 95825.7575, Val MAE: 51637.9834, Val MSE: 9182575805.3312, Val R2: 0.5335\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1307, Val Loss: 0.1381\n",
      "Val RMSE: 92215.3501, Val MAE: 49587.6233, Val MSE: 8503670798.7805, Val R2: 0.5680\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1261, Val Loss: 0.1364\n",
      "Val RMSE: 90994.8282, Val MAE: 50392.1861, Val MSE: 8280058766.3907, Val R2: 0.5793\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1210, Val Loss: 0.1289\n",
      "Val RMSE: 90771.6839, Val MAE: 47048.3593, Val MSE: 8239498601.3008, Val R2: 0.5814\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1152, Val Loss: 0.1223\n",
      "Val RMSE: 88561.0845, Val MAE: 46010.2212, Val MSE: 7843065691.4977, Val R2: 0.6015\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1107, Val Loss: 0.1353\n",
      "Val RMSE: 90681.7390, Val MAE: 47680.3365, Val MSE: 8223177794.8443, Val R2: 0.5822\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1088, Val Loss: 0.1274\n",
      "Val RMSE: 89396.0385, Val MAE: 47648.8957, Val MSE: 7991651705.5080, Val R2: 0.5940\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1033, Val Loss: 0.1213\n",
      "Val RMSE: 88687.6984, Val MAE: 46400.7576, Val MSE: 7865507844.4606, Val R2: 0.6004\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1000, Val Loss: 0.1232\n",
      "Val RMSE: 88933.6826, Val MAE: 43604.0894, Val MSE: 7909199907.5444, Val R2: 0.5982\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0948, Val Loss: 0.1171\n",
      "Val RMSE: 85753.6130, Val MAE: 43601.9428, Val MSE: 7353682135.6613, Val R2: 0.6264\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1220\n",
      "Val RMSE: 90079.0705, Val MAE: 43653.2889, Val MSE: 8114238945.5316, Val R2: 0.5877\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1232\n",
      "Val RMSE: 89764.7826, Val MAE: 46032.1297, Val MSE: 8057716203.5651, Val R2: 0.5906\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1189\n",
      "Val RMSE: 86640.1336, Val MAE: 44971.1887, Val MSE: 7506512746.8218, Val R2: 0.6186\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1077\n",
      "Val RMSE: 80014.8518, Val MAE: 42462.5861, Val MSE: 6402376509.1756, Val R2: 0.6747\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0877, Val Loss: 0.1144\n",
      "Val RMSE: 85934.6250, Val MAE: 44301.9234, Val MSE: 7384759772.8529, Val R2: 0.6248\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0861, Val Loss: 0.1138\n",
      "Val RMSE: 84990.7110, Val MAE: 42113.3139, Val MSE: 7223420961.1823, Val R2: 0.6330\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1220\n",
      "Val RMSE: 87312.8050, Val MAE: 45861.3240, Val MSE: 7623525924.7365, Val R2: 0.6127\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1181\n",
      "Val RMSE: 87373.0360, Val MAE: 42973.0961, Val MSE: 7634047417.2725, Val R2: 0.6121\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1039\n",
      "Val RMSE: 78157.8151, Val MAE: 41832.4765, Val MSE: 6108644066.7422, Val R2: 0.6896\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0783, Val Loss: 0.1171\n",
      "Val RMSE: 79956.6590, Val MAE: 43687.5964, Val MSE: 6393067325.7027, Val R2: 0.6752\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1162\n",
      "Val RMSE: 79537.5026, Val MAE: 42524.0652, Val MSE: 6326214326.4499, Val R2: 0.6786\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1114\n",
      "Val RMSE: 80699.1605, Val MAE: 42219.0388, Val MSE: 6512354509.9368, Val R2: 0.6691\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1127\n",
      "Val RMSE: 79938.5707, Val MAE: 43614.1612, Val MSE: 6390175083.4534, Val R2: 0.6753\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1116\n",
      "Val RMSE: 79900.9782, Val MAE: 43080.6449, Val MSE: 6384166318.3364, Val R2: 0.6756\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1123\n",
      "Val RMSE: 80190.3274, Val MAE: 41169.4691, Val MSE: 6430488610.0317, Val R2: 0.6733\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1145\n",
      "Val RMSE: 79405.0873, Val MAE: 43194.2605, Val MSE: 6305167883.1442, Val R2: 0.6797\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1155\n",
      "Val RMSE: 79183.8585, Val MAE: 41499.0424, Val MSE: 6270083447.1344, Val R2: 0.6814\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.0971\n",
      "Val RMSE: 74275.8594, Val MAE: 38266.0837, Val MSE: 5516903294.5643, Val R2: 0.7197\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1094\n",
      "Val RMSE: 77506.3108, Val MAE: 40444.1276, Val MSE: 6007228210.0029, Val R2: 0.6948\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1052\n",
      "Val RMSE: 73882.8833, Val MAE: 40384.2446, Val MSE: 5458680441.0990, Val R2: 0.7227\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1064\n",
      "Val RMSE: 73486.0465, Val MAE: 40534.0104, Val MSE: 5400199023.9557, Val R2: 0.7256\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1077\n",
      "Val RMSE: 74845.1306, Val MAE: 39931.7320, Val MSE: 5601793574.0151, Val R2: 0.7154\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1036\n",
      "Val RMSE: 73786.7492, Val MAE: 40502.9763, Val MSE: 5444484351.6478, Val R2: 0.7234\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1191\n",
      "Val RMSE: 77717.5787, Val MAE: 42179.9099, Val MSE: 6040022041.7595, Val R2: 0.6931\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1130\n",
      "Val RMSE: 75502.6049, Val MAE: 41017.7917, Val MSE: 5700643351.1784, Val R2: 0.7104\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1058\n",
      "Val RMSE: 76300.7808, Val MAE: 41422.5354, Val MSE: 5821809148.2179, Val R2: 0.7042\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1092\n",
      "Val RMSE: 78153.2414, Val MAE: 40911.1255, Val MSE: 6107929138.5085, Val R2: 0.6897\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1092\n",
      "Val RMSE: 74890.1792, Val MAE: 40577.0188, Val MSE: 5608538948.0385, Val R2: 0.7151\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1179\n",
      "Val RMSE: 75892.3752, Val MAE: 42123.5188, Val MSE: 5759652609.3302, Val R2: 0.7074\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1037\n",
      "Val RMSE: 73049.4375, Val MAE: 40199.9288, Val MSE: 5336220312.3225, Val R2: 0.7289\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0548, Val Loss: 0.0998\n",
      "Val RMSE: 72453.5545, Val MAE: 38667.5717, Val MSE: 5249517558.8812, Val R2: 0.7333\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1114\n",
      "Val RMSE: 75869.0116, Val MAE: 42987.3781, Val MSE: 5756106921.0034, Val R2: 0.7076\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.0973\n",
      "Val RMSE: 69145.3554, Val MAE: 38173.8980, Val MSE: 4781080174.3686, Val R2: 0.7571\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1056\n",
      "Val RMSE: 72064.2474, Val MAE: 41124.7332, Val MSE: 5193255754.6448, Val R2: 0.7361\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1015\n",
      "Val RMSE: 71519.3473, Val MAE: 38768.3917, Val MSE: 5115017043.1630, Val R2: 0.7401\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1025\n",
      "Val RMSE: 72667.0742, Val MAE: 39522.7966, Val MSE: 5280503675.1160, Val R2: 0.7317\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1048\n",
      "Val RMSE: 74347.0586, Val MAE: 40785.6981, Val MSE: 5527485120.1587, Val R2: 0.7192\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1015\n",
      "Val RMSE: 72742.8505, Val MAE: 38133.2089, Val MSE: 5291522304.3970, Val R2: 0.7312\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.0989\n",
      "Val RMSE: 68964.5983, Val MAE: 38932.1675, Val MSE: 4756115818.1931, Val R2: 0.7584\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1051\n",
      "Val RMSE: 73697.1782, Val MAE: 39630.1294, Val MSE: 5431274071.0405, Val R2: 0.7241\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1017\n",
      "Val RMSE: 72726.0107, Val MAE: 39639.9452, Val MSE: 5289072634.9591, Val R2: 0.7313\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1010\n",
      "Val RMSE: 70975.5816, Val MAE: 38422.0026, Val MSE: 5037533190.3140, Val R2: 0.7441\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.0950\n",
      "Val RMSE: 68305.3048, Val MAE: 37691.8743, Val MSE: 4665614661.1828, Val R2: 0.7630\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1027\n",
      "Val RMSE: 70344.0398, Val MAE: 39367.4322, Val MSE: 4948283939.0649, Val R2: 0.7486\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1042\n",
      "Val RMSE: 73566.4053, Val MAE: 38185.0840, Val MSE: 5412015989.3480, Val R2: 0.7250\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 66413.2553, Test MAE: 36976.8150, Test MSE: 4410720483.0150, Test R2: 0.7173\n",
      "Inference Time: 1.822974131657527e-05 seconds per sample\n",
      "\n",
      "Iteration 44 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3741, Val Loss: 0.2823\n",
      "Val RMSE: 139939.9698, Val MAE: 90746.8484, Val MSE: 19583195143.2438, Val R2: 0.0051\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2773, Val Loss: 0.2790\n",
      "Val RMSE: 142576.2102, Val MAE: 82411.3194, Val MSE: 20327975714.1125, Val R2: -0.0328\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2708, Val Loss: 0.2746\n",
      "Val RMSE: 141186.3887, Val MAE: 84094.0359, Val MSE: 19933596368.0940, Val R2: -0.0128\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2676, Val Loss: 0.2740\n",
      "Val RMSE: 141787.3745, Val MAE: 83203.3121, Val MSE: 20103659559.0568, Val R2: -0.0214\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2741\n",
      "Val RMSE: 141026.1730, Val MAE: 85232.6828, Val MSE: 19888381472.2400, Val R2: -0.0105\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2623, Val Loss: 0.2724\n",
      "Val RMSE: 140512.4556, Val MAE: 84688.1007, Val MSE: 19743750172.3759, Val R2: -0.0031\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2712\n",
      "Val RMSE: 142385.4833, Val MAE: 80369.1541, Val MSE: 20273625856.1094, Val R2: -0.0300\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2712\n",
      "Val RMSE: 140885.2733, Val MAE: 83006.7617, Val MSE: 19848660233.3507, Val R2: -0.0084\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2672\n",
      "Val RMSE: 140373.8877, Val MAE: 82305.1974, Val MSE: 19704828338.5403, Val R2: -0.0011\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2610\n",
      "Val RMSE: 139721.4095, Val MAE: 79124.2689, Val MSE: 19522072272.8502, Val R2: 0.0082\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2597\n",
      "Val RMSE: 135905.6930, Val MAE: 79892.4717, Val MSE: 18470357397.9240, Val R2: 0.0616\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2435, Val Loss: 0.2501\n",
      "Val RMSE: 135139.2154, Val MAE: 75166.1846, Val MSE: 18262607548.4417, Val R2: 0.0721\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2408, Val Loss: 0.2529\n",
      "Val RMSE: 133874.9462, Val MAE: 79099.8903, Val MSE: 17922501223.3711, Val R2: 0.0894\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2377\n",
      "Val RMSE: 133587.4255, Val MAE: 72523.1107, Val MSE: 17845600247.8736, Val R2: 0.0933\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2241, Val Loss: 0.2254\n",
      "Val RMSE: 127474.5417, Val MAE: 71847.9967, Val MSE: 16249758770.4694, Val R2: 0.1744\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2193, Val Loss: 0.2352\n",
      "Val RMSE: 132077.2089, Val MAE: 75313.4432, Val MSE: 17444389118.2784, Val R2: 0.1137\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2171, Val Loss: 0.2461\n",
      "Val RMSE: 134616.1882, Val MAE: 76974.2778, Val MSE: 18121518126.5339, Val R2: 0.0793\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2128, Val Loss: 0.2410\n",
      "Val RMSE: 130708.2505, Val MAE: 78422.0829, Val MSE: 17084646749.3954, Val R2: 0.1320\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2065, Val Loss: 0.2499\n",
      "Val RMSE: 133784.7406, Val MAE: 74934.0873, Val MSE: 17898356823.9530, Val R2: 0.0907\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2013, Val Loss: 0.2345\n",
      "Val RMSE: 129361.7208, Val MAE: 74613.9923, Val MSE: 16734454801.8313, Val R2: 0.1498\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1990, Val Loss: 0.2208\n",
      "Val RMSE: 124974.6955, Val MAE: 71810.5244, Val MSE: 15618674505.2918, Val R2: 0.2065\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1881, Val Loss: 0.1911\n",
      "Val RMSE: 108077.5701, Val MAE: 64472.5143, Val MSE: 11680761160.7368, Val R2: 0.4065\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1819, Val Loss: 0.1899\n",
      "Val RMSE: 107946.2239, Val MAE: 67316.5696, Val MSE: 11652387253.9748, Val R2: 0.4080\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1751, Val Loss: 0.1796\n",
      "Val RMSE: 104809.3104, Val MAE: 62122.0157, Val MSE: 10984991539.4209, Val R2: 0.4419\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1652, Val Loss: 0.1730\n",
      "Val RMSE: 102528.6203, Val MAE: 60438.8082, Val MSE: 10512117973.3997, Val R2: 0.4659\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1610, Val Loss: 0.1662\n",
      "Val RMSE: 100264.1215, Val MAE: 59039.5252, Val MSE: 10052894052.0944, Val R2: 0.4892\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1562, Val Loss: 0.1635\n",
      "Val RMSE: 97884.4395, Val MAE: 59921.9324, Val MSE: 9581363500.5275, Val R2: 0.5132\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1537, Val Loss: 0.1649\n",
      "Val RMSE: 99084.0986, Val MAE: 59107.2367, Val MSE: 9817658604.5111, Val R2: 0.5012\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1674\n",
      "Val RMSE: 101079.7784, Val MAE: 56997.7585, Val MSE: 10217121593.5905, Val R2: 0.4809\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1481, Val Loss: 0.1570\n",
      "Val RMSE: 96649.4602, Val MAE: 57370.8830, Val MSE: 9341118166.0897, Val R2: 0.5254\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1448, Val Loss: 0.1683\n",
      "Val RMSE: 99571.6881, Val MAE: 59490.8889, Val MSE: 9914521065.8520, Val R2: 0.4963\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1451, Val Loss: 0.1491\n",
      "Val RMSE: 94794.6043, Val MAE: 55531.9721, Val MSE: 8986017005.7280, Val R2: 0.5435\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1429, Val Loss: 0.1575\n",
      "Val RMSE: 98104.7352, Val MAE: 55462.8132, Val MSE: 9624539066.3384, Val R2: 0.5110\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1497\n",
      "Val RMSE: 95404.1912, Val MAE: 53545.5864, Val MSE: 9101959694.0848, Val R2: 0.5376\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1335, Val Loss: 0.1528\n",
      "Val RMSE: 95681.4790, Val MAE: 52969.1860, Val MSE: 9154945415.2455, Val R2: 0.5349\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1326, Val Loss: 0.1411\n",
      "Val RMSE: 93665.9672, Val MAE: 52384.0523, Val MSE: 8773313415.8503, Val R2: 0.5543\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1271, Val Loss: 0.1387\n",
      "Val RMSE: 92384.0435, Val MAE: 51817.1793, Val MSE: 8534811486.2539, Val R2: 0.5664\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1239, Val Loss: 0.1350\n",
      "Val RMSE: 91766.4371, Val MAE: 49838.0368, Val MSE: 8421078986.9590, Val R2: 0.5722\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1196, Val Loss: 0.1170\n",
      "Val RMSE: 87201.5417, Val MAE: 46913.0542, Val MSE: 7604108872.8212, Val R2: 0.6137\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1163, Val Loss: 0.1246\n",
      "Val RMSE: 89051.9244, Val MAE: 48415.6895, Val MSE: 7930245247.2547, Val R2: 0.5971\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1124, Val Loss: 0.1221\n",
      "Val RMSE: 87620.1067, Val MAE: 47171.8557, Val MSE: 7677283090.1493, Val R2: 0.6099\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1058, Val Loss: 0.1271\n",
      "Val RMSE: 88951.6592, Val MAE: 48621.7335, Val MSE: 7912397671.0786, Val R2: 0.5980\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1019, Val Loss: 0.1275\n",
      "Val RMSE: 89640.3784, Val MAE: 49155.5998, Val MSE: 8035397438.9674, Val R2: 0.5918\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0996, Val Loss: 0.1194\n",
      "Val RMSE: 86714.9665, Val MAE: 48056.3407, Val MSE: 7519485419.5455, Val R2: 0.6180\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0980, Val Loss: 0.1272\n",
      "Val RMSE: 91371.2094, Val MAE: 46899.7355, Val MSE: 8348697901.3949, Val R2: 0.5758\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0934, Val Loss: 0.1278\n",
      "Val RMSE: 90607.3603, Val MAE: 48063.1275, Val MSE: 8209693737.9770, Val R2: 0.5829\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1337\n",
      "Val RMSE: 92253.5558, Val MAE: 48829.0166, Val MSE: 8510718554.5584, Val R2: 0.5676\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1300\n",
      "Val RMSE: 88410.8257, Val MAE: 49353.6470, Val MSE: 7816474106.0228, Val R2: 0.6029\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1334\n",
      "Val RMSE: 89786.7327, Val MAE: 49279.2243, Val MSE: 8061657362.3152, Val R2: 0.5904\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1267\n",
      "Val RMSE: 85403.0936, Val MAE: 46273.7811, Val MSE: 7293688390.1199, Val R2: 0.6294\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1196\n",
      "Val RMSE: 83373.2399, Val MAE: 45809.0050, Val MSE: 6951097127.1297, Val R2: 0.6468\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1150\n",
      "Val RMSE: 78698.3854, Val MAE: 45789.2460, Val MSE: 6193435865.6252, Val R2: 0.6853\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1159\n",
      "Val RMSE: 78269.0276, Val MAE: 46195.0770, Val MSE: 6126040682.8367, Val R2: 0.6888\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1148\n",
      "Val RMSE: 79761.7859, Val MAE: 44846.5747, Val MSE: 6361942492.6038, Val R2: 0.6768\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0735, Val Loss: 0.1161\n",
      "Val RMSE: 77359.3038, Val MAE: 45747.0814, Val MSE: 5984461891.1214, Val R2: 0.6960\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1183\n",
      "Val RMSE: 82125.9306, Val MAE: 45625.5200, Val MSE: 6744668474.6442, Val R2: 0.6573\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1106\n",
      "Val RMSE: 76262.0392, Val MAE: 42973.5230, Val MSE: 5815898622.1172, Val R2: 0.7045\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1139\n",
      "Val RMSE: 75744.7179, Val MAE: 44890.0136, Val MSE: 5737262289.6097, Val R2: 0.7085\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1072\n",
      "Val RMSE: 71341.4742, Val MAE: 44025.9366, Val MSE: 5089605940.9122, Val R2: 0.7414\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0657, Val Loss: 0.1154\n",
      "Val RMSE: 73773.3018, Val MAE: 48513.7595, Val MSE: 5442500063.8874, Val R2: 0.7235\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1118\n",
      "Val RMSE: 71813.8484, Val MAE: 44785.0275, Val MSE: 5157228815.0936, Val R2: 0.7380\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1064\n",
      "Val RMSE: 71235.4807, Val MAE: 43470.2989, Val MSE: 5074493709.4176, Val R2: 0.7422\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1025\n",
      "Val RMSE: 68720.4008, Val MAE: 41827.5367, Val MSE: 4722493483.6791, Val R2: 0.7601\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1033\n",
      "Val RMSE: 70807.6053, Val MAE: 42180.4291, Val MSE: 5013716965.8163, Val R2: 0.7453\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.0947\n",
      "Val RMSE: 67890.9021, Val MAE: 39514.0044, Val MSE: 4609174592.6977, Val R2: 0.7658\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.0970\n",
      "Val RMSE: 67848.6327, Val MAE: 40770.1746, Val MSE: 4603436961.5898, Val R2: 0.7661\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0567, Val Loss: 0.1023\n",
      "Val RMSE: 70947.3797, Val MAE: 42669.7124, Val MSE: 5033530682.7170, Val R2: 0.7443\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.0979\n",
      "Val RMSE: 66974.0109, Val MAE: 40536.7280, Val MSE: 4485518139.5400, Val R2: 0.7721\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.0987\n",
      "Val RMSE: 68314.8515, Val MAE: 40713.0855, Val MSE: 4666918934.8440, Val R2: 0.7629\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1009\n",
      "Val RMSE: 67975.5055, Val MAE: 42959.7743, Val MSE: 4620669344.8319, Val R2: 0.7652\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.0976\n",
      "Val RMSE: 67978.0310, Val MAE: 40505.2030, Val MSE: 4621012699.1412, Val R2: 0.7652\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0906\n",
      "Val RMSE: 64520.8412, Val MAE: 37932.3399, Val MSE: 4162938947.8946, Val R2: 0.7885\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0914\n",
      "Val RMSE: 64761.1961, Val MAE: 38619.4022, Val MSE: 4194012526.3428, Val R2: 0.7869\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.0873\n",
      "Val RMSE: 63269.5241, Val MAE: 37203.7135, Val MSE: 4003032677.2180, Val R2: 0.7966\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.0991\n",
      "Val RMSE: 68320.6934, Val MAE: 41913.1120, Val MSE: 4667717150.3191, Val R2: 0.7629\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.0968\n",
      "Val RMSE: 66746.7214, Val MAE: 38877.6843, Val MSE: 4455124812.0519, Val R2: 0.7737\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1001\n",
      "Val RMSE: 69144.6151, Val MAE: 40484.7699, Val MSE: 4780977802.3424, Val R2: 0.7571\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1023\n",
      "Val RMSE: 68411.5927, Val MAE: 39497.3810, Val MSE: 4680146015.6337, Val R2: 0.7622\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.0951\n",
      "Val RMSE: 67323.4333, Val MAE: 39264.5336, Val MSE: 4532444670.5835, Val R2: 0.7697\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1102\n",
      "Val RMSE: 71777.6783, Val MAE: 42317.0093, Val MSE: 5152035107.5815, Val R2: 0.7382\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.0865\n",
      "Val RMSE: 63230.4343, Val MAE: 37636.6366, Val MSE: 3998087827.2811, Val R2: 0.7969\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.0923\n",
      "Val RMSE: 65744.0923, Val MAE: 38651.3635, Val MSE: 4322285676.4425, Val R2: 0.7804\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.0975\n",
      "Val RMSE: 70098.5805, Val MAE: 39247.6441, Val MSE: 4913810982.4775, Val R2: 0.7503\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.0996\n",
      "Val RMSE: 69707.8477, Val MAE: 39740.8476, Val MSE: 4859184037.6040, Val R2: 0.7531\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.0962\n",
      "Val RMSE: 67196.1531, Val MAE: 39153.9806, Val MSE: 4515322998.1442, Val R2: 0.7706\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.0914\n",
      "Val RMSE: 65745.8640, Val MAE: 39354.5559, Val MSE: 4322518631.0577, Val R2: 0.7804\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.0916\n",
      "Val RMSE: 66496.9014, Val MAE: 38136.1888, Val MSE: 4421837893.7486, Val R2: 0.7753\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.0887\n",
      "Val RMSE: 65970.6500, Val MAE: 38360.3755, Val MSE: 4352126658.8912, Val R2: 0.7789\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.0913\n",
      "Val RMSE: 66236.6368, Val MAE: 39013.5419, Val MSE: 4387292059.9690, Val R2: 0.7771\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.0861\n",
      "Val RMSE: 64145.3169, Val MAE: 36176.1779, Val MSE: 4114621686.1711, Val R2: 0.7910\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.0917\n",
      "Val RMSE: 67376.1576, Val MAE: 37560.4663, Val MSE: 4539546617.1493, Val R2: 0.7694\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.0987\n",
      "Val RMSE: 71666.3045, Val MAE: 38799.9869, Val MSE: 5136059196.3080, Val R2: 0.7391\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.0939\n",
      "Val RMSE: 68770.9300, Val MAE: 39238.4789, Val MSE: 4729440810.6698, Val R2: 0.7597\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.0863\n",
      "Val RMSE: 65850.7913, Val MAE: 37242.9627, Val MSE: 4336326714.8837, Val R2: 0.7797\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0399, Val Loss: 0.0873\n",
      "Val RMSE: 64588.4536, Val MAE: 36974.3575, Val MSE: 4171668336.5841, Val R2: 0.7881\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0389, Val Loss: 0.0993\n",
      "Val RMSE: 70834.6970, Val MAE: 37926.2666, Val MSE: 5017554295.6301, Val R2: 0.7451\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0382, Val Loss: 0.0907\n",
      "Val RMSE: 66141.0819, Val MAE: 38585.0876, Val MSE: 4374642720.8631, Val R2: 0.7777\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0391, Val Loss: 0.0906\n",
      "Val RMSE: 66281.2123, Val MAE: 37429.8234, Val MSE: 4393199097.6464, Val R2: 0.7768\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0395, Val Loss: 0.0934\n",
      "Val RMSE: 67364.4460, Val MAE: 37130.8454, Val MSE: 4537968589.7199, Val R2: 0.7694\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0375, Val Loss: 0.0996\n",
      "Val RMSE: 69550.5411, Val MAE: 40105.4679, Val MSE: 4837277771.0591, Val R2: 0.7542\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 66561.5989, Test MAE: 36812.5796, Test MSE: 4430446448.7163, Test R2: 0.7160\n",
      "Inference Time: 1.957071744478666e-05 seconds per sample\n",
      "\n",
      "Iteration 45 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3387, Val Loss: 0.3003\n",
      "Val RMSE: 146586.8380, Val MAE: 82651.1313, Val MSE: 21487701075.4833, Val R2: -0.0917\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2835, Val Loss: 0.2820\n",
      "Val RMSE: 141628.4101, Val MAE: 85815.9147, Val MSE: 20058606541.9567, Val R2: -0.0191\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2752, Val Loss: 0.2779\n",
      "Val RMSE: 142631.9505, Val MAE: 82610.7518, Val MSE: 20343873302.5277, Val R2: -0.0336\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2686, Val Loss: 0.2761\n",
      "Val RMSE: 141955.8331, Val MAE: 83251.2008, Val MSE: 20151458546.6345, Val R2: -0.0238\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2744\n",
      "Val RMSE: 142094.4137, Val MAE: 82774.4134, Val MSE: 20190822416.7803, Val R2: -0.0258\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2605, Val Loss: 0.2755\n",
      "Val RMSE: 141817.7507, Val MAE: 84571.0168, Val MSE: 20112274399.8650, Val R2: -0.0218\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2777\n",
      "Val RMSE: 141503.7241, Val MAE: 86181.9896, Val MSE: 20023303922.2973, Val R2: -0.0173\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2748\n",
      "Val RMSE: 141927.2437, Val MAE: 83253.3917, Val MSE: 20143342504.2772, Val R2: -0.0234\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2552, Val Loss: 0.2753\n",
      "Val RMSE: 142547.0210, Val MAE: 82693.2329, Val MSE: 20319653204.6109, Val R2: -0.0324\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2584, Val Loss: 0.2668\n",
      "Val RMSE: 141144.4936, Val MAE: 80483.5363, Val MSE: 19921768074.4019, Val R2: -0.0122\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2632\n",
      "Val RMSE: 138465.5790, Val MAE: 81318.4017, Val MSE: 19172716557.7751, Val R2: 0.0259\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2456, Val Loss: 0.2578\n",
      "Val RMSE: 137521.7960, Val MAE: 76265.5529, Val MSE: 18912244380.5232, Val R2: 0.0391\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2429, Val Loss: 0.2596\n",
      "Val RMSE: 136594.7654, Val MAE: 80310.3428, Val MSE: 18658129944.4191, Val R2: 0.0520\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2410, Val Loss: 0.2540\n",
      "Val RMSE: 136611.8016, Val MAE: 77742.7044, Val MSE: 18662784323.4478, Val R2: 0.0518\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2400, Val Loss: 0.2569\n",
      "Val RMSE: 136004.7972, Val MAE: 79052.8913, Val MSE: 18497304857.7387, Val R2: 0.0602\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2385, Val Loss: 0.2531\n",
      "Val RMSE: 133514.3091, Val MAE: 78376.7452, Val MSE: 17826070736.4312, Val R2: 0.0943\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2288, Val Loss: 0.2318\n",
      "Val RMSE: 129155.0113, Val MAE: 76651.2564, Val MSE: 16681016935.7344, Val R2: 0.1525\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2216, Val Loss: 0.2331\n",
      "Val RMSE: 131385.0072, Val MAE: 72118.7364, Val MSE: 17262020106.8656, Val R2: 0.1230\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2258, Val Loss: 0.2502\n",
      "Val RMSE: 140373.8769, Val MAE: 73583.0966, Val MSE: 19704825304.0733, Val R2: -0.0011\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2333, Val Loss: 0.2531\n",
      "Val RMSE: 139311.9694, Val MAE: 75061.5715, Val MSE: 19407824805.2298, Val R2: 0.0140\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2314, Val Loss: 0.2462\n",
      "Val RMSE: 136104.3276, Val MAE: 77607.4590, Val MSE: 18524387990.9637, Val R2: 0.0588\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2266, Val Loss: 0.2423\n",
      "Val RMSE: 134860.4728, Val MAE: 77534.6317, Val MSE: 18187347135.2498, Val R2: 0.0760\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2222, Val Loss: 0.2372\n",
      "Val RMSE: 134406.6500, Val MAE: 71489.6887, Val MSE: 18065147571.9094, Val R2: 0.0822\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2169, Val Loss: 0.2379\n",
      "Val RMSE: 133771.3897, Val MAE: 71402.7245, Val MSE: 17894784703.3793, Val R2: 0.0908\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2183, Val Loss: 0.2318\n",
      "Val RMSE: 129695.9296, Val MAE: 73697.4837, Val MSE: 16821034150.8749, Val R2: 0.1454\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2128, Val Loss: 0.2497\n",
      "Val RMSE: 134972.4948, Val MAE: 71801.1535, Val MSE: 18217574345.1281, Val R2: 0.0744\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2080, Val Loss: 0.2270\n",
      "Val RMSE: 130319.9878, Val MAE: 69530.4161, Val MSE: 16983299213.9402, Val R2: 0.1371\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2028, Val Loss: 0.2214\n",
      "Val RMSE: 128042.1744, Val MAE: 68763.7367, Val MSE: 16394798430.4480, Val R2: 0.1670\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1972, Val Loss: 0.2094\n",
      "Val RMSE: 120283.5066, Val MAE: 68150.9153, Val MSE: 14468121966.3129, Val R2: 0.2649\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1937, Val Loss: 0.2064\n",
      "Val RMSE: 116049.1222, Val MAE: 68389.9920, Val MSE: 13467398773.2558, Val R2: 0.3158\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.1826\n",
      "Val RMSE: 105404.8593, Val MAE: 61990.6765, Val MSE: 11110184359.9148, Val R2: 0.4355\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1765, Val Loss: 0.1723\n",
      "Val RMSE: 100174.3453, Val MAE: 61284.7091, Val MSE: 10034899453.0646, Val R2: 0.4902\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1732, Val Loss: 0.1684\n",
      "Val RMSE: 99254.0538, Val MAE: 58876.5338, Val MSE: 9851367197.7067, Val R2: 0.4995\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1709, Val Loss: 0.1737\n",
      "Val RMSE: 100508.9957, Val MAE: 60845.3878, Val MSE: 10102058208.6374, Val R2: 0.4868\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1664, Val Loss: 0.1661\n",
      "Val RMSE: 98416.7196, Val MAE: 57572.3672, Val MSE: 9685850689.2480, Val R2: 0.5079\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1620, Val Loss: 0.1778\n",
      "Val RMSE: 100861.5973, Val MAE: 58653.4104, Val MSE: 10173061810.5344, Val R2: 0.4831\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1644, Val Loss: 0.1694\n",
      "Val RMSE: 99709.5869, Val MAE: 56915.7305, Val MSE: 9942001729.2991, Val R2: 0.4949\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1609, Val Loss: 0.1726\n",
      "Val RMSE: 99666.6169, Val MAE: 58199.6890, Val MSE: 9933434528.6833, Val R2: 0.4953\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1592, Val Loss: 0.1561\n",
      "Val RMSE: 96441.5257, Val MAE: 54745.3869, Val MSE: 9300967871.5791, Val R2: 0.5275\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1692\n",
      "Val RMSE: 100920.4750, Val MAE: 56434.1439, Val MSE: 10184942274.7333, Val R2: 0.4825\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1555, Val Loss: 0.1654\n",
      "Val RMSE: 96576.7435, Val MAE: 56794.6260, Val MSE: 9327067388.3458, Val R2: 0.5261\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1466, Val Loss: 0.1613\n",
      "Val RMSE: 98067.3523, Val MAE: 55048.0453, Val MSE: 9617205586.4921, Val R2: 0.5114\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1552\n",
      "Val RMSE: 96175.4621, Val MAE: 54855.2602, Val MSE: 9249719502.3105, Val R2: 0.5301\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1415, Val Loss: 0.1603\n",
      "Val RMSE: 96754.7637, Val MAE: 57149.8708, Val MSE: 9361484301.3390, Val R2: 0.5244\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1389, Val Loss: 0.1642\n",
      "Val RMSE: 94812.2256, Val MAE: 58029.1103, Val MSE: 8989358126.8059, Val R2: 0.5433\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1367, Val Loss: 0.1476\n",
      "Val RMSE: 94923.9601, Val MAE: 51909.8759, Val MSE: 9010558209.8729, Val R2: 0.5422\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1325, Val Loss: 0.1428\n",
      "Val RMSE: 92431.5634, Val MAE: 51259.5798, Val MSE: 8543593915.3020, Val R2: 0.5659\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1290, Val Loss: 0.1530\n",
      "Val RMSE: 93752.5383, Val MAE: 54380.5875, Val MSE: 8789538434.1951, Val R2: 0.5534\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1450\n",
      "Val RMSE: 92728.4107, Val MAE: 53360.6550, Val MSE: 8598558154.9543, Val R2: 0.5631\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1220, Val Loss: 0.1387\n",
      "Val RMSE: 90899.9304, Val MAE: 50991.8248, Val MSE: 8262797338.5689, Val R2: 0.5802\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1194, Val Loss: 0.1489\n",
      "Val RMSE: 94738.8953, Val MAE: 52729.1739, Val MSE: 8975458283.6603, Val R2: 0.5440\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1179, Val Loss: 0.1560\n",
      "Val RMSE: 96007.5249, Val MAE: 54997.6563, Val MSE: 9217444828.5374, Val R2: 0.5317\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1183, Val Loss: 0.1516\n",
      "Val RMSE: 95416.9530, Val MAE: 54316.9994, Val MSE: 9104394912.1905, Val R2: 0.5374\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1126, Val Loss: 0.1498\n",
      "Val RMSE: 93677.8187, Val MAE: 54779.8227, Val MSE: 8775533717.1952, Val R2: 0.5541\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1398\n",
      "Val RMSE: 90792.4648, Val MAE: 51067.3907, Val MSE: 8243271666.1182, Val R2: 0.5812\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1393\n",
      "Val RMSE: 90606.4429, Val MAE: 51955.9293, Val MSE: 8209527494.1295, Val R2: 0.5829\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1061, Val Loss: 0.1412\n",
      "Val RMSE: 90623.5752, Val MAE: 50229.8581, Val MSE: 8212632388.4350, Val R2: 0.5827\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1033, Val Loss: 0.1541\n",
      "Val RMSE: 95322.9034, Val MAE: 55257.2650, Val MSE: 9086455906.7247, Val R2: 0.5384\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0994, Val Loss: 0.1532\n",
      "Val RMSE: 94571.8947, Val MAE: 52531.2457, Val MSE: 8943843274.3916, Val R2: 0.5456\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0983, Val Loss: 0.1488\n",
      "Val RMSE: 94216.0893, Val MAE: 52464.5544, Val MSE: 8876671491.9110, Val R2: 0.5490\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0949, Val Loss: 0.1489\n",
      "Val RMSE: 92476.1844, Val MAE: 54422.5655, Val MSE: 8551844682.2821, Val R2: 0.5655\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0933, Val Loss: 0.1437\n",
      "Val RMSE: 91528.2631, Val MAE: 51868.8782, Val MSE: 8377422941.5885, Val R2: 0.5744\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0901, Val Loss: 0.1457\n",
      "Val RMSE: 91339.9526, Val MAE: 53857.4165, Val MSE: 8342986947.1951, Val R2: 0.5761\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1741\n",
      "Val RMSE: 96890.9969, Val MAE: 61620.7733, Val MSE: 9387865275.1239, Val R2: 0.5230\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1411\n",
      "Val RMSE: 86215.1409, Val MAE: 52536.9250, Val MSE: 7433050525.3681, Val R2: 0.6224\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1408\n",
      "Val RMSE: 89356.0473, Val MAE: 50842.3176, Val MSE: 7984503182.1400, Val R2: 0.5943\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1391\n",
      "Val RMSE: 86789.2404, Val MAE: 51731.6076, Val MSE: 7532372247.2280, Val R2: 0.6173\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0833, Val Loss: 0.1462\n",
      "Val RMSE: 91229.1130, Val MAE: 53128.0822, Val MSE: 8322751059.7085, Val R2: 0.5772\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1421\n",
      "Val RMSE: 89757.3494, Val MAE: 51201.3724, Val MSE: 8056381769.9435, Val R2: 0.5907\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1479\n",
      "Val RMSE: 91142.2039, Val MAE: 51963.4399, Val MSE: 8306901334.7477, Val R2: 0.5780\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1530\n",
      "Val RMSE: 89189.5596, Val MAE: 54274.6600, Val MSE: 7954777548.7233, Val R2: 0.5958\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1389\n",
      "Val RMSE: 87893.3635, Val MAE: 50200.4222, Val MSE: 7725243342.6952, Val R2: 0.6075\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1595\n",
      "Val RMSE: 93947.2592, Val MAE: 55270.9845, Val MSE: 8826087520.0984, Val R2: 0.5516\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1476\n",
      "Val RMSE: 89726.2289, Val MAE: 53027.3776, Val MSE: 8050796144.2734, Val R2: 0.5910\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1404\n",
      "Val RMSE: 84982.7299, Val MAE: 51045.4458, Val MSE: 7222064385.1280, Val R2: 0.6331\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1495\n",
      "Val RMSE: 90172.0903, Val MAE: 54112.9820, Val MSE: 8131005876.7911, Val R2: 0.5869\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1298\n",
      "Val RMSE: 80467.9942, Val MAE: 48224.9343, Val MSE: 6475098092.7935, Val R2: 0.6710\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0725, Val Loss: 0.1444\n",
      "Val RMSE: 89492.4855, Val MAE: 51213.1149, Val MSE: 8008904958.7697, Val R2: 0.5931\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1323\n",
      "Val RMSE: 80312.9880, Val MAE: 48432.4330, Val MSE: 6450176048.2199, Val R2: 0.6723\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1389\n",
      "Val RMSE: 84493.3093, Val MAE: 50170.9632, Val MSE: 7139119313.2047, Val R2: 0.6373\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1305\n",
      "Val RMSE: 79489.7858, Val MAE: 48347.1250, Val MSE: 6318626039.5650, Val R2: 0.6790\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1503\n",
      "Val RMSE: 83573.2846, Val MAE: 52778.7858, Val MSE: 6984493898.7179, Val R2: 0.6451\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1505\n",
      "Val RMSE: 85529.0301, Val MAE: 54616.0608, Val MSE: 7315214983.1121, Val R2: 0.6283\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1403\n",
      "Val RMSE: 82395.5124, Val MAE: 50985.6448, Val MSE: 6789020463.2363, Val R2: 0.6551\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1285\n",
      "Val RMSE: 79221.3676, Val MAE: 47920.4135, Val MSE: 6276025084.8531, Val R2: 0.6811\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1362\n",
      "Val RMSE: 82841.9704, Val MAE: 50228.3312, Val MSE: 6862792053.5786, Val R2: 0.6513\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1247\n",
      "Val RMSE: 77896.0387, Val MAE: 46971.7634, Val MSE: 6067792842.0230, Val R2: 0.6917\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1261\n",
      "Val RMSE: 78128.8757, Val MAE: 47045.1614, Val MSE: 6104121218.4023, Val R2: 0.6899\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1243\n",
      "Val RMSE: 77312.9004, Val MAE: 47511.1932, Val MSE: 5977284567.4783, Val R2: 0.6963\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0579, Val Loss: 0.1216\n",
      "Val RMSE: 76344.1842, Val MAE: 46565.5102, Val MSE: 5828434456.9450, Val R2: 0.7039\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1337\n",
      "Val RMSE: 79072.8026, Val MAE: 48677.1142, Val MSE: 6252508111.4254, Val R2: 0.6823\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1314\n",
      "Val RMSE: 80522.9220, Val MAE: 48585.4841, Val MSE: 6483940965.5486, Val R2: 0.6706\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1317\n",
      "Val RMSE: 80461.5573, Val MAE: 50123.0882, Val MSE: 6474062201.3467, Val R2: 0.6711\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1196\n",
      "Val RMSE: 77121.8427, Val MAE: 45598.2355, Val MSE: 5947778628.2644, Val R2: 0.6978\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1207\n",
      "Val RMSE: 78014.1740, Val MAE: 45281.4154, Val MSE: 6086211349.3594, Val R2: 0.6908\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1213\n",
      "Val RMSE: 77366.8565, Val MAE: 45748.2598, Val MSE: 5985630481.9883, Val R2: 0.6959\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1252\n",
      "Val RMSE: 78959.1061, Val MAE: 46418.1565, Val MSE: 6234540442.6591, Val R2: 0.6832\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1134\n",
      "Val RMSE: 75720.7316, Val MAE: 43785.0150, Val MSE: 5733629192.5397, Val R2: 0.7087\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1314\n",
      "Val RMSE: 80824.1716, Val MAE: 49713.6846, Val MSE: 6532546716.1156, Val R2: 0.6681\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1226\n",
      "Val RMSE: 76850.8101, Val MAE: 46358.6864, Val MSE: 5906047010.7884, Val R2: 0.6999\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76460.2049, Test MAE: 43247.4521, Test MSE: 5846162937.6689, Test R2: 0.6253\n",
      "Inference Time: 2.200020276583158e-05 seconds per sample\n",
      "\n",
      "Iteration 46 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3378, Val Loss: 0.2764\n",
      "Val RMSE: 140284.2921, Val MAE: 87637.0416, Val MSE: 19679682613.1345, Val R2: 0.0001\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2734, Val Loss: 0.2753\n",
      "Val RMSE: 141527.5461, Val MAE: 84007.6535, Val MSE: 20030046296.7425, Val R2: -0.0177\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2703, Val Loss: 0.2750\n",
      "Val RMSE: 141752.7542, Val MAE: 83192.6742, Val MSE: 20093843330.2604, Val R2: -0.0209\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2735\n",
      "Val RMSE: 141364.9411, Val MAE: 83784.0275, Val MSE: 19984046579.2323, Val R2: -0.0153\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2633, Val Loss: 0.2992\n",
      "Val RMSE: 143183.1632, Val MAE: 92260.7256, Val MSE: 20501418217.9505, Val R2: -0.0416\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2633, Val Loss: 0.2719\n",
      "Val RMSE: 140933.0234, Val MAE: 84254.8993, Val MSE: 19862117074.1381, Val R2: -0.0091\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2719\n",
      "Val RMSE: 141577.5739, Val MAE: 82050.2383, Val MSE: 20044209440.1388, Val R2: -0.0184\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2663\n",
      "Val RMSE: 140638.4254, Val MAE: 81422.6937, Val MSE: 19779166691.4664, Val R2: -0.0049\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2712\n",
      "Val RMSE: 141509.1506, Val MAE: 81141.0963, Val MSE: 20024839713.6226, Val R2: -0.0174\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2658\n",
      "Val RMSE: 140745.6686, Val MAE: 79598.9223, Val MSE: 19809343232.5333, Val R2: -0.0064\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2755\n",
      "Val RMSE: 140434.9743, Val MAE: 84818.9196, Val MSE: 19721982017.9194, Val R2: -0.0020\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2806\n",
      "Val RMSE: 141401.6609, Val MAE: 85287.7185, Val MSE: 19994429704.8689, Val R2: -0.0158\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2500, Val Loss: 0.2655\n",
      "Val RMSE: 139345.9448, Val MAE: 83289.1036, Val MSE: 19417292318.4949, Val R2: 0.0135\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2478, Val Loss: 0.2529\n",
      "Val RMSE: 136910.6984, Val MAE: 76299.7445, Val MSE: 18744539347.0267, Val R2: 0.0477\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2565\n",
      "Val RMSE: 136554.5469, Val MAE: 74852.1067, Val MSE: 18647144284.3852, Val R2: 0.0526\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2395, Val Loss: 0.2526\n",
      "Val RMSE: 136459.0514, Val MAE: 77393.0755, Val MSE: 18621072699.9826, Val R2: 0.0539\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2345, Val Loss: 0.2367\n",
      "Val RMSE: 131066.7978, Val MAE: 76940.4880, Val MSE: 17178505484.9696, Val R2: 0.1272\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2225, Val Loss: 0.2390\n",
      "Val RMSE: 130690.4228, Val MAE: 78138.1072, Val MSE: 17079986608.9496, Val R2: 0.1322\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2163, Val Loss: 0.2448\n",
      "Val RMSE: 130763.8742, Val MAE: 79622.6099, Val MSE: 17099190784.9211, Val R2: 0.1313\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2187, Val Loss: 0.2462\n",
      "Val RMSE: 135764.5566, Val MAE: 73021.2534, Val MSE: 18432014828.0335, Val R2: 0.0635\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2151, Val Loss: 0.2414\n",
      "Val RMSE: 134223.2706, Val MAE: 72815.2916, Val MSE: 18015886374.0352, Val R2: 0.0847\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2102, Val Loss: 0.2536\n",
      "Val RMSE: 140592.5656, Val MAE: 76664.6546, Val MSE: 19766269513.2933, Val R2: -0.0043\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2060, Val Loss: 0.2347\n",
      "Val RMSE: 129902.7841, Val MAE: 76999.3785, Val MSE: 16874733329.5735, Val R2: 0.1427\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2515, Val Loss: 0.2483\n",
      "Val RMSE: 135051.1198, Val MAE: 73142.1150, Val MSE: 18238804961.0884, Val R2: 0.0734\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2239, Val Loss: 0.2488\n",
      "Val RMSE: 136299.3625, Val MAE: 76477.0733, Val MSE: 18577516213.3733, Val R2: 0.0561\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2031, Val Loss: 0.2334\n",
      "Val RMSE: 131560.5401, Val MAE: 71035.7735, Val MSE: 17308175723.2035, Val R2: 0.1206\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1991, Val Loss: 0.2190\n",
      "Val RMSE: 124668.1000, Val MAE: 70962.4385, Val MSE: 15542135154.8907, Val R2: 0.2104\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1927, Val Loss: 0.2229\n",
      "Val RMSE: 125830.2395, Val MAE: 70638.5907, Val MSE: 15833249181.5132, Val R2: 0.1956\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1813, Val Loss: 0.2079\n",
      "Val RMSE: 119959.2553, Val MAE: 68369.4370, Val MSE: 14390222928.7192, Val R2: 0.2689\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1804, Val Loss: 0.2154\n",
      "Val RMSE: 119430.4927, Val MAE: 67669.5762, Val MSE: 14263642578.5751, Val R2: 0.2753\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1794, Val Loss: 0.2068\n",
      "Val RMSE: 117737.1868, Val MAE: 67055.7006, Val MSE: 13862045155.1047, Val R2: 0.2957\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1747, Val Loss: 0.1993\n",
      "Val RMSE: 111528.6086, Val MAE: 65432.7179, Val MSE: 12438630539.8380, Val R2: 0.3680\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1750, Val Loss: 0.1890\n",
      "Val RMSE: 108712.9137, Val MAE: 65582.5688, Val MSE: 11818497601.6237, Val R2: 0.3995\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1702, Val Loss: 0.1961\n",
      "Val RMSE: 111495.3410, Val MAE: 65888.8408, Val MSE: 12431211067.3144, Val R2: 0.3684\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1682, Val Loss: 0.1938\n",
      "Val RMSE: 107090.0293, Val MAE: 68397.9056, Val MSE: 11468274366.1437, Val R2: 0.4173\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1646, Val Loss: 0.1830\n",
      "Val RMSE: 104687.5116, Val MAE: 63519.8753, Val MSE: 10959475090.1248, Val R2: 0.4432\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1627, Val Loss: 0.1822\n",
      "Val RMSE: 104185.7244, Val MAE: 63533.1358, Val MSE: 10854665159.8293, Val R2: 0.4485\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1701\n",
      "Val RMSE: 100127.6219, Val MAE: 61430.4644, Val MSE: 10025540658.6911, Val R2: 0.4906\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1568, Val Loss: 0.1742\n",
      "Val RMSE: 101271.2921, Val MAE: 61388.3987, Val MSE: 10255874613.4413, Val R2: 0.4789\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1530, Val Loss: 0.1697\n",
      "Val RMSE: 100298.2168, Val MAE: 60317.1771, Val MSE: 10059732294.1558, Val R2: 0.4889\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1513, Val Loss: 0.1689\n",
      "Val RMSE: 101311.0880, Val MAE: 61854.8635, Val MSE: 10263936544.7049, Val R2: 0.4785\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1560, Val Loss: 0.1630\n",
      "Val RMSE: 99351.2514, Val MAE: 59456.6329, Val MSE: 9870671157.5314, Val R2: 0.4985\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1548, Val Loss: 0.1693\n",
      "Val RMSE: 101047.0918, Val MAE: 59876.1887, Val MSE: 10210514768.6065, Val R2: 0.4812\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1635\n",
      "Val RMSE: 98591.6031, Val MAE: 58133.6686, Val MSE: 9720304203.9048, Val R2: 0.5061\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1435, Val Loss: 0.1510\n",
      "Val RMSE: 95805.9522, Val MAE: 55196.2571, Val MSE: 9178780468.6536, Val R2: 0.5337\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1433, Val Loss: 0.1548\n",
      "Val RMSE: 96170.7180, Val MAE: 56394.2479, Val MSE: 9248806995.3153, Val R2: 0.5301\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1601\n",
      "Val RMSE: 96459.6687, Val MAE: 57341.2310, Val MSE: 9304467685.0913, Val R2: 0.5273\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1391, Val Loss: 0.1507\n",
      "Val RMSE: 94907.3745, Val MAE: 55534.0883, Val MSE: 9007409737.2910, Val R2: 0.5424\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1366, Val Loss: 0.1423\n",
      "Val RMSE: 92669.3445, Val MAE: 53565.3423, Val MSE: 8587607414.4330, Val R2: 0.5637\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1337, Val Loss: 0.1426\n",
      "Val RMSE: 93358.1948, Val MAE: 53404.2306, Val MSE: 8715752532.4487, Val R2: 0.5572\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1327, Val Loss: 0.1518\n",
      "Val RMSE: 94242.6914, Val MAE: 55505.2300, Val MSE: 8881684890.8865, Val R2: 0.5488\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1300, Val Loss: 0.1435\n",
      "Val RMSE: 93860.0650, Val MAE: 51509.1327, Val MSE: 8809711794.2113, Val R2: 0.5524\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1283, Val Loss: 0.1434\n",
      "Val RMSE: 93454.4382, Val MAE: 50774.3535, Val MSE: 8733732020.3681, Val R2: 0.5563\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1233, Val Loss: 0.1439\n",
      "Val RMSE: 93527.9770, Val MAE: 54622.8901, Val MSE: 8747482487.3598, Val R2: 0.5556\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1210, Val Loss: 0.1338\n",
      "Val RMSE: 90611.6818, Val MAE: 50579.5493, Val MSE: 8210476885.3067, Val R2: 0.5829\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1203, Val Loss: 0.1297\n",
      "Val RMSE: 88757.0385, Val MAE: 50826.5341, Val MSE: 7877811876.6468, Val R2: 0.5998\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1142, Val Loss: 0.1353\n",
      "Val RMSE: 91630.1280, Val MAE: 50003.4209, Val MSE: 8396080359.0566, Val R2: 0.5734\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1092, Val Loss: 0.1315\n",
      "Val RMSE: 90322.1664, Val MAE: 49405.5270, Val MSE: 8158093749.2036, Val R2: 0.5855\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1345\n",
      "Val RMSE: 90151.2481, Val MAE: 51665.6055, Val MSE: 8127247529.3158, Val R2: 0.5871\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1085, Val Loss: 0.1334\n",
      "Val RMSE: 91015.6987, Val MAE: 49749.5503, Val MSE: 8283857410.5612, Val R2: 0.5791\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1345\n",
      "Val RMSE: 91857.0028, Val MAE: 50547.0152, Val MSE: 8437708958.0198, Val R2: 0.5713\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1040, Val Loss: 0.1334\n",
      "Val RMSE: 90099.6221, Val MAE: 50856.9465, Val MSE: 8117941901.1042, Val R2: 0.5876\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1255\n",
      "Val RMSE: 88148.1337, Val MAE: 48248.9834, Val MSE: 7770093472.5320, Val R2: 0.6052\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0974, Val Loss: 0.1264\n",
      "Val RMSE: 88512.3120, Val MAE: 49005.6611, Val MSE: 7834429378.2820, Val R2: 0.6020\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0955, Val Loss: 0.1316\n",
      "Val RMSE: 90205.9321, Val MAE: 48762.3139, Val MSE: 8137110184.6023, Val R2: 0.5866\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1524\n",
      "Val RMSE: 91816.2904, Val MAE: 53246.6220, Val MSE: 8430231187.0278, Val R2: 0.5717\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0908, Val Loss: 0.1322\n",
      "Val RMSE: 90174.0985, Val MAE: 49015.5969, Val MSE: 8131368039.1850, Val R2: 0.5869\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1282\n",
      "Val RMSE: 88863.2830, Val MAE: 48437.8784, Val MSE: 7896683068.4520, Val R2: 0.5988\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0875, Val Loss: 0.1477\n",
      "Val RMSE: 92552.6474, Val MAE: 54591.0582, Val MSE: 8565992536.2791, Val R2: 0.5648\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0865, Val Loss: 0.1293\n",
      "Val RMSE: 86984.1364, Val MAE: 51676.3809, Val MSE: 7566239990.2868, Val R2: 0.6156\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1290\n",
      "Val RMSE: 86643.7512, Val MAE: 47876.9049, Val MSE: 7507139613.3919, Val R2: 0.6186\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1314\n",
      "Val RMSE: 87979.0192, Val MAE: 47585.7211, Val MSE: 7740307820.0366, Val R2: 0.6067\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1276\n",
      "Val RMSE: 86425.4891, Val MAE: 48368.2537, Val MSE: 7469365173.1148, Val R2: 0.6205\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0820, Val Loss: 0.1303\n",
      "Val RMSE: 86256.3205, Val MAE: 48445.2931, Val MSE: 7440152818.8657, Val R2: 0.6220\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1393\n",
      "Val RMSE: 87346.4708, Val MAE: 52960.7893, Val MSE: 7629405968.8848, Val R2: 0.6124\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1309\n",
      "Val RMSE: 84274.8526, Val MAE: 50998.9042, Val MSE: 7102250779.6486, Val R2: 0.6392\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1324\n",
      "Val RMSE: 85298.8741, Val MAE: 51659.9918, Val MSE: 7275897914.5753, Val R2: 0.6303\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1305\n",
      "Val RMSE: 85253.3577, Val MAE: 46664.4273, Val MSE: 7268135000.9983, Val R2: 0.6307\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.1339\n",
      "Val RMSE: 86264.6366, Val MAE: 48505.2784, Val MSE: 7441587535.4406, Val R2: 0.6219\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1206\n",
      "Val RMSE: 82731.6465, Val MAE: 47511.3023, Val MSE: 6844525325.1912, Val R2: 0.6523\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1202\n",
      "Val RMSE: 81718.4238, Val MAE: 45422.9536, Val MSE: 6677900796.0126, Val R2: 0.6607\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1360\n",
      "Val RMSE: 86824.5007, Val MAE: 53255.1364, Val MSE: 7538493928.6724, Val R2: 0.6170\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1188\n",
      "Val RMSE: 81457.3050, Val MAE: 45247.9029, Val MSE: 6635292537.4204, Val R2: 0.6629\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1348\n",
      "Val RMSE: 84965.5545, Val MAE: 48350.0875, Val MSE: 7219145459.2579, Val R2: 0.6332\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1182\n",
      "Val RMSE: 79606.0831, Val MAE: 46468.6978, Val MSE: 6337128468.3333, Val R2: 0.6780\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1357\n",
      "Val RMSE: 86323.4805, Val MAE: 48399.9179, Val MSE: 7451743292.1473, Val R2: 0.6214\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1248\n",
      "Val RMSE: 82673.4502, Val MAE: 47812.0886, Val MSE: 6834899371.6287, Val R2: 0.6527\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1267\n",
      "Val RMSE: 82638.2148, Val MAE: 47354.6071, Val MSE: 6829074551.2627, Val R2: 0.6530\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0671, Val Loss: 0.1326\n",
      "Val RMSE: 85187.5041, Val MAE: 47330.1257, Val MSE: 7256910856.1438, Val R2: 0.6313\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1243\n",
      "Val RMSE: 81677.1821, Val MAE: 46059.8028, Val MSE: 6671162070.7321, Val R2: 0.6611\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1327\n",
      "Val RMSE: 84109.6280, Val MAE: 47429.1976, Val MSE: 7074429523.6401, Val R2: 0.6406\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1274\n",
      "Val RMSE: 82018.2137, Val MAE: 47188.9492, Val MSE: 6726987384.9244, Val R2: 0.6582\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1304\n",
      "Val RMSE: 83155.7780, Val MAE: 48754.3094, Val MSE: 6914883406.8654, Val R2: 0.6487\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1385\n",
      "Val RMSE: 84684.1735, Val MAE: 52334.1785, Val MSE: 7171409247.1002, Val R2: 0.6356\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0644, Val Loss: 0.1227\n",
      "Val RMSE: 79022.5526, Val MAE: 47883.9863, Val MSE: 6244563819.2785, Val R2: 0.6827\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1339\n",
      "Val RMSE: 83686.6262, Val MAE: 50158.5380, Val MSE: 7003451410.1937, Val R2: 0.6442\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1285\n",
      "Val RMSE: 83577.5903, Val MAE: 49196.2328, Val MSE: 6985213593.3486, Val R2: 0.6451\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1370\n",
      "Val RMSE: 86003.5501, Val MAE: 47777.2370, Val MSE: 7396610621.4600, Val R2: 0.6242\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1164\n",
      "Val RMSE: 78244.1408, Val MAE: 44822.4311, Val MSE: 6122145574.5964, Val R2: 0.6890\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1292\n",
      "Val RMSE: 82559.6869, Val MAE: 48444.6986, Val MSE: 6816101904.1255, Val R2: 0.6537\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 87448.2415, Test MAE: 50077.1915, Test MSE: 7647194932.8449, Test R2: 0.5098\n",
      "Inference Time: 1.826924544114333e-05 seconds per sample\n",
      "\n",
      "Iteration 47 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3653, Val Loss: 0.2888\n",
      "Val RMSE: 143626.0581, Val MAE: 83908.0730, Val MSE: 20628444573.7374, Val R2: -0.0481\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2797, Val Loss: 0.2848\n",
      "Val RMSE: 142698.0162, Val MAE: 84280.4593, Val MSE: 20362723827.6693, Val R2: -0.0346\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2773\n",
      "Val RMSE: 142154.0776, Val MAE: 82818.5347, Val MSE: 20207781788.0068, Val R2: -0.0267\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2694, Val Loss: 0.2741\n",
      "Val RMSE: 141101.5041, Val MAE: 84044.0697, Val MSE: 19909634456.7200, Val R2: -0.0115\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2767\n",
      "Val RMSE: 141022.0701, Val MAE: 86244.5993, Val MSE: 19887224267.9551, Val R2: -0.0104\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2615, Val Loss: 0.2740\n",
      "Val RMSE: 142543.2609, Val MAE: 82496.2460, Val MSE: 20318581215.0190, Val R2: -0.0323\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2755\n",
      "Val RMSE: 140989.9771, Val MAE: 85290.3861, Val MSE: 19878173634.2112, Val R2: -0.0099\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2732\n",
      "Val RMSE: 142193.0225, Val MAE: 81254.2956, Val MSE: 20218855636.5503, Val R2: -0.0272\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2577, Val Loss: 0.2698\n",
      "Val RMSE: 141394.7878, Val MAE: 81722.9576, Val MSE: 19992486007.9339, Val R2: -0.0157\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2552, Val Loss: 0.2702\n",
      "Val RMSE: 140547.9239, Val MAE: 83796.3288, Val MSE: 19753718911.4696, Val R2: -0.0036\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2558, Val Loss: 0.2715\n",
      "Val RMSE: 141149.7534, Val MAE: 82865.6251, Val MSE: 19923252878.3623, Val R2: -0.0122\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2684\n",
      "Val RMSE: 140228.7324, Val MAE: 82214.2697, Val MSE: 19664097380.1678, Val R2: 0.0009\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2684\n",
      "Val RMSE: 138174.6331, Val MAE: 83163.8268, Val MSE: 19092229228.7104, Val R2: 0.0300\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2451, Val Loss: 0.2556\n",
      "Val RMSE: 134982.9612, Val MAE: 79629.7130, Val MSE: 18220399820.0175, Val R2: 0.0743\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2414, Val Loss: 0.2586\n",
      "Val RMSE: 134498.1626, Val MAE: 80954.3162, Val MSE: 18089755737.6812, Val R2: 0.0809\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2450, Val Loss: 0.2663\n",
      "Val RMSE: 135873.2260, Val MAE: 81839.7338, Val MSE: 18461533544.4229, Val R2: 0.0620\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2386, Val Loss: 0.2562\n",
      "Val RMSE: 134853.2991, Val MAE: 80098.8092, Val MSE: 18185412277.4116, Val R2: 0.0761\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2349, Val Loss: 0.2349\n",
      "Val RMSE: 131254.7458, Val MAE: 73214.2106, Val MSE: 17227808291.0863, Val R2: 0.1247\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2229, Val Loss: 0.2429\n",
      "Val RMSE: 131946.3451, Val MAE: 75246.7155, Val MSE: 17409837993.7631, Val R2: 0.1155\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2180, Val Loss: 0.2287\n",
      "Val RMSE: 129606.8390, Val MAE: 73801.9246, Val MSE: 16797932717.7134, Val R2: 0.1466\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2128, Val Loss: 0.2332\n",
      "Val RMSE: 129877.7184, Val MAE: 74444.8445, Val MSE: 16868221726.8346, Val R2: 0.1430\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2289\n",
      "Val RMSE: 129419.1491, Val MAE: 74036.8501, Val MSE: 16749316152.9965, Val R2: 0.1490\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2293\n",
      "Val RMSE: 130165.2249, Val MAE: 72688.3886, Val MSE: 16942985774.2680, Val R2: 0.1392\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2070, Val Loss: 0.2322\n",
      "Val RMSE: 131647.3923, Val MAE: 72140.7660, Val MSE: 17331035910.9827, Val R2: 0.1195\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2068, Val Loss: 0.2291\n",
      "Val RMSE: 124737.6099, Val MAE: 78117.5592, Val MSE: 15559471325.6786, Val R2: 0.2095\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2001, Val Loss: 0.2214\n",
      "Val RMSE: 125545.3518, Val MAE: 70544.9246, Val MSE: 15761635363.4708, Val R2: 0.1992\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1939, Val Loss: 0.2158\n",
      "Val RMSE: 120000.9869, Val MAE: 67736.7761, Val MSE: 14400236863.3188, Val R2: 0.2684\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1850, Val Loss: 0.1899\n",
      "Val RMSE: 107770.1821, Val MAE: 63149.7058, Val MSE: 11614412152.9888, Val R2: 0.4099\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1787, Val Loss: 0.2072\n",
      "Val RMSE: 111464.3707, Val MAE: 67505.2494, Val MSE: 12424305932.7269, Val R2: 0.3688\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.1891\n",
      "Val RMSE: 104371.8696, Val MAE: 63670.6006, Val MSE: 10893487162.2876, Val R2: 0.4465\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1673, Val Loss: 0.1687\n",
      "Val RMSE: 99187.7345, Val MAE: 61295.6437, Val MSE: 9838206673.1130, Val R2: 0.5002\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1628, Val Loss: 0.1705\n",
      "Val RMSE: 100409.4979, Val MAE: 61776.0736, Val MSE: 10082067277.6650, Val R2: 0.4878\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1597, Val Loss: 0.1715\n",
      "Val RMSE: 100168.3148, Val MAE: 60175.3172, Val MSE: 10033691291.3196, Val R2: 0.4902\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1553, Val Loss: 0.1601\n",
      "Val RMSE: 99002.0091, Val MAE: 57362.1315, Val MSE: 9801397812.4539, Val R2: 0.5020\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1542, Val Loss: 0.1752\n",
      "Val RMSE: 102085.1043, Val MAE: 60662.6132, Val MSE: 10421368518.2054, Val R2: 0.4705\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1546, Val Loss: 0.1738\n",
      "Val RMSE: 101585.8342, Val MAE: 58397.3746, Val MSE: 10319681708.4555, Val R2: 0.4757\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1471, Val Loss: 0.1627\n",
      "Val RMSE: 98262.7516, Val MAE: 55194.8684, Val MSE: 9655568355.7250, Val R2: 0.5094\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1627\n",
      "Val RMSE: 95981.4871, Val MAE: 57925.2213, Val MSE: 9212445863.9752, Val R2: 0.5319\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1339, Val Loss: 0.1500\n",
      "Val RMSE: 93378.0233, Val MAE: 57695.9774, Val MSE: 8719455227.1080, Val R2: 0.5570\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1302, Val Loss: 0.1382\n",
      "Val RMSE: 91372.3889, Val MAE: 51556.9506, Val MSE: 8348913450.2024, Val R2: 0.5758\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1245, Val Loss: 0.1722\n",
      "Val RMSE: 98196.6659, Val MAE: 57388.6179, Val MSE: 9642585189.2785, Val R2: 0.5101\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1203, Val Loss: 0.1504\n",
      "Val RMSE: 95892.9789, Val MAE: 52318.3376, Val MSE: 9195463407.4825, Val R2: 0.5328\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1153, Val Loss: 0.1332\n",
      "Val RMSE: 89664.3012, Val MAE: 49176.0033, Val MSE: 8039686914.8868, Val R2: 0.5915\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1408\n",
      "Val RMSE: 92172.7362, Val MAE: 49770.8366, Val MSE: 8495813295.4962, Val R2: 0.5684\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1099, Val Loss: 0.1278\n",
      "Val RMSE: 88259.3792, Val MAE: 49053.3571, Val MSE: 7789718016.0663, Val R2: 0.6042\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1047, Val Loss: 0.1388\n",
      "Val RMSE: 91754.1474, Val MAE: 49230.0392, Val MSE: 8418823561.0827, Val R2: 0.5723\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1350\n",
      "Val RMSE: 89021.8493, Val MAE: 49933.6288, Val MSE: 7924889655.7017, Val R2: 0.5974\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0983, Val Loss: 0.1437\n",
      "Val RMSE: 92318.7799, Val MAE: 52212.2998, Val MSE: 8522757131.3477, Val R2: 0.5670\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1373\n",
      "Val RMSE: 91273.5339, Val MAE: 51285.5798, Val MSE: 8330857994.1888, Val R2: 0.5767\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1335\n",
      "Val RMSE: 90067.9126, Val MAE: 46425.1126, Val MSE: 8112228884.5853, Val R2: 0.5878\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1328\n",
      "Val RMSE: 87348.4784, Val MAE: 48564.6033, Val MSE: 7629756687.2737, Val R2: 0.6124\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0866, Val Loss: 0.1304\n",
      "Val RMSE: 88734.9528, Val MAE: 50423.8533, Val MSE: 7873891850.5928, Val R2: 0.6000\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0875, Val Loss: 0.1548\n",
      "Val RMSE: 91645.9741, Val MAE: 54757.8089, Val MSE: 8398984571.2307, Val R2: 0.5733\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1238\n",
      "Val RMSE: 83830.3104, Val MAE: 45971.6221, Val MSE: 7027520949.8750, Val R2: 0.6430\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1357\n",
      "Val RMSE: 87138.7272, Val MAE: 46500.1143, Val MSE: 7593157776.1188, Val R2: 0.6142\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1309\n",
      "Val RMSE: 84771.1583, Val MAE: 47086.1373, Val MSE: 7186149278.1334, Val R2: 0.6349\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0760, Val Loss: 0.1309\n",
      "Val RMSE: 85993.3005, Val MAE: 45828.3958, Val MSE: 7394847724.0230, Val R2: 0.6243\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1252\n",
      "Val RMSE: 82170.4339, Val MAE: 46166.9923, Val MSE: 6751980201.5408, Val R2: 0.6570\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1304\n",
      "Val RMSE: 83373.5336, Val MAE: 46146.0531, Val MSE: 6951146112.1829, Val R2: 0.6468\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1527\n",
      "Val RMSE: 84845.5466, Val MAE: 53956.7454, Val MSE: 7198766781.3152, Val R2: 0.6343\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0733, Val Loss: 0.1358\n",
      "Val RMSE: 79054.0594, Val MAE: 49120.8744, Val MSE: 6249544312.1681, Val R2: 0.6825\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0710, Val Loss: 0.1299\n",
      "Val RMSE: 79560.6673, Val MAE: 46700.1262, Val MSE: 6329899782.3212, Val R2: 0.6784\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1192\n",
      "Val RMSE: 77050.8159, Val MAE: 44650.3925, Val MSE: 5936828227.2641, Val R2: 0.6984\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0649, Val Loss: 0.1261\n",
      "Val RMSE: 80233.8917, Val MAE: 44527.1763, Val MSE: 6437477381.1959, Val R2: 0.6729\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.1175\n",
      "Val RMSE: 79080.5295, Val MAE: 44000.1216, Val MSE: 6253730144.7597, Val R2: 0.6823\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1264\n",
      "Val RMSE: 81644.3657, Val MAE: 44942.5983, Val MSE: 6665802446.8010, Val R2: 0.6613\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.1231\n",
      "Val RMSE: 80807.6646, Val MAE: 44608.8879, Val MSE: 6529878656.5754, Val R2: 0.6682\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1268\n",
      "Val RMSE: 81293.0065, Val MAE: 47508.3692, Val MSE: 6608552901.1551, Val R2: 0.6642\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1251\n",
      "Val RMSE: 81183.6165, Val MAE: 44945.1851, Val MSE: 6590779586.3707, Val R2: 0.6651\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1092\n",
      "Val RMSE: 73610.2572, Val MAE: 41260.5095, Val MSE: 5418469963.3113, Val R2: 0.7247\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.1126\n",
      "Val RMSE: 74767.4974, Val MAE: 42767.3958, Val MSE: 5590178669.3695, Val R2: 0.7160\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1257\n",
      "Val RMSE: 80770.3977, Val MAE: 44913.5867, Val MSE: 6523857152.1431, Val R2: 0.6685\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1252\n",
      "Val RMSE: 82483.7833, Val MAE: 43551.0609, Val MSE: 6803574499.8546, Val R2: 0.6543\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1308\n",
      "Val RMSE: 80269.4857, Val MAE: 45472.4695, Val MSE: 6443190329.3927, Val R2: 0.6726\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1229\n",
      "Val RMSE: 77753.6678, Val MAE: 44393.4944, Val MSE: 6045632863.9858, Val R2: 0.6928\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1192\n",
      "Val RMSE: 77265.4450, Val MAE: 43309.8310, Val MSE: 5969948991.6224, Val R2: 0.6967\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1300\n",
      "Val RMSE: 81362.7497, Val MAE: 45696.2837, Val MSE: 6619897032.5801, Val R2: 0.6637\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1353\n",
      "Val RMSE: 80962.0988, Val MAE: 47388.8541, Val MSE: 6554861442.0758, Val R2: 0.6670\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1251\n",
      "Val RMSE: 78300.2981, Val MAE: 44994.0805, Val MSE: 6130936675.6158, Val R2: 0.6885\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1191\n",
      "Val RMSE: 77578.0482, Val MAE: 43824.0752, Val MSE: 6018353559.0857, Val R2: 0.6942\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1187\n",
      "Val RMSE: 76526.7854, Val MAE: 43197.4185, Val MSE: 5856348889.2713, Val R2: 0.7025\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1125\n",
      "Val RMSE: 76085.1429, Val MAE: 41704.3001, Val MSE: 5788948977.3254, Val R2: 0.7059\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1467\n",
      "Val RMSE: 84153.1539, Val MAE: 48138.6695, Val MSE: 7081753316.8263, Val R2: 0.6402\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1157\n",
      "Val RMSE: 76707.1712, Val MAE: 43117.3456, Val MSE: 5883990110.7513, Val R2: 0.7011\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1175\n",
      "Val RMSE: 77141.8168, Val MAE: 43035.1787, Val MSE: 5950859898.2939, Val R2: 0.6977\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1187\n",
      "Val RMSE: 79124.9408, Val MAE: 42444.0631, Val MSE: 6260756258.7850, Val R2: 0.6819\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1153\n",
      "Val RMSE: 78441.0921, Val MAE: 41910.9093, Val MSE: 6153004932.2353, Val R2: 0.6874\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1136\n",
      "Val RMSE: 76660.9372, Val MAE: 41970.2429, Val MSE: 5876899285.3916, Val R2: 0.7014\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1266\n",
      "Val RMSE: 81441.4159, Val MAE: 44576.4514, Val MSE: 6632704226.8617, Val R2: 0.6630\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1134\n",
      "Val RMSE: 75494.5092, Val MAE: 42001.8907, Val MSE: 5699420919.3189, Val R2: 0.7104\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1161\n",
      "Val RMSE: 77344.1544, Val MAE: 42116.6036, Val MSE: 5982118216.7030, Val R2: 0.6961\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.1202\n",
      "Val RMSE: 79624.7954, Val MAE: 44669.6510, Val MSE: 6340108048.6157, Val R2: 0.6779\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1184\n",
      "Val RMSE: 79473.3823, Val MAE: 43191.2096, Val MSE: 6316018487.1133, Val R2: 0.6791\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1083\n",
      "Val RMSE: 75035.2279, Val MAE: 40624.4204, Val MSE: 5630285423.4186, Val R2: 0.7139\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1067\n",
      "Val RMSE: 75104.1288, Val MAE: 39891.6872, Val MSE: 5640630162.9076, Val R2: 0.7134\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1196\n",
      "Val RMSE: 78374.3677, Val MAE: 43570.3185, Val MSE: 6142541509.3791, Val R2: 0.6879\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.1046\n",
      "Val RMSE: 74038.6679, Val MAE: 39682.0607, Val MSE: 5481724341.1344, Val R2: 0.7215\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.1261\n",
      "Val RMSE: 80049.6052, Val MAE: 44014.7915, Val MSE: 6407939293.6140, Val R2: 0.6744\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1226\n",
      "Val RMSE: 77674.1168, Val MAE: 43672.9780, Val MSE: 6033268412.9737, Val R2: 0.6935\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.1259\n",
      "Val RMSE: 82131.9736, Val MAE: 44534.5857, Val MSE: 6745661081.9651, Val R2: 0.6573\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 78804.5979, Test MAE: 43292.3650, Test MSE: 6210164656.5194, Test R2: 0.6019\n",
      "Inference Time: 1.866780794583834e-05 seconds per sample\n",
      "\n",
      "Iteration 48 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3552, Val Loss: 0.2982\n",
      "Val RMSE: 146337.4460, Val MAE: 82237.6924, Val MSE: 21414648101.3590, Val R2: -0.0880\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2803, Val Loss: 0.2836\n",
      "Val RMSE: 143454.4009, Val MAE: 82119.8339, Val MSE: 20579165145.6041, Val R2: -0.0456\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2720, Val Loss: 0.2764\n",
      "Val RMSE: 142317.0949, Val MAE: 82663.3875, Val MSE: 20254155487.2684, Val R2: -0.0290\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2690, Val Loss: 0.2745\n",
      "Val RMSE: 141372.1554, Val MAE: 83945.2967, Val MSE: 19986086311.3854, Val R2: -0.0154\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2769\n",
      "Val RMSE: 142283.0522, Val MAE: 82348.6600, Val MSE: 20244466931.9029, Val R2: -0.0285\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2765\n",
      "Val RMSE: 141162.6886, Val MAE: 85333.6045, Val MSE: 19926904638.7952, Val R2: -0.0124\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2584, Val Loss: 0.2804\n",
      "Val RMSE: 143063.6082, Val MAE: 81222.4259, Val MSE: 20467195992.7173, Val R2: -0.0399\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2569, Val Loss: 0.2800\n",
      "Val RMSE: 143633.7569, Val MAE: 80118.2933, Val MSE: 20630656121.9389, Val R2: -0.0482\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2699\n",
      "Val RMSE: 141169.5389, Val MAE: 82047.5451, Val MSE: 19928838704.5699, Val R2: -0.0125\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2691\n",
      "Val RMSE: 140628.8283, Val MAE: 82000.9969, Val MSE: 19776467346.8907, Val R2: -0.0048\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2509, Val Loss: 0.2636\n",
      "Val RMSE: 140079.4904, Val MAE: 79017.3527, Val MSE: 19622263625.2013, Val R2: 0.0031\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2405, Val Loss: 0.2819\n",
      "Val RMSE: 143445.4365, Val MAE: 77220.0473, Val MSE: 20576593260.8105, Val R2: -0.0454\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2412, Val Loss: 0.2532\n",
      "Val RMSE: 134847.5502, Val MAE: 78634.3430, Val MSE: 18183861797.3415, Val R2: 0.0761\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2311, Val Loss: 0.2484\n",
      "Val RMSE: 132480.8904, Val MAE: 78342.8594, Val MSE: 17551186314.5614, Val R2: 0.1083\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2239, Val Loss: 0.2528\n",
      "Val RMSE: 134088.1376, Val MAE: 78372.7953, Val MSE: 17979628638.1916, Val R2: 0.0865\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2191, Val Loss: 0.2389\n",
      "Val RMSE: 134527.4114, Val MAE: 73999.0531, Val MSE: 18097624429.6805, Val R2: 0.0805\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2157, Val Loss: 0.2393\n",
      "Val RMSE: 133705.0314, Val MAE: 73983.1479, Val MSE: 17877035417.7137, Val R2: 0.0917\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2089, Val Loss: 0.2339\n",
      "Val RMSE: 130396.8921, Val MAE: 72956.4497, Val MSE: 17003349478.6688, Val R2: 0.1361\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2295\n",
      "Val RMSE: 125908.7510, Val MAE: 74765.9477, Val MSE: 15853013568.4670, Val R2: 0.1946\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.1928, Val Loss: 0.2205\n",
      "Val RMSE: 122791.2095, Val MAE: 68948.9559, Val MSE: 15077681124.3658, Val R2: 0.2340\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1821, Val Loss: 0.1963\n",
      "Val RMSE: 111863.6626, Val MAE: 65431.2450, Val MSE: 12513479016.6275, Val R2: 0.3642\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1754, Val Loss: 0.1889\n",
      "Val RMSE: 105965.2868, Val MAE: 67673.7382, Val MSE: 11228641997.9050, Val R2: 0.4295\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1847\n",
      "Val RMSE: 103456.7087, Val MAE: 65350.8904, Val MSE: 10703290570.6986, Val R2: 0.4562\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1635, Val Loss: 0.1714\n",
      "Val RMSE: 100592.6360, Val MAE: 60790.2272, Val MSE: 10118878417.7657, Val R2: 0.4859\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1576, Val Loss: 0.1771\n",
      "Val RMSE: 102366.5166, Val MAE: 62683.2477, Val MSE: 10478903712.1261, Val R2: 0.4676\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1540, Val Loss: 0.1697\n",
      "Val RMSE: 101867.6504, Val MAE: 57831.2272, Val MSE: 10377018196.9285, Val R2: 0.4728\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1668\n",
      "Val RMSE: 100834.8376, Val MAE: 58114.3728, Val MSE: 10167664466.7266, Val R2: 0.4834\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1500, Val Loss: 0.1613\n",
      "Val RMSE: 98501.2093, Val MAE: 57052.1691, Val MSE: 9702488237.3899, Val R2: 0.5071\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1448, Val Loss: 0.1641\n",
      "Val RMSE: 96535.0172, Val MAE: 57314.2959, Val MSE: 9319009546.5974, Val R2: 0.5265\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1419, Val Loss: 0.1597\n",
      "Val RMSE: 98238.1230, Val MAE: 56348.0611, Val MSE: 9650728812.8976, Val R2: 0.5097\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1394, Val Loss: 0.1550\n",
      "Val RMSE: 97613.0935, Val MAE: 54064.2919, Val MSE: 9528316023.8472, Val R2: 0.5159\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1587\n",
      "Val RMSE: 95377.9404, Val MAE: 56644.1038, Val MSE: 9096951516.2753, Val R2: 0.5378\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1273, Val Loss: 0.1476\n",
      "Val RMSE: 95567.3533, Val MAE: 52396.1251, Val MSE: 9133119010.7585, Val R2: 0.5360\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1199, Val Loss: 0.1402\n",
      "Val RMSE: 94361.2031, Val MAE: 49896.9631, Val MSE: 8904036642.4742, Val R2: 0.5476\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1425\n",
      "Val RMSE: 94521.9095, Val MAE: 49665.5611, Val MSE: 8934391372.7884, Val R2: 0.5461\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1138, Val Loss: 0.1269\n",
      "Val RMSE: 89755.8370, Val MAE: 47216.3760, Val MSE: 8056110270.8715, Val R2: 0.5907\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1095, Val Loss: 0.1303\n",
      "Val RMSE: 92228.6843, Val MAE: 47547.4614, Val MSE: 8506130205.4129, Val R2: 0.5678\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1064, Val Loss: 0.1362\n",
      "Val RMSE: 91688.7323, Val MAE: 49421.2264, Val MSE: 8406823626.8441, Val R2: 0.5729\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1031, Val Loss: 0.1284\n",
      "Val RMSE: 91745.5611, Val MAE: 47340.6169, Val MSE: 8417247988.1610, Val R2: 0.5724\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0979, Val Loss: 0.1280\n",
      "Val RMSE: 90756.8413, Val MAE: 45713.8674, Val MSE: 8236804248.0532, Val R2: 0.5815\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0962, Val Loss: 0.1252\n",
      "Val RMSE: 87705.3459, Val MAE: 46177.4111, Val MSE: 7692227706.4788, Val R2: 0.6092\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1104\n",
      "Val RMSE: 85620.5522, Val MAE: 42711.1394, Val MSE: 7330878957.3234, Val R2: 0.6275\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0928, Val Loss: 0.1232\n",
      "Val RMSE: 88430.0389, Val MAE: 46727.0889, Val MSE: 7819871787.0543, Val R2: 0.6027\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1140\n",
      "Val RMSE: 83683.7736, Val MAE: 43236.4197, Val MSE: 7002973969.4683, Val R2: 0.6442\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1161\n",
      "Val RMSE: 84682.4635, Val MAE: 43459.7556, Val MSE: 7171119616.9237, Val R2: 0.6357\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1132\n",
      "Val RMSE: 79552.4198, Val MAE: 43594.5388, Val MSE: 6328587496.4176, Val R2: 0.6785\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1102\n",
      "Val RMSE: 78011.6395, Val MAE: 42673.9499, Val MSE: 6085815889.9878, Val R2: 0.6908\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1041\n",
      "Val RMSE: 73915.0896, Val MAE: 42625.1041, Val MSE: 5463440476.8040, Val R2: 0.7224\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.0979\n",
      "Val RMSE: 70747.0550, Val MAE: 43299.1379, Val MSE: 5005145787.4630, Val R2: 0.7457\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1019\n",
      "Val RMSE: 71736.6203, Val MAE: 41652.1104, Val MSE: 5146142690.0582, Val R2: 0.7385\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0749, Val Loss: 0.1083\n",
      "Val RMSE: 73609.1148, Val MAE: 43959.0217, Val MSE: 5418301783.0500, Val R2: 0.7247\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1028\n",
      "Val RMSE: 72469.8612, Val MAE: 41178.3701, Val MSE: 5251880788.5682, Val R2: 0.7332\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1175\n",
      "Val RMSE: 82447.4088, Val MAE: 45261.3998, Val MSE: 6797575223.6441, Val R2: 0.6546\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.0915\n",
      "Val RMSE: 68501.7069, Val MAE: 38600.3281, Val MSE: 4692483843.0194, Val R2: 0.7616\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0664, Val Loss: 0.1029\n",
      "Val RMSE: 73643.6660, Val MAE: 39646.7645, Val MSE: 5423389539.1438, Val R2: 0.7245\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.0964\n",
      "Val RMSE: 70450.5711, Val MAE: 40433.0458, Val MSE: 4963282969.1216, Val R2: 0.7478\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.0970\n",
      "Val RMSE: 70152.8677, Val MAE: 40450.5246, Val MSE: 4921424842.6109, Val R2: 0.7500\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1129\n",
      "Val RMSE: 77460.1012, Val MAE: 42630.8699, Val MSE: 6000067274.1562, Val R2: 0.6952\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1054\n",
      "Val RMSE: 75645.6776, Val MAE: 41053.7149, Val MSE: 5722268538.7454, Val R2: 0.7093\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.0913\n",
      "Val RMSE: 69725.9825, Val MAE: 37843.9331, Val MSE: 4861712632.7707, Val R2: 0.7530\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.0916\n",
      "Val RMSE: 69545.0713, Val MAE: 37996.3219, Val MSE: 4836516944.0358, Val R2: 0.7543\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.0879\n",
      "Val RMSE: 68589.9938, Val MAE: 36004.6120, Val MSE: 4704587243.0927, Val R2: 0.7610\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.0890\n",
      "Val RMSE: 68389.0979, Val MAE: 37737.2550, Val MSE: 4677068716.6269, Val R2: 0.7624\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.0996\n",
      "Val RMSE: 72192.3666, Val MAE: 42098.8153, Val MSE: 5211737791.3258, Val R2: 0.7352\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.0850\n",
      "Val RMSE: 65640.5789, Val MAE: 37934.0945, Val MSE: 4308685603.9293, Val R2: 0.7811\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.0895\n",
      "Val RMSE: 67457.8492, Val MAE: 38932.3675, Val MSE: 4550561413.2126, Val R2: 0.7688\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.0923\n",
      "Val RMSE: 68624.9515, Val MAE: 37003.4680, Val MSE: 4709383973.6250, Val R2: 0.7607\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1042\n",
      "Val RMSE: 76075.2571, Val MAE: 39335.9922, Val MSE: 5787444747.9000, Val R2: 0.7060\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1063\n",
      "Val RMSE: 76091.6630, Val MAE: 40942.7819, Val MSE: 5789941176.5669, Val R2: 0.7058\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.0960\n",
      "Val RMSE: 71209.8034, Val MAE: 39232.8805, Val MSE: 5070836105.0169, Val R2: 0.7424\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.0912\n",
      "Val RMSE: 69422.9337, Val MAE: 37486.6045, Val MSE: 4819543729.6802, Val R2: 0.7551\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.0805\n",
      "Val RMSE: 61473.3449, Val MAE: 36815.5482, Val MSE: 3778972133.5025, Val R2: 0.8080\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.0973\n",
      "Val RMSE: 68099.0092, Val MAE: 41383.2039, Val MSE: 4637475047.2127, Val R2: 0.7644\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.0889\n",
      "Val RMSE: 66010.0491, Val MAE: 38411.8341, Val MSE: 4357326576.0663, Val R2: 0.7786\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.0882\n",
      "Val RMSE: 67446.4452, Val MAE: 36382.7884, Val MSE: 4549022975.7511, Val R2: 0.7689\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.0957\n",
      "Val RMSE: 69200.7591, Val MAE: 38181.5519, Val MSE: 4788745058.1100, Val R2: 0.7567\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.0997\n",
      "Val RMSE: 73176.6276, Val MAE: 37594.3872, Val MSE: 5354818829.5206, Val R2: 0.7279\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.0996\n",
      "Val RMSE: 73181.1289, Val MAE: 38490.8684, Val MSE: 5355477633.5097, Val R2: 0.7279\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.0875\n",
      "Val RMSE: 68082.8682, Val MAE: 35729.6767, Val MSE: 4635276937.3825, Val R2: 0.7645\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.0946\n",
      "Val RMSE: 72070.9474, Val MAE: 36736.1089, Val MSE: 5194221454.1186, Val R2: 0.7361\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1077\n",
      "Val RMSE: 78504.1242, Val MAE: 40043.0947, Val MSE: 6162897514.3451, Val R2: 0.6869\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.1009\n",
      "Val RMSE: 73252.5586, Val MAE: 39697.7624, Val MSE: 5365937347.1817, Val R2: 0.7274\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0421, Val Loss: 0.1022\n",
      "Val RMSE: 75119.7002, Val MAE: 39473.3687, Val MSE: 5642969356.5226, Val R2: 0.7133\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.0930\n",
      "Val RMSE: 69459.2215, Val MAE: 38818.3478, Val MSE: 4824583452.8996, Val R2: 0.7549\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.0996\n",
      "Val RMSE: 74031.6462, Val MAE: 38864.7424, Val MSE: 5480684637.8433, Val R2: 0.7215\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0418, Val Loss: 0.1053\n",
      "Val RMSE: 75216.8672, Val MAE: 41592.4841, Val MSE: 5657577105.6623, Val R2: 0.7126\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0404, Val Loss: 0.0856\n",
      "Val RMSE: 66490.4992, Val MAE: 35581.2102, Val MSE: 4420986489.9169, Val R2: 0.7754\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0402, Val Loss: 0.0908\n",
      "Val RMSE: 69063.4302, Val MAE: 37518.9100, Val MSE: 4769757388.4346, Val R2: 0.7577\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0401, Val Loss: 0.0897\n",
      "Val RMSE: 67985.9996, Val MAE: 36941.1614, Val MSE: 4622096134.8740, Val R2: 0.7652\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0416, Val Loss: 0.0889\n",
      "Val RMSE: 67400.2555, Val MAE: 37626.4225, Val MSE: 4542794440.4409, Val R2: 0.7692\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0405, Val Loss: 0.0999\n",
      "Val RMSE: 74980.3425, Val MAE: 38802.5623, Val MSE: 5622051758.7914, Val R2: 0.7144\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0384, Val Loss: 0.1154\n",
      "Val RMSE: 81662.3318, Val MAE: 41955.1039, Val MSE: 6668736443.1204, Val R2: 0.6612\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0385, Val Loss: 0.1121\n",
      "Val RMSE: 81307.4273, Val MAE: 40934.8696, Val MSE: 6610897732.1813, Val R2: 0.6641\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0393, Val Loss: 0.0961\n",
      "Val RMSE: 73008.6934, Val MAE: 37836.5141, Val MSE: 5330269307.0179, Val R2: 0.7292\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0384, Val Loss: 0.0989\n",
      "Val RMSE: 72724.5985, Val MAE: 38546.2601, Val MSE: 5288867233.5198, Val R2: 0.7313\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0379, Val Loss: 0.0915\n",
      "Val RMSE: 70621.5543, Val MAE: 36203.5949, Val MSE: 4987403927.8939, Val R2: 0.7466\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0380, Val Loss: 0.0840\n",
      "Val RMSE: 65924.6825, Val MAE: 35480.3916, Val MSE: 4346063759.1057, Val R2: 0.7792\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0384, Val Loss: 0.0890\n",
      "Val RMSE: 67111.7920, Val MAE: 36936.1490, Val MSE: 4503992632.0276, Val R2: 0.7712\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0368, Val Loss: 0.1003\n",
      "Val RMSE: 77296.4672, Val MAE: 37680.1281, Val MSE: 5974743835.1578, Val R2: 0.6964\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0365, Val Loss: 0.0847\n",
      "Val RMSE: 66974.2227, Val MAE: 35224.6842, Val MSE: 4485546509.4541, Val R2: 0.7721\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 67616.3362, Test MAE: 36769.6127, Test MSE: 4571968927.5931, Test R2: 0.7069\n",
      "Inference Time: 1.6891039334810696e-05 seconds per sample\n",
      "\n",
      "Iteration 49 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3853, Val Loss: 0.2839\n",
      "Val RMSE: 143116.4090, Val MAE: 82990.9669, Val MSE: 20482306520.4206, Val R2: -0.0406\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2861, Val Loss: 0.2752\n",
      "Val RMSE: 140504.0428, Val MAE: 85976.7428, Val MSE: 19741386038.4366, Val R2: -0.0030\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2753, Val Loss: 0.2794\n",
      "Val RMSE: 143477.3099, Val MAE: 81033.7056, Val MSE: 20585738456.7215, Val R2: -0.0459\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2695, Val Loss: 0.2726\n",
      "Val RMSE: 141117.6226, Val MAE: 84047.8990, Val MSE: 19914183395.5621, Val R2: -0.0118\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2651, Val Loss: 0.2753\n",
      "Val RMSE: 142396.1081, Val MAE: 82113.4904, Val MSE: 20276651607.1683, Val R2: -0.0302\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2600, Val Loss: 0.2773\n",
      "Val RMSE: 140964.9931, Val MAE: 86923.4662, Val MSE: 19871129280.9005, Val R2: -0.0096\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2740\n",
      "Val RMSE: 141289.8407, Val MAE: 83680.6418, Val MSE: 19962819097.8351, Val R2: -0.0142\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2822\n",
      "Val RMSE: 143526.6630, Val MAE: 80923.4498, Val MSE: 20599902982.7946, Val R2: -0.0466\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2697\n",
      "Val RMSE: 141203.8361, Val MAE: 81097.5243, Val MSE: 19938523341.3815, Val R2: -0.0130\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2716\n",
      "Val RMSE: 142412.2941, Val MAE: 80243.1408, Val MSE: 20281261519.7390, Val R2: -0.0304\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2670\n",
      "Val RMSE: 139802.7072, Val MAE: 82451.9298, Val MSE: 19544796931.2488, Val R2: 0.0070\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2486, Val Loss: 0.2598\n",
      "Val RMSE: 138570.3804, Val MAE: 77227.4663, Val MSE: 19201750328.5653, Val R2: 0.0244\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2417, Val Loss: 0.2531\n",
      "Val RMSE: 135921.2794, Val MAE: 78893.7297, Val MSE: 18474594183.8011, Val R2: 0.0614\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2388, Val Loss: 0.2669\n",
      "Val RMSE: 138465.2750, Val MAE: 75465.8435, Val MSE: 19172632368.1423, Val R2: 0.0259\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2333\n",
      "Val RMSE: 130584.0542, Val MAE: 73914.5124, Val MSE: 17052195221.4243, Val R2: 0.1336\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2200, Val Loss: 0.2712\n",
      "Val RMSE: 134557.0034, Val MAE: 80837.7387, Val MSE: 18105587158.9293, Val R2: 0.0801\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2234, Val Loss: 0.2325\n",
      "Val RMSE: 131353.9970, Val MAE: 70712.9381, Val MSE: 17253872534.0532, Val R2: 0.1234\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2153, Val Loss: 0.2430\n",
      "Val RMSE: 131668.8268, Val MAE: 73841.0590, Val MSE: 17336679956.9272, Val R2: 0.1192\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2127, Val Loss: 0.2549\n",
      "Val RMSE: 138348.4236, Val MAE: 76241.1375, Val MSE: 19140286311.3505, Val R2: 0.0276\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2641\n",
      "Val RMSE: 142891.9099, Val MAE: 76371.7108, Val MSE: 20418097920.6338, Val R2: -0.0374\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2053, Val Loss: 0.2491\n",
      "Val RMSE: 138236.8230, Val MAE: 74462.8720, Val MSE: 19109419224.8999, Val R2: 0.0291\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2069, Val Loss: 0.2460\n",
      "Val RMSE: 133315.2595, Val MAE: 72683.6914, Val MSE: 17772958420.5604, Val R2: 0.0970\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2303\n",
      "Val RMSE: 128460.3679, Val MAE: 72266.1103, Val MSE: 16502066112.8651, Val R2: 0.1616\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2024, Val Loss: 0.2332\n",
      "Val RMSE: 131177.0356, Val MAE: 72676.6811, Val MSE: 17207414656.4572, Val R2: 0.1258\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1992, Val Loss: 0.2504\n",
      "Val RMSE: 138711.7396, Val MAE: 76562.2229, Val MSE: 19240946703.1469, Val R2: 0.0224\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1971, Val Loss: 0.2534\n",
      "Val RMSE: 138854.5520, Val MAE: 76704.5456, Val MSE: 19280586608.7637, Val R2: 0.0204\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1935, Val Loss: 0.2087\n",
      "Val RMSE: 116575.3964, Val MAE: 70873.8244, Val MSE: 13589823052.0709, Val R2: 0.3096\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1947, Val Loss: 0.2244\n",
      "Val RMSE: 125180.5068, Val MAE: 71703.9078, Val MSE: 15670159274.6306, Val R2: 0.2039\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1808, Val Loss: 0.2042\n",
      "Val RMSE: 115393.8459, Val MAE: 66816.9673, Val MSE: 13315739661.6270, Val R2: 0.3235\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1806, Val Loss: 0.2024\n",
      "Val RMSE: 114034.9475, Val MAE: 65277.6608, Val MSE: 13003969242.8938, Val R2: 0.3393\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1811, Val Loss: 0.2063\n",
      "Val RMSE: 114570.1693, Val MAE: 67416.6175, Val MSE: 13126323693.5136, Val R2: 0.3331\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1742, Val Loss: 0.1950\n",
      "Val RMSE: 110061.0511, Val MAE: 64106.6162, Val MSE: 12113434958.6556, Val R2: 0.3846\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1667, Val Loss: 0.1789\n",
      "Val RMSE: 102958.4302, Val MAE: 61309.5772, Val MSE: 10600438345.1102, Val R2: 0.4614\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1629, Val Loss: 0.1849\n",
      "Val RMSE: 103738.0929, Val MAE: 61886.7613, Val MSE: 10761591925.6912, Val R2: 0.4532\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1604, Val Loss: 0.1640\n",
      "Val RMSE: 98704.3972, Val MAE: 60008.0324, Val MSE: 9742558027.9847, Val R2: 0.5050\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1578, Val Loss: 0.1604\n",
      "Val RMSE: 97990.6506, Val MAE: 57923.7666, Val MSE: 9602167601.3637, Val R2: 0.5121\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1551, Val Loss: 0.1743\n",
      "Val RMSE: 100741.0091, Val MAE: 57941.8179, Val MSE: 10148750914.4830, Val R2: 0.4844\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1505\n",
      "Val RMSE: 95137.3223, Val MAE: 54137.1274, Val MSE: 9051110085.8913, Val R2: 0.5401\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1503, Val Loss: 0.1497\n",
      "Val RMSE: 94899.1716, Val MAE: 54855.2834, Val MSE: 9005852771.2094, Val R2: 0.5424\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1459, Val Loss: 0.1509\n",
      "Val RMSE: 96031.9407, Val MAE: 53473.9268, Val MSE: 9222133639.8943, Val R2: 0.5315\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1406, Val Loss: 0.1443\n",
      "Val RMSE: 92147.9935, Val MAE: 52008.8731, Val MSE: 8491252700.5369, Val R2: 0.5686\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1393, Val Loss: 0.1493\n",
      "Val RMSE: 94988.6679, Val MAE: 53276.3896, Val MSE: 9022847021.1321, Val R2: 0.5416\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1388\n",
      "Val RMSE: 92733.3271, Val MAE: 48228.5250, Val MSE: 8599469955.7767, Val R2: 0.5631\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1257, Val Loss: 0.1422\n",
      "Val RMSE: 95099.8925, Val MAE: 49400.3410, Val MSE: 9043989551.7837, Val R2: 0.5405\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1223, Val Loss: 0.1382\n",
      "Val RMSE: 93228.3066, Val MAE: 49788.1595, Val MSE: 8691517156.3805, Val R2: 0.5584\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1167, Val Loss: 0.1533\n",
      "Val RMSE: 94492.0385, Val MAE: 51224.5480, Val MSE: 8928745348.9021, Val R2: 0.5464\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1403\n",
      "Val RMSE: 93196.7067, Val MAE: 52249.5076, Val MSE: 8685626144.2049, Val R2: 0.5587\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1158, Val Loss: 0.1235\n",
      "Val RMSE: 88900.9120, Val MAE: 46072.3779, Val MSE: 7903372156.7096, Val R2: 0.5985\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1326\n",
      "Val RMSE: 90372.4635, Val MAE: 49910.6189, Val MSE: 8167182168.0232, Val R2: 0.5851\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1262\n",
      "Val RMSE: 88964.1387, Val MAE: 48428.0509, Val MSE: 7914617978.8146, Val R2: 0.5979\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0983, Val Loss: 0.1354\n",
      "Val RMSE: 91218.0604, Val MAE: 47807.7760, Val MSE: 8320734548.1252, Val R2: 0.5773\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1271\n",
      "Val RMSE: 88895.7480, Val MAE: 49731.1619, Val MSE: 7902454021.2127, Val R2: 0.5985\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1264\n",
      "Val RMSE: 88652.5209, Val MAE: 48572.8134, Val MSE: 7859269460.9689, Val R2: 0.6007\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1278\n",
      "Val RMSE: 89090.4360, Val MAE: 46636.4046, Val MSE: 7937105790.0974, Val R2: 0.5967\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0892, Val Loss: 0.1238\n",
      "Val RMSE: 87590.2446, Val MAE: 44607.2698, Val MSE: 7672050954.4963, Val R2: 0.6102\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1303\n",
      "Val RMSE: 89900.7723, Val MAE: 49078.3697, Val MSE: 8082148862.7388, Val R2: 0.5894\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1240\n",
      "Val RMSE: 86595.2212, Val MAE: 44131.7372, Val MSE: 7498732331.3541, Val R2: 0.6190\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0860, Val Loss: 0.1281\n",
      "Val RMSE: 87141.6385, Val MAE: 45571.6761, Val MSE: 7593665156.7104, Val R2: 0.6142\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1267\n",
      "Val RMSE: 86597.8841, Val MAE: 49819.2781, Val MSE: 7499193523.9599, Val R2: 0.6190\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1190\n",
      "Val RMSE: 82985.0998, Val MAE: 45600.9811, Val MSE: 6886526784.9214, Val R2: 0.6501\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1208\n",
      "Val RMSE: 83256.9997, Val MAE: 45150.4820, Val MSE: 6931727999.5063, Val R2: 0.6478\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1106\n",
      "Val RMSE: 78045.0446, Val MAE: 43493.9182, Val MSE: 6091028985.0470, Val R2: 0.6905\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1167\n",
      "Val RMSE: 80587.8214, Val MAE: 43348.1149, Val MSE: 6494396965.6248, Val R2: 0.6700\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1144\n",
      "Val RMSE: 80299.3667, Val MAE: 43454.9163, Val MSE: 6447988285.2595, Val R2: 0.6724\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1269\n",
      "Val RMSE: 85083.3192, Val MAE: 47159.9738, Val MSE: 7239171207.9863, Val R2: 0.6322\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1347\n",
      "Val RMSE: 86209.1148, Val MAE: 44832.3603, Val MSE: 7432011467.0414, Val R2: 0.6224\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1106\n",
      "Val RMSE: 76916.6341, Val MAE: 42962.0826, Val MSE: 5916168608.1383, Val R2: 0.6994\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1236\n",
      "Val RMSE: 83324.9400, Val MAE: 46011.9598, Val MSE: 6943045624.9944, Val R2: 0.6472\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1367\n",
      "Val RMSE: 86623.3942, Val MAE: 46302.7621, Val MSE: 7503612429.3358, Val R2: 0.6188\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1194\n",
      "Val RMSE: 78097.2241, Val MAE: 42282.4162, Val MSE: 6099176415.9733, Val R2: 0.6901\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1228\n",
      "Val RMSE: 81123.9437, Val MAE: 46462.8489, Val MSE: 6581094234.8020, Val R2: 0.6656\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0646, Val Loss: 0.1138\n",
      "Val RMSE: 76629.4356, Val MAE: 41138.1340, Val MSE: 5872070397.6688, Val R2: 0.7017\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1139\n",
      "Val RMSE: 75772.8486, Val MAE: 45135.8305, Val MSE: 5741524579.9056, Val R2: 0.7083\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1153\n",
      "Val RMSE: 77813.0310, Val MAE: 42747.8490, Val MSE: 6054867788.4437, Val R2: 0.6924\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1155\n",
      "Val RMSE: 77106.3165, Val MAE: 42339.9614, Val MSE: 5945384039.0402, Val R2: 0.6979\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1191\n",
      "Val RMSE: 78469.6397, Val MAE: 43791.3461, Val MSE: 6157484352.4545, Val R2: 0.6872\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1110\n",
      "Val RMSE: 76349.3901, Val MAE: 42011.9828, Val MSE: 5829229369.5506, Val R2: 0.7038\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1223\n",
      "Val RMSE: 80969.4491, Val MAE: 45449.3601, Val MSE: 6556051694.5189, Val R2: 0.6669\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1044\n",
      "Val RMSE: 72470.7786, Val MAE: 40233.9775, Val MSE: 5252013758.0627, Val R2: 0.7332\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1156\n",
      "Val RMSE: 76251.0792, Val MAE: 41466.6154, Val MSE: 5814227078.9275, Val R2: 0.7046\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1165\n",
      "Val RMSE: 77773.1945, Val MAE: 42235.7312, Val MSE: 6048669786.0131, Val R2: 0.6927\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1084\n",
      "Val RMSE: 74197.5611, Val MAE: 39868.3167, Val MSE: 5505278072.2997, Val R2: 0.7203\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1085\n",
      "Val RMSE: 73539.1815, Val MAE: 40090.3121, Val MSE: 5408011217.7674, Val R2: 0.7252\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1103\n",
      "Val RMSE: 76079.5153, Val MAE: 41891.6337, Val MSE: 5788092644.8473, Val R2: 0.7059\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1131\n",
      "Val RMSE: 76789.0314, Val MAE: 42470.6810, Val MSE: 5896555338.8504, Val R2: 0.7004\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1105\n",
      "Val RMSE: 74993.6377, Val MAE: 41897.1769, Val MSE: 5624045700.6726, Val R2: 0.7143\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1128\n",
      "Val RMSE: 75887.2265, Val MAE: 41804.0871, Val MSE: 5758871141.7555, Val R2: 0.7074\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1174\n",
      "Val RMSE: 75923.4868, Val MAE: 44658.9671, Val MSE: 5764375853.4754, Val R2: 0.7071\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1139\n",
      "Val RMSE: 76735.6645, Val MAE: 42280.2127, Val MSE: 5888362212.0257, Val R2: 0.7008\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1058\n",
      "Val RMSE: 72837.4149, Val MAE: 40395.2832, Val MSE: 5305289012.5131, Val R2: 0.7305\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1285\n",
      "Val RMSE: 80297.3263, Val MAE: 48522.5521, Val MSE: 6447660610.7004, Val R2: 0.6724\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1186\n",
      "Val RMSE: 79085.6616, Val MAE: 45709.4055, Val MSE: 6254541875.5274, Val R2: 0.6822\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1252\n",
      "Val RMSE: 81808.1299, Val MAE: 43969.0712, Val MSE: 6692570112.4375, Val R2: 0.6600\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1058\n",
      "Val RMSE: 72759.7535, Val MAE: 41237.5801, Val MSE: 5293981728.4989, Val R2: 0.7310\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1242\n",
      "Val RMSE: 81971.9138, Val MAE: 42407.3855, Val MSE: 6719394648.5707, Val R2: 0.6586\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1267\n",
      "Val RMSE: 81338.3076, Val MAE: 44223.4390, Val MSE: 6615920281.1912, Val R2: 0.6639\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1106\n",
      "Val RMSE: 74464.6082, Val MAE: 41707.4566, Val MSE: 5544977879.1998, Val R2: 0.7183\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1388\n",
      "Val RMSE: 85843.2666, Val MAE: 48394.7920, Val MSE: 7369066420.5592, Val R2: 0.6256\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1500\n",
      "Val RMSE: 100305.0401, Val MAE: 50025.1670, Val MSE: 10061101075.9843, Val R2: 0.4888\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1247\n",
      "Val RMSE: 79677.3894, Val MAE: 43637.7413, Val MSE: 6348486375.6338, Val R2: 0.6775\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 78329.0735, Test MAE: 41872.2572, Test MSE: 6135443755.5362, Test R2: 0.6067\n",
      "Inference Time: 1.9741095029390776e-05 seconds per sample\n",
      "\n",
      "Iteration 50 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3452, Val Loss: 0.2998\n",
      "Val RMSE: 146567.0997, Val MAE: 82464.7925, Val MSE: 21481914719.4875, Val R2: -0.0914\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2770, Val Loss: 0.2820\n",
      "Val RMSE: 142102.7168, Val MAE: 84561.2940, Val MSE: 20193182116.5364, Val R2: -0.0259\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2680, Val Loss: 0.2768\n",
      "Val RMSE: 142206.0696, Val MAE: 83185.0639, Val MSE: 20222566232.1387, Val R2: -0.0274\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2679, Val Loss: 0.2749\n",
      "Val RMSE: 140800.8171, Val MAE: 85467.3983, Val MSE: 19824870109.5032, Val R2: -0.0072\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2640, Val Loss: 0.2744\n",
      "Val RMSE: 141422.9082, Val MAE: 84098.6759, Val MSE: 20000438961.6394, Val R2: -0.0161\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2619, Val Loss: 0.2772\n",
      "Val RMSE: 140398.6108, Val MAE: 87695.8384, Val MSE: 19711769927.4160, Val R2: -0.0015\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2724\n",
      "Val RMSE: 140870.9174, Val MAE: 83678.5307, Val MSE: 19844615360.7753, Val R2: -0.0082\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2787\n",
      "Val RMSE: 141262.0114, Val MAE: 86516.0993, Val MSE: 19954955866.6133, Val R2: -0.0138\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2679\n",
      "Val RMSE: 140920.4076, Val MAE: 82496.1370, Val MSE: 19858561267.1175, Val R2: -0.0089\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2720\n",
      "Val RMSE: 142545.1992, Val MAE: 79716.1056, Val MSE: 20319133825.7913, Val R2: -0.0323\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2538, Val Loss: 0.2686\n",
      "Val RMSE: 140763.8956, Val MAE: 81132.6139, Val MSE: 19814474295.2455, Val R2: -0.0067\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2782\n",
      "Val RMSE: 141693.1398, Val MAE: 84169.3776, Val MSE: 20076945868.9388, Val R2: -0.0200\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2595\n",
      "Val RMSE: 138596.7683, Val MAE: 79794.8982, Val MSE: 19209064183.1900, Val R2: 0.0241\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2541\n",
      "Val RMSE: 135797.6064, Val MAE: 78884.4037, Val MSE: 18440989899.5388, Val R2: 0.0631\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2356, Val Loss: 0.2686\n",
      "Val RMSE: 133498.1609, Val MAE: 84851.3872, Val MSE: 17821758969.8265, Val R2: 0.0945\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2387\n",
      "Val RMSE: 133409.9049, Val MAE: 71378.7604, Val MSE: 17798202714.6921, Val R2: 0.0957\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2198, Val Loss: 0.2300\n",
      "Val RMSE: 128925.7514, Val MAE: 75439.8218, Val MSE: 16621849367.9147, Val R2: 0.1555\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2163, Val Loss: 0.2397\n",
      "Val RMSE: 130466.9538, Val MAE: 77858.9710, Val MSE: 17021626023.8575, Val R2: 0.1352\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2155, Val Loss: 0.2324\n",
      "Val RMSE: 130418.9423, Val MAE: 74152.1447, Val MSE: 17009100505.7118, Val R2: 0.1358\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2116, Val Loss: 0.2312\n",
      "Val RMSE: 131605.5801, Val MAE: 73168.5293, Val MSE: 17320028718.0012, Val R2: 0.1200\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2149, Val Loss: 0.2301\n",
      "Val RMSE: 131449.5264, Val MAE: 71199.7487, Val MSE: 17278977984.2714, Val R2: 0.1221\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2111, Val Loss: 0.2329\n",
      "Val RMSE: 130932.5552, Val MAE: 73245.6417, Val MSE: 17143334002.7384, Val R2: 0.1290\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2119, Val Loss: 0.2379\n",
      "Val RMSE: 132196.7044, Val MAE: 72581.3166, Val MSE: 17475968643.3558, Val R2: 0.1121\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2025, Val Loss: 0.2314\n",
      "Val RMSE: 132719.5839, Val MAE: 71949.0506, Val MSE: 17614487956.6080, Val R2: 0.1051\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2032, Val Loss: 0.2249\n",
      "Val RMSE: 128563.7199, Val MAE: 72219.8889, Val MSE: 16528630084.1632, Val R2: 0.1602\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2004, Val Loss: 0.2594\n",
      "Val RMSE: 140676.1028, Val MAE: 78699.2874, Val MSE: 19789765909.1116, Val R2: -0.0054\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2013, Val Loss: 0.2279\n",
      "Val RMSE: 129643.5217, Val MAE: 73798.4131, Val MSE: 16807442720.4742, Val R2: 0.1461\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1963, Val Loss: 0.2223\n",
      "Val RMSE: 128213.8345, Val MAE: 70746.6211, Val MSE: 16438787346.1479, Val R2: 0.1648\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1936, Val Loss: 0.2107\n",
      "Val RMSE: 119496.9057, Val MAE: 68288.1501, Val MSE: 14279510471.8606, Val R2: 0.2745\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1819, Val Loss: 0.1994\n",
      "Val RMSE: 111584.9289, Val MAE: 70095.0816, Val MSE: 12451196346.9340, Val R2: 0.3674\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1747, Val Loss: 0.1936\n",
      "Val RMSE: 108423.6067, Val MAE: 65704.1328, Val MSE: 11755678494.5520, Val R2: 0.4027\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1666, Val Loss: 0.1815\n",
      "Val RMSE: 102901.1283, Val MAE: 64401.8624, Val MSE: 10588642204.6125, Val R2: 0.4620\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1616, Val Loss: 0.1998\n",
      "Val RMSE: 107540.1624, Val MAE: 63775.8149, Val MSE: 11564886526.8087, Val R2: 0.4124\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1593, Val Loss: 0.1630\n",
      "Val RMSE: 98375.9273, Val MAE: 59547.5759, Val MSE: 9677823069.6195, Val R2: 0.5083\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1551, Val Loss: 0.1687\n",
      "Val RMSE: 100510.0552, Val MAE: 59050.2793, Val MSE: 10102271201.5892, Val R2: 0.4867\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1595, Val Loss: 0.1790\n",
      "Val RMSE: 101437.1776, Val MAE: 60240.3196, Val MSE: 10289501000.9125, Val R2: 0.4772\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1505, Val Loss: 0.1584\n",
      "Val RMSE: 96841.7825, Val MAE: 55538.1326, Val MSE: 9378330841.4321, Val R2: 0.5235\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1459, Val Loss: 0.1531\n",
      "Val RMSE: 94985.5689, Val MAE: 56009.6614, Val MSE: 9022258297.9491, Val R2: 0.5416\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1534\n",
      "Val RMSE: 96468.2627, Val MAE: 56376.4136, Val MSE: 9306125701.8521, Val R2: 0.5272\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1394, Val Loss: 0.1425\n",
      "Val RMSE: 93131.1274, Val MAE: 52550.4519, Val MSE: 8673406888.2129, Val R2: 0.5593\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1360, Val Loss: 0.1443\n",
      "Val RMSE: 92640.2531, Val MAE: 54888.5999, Val MSE: 8582216485.6684, Val R2: 0.5640\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1318, Val Loss: 0.1453\n",
      "Val RMSE: 93205.8288, Val MAE: 51769.7818, Val MSE: 8687326515.8439, Val R2: 0.5586\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1287, Val Loss: 0.1372\n",
      "Val RMSE: 91037.5891, Val MAE: 49940.9680, Val MSE: 8287842628.6271, Val R2: 0.5789\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1250, Val Loss: 0.1329\n",
      "Val RMSE: 88112.7049, Val MAE: 48616.7288, Val MSE: 7763848772.1313, Val R2: 0.6055\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1215, Val Loss: 0.1405\n",
      "Val RMSE: 88711.4674, Val MAE: 51836.4564, Val MSE: 7869724453.9724, Val R2: 0.6002\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1166, Val Loss: 0.1400\n",
      "Val RMSE: 92098.0050, Val MAE: 50510.4641, Val MSE: 8482042525.7774, Val R2: 0.5691\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1151, Val Loss: 0.1292\n",
      "Val RMSE: 86434.0912, Val MAE: 46875.2224, Val MSE: 7470852124.5871, Val R2: 0.6204\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1102, Val Loss: 0.1327\n",
      "Val RMSE: 88965.7954, Val MAE: 48294.0684, Val MSE: 7914912756.7200, Val R2: 0.5979\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1133\n",
      "Val RMSE: 80986.4166, Val MAE: 44990.3491, Val MSE: 6558799670.3217, Val R2: 0.6668\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1225\n",
      "Val RMSE: 81662.0223, Val MAE: 47171.0355, Val MSE: 6668685886.9912, Val R2: 0.6612\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0958, Val Loss: 0.1283\n",
      "Val RMSE: 84728.4796, Val MAE: 46993.8295, Val MSE: 7178915255.5168, Val R2: 0.6353\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0914, Val Loss: 0.1185\n",
      "Val RMSE: 77484.4464, Val MAE: 44575.1042, Val MSE: 6003839439.3704, Val R2: 0.6950\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1277\n",
      "Val RMSE: 77872.8700, Val MAE: 48881.6068, Val MSE: 6064183881.7956, Val R2: 0.6919\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1310\n",
      "Val RMSE: 81240.3900, Val MAE: 47703.2780, Val MSE: 6600000963.8388, Val R2: 0.6647\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1105\n",
      "Val RMSE: 73408.9635, Val MAE: 45644.3830, Val MSE: 5388875922.9107, Val R2: 0.7262\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0810, Val Loss: 0.1158\n",
      "Val RMSE: 77727.2789, Val MAE: 43633.5180, Val MSE: 6041529880.4430, Val R2: 0.6931\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1103\n",
      "Val RMSE: 75049.6624, Val MAE: 42787.3921, Val MSE: 5632451826.9200, Val R2: 0.7138\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0770, Val Loss: 0.1100\n",
      "Val RMSE: 75526.8067, Val MAE: 43317.0884, Val MSE: 5704298523.8320, Val R2: 0.7102\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1000\n",
      "Val RMSE: 69422.6097, Val MAE: 41564.7337, Val MSE: 4819498739.0706, Val R2: 0.7551\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1041\n",
      "Val RMSE: 71462.8484, Val MAE: 42829.1927, Val MSE: 5106938708.3064, Val R2: 0.7405\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1006\n",
      "Val RMSE: 69114.1904, Val MAE: 40526.7794, Val MSE: 4776771309.5072, Val R2: 0.7573\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1011\n",
      "Val RMSE: 69702.1987, Val MAE: 40261.6490, Val MSE: 4858396506.6718, Val R2: 0.7532\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1098\n",
      "Val RMSE: 73422.5750, Val MAE: 41702.3693, Val MSE: 5390874520.3339, Val R2: 0.7261\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1115\n",
      "Val RMSE: 73221.5447, Val MAE: 45475.2016, Val MSE: 5361394605.9967, Val R2: 0.7276\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1222\n",
      "Val RMSE: 76755.2776, Val MAE: 48015.8296, Val MSE: 5891372644.1748, Val R2: 0.7007\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1029\n",
      "Val RMSE: 70663.3426, Val MAE: 41805.6937, Val MSE: 4993307988.0704, Val R2: 0.7463\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1080\n",
      "Val RMSE: 71569.6907, Val MAE: 43627.7069, Val MSE: 5122220630.9946, Val R2: 0.7398\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1045\n",
      "Val RMSE: 68514.5163, Val MAE: 44239.7152, Val MSE: 4694238947.7929, Val R2: 0.7615\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1042\n",
      "Val RMSE: 70352.8411, Val MAE: 41012.3190, Val MSE: 4949522245.5384, Val R2: 0.7485\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1017\n",
      "Val RMSE: 69593.2070, Val MAE: 40128.0982, Val MSE: 4843214466.6712, Val R2: 0.7539\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1125\n",
      "Val RMSE: 74318.1682, Val MAE: 43365.7027, Val MSE: 5523190128.3579, Val R2: 0.7194\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1033\n",
      "Val RMSE: 70662.3256, Val MAE: 40412.7031, Val MSE: 4993164258.5975, Val R2: 0.7463\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1052\n",
      "Val RMSE: 71582.9938, Val MAE: 40890.3286, Val MSE: 5124125004.4079, Val R2: 0.7397\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1070\n",
      "Val RMSE: 69974.7719, Val MAE: 44219.9256, Val MSE: 4896468707.7737, Val R2: 0.7512\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1267\n",
      "Val RMSE: 78572.1727, Val MAE: 49493.1702, Val MSE: 6173586324.8509, Val R2: 0.6863\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1048\n",
      "Val RMSE: 70553.8521, Val MAE: 41461.8381, Val MSE: 4977846040.3691, Val R2: 0.7471\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1119\n",
      "Val RMSE: 73533.0810, Val MAE: 43563.0214, Val MSE: 5407114003.5489, Val R2: 0.7253\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1079\n",
      "Val RMSE: 69484.0523, Val MAE: 42462.0503, Val MSE: 4828033520.6907, Val R2: 0.7547\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1064\n",
      "Val RMSE: 71159.3612, Val MAE: 42553.8456, Val MSE: 5063654686.2859, Val R2: 0.7427\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1164\n",
      "Val RMSE: 75510.5648, Val MAE: 45343.5675, Val MSE: 5701845401.7746, Val R2: 0.7103\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1145\n",
      "Val RMSE: 74309.9831, Val MAE: 45122.6282, Val MSE: 5521973594.2455, Val R2: 0.7194\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1080\n",
      "Val RMSE: 72880.1339, Val MAE: 41989.5820, Val MSE: 5311513913.3932, Val R2: 0.7301\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1122\n",
      "Val RMSE: 73402.2291, Val MAE: 42906.1831, Val MSE: 5387887243.9304, Val R2: 0.7263\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1159\n",
      "Val RMSE: 75107.4469, Val MAE: 45229.5586, Val MSE: 5641128578.0895, Val R2: 0.7134\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1192\n",
      "Val RMSE: 78158.8110, Val MAE: 45356.0990, Val MSE: 6108799738.3137, Val R2: 0.6896\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1151\n",
      "Val RMSE: 75012.5635, Val MAE: 44822.0576, Val MSE: 5626884677.3381, Val R2: 0.7141\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1135\n",
      "Val RMSE: 75128.5703, Val MAE: 41813.1422, Val MSE: 5644302082.7101, Val R2: 0.7132\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1133\n",
      "Val RMSE: 73974.1991, Val MAE: 43547.3333, Val MSE: 5472182129.8396, Val R2: 0.7220\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1087\n",
      "Val RMSE: 70974.0251, Val MAE: 42156.9853, Val MSE: 5037312243.3331, Val R2: 0.7441\n",
      "Early stopping triggered after epoch 89\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 78226.5078, Test MAE: 44157.7020, Test MSE: 6119386515.6534, Test R2: 0.6077\n",
      "Inference Time: 1.7060499924879806e-05 seconds per sample\n",
      "\n",
      "Iteration 51 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3727, Val Loss: 0.2786\n",
      "Val RMSE: 140057.8634, Val MAE: 88924.9960, Val MSE: 19616205094.7778, Val R2: 0.0034\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2753\n",
      "Val RMSE: 141160.5864, Val MAE: 83986.7317, Val MSE: 19926311143.8169, Val R2: -0.0124\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2686, Val Loss: 0.2750\n",
      "Val RMSE: 141240.3390, Val MAE: 83857.7268, Val MSE: 19948833368.4898, Val R2: -0.0135\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2662, Val Loss: 0.2815\n",
      "Val RMSE: 143810.6791, Val MAE: 81057.5917, Val MSE: 20681511410.4049, Val R2: -0.0508\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2625, Val Loss: 0.2774\n",
      "Val RMSE: 143426.6763, Val MAE: 80159.3622, Val MSE: 20571211478.7753, Val R2: -0.0451\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2584, Val Loss: 0.2754\n",
      "Val RMSE: 141137.6859, Val MAE: 84805.4256, Val MSE: 19919846370.6712, Val R2: -0.0121\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2699\n",
      "Val RMSE: 141517.9312, Val MAE: 80553.1446, Val MSE: 20027324854.0944, Val R2: -0.0175\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2679\n",
      "Val RMSE: 142961.1076, Val MAE: 77951.0828, Val MSE: 20437878274.4060, Val R2: -0.0384\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2605\n",
      "Val RMSE: 139292.1356, Val MAE: 78475.7496, Val MSE: 19402299045.7472, Val R2: 0.0142\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2429, Val Loss: 0.2525\n",
      "Val RMSE: 136589.0128, Val MAE: 75099.4710, Val MSE: 18656558426.1477, Val R2: 0.0521\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2398, Val Loss: 0.2507\n",
      "Val RMSE: 133691.4191, Val MAE: 79697.2043, Val MSE: 17873395550.4087, Val R2: 0.0919\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2356, Val Loss: 0.2442\n",
      "Val RMSE: 131749.8322, Val MAE: 74159.5487, Val MSE: 17358018282.0759, Val R2: 0.1181\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2248, Val Loss: 0.2364\n",
      "Val RMSE: 130337.0143, Val MAE: 75778.9088, Val MSE: 16987737283.7718, Val R2: 0.1369\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2208, Val Loss: 0.2308\n",
      "Val RMSE: 129567.0229, Val MAE: 74546.4229, Val MSE: 16787613429.4012, Val R2: 0.1471\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2305\n",
      "Val RMSE: 131196.4635, Val MAE: 71398.3183, Val MSE: 17212512032.9886, Val R2: 0.1255\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2184, Val Loss: 0.2381\n",
      "Val RMSE: 133071.1576, Val MAE: 72615.0019, Val MSE: 17707932990.0044, Val R2: 0.1003\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2124, Val Loss: 0.2422\n",
      "Val RMSE: 133732.2575, Val MAE: 73512.1879, Val MSE: 17884316707.7365, Val R2: 0.0914\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2111, Val Loss: 0.2289\n",
      "Val RMSE: 128703.7695, Val MAE: 75802.4705, Val MSE: 16564660295.9666, Val R2: 0.1584\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2043, Val Loss: 0.2262\n",
      "Val RMSE: 129157.5539, Val MAE: 71576.1746, Val MSE: 16681673726.0452, Val R2: 0.1525\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.1993, Val Loss: 0.2268\n",
      "Val RMSE: 127907.2783, Val MAE: 71403.6740, Val MSE: 16360271833.2351, Val R2: 0.1688\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1988, Val Loss: 0.2243\n",
      "Val RMSE: 125861.5068, Val MAE: 71902.0983, Val MSE: 15841118893.6337, Val R2: 0.1952\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1918, Val Loss: 0.2234\n",
      "Val RMSE: 120383.4920, Val MAE: 76239.3976, Val MSE: 14492185148.9879, Val R2: 0.2637\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1895, Val Loss: 0.2165\n",
      "Val RMSE: 121110.0469, Val MAE: 68740.4788, Val MSE: 14667643450.9333, Val R2: 0.2548\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1784, Val Loss: 0.1919\n",
      "Val RMSE: 107667.6145, Val MAE: 64619.6097, Val MSE: 11592315211.9532, Val R2: 0.4110\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1754, Val Loss: 0.1835\n",
      "Val RMSE: 104000.2669, Val MAE: 62037.6781, Val MSE: 10816055525.0320, Val R2: 0.4505\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1891\n",
      "Val RMSE: 107177.1814, Val MAE: 64452.1586, Val MSE: 11486948216.3770, Val R2: 0.4164\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1653, Val Loss: 0.1862\n",
      "Val RMSE: 105819.1903, Val MAE: 61385.2223, Val MSE: 11197701025.4573, Val R2: 0.4311\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1624, Val Loss: 0.1879\n",
      "Val RMSE: 105168.7097, Val MAE: 65273.2624, Val MSE: 11060457503.4123, Val R2: 0.4381\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1571, Val Loss: 0.1811\n",
      "Val RMSE: 102167.0996, Val MAE: 59794.3101, Val MSE: 10438116245.7191, Val R2: 0.4697\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1548, Val Loss: 0.1608\n",
      "Val RMSE: 97857.1742, Val MAE: 56289.9587, Val MSE: 9576026547.4834, Val R2: 0.5135\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1709\n",
      "Val RMSE: 99983.7278, Val MAE: 60182.9947, Val MSE: 9996745829.7795, Val R2: 0.4921\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1379, Val Loss: 0.1641\n",
      "Val RMSE: 97904.9744, Val MAE: 57911.3221, Val MSE: 9585384020.6776, Val R2: 0.5130\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1310, Val Loss: 0.1675\n",
      "Val RMSE: 99706.4116, Val MAE: 57087.4289, Val MSE: 9941368506.5731, Val R2: 0.4949\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1258, Val Loss: 0.1602\n",
      "Val RMSE: 97777.6832, Val MAE: 56060.3741, Val MSE: 9560475336.6607, Val R2: 0.5143\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1207, Val Loss: 0.1555\n",
      "Val RMSE: 95148.3742, Val MAE: 54836.5985, Val MSE: 9053213120.3895, Val R2: 0.5400\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1191, Val Loss: 0.1601\n",
      "Val RMSE: 96257.0183, Val MAE: 58856.1189, Val MSE: 9265413573.6733, Val R2: 0.5293\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1141, Val Loss: 0.1595\n",
      "Val RMSE: 96159.7038, Val MAE: 56202.4989, Val MSE: 9246688626.8838, Val R2: 0.5302\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1130, Val Loss: 0.1549\n",
      "Val RMSE: 94053.6231, Val MAE: 56904.7547, Val MSE: 8846084025.0140, Val R2: 0.5506\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1112, Val Loss: 0.1551\n",
      "Val RMSE: 94306.0066, Val MAE: 56802.3777, Val MSE: 8893622889.8464, Val R2: 0.5481\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1050, Val Loss: 0.1729\n",
      "Val RMSE: 97753.9139, Val MAE: 59200.2771, Val MSE: 9555827689.5791, Val R2: 0.5145\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1668\n",
      "Val RMSE: 97340.8357, Val MAE: 58460.0827, Val MSE: 9475238296.6451, Val R2: 0.5186\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0996, Val Loss: 0.1728\n",
      "Val RMSE: 98395.1873, Val MAE: 62384.4470, Val MSE: 9681612882.3871, Val R2: 0.5081\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0963, Val Loss: 0.1687\n",
      "Val RMSE: 97620.1976, Val MAE: 59975.8962, Val MSE: 9529702971.9033, Val R2: 0.5158\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0967, Val Loss: 0.1641\n",
      "Val RMSE: 97163.2501, Val MAE: 58779.7430, Val MSE: 9440697172.2938, Val R2: 0.5204\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1621\n",
      "Val RMSE: 96594.4050, Val MAE: 58320.5261, Val MSE: 9330479082.6312, Val R2: 0.5260\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1612\n",
      "Val RMSE: 95995.7209, Val MAE: 56468.8554, Val MSE: 9215178431.3152, Val R2: 0.5318\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1687\n",
      "Val RMSE: 99320.7807, Val MAE: 60181.6555, Val MSE: 9864617479.9461, Val R2: 0.4988\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0855, Val Loss: 0.1700\n",
      "Val RMSE: 98533.3651, Val MAE: 57739.5890, Val MSE: 9708824034.5470, Val R2: 0.5067\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1614\n",
      "Val RMSE: 95702.1812, Val MAE: 57774.7952, Val MSE: 9158907486.7211, Val R2: 0.5347\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1671\n",
      "Val RMSE: 96015.4245, Val MAE: 59138.4122, Val MSE: 9218961734.0121, Val R2: 0.5316\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1690\n",
      "Val RMSE: 99489.2084, Val MAE: 58223.8892, Val MSE: 9898102578.5264, Val R2: 0.4971\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1663\n",
      "Val RMSE: 96539.5889, Val MAE: 56513.5295, Val MSE: 9319892227.0806, Val R2: 0.5265\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.1516\n",
      "Val RMSE: 90480.2510, Val MAE: 53509.2215, Val MSE: 8186675825.5432, Val R2: 0.5841\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1610\n",
      "Val RMSE: 94579.6671, Val MAE: 56235.7904, Val MSE: 8945313437.5247, Val R2: 0.5455\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1519\n",
      "Val RMSE: 91080.3862, Val MAE: 53804.8991, Val MSE: 8295636752.6797, Val R2: 0.5785\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0725, Val Loss: 0.1545\n",
      "Val RMSE: 90300.6865, Val MAE: 53794.8589, Val MSE: 8154213974.1078, Val R2: 0.5857\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1507\n",
      "Val RMSE: 87363.3974, Val MAE: 53745.4755, Val MSE: 7632363198.2739, Val R2: 0.6122\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1530\n",
      "Val RMSE: 88339.4951, Val MAE: 54565.4688, Val MSE: 7803866387.7982, Val R2: 0.6035\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1490\n",
      "Val RMSE: 87434.6962, Val MAE: 52845.8582, Val MSE: 7644826107.6940, Val R2: 0.6116\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1543\n",
      "Val RMSE: 89927.3961, Val MAE: 53073.3204, Val MSE: 8086936571.3664, Val R2: 0.5891\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1673\n",
      "Val RMSE: 88145.3781, Val MAE: 54041.4949, Val MSE: 7769607684.7673, Val R2: 0.6053\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1582\n",
      "Val RMSE: 89426.4299, Val MAE: 55723.0197, Val MSE: 7997086357.7079, Val R2: 0.5937\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1467\n",
      "Val RMSE: 84421.9906, Val MAE: 51577.5549, Val MSE: 7127072498.2412, Val R2: 0.6379\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1520\n",
      "Val RMSE: 87218.3369, Val MAE: 53932.3177, Val MSE: 7607038289.2470, Val R2: 0.6135\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1537\n",
      "Val RMSE: 87665.0364, Val MAE: 54597.4092, Val MSE: 7685158613.7924, Val R2: 0.6095\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1476\n",
      "Val RMSE: 85424.8684, Val MAE: 52341.1331, Val MSE: 7297408145.6263, Val R2: 0.6292\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1550\n",
      "Val RMSE: 86644.3834, Val MAE: 52533.3474, Val MSE: 7507249172.8128, Val R2: 0.6186\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1498\n",
      "Val RMSE: 86061.2604, Val MAE: 51729.5472, Val MSE: 7406540547.7237, Val R2: 0.6237\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0548, Val Loss: 0.1476\n",
      "Val RMSE: 85074.6496, Val MAE: 52061.5310, Val MSE: 7237695998.4377, Val R2: 0.6323\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1486\n",
      "Val RMSE: 85739.1321, Val MAE: 52805.1957, Val MSE: 7351198766.1831, Val R2: 0.6265\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1489\n",
      "Val RMSE: 85385.2287, Val MAE: 52616.5420, Val MSE: 7290637274.3805, Val R2: 0.6296\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1515\n",
      "Val RMSE: 87012.1273, Val MAE: 53609.3665, Val MSE: 7571110299.8020, Val R2: 0.6153\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.1364\n",
      "Val RMSE: 80625.0318, Val MAE: 49286.8391, Val MSE: 6500395751.2506, Val R2: 0.6697\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1395\n",
      "Val RMSE: 82046.6823, Val MAE: 50423.3260, Val MSE: 6731658081.2707, Val R2: 0.6580\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1456\n",
      "Val RMSE: 81638.3568, Val MAE: 52767.1884, Val MSE: 6664821298.4678, Val R2: 0.6614\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1470\n",
      "Val RMSE: 85376.3900, Val MAE: 51956.6771, Val MSE: 7289127967.2549, Val R2: 0.6297\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1508\n",
      "Val RMSE: 86832.6804, Val MAE: 53086.9615, Val MSE: 7539914379.7559, Val R2: 0.6169\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1390\n",
      "Val RMSE: 81255.1109, Val MAE: 50293.7310, Val MSE: 6602393053.2169, Val R2: 0.6646\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1468\n",
      "Val RMSE: 83742.0797, Val MAE: 51624.5439, Val MSE: 7012735919.5635, Val R2: 0.6437\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1450\n",
      "Val RMSE: 84311.3114, Val MAE: 51254.0137, Val MSE: 7108397222.1743, Val R2: 0.6388\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1548\n",
      "Val RMSE: 86210.8289, Val MAE: 55090.7183, Val MSE: 7432307026.9086, Val R2: 0.6224\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1531\n",
      "Val RMSE: 87471.6900, Val MAE: 53339.0412, Val MSE: 7651296555.6075, Val R2: 0.6113\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1480\n",
      "Val RMSE: 85690.0672, Val MAE: 53620.1417, Val MSE: 7342787616.4937, Val R2: 0.6269\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1461\n",
      "Val RMSE: 84488.2892, Val MAE: 51749.0814, Val MSE: 7138271010.0800, Val R2: 0.6373\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1364\n",
      "Val RMSE: 79208.4444, Val MAE: 50010.7033, Val MSE: 6273977660.0772, Val R2: 0.6812\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1333\n",
      "Val RMSE: 78749.8790, Val MAE: 47286.6046, Val MSE: 6201543450.2748, Val R2: 0.6849\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1522\n",
      "Val RMSE: 88761.7032, Val MAE: 49884.2467, Val MSE: 7878639953.3664, Val R2: 0.5997\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1441\n",
      "Val RMSE: 82568.8964, Val MAE: 50347.5123, Val MSE: 6817622655.8128, Val R2: 0.6536\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.1389\n",
      "Val RMSE: 80963.5551, Val MAE: 49006.0619, Val MSE: 6555097248.6940, Val R2: 0.6670\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1427\n",
      "Val RMSE: 83229.9766, Val MAE: 49737.1280, Val MSE: 6927229002.0133, Val R2: 0.6481\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1442\n",
      "Val RMSE: 81987.9005, Val MAE: 50339.6438, Val MSE: 6722015822.6976, Val R2: 0.6585\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.1462\n",
      "Val RMSE: 82582.5632, Val MAE: 53139.5298, Val MSE: 6819879746.8241, Val R2: 0.6535\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1363\n",
      "Val RMSE: 79906.6573, Val MAE: 48989.8997, Val MSE: 6385073883.8119, Val R2: 0.6756\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.1328\n",
      "Val RMSE: 79519.9628, Val MAE: 47485.7077, Val MSE: 6323424484.4061, Val R2: 0.6787\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.1381\n",
      "Val RMSE: 79760.9890, Val MAE: 49870.1874, Val MSE: 6361815365.1215, Val R2: 0.6768\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.1474\n",
      "Val RMSE: 84369.6754, Val MAE: 51048.0908, Val MSE: 7118242120.9432, Val R2: 0.6383\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.1342\n",
      "Val RMSE: 80158.4677, Val MAE: 48444.0569, Val MSE: 6425379948.2349, Val R2: 0.6736\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0413, Val Loss: 0.1263\n",
      "Val RMSE: 75543.5220, Val MAE: 46758.5447, Val MSE: 5706823710.3459, Val R2: 0.7101\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0410, Val Loss: 0.1474\n",
      "Val RMSE: 83377.2999, Val MAE: 48417.1204, Val MSE: 6951774131.8880, Val R2: 0.6468\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0391, Val Loss: 0.1304\n",
      "Val RMSE: 77530.6056, Val MAE: 47644.8801, Val MSE: 6010994798.2147, Val R2: 0.6946\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83568.6488, Test MAE: 48698.6479, Test MSE: 6983719068.0722, Test R2: 0.5523\n",
      "Inference Time: 1.83718021099384e-05 seconds per sample\n",
      "\n",
      "Iteration 52 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3312, Val Loss: 0.2839\n",
      "Val RMSE: 144406.2085, Val MAE: 81195.9430, Val MSE: 20853153065.4093, Val R2: -0.0595\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2700, Val Loss: 0.2773\n",
      "Val RMSE: 142062.9157, Val MAE: 82681.4347, Val MSE: 20181872009.1424, Val R2: -0.0254\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2687, Val Loss: 0.2787\n",
      "Val RMSE: 142555.0749, Val MAE: 82297.3807, Val MSE: 20321949367.3894, Val R2: -0.0325\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2813\n",
      "Val RMSE: 143576.7496, Val MAE: 81727.4092, Val MSE: 20614283022.4315, Val R2: -0.0473\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2757\n",
      "Val RMSE: 142267.0561, Val MAE: 83812.8369, Val MSE: 20239915246.4388, Val R2: -0.0283\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2598, Val Loss: 0.2757\n",
      "Val RMSE: 142468.9592, Val MAE: 82666.3327, Val MSE: 20297404329.1362, Val R2: -0.0312\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2756\n",
      "Val RMSE: 141509.8792, Val MAE: 84558.8785, Val MSE: 20025045913.0456, Val R2: -0.0174\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2568, Val Loss: 0.2730\n",
      "Val RMSE: 142258.6961, Val MAE: 82248.5553, Val MSE: 20237536621.0346, Val R2: -0.0282\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2709\n",
      "Val RMSE: 143809.2775, Val MAE: 78276.9829, Val MSE: 20681108295.6339, Val R2: -0.0507\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2666\n",
      "Val RMSE: 141718.2789, Val MAE: 79609.5466, Val MSE: 20084070578.1609, Val R2: -0.0204\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2664\n",
      "Val RMSE: 142843.9182, Val MAE: 77624.7419, Val MSE: 20404384966.6329, Val R2: -0.0367\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2491, Val Loss: 0.2668\n",
      "Val RMSE: 141071.3028, Val MAE: 80045.4685, Val MSE: 19901112487.6356, Val R2: -0.0111\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2446, Val Loss: 0.2736\n",
      "Val RMSE: 140524.4254, Val MAE: 83820.6789, Val MSE: 19747114144.6598, Val R2: -0.0033\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2677\n",
      "Val RMSE: 140964.3790, Val MAE: 79638.9658, Val MSE: 19870956157.9629, Val R2: -0.0096\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2659\n",
      "Val RMSE: 139500.7453, Val MAE: 81639.6808, Val MSE: 19460457930.7083, Val R2: 0.0113\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2423, Val Loss: 0.2745\n",
      "Val RMSE: 141216.5893, Val MAE: 82343.7712, Val MSE: 19942125101.3675, Val R2: -0.0132\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2397, Val Loss: 0.2575\n",
      "Val RMSE: 138742.7073, Val MAE: 77811.2314, Val MSE: 19249538827.6803, Val R2: 0.0220\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2307, Val Loss: 0.2462\n",
      "Val RMSE: 134974.2077, Val MAE: 72918.3102, Val MSE: 18218036754.3386, Val R2: 0.0744\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2220, Val Loss: 0.2371\n",
      "Val RMSE: 132432.6992, Val MAE: 72179.9499, Val MSE: 17538419826.7460, Val R2: 0.1089\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2178, Val Loss: 0.2466\n",
      "Val RMSE: 130425.3840, Val MAE: 78026.3516, Val MSE: 17010780798.1107, Val R2: 0.1357\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2184, Val Loss: 0.2540\n",
      "Val RMSE: 138563.7158, Val MAE: 79111.0844, Val MSE: 19199903347.2365, Val R2: 0.0245\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2056, Val Loss: 0.2271\n",
      "Val RMSE: 130459.7237, Val MAE: 70021.1486, Val MSE: 17019739496.1791, Val R2: 0.1353\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2040, Val Loss: 0.2276\n",
      "Val RMSE: 127583.5793, Val MAE: 73912.6318, Val MSE: 16277569703.9903, Val R2: 0.1730\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2020, Val Loss: 0.2259\n",
      "Val RMSE: 128082.2809, Val MAE: 70423.0463, Val MSE: 16405070672.8002, Val R2: 0.1665\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1940, Val Loss: 0.2150\n",
      "Val RMSE: 122054.2068, Val MAE: 69908.6119, Val MSE: 14897229390.4042, Val R2: 0.2431\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1889, Val Loss: 0.2167\n",
      "Val RMSE: 124043.3809, Val MAE: 67617.9010, Val MSE: 15386760356.6886, Val R2: 0.2183\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1786, Val Loss: 0.2046\n",
      "Val RMSE: 115500.0483, Val MAE: 65458.2022, Val MSE: 13340261159.6716, Val R2: 0.3222\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1717, Val Loss: 0.1845\n",
      "Val RMSE: 105607.0730, Val MAE: 62080.7210, Val MSE: 11152853868.5744, Val R2: 0.4334\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1687, Val Loss: 0.1813\n",
      "Val RMSE: 104090.9105, Val MAE: 62199.1766, Val MSE: 10834917648.6466, Val R2: 0.4495\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1611, Val Loss: 0.1836\n",
      "Val RMSE: 104562.4295, Val MAE: 61870.2651, Val MSE: 10933301669.1629, Val R2: 0.4445\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1548, Val Loss: 0.1768\n",
      "Val RMSE: 102254.0553, Val MAE: 59855.3505, Val MSE: 10455891815.4206, Val R2: 0.4688\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1750\n",
      "Val RMSE: 100951.4290, Val MAE: 59476.2273, Val MSE: 10191191017.2459, Val R2: 0.4822\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1505, Val Loss: 0.1774\n",
      "Val RMSE: 101725.3327, Val MAE: 58866.1979, Val MSE: 10348043309.0848, Val R2: 0.4743\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1667\n",
      "Val RMSE: 97541.2805, Val MAE: 58728.4949, Val MSE: 9514301405.2425, Val R2: 0.5166\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1409, Val Loss: 0.1783\n",
      "Val RMSE: 100282.8744, Val MAE: 58919.7047, Val MSE: 10056654889.3920, Val R2: 0.4891\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1361, Val Loss: 0.1687\n",
      "Val RMSE: 99102.6430, Val MAE: 56343.9327, Val MSE: 9821333848.1241, Val R2: 0.5010\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1289, Val Loss: 0.1574\n",
      "Val RMSE: 96906.2729, Val MAE: 54152.2617, Val MSE: 9390825729.7365, Val R2: 0.5229\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1231, Val Loss: 0.1540\n",
      "Val RMSE: 95808.7347, Val MAE: 55291.3434, Val MSE: 9179313646.9412, Val R2: 0.5336\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1178, Val Loss: 0.1493\n",
      "Val RMSE: 93902.8560, Val MAE: 52444.3638, Val MSE: 8817746366.7259, Val R2: 0.5520\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1127, Val Loss: 0.1586\n",
      "Val RMSE: 95748.8911, Val MAE: 56337.3332, Val MSE: 9167850137.5860, Val R2: 0.5342\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1097, Val Loss: 0.1409\n",
      "Val RMSE: 92388.4986, Val MAE: 48599.4989, Val MSE: 8535634676.2584, Val R2: 0.5663\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1053, Val Loss: 0.1386\n",
      "Val RMSE: 90177.0888, Val MAE: 50843.4328, Val MSE: 8131907344.6657, Val R2: 0.5868\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1441\n",
      "Val RMSE: 91642.0365, Val MAE: 49909.2280, Val MSE: 8398262862.0622, Val R2: 0.5733\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1019, Val Loss: 0.1362\n",
      "Val RMSE: 89853.7380, Val MAE: 47378.4428, Val MSE: 8073694224.4193, Val R2: 0.5898\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0960, Val Loss: 0.1267\n",
      "Val RMSE: 86744.9720, Val MAE: 46403.2188, Val MSE: 7524690173.0717, Val R2: 0.6177\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1572\n",
      "Val RMSE: 93274.5031, Val MAE: 55889.8778, Val MSE: 8700132935.2682, Val R2: 0.5580\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1241\n",
      "Val RMSE: 83798.7136, Val MAE: 45228.2920, Val MSE: 7022224400.8680, Val R2: 0.6432\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1365\n",
      "Val RMSE: 88735.1526, Val MAE: 50492.2130, Val MSE: 7873927301.6056, Val R2: 0.6000\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0853, Val Loss: 0.1258\n",
      "Val RMSE: 85612.1904, Val MAE: 45520.7093, Val MSE: 7329447146.9771, Val R2: 0.6276\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0799, Val Loss: 0.1449\n",
      "Val RMSE: 90042.1307, Val MAE: 50400.6737, Val MSE: 8107585307.0881, Val R2: 0.5881\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0819, Val Loss: 0.1273\n",
      "Val RMSE: 80457.8069, Val MAE: 47750.7150, Val MSE: 6473458689.5576, Val R2: 0.6711\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1470\n",
      "Val RMSE: 87127.2529, Val MAE: 50991.3712, Val MSE: 7591158198.5018, Val R2: 0.6143\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1522\n",
      "Val RMSE: 86668.5212, Val MAE: 52671.0034, Val MSE: 7511432570.6676, Val R2: 0.6184\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1135\n",
      "Val RMSE: 74439.7215, Val MAE: 43414.0309, Val MSE: 5541272141.2760, Val R2: 0.7185\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1300\n",
      "Val RMSE: 78381.7413, Val MAE: 47601.0419, Val MSE: 6143697365.1752, Val R2: 0.6879\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1115\n",
      "Val RMSE: 73179.9291, Val MAE: 41947.0840, Val MSE: 5355302030.1378, Val R2: 0.7279\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1306\n",
      "Val RMSE: 81183.0972, Val MAE: 46195.0442, Val MSE: 6590695269.1432, Val R2: 0.6652\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0684, Val Loss: 0.1475\n",
      "Val RMSE: 83415.3017, Val MAE: 52292.0400, Val MSE: 6958112549.8942, Val R2: 0.6465\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1112\n",
      "Val RMSE: 72766.4038, Val MAE: 41701.7527, Val MSE: 5294949518.1388, Val R2: 0.7310\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1164\n",
      "Val RMSE: 74449.3747, Val MAE: 43671.8071, Val MSE: 5542709396.0472, Val R2: 0.7184\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.1137\n",
      "Val RMSE: 75228.7986, Val MAE: 42300.6765, Val MSE: 5659372141.4625, Val R2: 0.7125\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1329\n",
      "Val RMSE: 79063.2289, Val MAE: 48918.9212, Val MSE: 6250994170.4282, Val R2: 0.6824\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1389\n",
      "Val RMSE: 80983.0954, Val MAE: 51091.5856, Val MSE: 6558261737.3886, Val R2: 0.6668\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1207\n",
      "Val RMSE: 78162.0891, Val MAE: 44362.8154, Val MSE: 6109312165.9357, Val R2: 0.6896\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1288\n",
      "Val RMSE: 80216.4951, Val MAE: 47038.8721, Val MSE: 6434686079.4722, Val R2: 0.6731\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1153\n",
      "Val RMSE: 74623.4573, Val MAE: 42757.1235, Val MSE: 5568660378.8728, Val R2: 0.7171\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1233\n",
      "Val RMSE: 77791.0296, Val MAE: 45011.1956, Val MSE: 6051444286.4517, Val R2: 0.6925\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1203\n",
      "Val RMSE: 77470.2585, Val MAE: 44150.5979, Val MSE: 6001640959.3756, Val R2: 0.6951\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1103\n",
      "Val RMSE: 76280.9774, Val MAE: 40471.9352, Val MSE: 5818787513.4531, Val R2: 0.7044\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1168\n",
      "Val RMSE: 73860.0019, Val MAE: 43874.8899, Val MSE: 5455299885.7723, Val R2: 0.7228\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1243\n",
      "Val RMSE: 78246.2747, Val MAE: 46610.9633, Val MSE: 6122479499.2613, Val R2: 0.6889\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1250\n",
      "Val RMSE: 77410.5278, Val MAE: 46266.3112, Val MSE: 5992389808.4439, Val R2: 0.6955\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1334\n",
      "Val RMSE: 78937.4789, Val MAE: 49090.2946, Val MSE: 6231125582.8503, Val R2: 0.6834\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1213\n",
      "Val RMSE: 77059.9376, Val MAE: 45548.6038, Val MSE: 5938233985.0692, Val R2: 0.6983\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1073\n",
      "Val RMSE: 71719.0836, Val MAE: 42796.1339, Val MSE: 5143626945.9536, Val R2: 0.7387\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1132\n",
      "Val RMSE: 73806.1681, Val MAE: 43880.2980, Val MSE: 5447350449.2995, Val R2: 0.7232\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1060\n",
      "Val RMSE: 70932.7963, Val MAE: 41765.2127, Val MSE: 5031461594.8569, Val R2: 0.7444\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1219\n",
      "Val RMSE: 77639.6347, Val MAE: 44433.2928, Val MSE: 6027912879.6112, Val R2: 0.6937\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1248\n",
      "Val RMSE: 79057.2640, Val MAE: 45488.7291, Val MSE: 6250050996.2709, Val R2: 0.6825\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1074\n",
      "Val RMSE: 73409.6949, Val MAE: 43309.2599, Val MSE: 5388983311.4843, Val R2: 0.7262\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1213\n",
      "Val RMSE: 76609.0182, Val MAE: 46182.9746, Val MSE: 5868941661.9335, Val R2: 0.7018\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1211\n",
      "Val RMSE: 76800.5603, Val MAE: 45499.8564, Val MSE: 5898326054.9673, Val R2: 0.7003\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1099\n",
      "Val RMSE: 72897.4149, Val MAE: 41932.7186, Val MSE: 5314033098.4928, Val R2: 0.7300\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1281\n",
      "Val RMSE: 80849.5755, Val MAE: 47250.5093, Val MSE: 6536653858.2360, Val R2: 0.6679\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1129\n",
      "Val RMSE: 74449.6239, Val MAE: 44028.0114, Val MSE: 5542746505.9534, Val R2: 0.7184\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.0966\n",
      "Val RMSE: 67616.0993, Val MAE: 41290.1377, Val MSE: 4571936886.8771, Val R2: 0.7677\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.0997\n",
      "Val RMSE: 69445.9542, Val MAE: 41072.9628, Val MSE: 4822740553.9686, Val R2: 0.7550\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0435, Val Loss: 0.1242\n",
      "Val RMSE: 78363.1070, Val MAE: 46445.5309, Val MSE: 6140776536.4166, Val R2: 0.6880\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1179\n",
      "Val RMSE: 78431.1914, Val MAE: 44353.1417, Val MSE: 6151451781.5862, Val R2: 0.6875\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.1292\n",
      "Val RMSE: 80682.2317, Val MAE: 46803.8145, Val MSE: 6509622514.3650, Val R2: 0.6693\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1058\n",
      "Val RMSE: 73710.2780, Val MAE: 39686.4256, Val MSE: 5433205078.3160, Val R2: 0.7240\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1044\n",
      "Val RMSE: 72084.5865, Val MAE: 40339.9074, Val MSE: 5196187609.3945, Val R2: 0.7360\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.1132\n",
      "Val RMSE: 75661.3898, Val MAE: 41389.8604, Val MSE: 5724645903.4766, Val R2: 0.7092\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.1270\n",
      "Val RMSE: 78667.1428, Val MAE: 48289.1899, Val MSE: 6188519357.9747, Val R2: 0.6856\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0399, Val Loss: 0.1101\n",
      "Val RMSE: 75689.8425, Val MAE: 42667.8276, Val MSE: 5728952257.3538, Val R2: 0.7089\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0396, Val Loss: 0.1064\n",
      "Val RMSE: 73944.5810, Val MAE: 41076.0879, Val MSE: 5467801063.3018, Val R2: 0.7222\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.0999\n",
      "Val RMSE: 69895.2838, Val MAE: 39699.1317, Val MSE: 4885350695.3588, Val R2: 0.7518\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.1178\n",
      "Val RMSE: 76374.4464, Val MAE: 44851.3825, Val MSE: 5833056055.7819, Val R2: 0.7036\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0389, Val Loss: 0.1125\n",
      "Val RMSE: 77054.5019, Val MAE: 42079.1411, Val MSE: 5937396268.6225, Val R2: 0.6983\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0403, Val Loss: 0.1022\n",
      "Val RMSE: 73153.5844, Val MAE: 39480.2718, Val MSE: 5351446913.0846, Val R2: 0.7281\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 71662.0803, Test MAE: 44781.4120, Test MSE: 5135453753.5240, Test R2: 0.6708\n",
      "Inference Time: 2.1327789013202373e-05 seconds per sample\n",
      "\n",
      "Iteration 53 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3894, Val Loss: 0.2891\n",
      "Val RMSE: 143890.9439, Val MAE: 83504.4027, Val MSE: 20704603731.3419, Val R2: -0.0519\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2854, Val Loss: 0.2855\n",
      "Val RMSE: 143168.6237, Val MAE: 83578.1928, Val MSE: 20497254800.1506, Val R2: -0.0414\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2760\n",
      "Val RMSE: 141507.7871, Val MAE: 83960.8392, Val MSE: 20024453810.8032, Val R2: -0.0174\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2694, Val Loss: 0.2783\n",
      "Val RMSE: 143191.0189, Val MAE: 81282.5580, Val MSE: 20503667895.6510, Val R2: -0.0417\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2666, Val Loss: 0.2758\n",
      "Val RMSE: 140606.4973, Val MAE: 86193.2037, Val MSE: 19770187071.2503, Val R2: -0.0045\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2653, Val Loss: 0.2752\n",
      "Val RMSE: 141044.8328, Val MAE: 84315.9398, Val MSE: 19893644863.8568, Val R2: -0.0107\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2619, Val Loss: 0.2749\n",
      "Val RMSE: 142120.6995, Val MAE: 81792.7217, Val MSE: 20198293240.4313, Val R2: -0.0262\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2742\n",
      "Val RMSE: 141717.0307, Val MAE: 82873.7246, Val MSE: 20083716778.2720, Val R2: -0.0204\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2749\n",
      "Val RMSE: 141309.4529, Val MAE: 84402.4646, Val MSE: 19968361487.0844, Val R2: -0.0145\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2577, Val Loss: 0.2725\n",
      "Val RMSE: 141239.6434, Val MAE: 83048.9669, Val MSE: 19948636878.8545, Val R2: -0.0135\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2766\n",
      "Val RMSE: 141864.4813, Val MAE: 82441.3689, Val MSE: 20125531068.0797, Val R2: -0.0225\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2558, Val Loss: 0.2747\n",
      "Val RMSE: 141500.2822, Val MAE: 83503.5086, Val MSE: 20022329856.9490, Val R2: -0.0173\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2711\n",
      "Val RMSE: 141724.5593, Val MAE: 82381.8523, Val MSE: 20085850697.0843, Val R2: -0.0205\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2733\n",
      "Val RMSE: 141755.3611, Val MAE: 82556.0807, Val MSE: 20094582395.6935, Val R2: -0.0209\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2504, Val Loss: 0.2806\n",
      "Val RMSE: 143705.4295, Val MAE: 80102.5855, Val MSE: 20651250471.6187, Val R2: -0.0492\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2734\n",
      "Val RMSE: 140531.9828, Val MAE: 85272.6617, Val MSE: 19749238197.5424, Val R2: -0.0034\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2501, Val Loss: 0.2683\n",
      "Val RMSE: 140637.3896, Val MAE: 82445.1404, Val MSE: 19778875355.7796, Val R2: -0.0049\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2470, Val Loss: 0.2666\n",
      "Val RMSE: 140534.2636, Val MAE: 80447.6599, Val MSE: 19749879245.7653, Val R2: -0.0034\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2690\n",
      "Val RMSE: 138949.8592, Val MAE: 84898.6163, Val MSE: 19307063367.1666, Val R2: 0.0191\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2667\n",
      "Val RMSE: 141822.3554, Val MAE: 79199.7847, Val MSE: 20113580490.0485, Val R2: -0.0219\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2439, Val Loss: 0.2654\n",
      "Val RMSE: 139976.2866, Val MAE: 81094.4017, Val MSE: 19593360797.7488, Val R2: 0.0045\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2439, Val Loss: 0.2690\n",
      "Val RMSE: 141787.6255, Val MAE: 78893.6456, Val MSE: 20103730751.9760, Val R2: -0.0214\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2415, Val Loss: 0.2801\n",
      "Val RMSE: 144579.3387, Val MAE: 78269.9857, Val MSE: 20903185179.9326, Val R2: -0.0620\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2438, Val Loss: 0.2602\n",
      "Val RMSE: 139901.3101, Val MAE: 79009.1610, Val MSE: 19572376566.8291, Val R2: 0.0056\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2540\n",
      "Val RMSE: 138268.0363, Val MAE: 76052.8559, Val MSE: 19118049858.3085, Val R2: 0.0287\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2305, Val Loss: 0.2467\n",
      "Val RMSE: 134231.6704, Val MAE: 74763.1878, Val MSE: 18018141342.5921, Val R2: 0.0846\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2244, Val Loss: 0.2346\n",
      "Val RMSE: 132377.0591, Val MAE: 72370.1877, Val MSE: 17523685773.7929, Val R2: 0.1097\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2194, Val Loss: 0.2438\n",
      "Val RMSE: 135717.7533, Val MAE: 70890.9033, Val MSE: 18419308548.4472, Val R2: 0.0642\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2159, Val Loss: 0.2320\n",
      "Val RMSE: 132163.9482, Val MAE: 69936.9752, Val MSE: 17467309198.0464, Val R2: 0.1126\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2062, Val Loss: 0.2145\n",
      "Val RMSE: 120829.4498, Val MAE: 66954.2590, Val MSE: 14599755929.1422, Val R2: 0.2582\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2089\n",
      "Val RMSE: 117665.9361, Val MAE: 68382.6797, Val MSE: 13845272527.9179, Val R2: 0.2966\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1876, Val Loss: 0.2146\n",
      "Val RMSE: 118431.6626, Val MAE: 70089.7542, Val MSE: 14026058711.7923, Val R2: 0.2874\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1839, Val Loss: 0.2070\n",
      "Val RMSE: 113849.7092, Val MAE: 67063.0198, Val MSE: 12961756280.0261, Val R2: 0.3415\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1749, Val Loss: 0.1870\n",
      "Val RMSE: 104426.0963, Val MAE: 65881.9390, Val MSE: 10904809597.4054, Val R2: 0.4460\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1695, Val Loss: 0.1797\n",
      "Val RMSE: 102565.3197, Val MAE: 63258.7534, Val MSE: 10519644802.7311, Val R2: 0.4655\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1659, Val Loss: 0.1709\n",
      "Val RMSE: 99797.1228, Val MAE: 60785.8882, Val MSE: 9959465726.9333, Val R2: 0.4940\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1579, Val Loss: 0.1620\n",
      "Val RMSE: 97661.6570, Val MAE: 58048.8768, Val MSE: 9537799248.4266, Val R2: 0.5154\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1540, Val Loss: 0.1604\n",
      "Val RMSE: 96812.7505, Val MAE: 58837.2332, Val MSE: 9372708650.9806, Val R2: 0.5238\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1474, Val Loss: 0.1595\n",
      "Val RMSE: 97431.9492, Val MAE: 55979.7698, Val MSE: 9492984717.8374, Val R2: 0.5177\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1500, Val Loss: 0.1536\n",
      "Val RMSE: 94870.2636, Val MAE: 55026.2968, Val MSE: 9000366916.4325, Val R2: 0.5427\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1651\n",
      "Val RMSE: 97685.4395, Val MAE: 56387.2506, Val MSE: 9542445082.8853, Val R2: 0.5152\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1388, Val Loss: 0.1482\n",
      "Val RMSE: 92812.7264, Val MAE: 53796.0190, Val MSE: 8614202180.8455, Val R2: 0.5623\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1373, Val Loss: 0.1652\n",
      "Val RMSE: 95982.6608, Val MAE: 57114.5688, Val MSE: 9212671172.7721, Val R2: 0.5319\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1296, Val Loss: 0.1577\n",
      "Val RMSE: 93974.8367, Val MAE: 55588.9382, Val MSE: 8831269933.6953, Val R2: 0.5513\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1259, Val Loss: 0.1412\n",
      "Val RMSE: 92258.9166, Val MAE: 51884.8477, Val MSE: 8511707686.9330, Val R2: 0.5676\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1205, Val Loss: 0.1486\n",
      "Val RMSE: 92268.4110, Val MAE: 54219.0909, Val MSE: 8513459659.3834, Val R2: 0.5675\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1607\n",
      "Val RMSE: 94231.8899, Val MAE: 56307.2744, Val MSE: 8879649073.5125, Val R2: 0.5489\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1169, Val Loss: 0.1416\n",
      "Val RMSE: 90748.1197, Val MAE: 51451.0564, Val MSE: 8235221235.7116, Val R2: 0.5816\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1431\n",
      "Val RMSE: 91405.4253, Val MAE: 53317.6890, Val MSE: 8354951767.6464, Val R2: 0.5755\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1083, Val Loss: 0.1324\n",
      "Val RMSE: 87863.5206, Val MAE: 49673.6170, Val MSE: 7719998254.9755, Val R2: 0.6078\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1046, Val Loss: 0.1366\n",
      "Val RMSE: 88861.9602, Val MAE: 50234.6478, Val MSE: 7896447965.8305, Val R2: 0.5988\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1019, Val Loss: 0.1394\n",
      "Val RMSE: 89564.1651, Val MAE: 52815.8097, Val MSE: 8021739667.3966, Val R2: 0.5924\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0993, Val Loss: 0.1343\n",
      "Val RMSE: 88106.7037, Val MAE: 50595.6633, Val MSE: 7762791238.3304, Val R2: 0.6056\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1395\n",
      "Val RMSE: 89763.1773, Val MAE: 52346.1935, Val MSE: 8057427996.1763, Val R2: 0.5906\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1403\n",
      "Val RMSE: 89111.5432, Val MAE: 49848.2402, Val MSE: 7940867138.3509, Val R2: 0.5966\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0915, Val Loss: 0.1322\n",
      "Val RMSE: 88110.7348, Val MAE: 48122.4365, Val MSE: 7763501587.8490, Val R2: 0.6056\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0893, Val Loss: 0.1338\n",
      "Val RMSE: 88934.2566, Val MAE: 49450.9944, Val MSE: 7909302004.8364, Val R2: 0.5982\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0892, Val Loss: 0.1357\n",
      "Val RMSE: 89227.1463, Val MAE: 48850.0609, Val MSE: 7961483629.3065, Val R2: 0.5955\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0865, Val Loss: 0.1377\n",
      "Val RMSE: 89486.6425, Val MAE: 48112.9251, Val MSE: 8007859194.1362, Val R2: 0.5932\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0853, Val Loss: 0.1407\n",
      "Val RMSE: 87041.6505, Val MAE: 49718.1713, Val MSE: 7576248921.7267, Val R2: 0.6151\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1302\n",
      "Val RMSE: 83566.6270, Val MAE: 46712.4763, Val MSE: 6983381141.4337, Val R2: 0.6452\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1375\n",
      "Val RMSE: 85123.6499, Val MAE: 48513.3683, Val MSE: 7246035768.7541, Val R2: 0.6319\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1399\n",
      "Val RMSE: 86738.6214, Val MAE: 48711.8029, Val MSE: 7523588436.5331, Val R2: 0.6178\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1304\n",
      "Val RMSE: 82720.7156, Val MAE: 47375.6791, Val MSE: 6842716787.3807, Val R2: 0.6523\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1362\n",
      "Val RMSE: 82783.4068, Val MAE: 48241.0867, Val MSE: 6853092440.0802, Val R2: 0.6518\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1450\n",
      "Val RMSE: 81978.0965, Val MAE: 50341.9678, Val MSE: 6720408313.1662, Val R2: 0.6586\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1370\n",
      "Val RMSE: 82105.0193, Val MAE: 48614.9879, Val MSE: 6741234191.8865, Val R2: 0.6575\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1220\n",
      "Val RMSE: 80007.9097, Val MAE: 44450.7966, Val MSE: 6401265607.0894, Val R2: 0.6748\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1269\n",
      "Val RMSE: 79304.4325, Val MAE: 45928.9065, Val MSE: 6289193018.5723, Val R2: 0.6805\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1353\n",
      "Val RMSE: 81449.3936, Val MAE: 47148.3593, Val MSE: 6634003724.3976, Val R2: 0.6630\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1445\n",
      "Val RMSE: 83722.6958, Val MAE: 48835.2702, Val MSE: 7009489791.0046, Val R2: 0.6439\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1210\n",
      "Val RMSE: 77203.6388, Val MAE: 44017.8984, Val MSE: 5960401842.8876, Val R2: 0.6972\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1243\n",
      "Val RMSE: 75999.4448, Val MAE: 45362.0489, Val MSE: 5775915606.4074, Val R2: 0.7065\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0669, Val Loss: 0.1250\n",
      "Val RMSE: 77123.7242, Val MAE: 44937.6784, Val MSE: 5948068830.5767, Val R2: 0.6978\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0644, Val Loss: 0.1258\n",
      "Val RMSE: 79353.7151, Val MAE: 45330.8776, Val MSE: 6297012099.8145, Val R2: 0.6801\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1214\n",
      "Val RMSE: 77137.1140, Val MAE: 44127.2860, Val MSE: 5950134349.9524, Val R2: 0.6977\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1253\n",
      "Val RMSE: 78206.6809, Val MAE: 44891.1830, Val MSE: 6116284931.2688, Val R2: 0.6893\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1569\n",
      "Val RMSE: 83561.6469, Val MAE: 50105.5986, Val MSE: 6982548835.2424, Val R2: 0.6452\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1224\n",
      "Val RMSE: 77249.9004, Val MAE: 44503.2259, Val MSE: 5967547104.6916, Val R2: 0.6968\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1196\n",
      "Val RMSE: 76894.7323, Val MAE: 43405.4911, Val MSE: 5912799856.8667, Val R2: 0.6996\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1210\n",
      "Val RMSE: 79750.5880, Val MAE: 43704.8852, Val MSE: 6360156282.7408, Val R2: 0.6769\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1164\n",
      "Val RMSE: 75292.0784, Val MAE: 42381.7345, Val MSE: 5668897063.9322, Val R2: 0.7120\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1169\n",
      "Val RMSE: 76074.1877, Val MAE: 43726.5152, Val MSE: 5787282032.1856, Val R2: 0.7060\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1072\n",
      "Val RMSE: 70070.0878, Val MAE: 41167.8663, Val MSE: 4909817208.6606, Val R2: 0.7506\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1174\n",
      "Val RMSE: 78772.5539, Val MAE: 42212.4940, Val MSE: 6205115249.3240, Val R2: 0.6847\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1100\n",
      "Val RMSE: 73171.5813, Val MAE: 40177.9919, Val MSE: 5354080307.3657, Val R2: 0.7280\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.1073\n",
      "Val RMSE: 72507.8406, Val MAE: 39346.8234, Val MSE: 5257386942.9525, Val R2: 0.7329\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1193\n",
      "Val RMSE: 76287.7033, Val MAE: 42991.9119, Val MSE: 5819813678.8631, Val R2: 0.7043\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1149\n",
      "Val RMSE: 75422.8202, Val MAE: 41958.1157, Val MSE: 5688601809.0128, Val R2: 0.7110\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1114\n",
      "Val RMSE: 74359.0551, Val MAE: 40215.8680, Val MSE: 5529269069.8276, Val R2: 0.7191\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1095\n",
      "Val RMSE: 73521.4000, Val MAE: 39191.9878, Val MSE: 5405396253.3457, Val R2: 0.7254\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1116\n",
      "Val RMSE: 72570.0926, Val MAE: 40169.9471, Val MSE: 5266418334.8535, Val R2: 0.7324\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1140\n",
      "Val RMSE: 77189.3580, Val MAE: 39891.1191, Val MSE: 5958196991.0452, Val R2: 0.6973\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1202\n",
      "Val RMSE: 77032.0424, Val MAE: 41878.6037, Val MSE: 5933935550.3099, Val R2: 0.6985\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1145\n",
      "Val RMSE: 74920.8448, Val MAE: 40405.4958, Val MSE: 5613132990.4887, Val R2: 0.7148\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1088\n",
      "Val RMSE: 73156.3049, Val MAE: 39213.7285, Val MSE: 5351844946.3712, Val R2: 0.7281\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1169\n",
      "Val RMSE: 75385.2804, Val MAE: 41323.2452, Val MSE: 5682940505.2537, Val R2: 0.7113\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1100\n",
      "Val RMSE: 75021.2868, Val MAE: 39538.0089, Val MSE: 5628193472.4353, Val R2: 0.7141\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1050\n",
      "Val RMSE: 70051.5918, Val MAE: 38583.4967, Val MSE: 4907225518.7365, Val R2: 0.7507\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.0971\n",
      "Val RMSE: 67140.8246, Val MAE: 36878.8156, Val MSE: 4507890322.3980, Val R2: 0.7710\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 70797.2314, Test MAE: 37102.2848, Test MSE: 5012247974.6049, Test R2: 0.6787\n",
      "Inference Time: 1.807986772977389e-05 seconds per sample\n",
      "\n",
      "Iteration 54 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3632, Val Loss: 0.2868\n",
      "Val RMSE: 139839.8141, Val MAE: 93810.3450, Val MSE: 19555173594.1766, Val R2: 0.0065\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2756\n",
      "Val RMSE: 141300.6695, Val MAE: 84475.6333, Val MSE: 19965879189.4960, Val R2: -0.0144\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2698, Val Loss: 0.2752\n",
      "Val RMSE: 141644.7971, Val MAE: 83522.9115, Val MSE: 20063248546.7227, Val R2: -0.0193\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2643, Val Loss: 0.2747\n",
      "Val RMSE: 142176.9881, Val MAE: 82464.0039, Val MSE: 20214295959.2676, Val R2: -0.0270\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2621, Val Loss: 0.2780\n",
      "Val RMSE: 142168.6779, Val MAE: 84530.3364, Val MSE: 20211932962.1864, Val R2: -0.0269\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2841\n",
      "Val RMSE: 142138.5997, Val MAE: 86727.2897, Val MSE: 20203381532.8010, Val R2: -0.0265\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2785\n",
      "Val RMSE: 141787.1742, Val MAE: 85993.8117, Val MSE: 20103602771.3421, Val R2: -0.0214\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2713\n",
      "Val RMSE: 141527.1954, Val MAE: 82461.1218, Val MSE: 20029947042.6808, Val R2: -0.0176\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2577, Val Loss: 0.2719\n",
      "Val RMSE: 140574.0967, Val MAE: 84823.2824, Val MSE: 19761076651.6587, Val R2: -0.0040\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2737\n",
      "Val RMSE: 140840.6475, Val MAE: 84148.4823, Val MSE: 19836087983.6806, Val R2: -0.0078\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2775\n",
      "Val RMSE: 141815.1078, Val MAE: 84667.0990, Val MSE: 20111524790.5362, Val R2: -0.0218\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2869\n",
      "Val RMSE: 144991.1612, Val MAE: 80527.4669, Val MSE: 21022436831.4719, Val R2: -0.0681\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2693\n",
      "Val RMSE: 141611.9860, Val MAE: 80328.4431, Val MSE: 20053954589.3569, Val R2: -0.0189\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2503, Val Loss: 0.2696\n",
      "Val RMSE: 141787.8534, Val MAE: 79963.1109, Val MSE: 20103795362.4817, Val R2: -0.0214\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2481, Val Loss: 0.2683\n",
      "Val RMSE: 141630.6670, Val MAE: 79723.1374, Val MSE: 20059245826.9302, Val R2: -0.0191\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2456, Val Loss: 0.2607\n",
      "Val RMSE: 140364.4175, Val MAE: 76743.4429, Val MSE: 19702169702.6963, Val R2: -0.0010\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2356, Val Loss: 0.2586\n",
      "Val RMSE: 136287.7200, Val MAE: 77978.2335, Val MSE: 18574342635.0280, Val R2: 0.0563\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2314, Val Loss: 0.2493\n",
      "Val RMSE: 134044.3835, Val MAE: 77708.6723, Val MSE: 17967896746.9059, Val R2: 0.0871\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2305, Val Loss: 0.2547\n",
      "Val RMSE: 132504.5239, Val MAE: 80672.0027, Val MSE: 17557448858.0610, Val R2: 0.1080\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2317, Val Loss: 0.2475\n",
      "Val RMSE: 134522.2156, Val MAE: 75613.9182, Val MSE: 18096226489.3203, Val R2: 0.0806\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2305, Val Loss: 0.2556\n",
      "Val RMSE: 138058.3139, Val MAE: 73664.5286, Val MSE: 19060098034.8562, Val R2: 0.0316\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2359, Val Loss: 0.2517\n",
      "Val RMSE: 136926.4890, Val MAE: 73602.4841, Val MSE: 18748863379.8014, Val R2: 0.0474\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2202, Val Loss: 0.2393\n",
      "Val RMSE: 133058.7099, Val MAE: 71810.4433, Val MSE: 17704620290.9461, Val R2: 0.1005\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2183, Val Loss: 0.2463\n",
      "Val RMSE: 131784.0994, Val MAE: 76755.7951, Val MSE: 17367048862.9023, Val R2: 0.1176\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2133, Val Loss: 0.2283\n",
      "Val RMSE: 131067.3753, Val MAE: 72416.3488, Val MSE: 17178656875.1929, Val R2: 0.1272\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2035, Val Loss: 0.2288\n",
      "Val RMSE: 129429.0138, Val MAE: 68747.1638, Val MSE: 16751869616.9325, Val R2: 0.1489\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1921, Val Loss: 0.1996\n",
      "Val RMSE: 111316.4229, Val MAE: 68663.3747, Val MSE: 12391346009.0718, Val R2: 0.3704\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1833, Val Loss: 0.2107\n",
      "Val RMSE: 114841.5759, Val MAE: 65466.1548, Val MSE: 13188587550.7220, Val R2: 0.3299\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1906, Val Loss: 0.2029\n",
      "Val RMSE: 114307.2969, Val MAE: 63659.3754, Val MSE: 13066158114.5011, Val R2: 0.3362\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1823, Val Loss: 0.1901\n",
      "Val RMSE: 108121.6955, Val MAE: 65858.1035, Val MSE: 11690301036.2157, Val R2: 0.4061\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1834, Val Loss: 0.1971\n",
      "Val RMSE: 109991.2931, Val MAE: 64655.5971, Val MSE: 12098084557.6703, Val R2: 0.3853\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1846\n",
      "Val RMSE: 104631.2191, Val MAE: 64286.1053, Val MSE: 10947692016.5805, Val R2: 0.4438\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1664, Val Loss: 0.1883\n",
      "Val RMSE: 107366.3875, Val MAE: 61438.1849, Val MSE: 11527541160.2202, Val R2: 0.4143\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1631, Val Loss: 0.1824\n",
      "Val RMSE: 104544.9398, Val MAE: 61346.8140, Val MSE: 10929644447.0364, Val R2: 0.4447\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1580, Val Loss: 0.1902\n",
      "Val RMSE: 104962.0015, Val MAE: 61268.1556, Val MSE: 11017021754.2935, Val R2: 0.4403\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1573, Val Loss: 0.1729\n",
      "Val RMSE: 101475.1477, Val MAE: 60194.4791, Val MSE: 10297205596.7434, Val R2: 0.4768\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1547, Val Loss: 0.1661\n",
      "Val RMSE: 100087.2308, Val MAE: 59188.8886, Val MSE: 10017453771.7433, Val R2: 0.4911\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1526, Val Loss: 0.1634\n",
      "Val RMSE: 99357.2916, Val MAE: 58950.0964, Val MSE: 9871871390.5952, Val R2: 0.4984\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1479, Val Loss: 0.1665\n",
      "Val RMSE: 99850.7042, Val MAE: 58799.4116, Val MSE: 9970163134.8663, Val R2: 0.4935\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1465, Val Loss: 0.1592\n",
      "Val RMSE: 97987.7224, Val MAE: 57150.6659, Val MSE: 9601593737.6948, Val R2: 0.5122\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1623\n",
      "Val RMSE: 97968.8335, Val MAE: 58105.7779, Val MSE: 9597892332.4007, Val R2: 0.5124\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1414, Val Loss: 0.1582\n",
      "Val RMSE: 97000.1989, Val MAE: 57418.2504, Val MSE: 9409038590.8207, Val R2: 0.5220\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1606\n",
      "Val RMSE: 97915.9957, Val MAE: 57090.3056, Val MSE: 9587542216.4854, Val R2: 0.5129\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1385, Val Loss: 0.1773\n",
      "Val RMSE: 100876.8300, Val MAE: 59336.0139, Val MSE: 10176134823.8901, Val R2: 0.4830\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1418, Val Loss: 0.1566\n",
      "Val RMSE: 95397.0121, Val MAE: 55666.8407, Val MSE: 9100589913.1812, Val R2: 0.5376\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1353, Val Loss: 0.1660\n",
      "Val RMSE: 98819.1162, Val MAE: 57973.6802, Val MSE: 9765217728.5824, Val R2: 0.5039\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1302, Val Loss: 0.1570\n",
      "Val RMSE: 96355.8711, Val MAE: 55806.0646, Val MSE: 9284453898.5636, Val R2: 0.5283\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1264, Val Loss: 0.1518\n",
      "Val RMSE: 94619.9257, Val MAE: 55864.7175, Val MSE: 8952930345.8198, Val R2: 0.5451\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1237, Val Loss: 0.1561\n",
      "Val RMSE: 94703.6054, Val MAE: 55844.8361, Val MSE: 8968772877.8722, Val R2: 0.5443\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1213, Val Loss: 0.1637\n",
      "Val RMSE: 95880.1232, Val MAE: 58327.6397, Val MSE: 9192998027.5443, Val R2: 0.5329\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1196, Val Loss: 0.1665\n",
      "Val RMSE: 97285.3957, Val MAE: 57996.7134, Val MSE: 9464448220.4974, Val R2: 0.5191\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1167, Val Loss: 0.1529\n",
      "Val RMSE: 95540.3484, Val MAE: 54592.0651, Val MSE: 9127958165.3886, Val R2: 0.5362\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1416\n",
      "Val RMSE: 91557.5958, Val MAE: 51896.1812, Val MSE: 8382793355.7803, Val R2: 0.5741\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1120, Val Loss: 0.1502\n",
      "Val RMSE: 94479.3309, Val MAE: 53266.3688, Val MSE: 8926343966.9304, Val R2: 0.5465\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1095, Val Loss: 0.1511\n",
      "Val RMSE: 93667.3416, Val MAE: 54562.0615, Val MSE: 8773570876.3457, Val R2: 0.5542\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1069, Val Loss: 0.1563\n",
      "Val RMSE: 95745.8229, Val MAE: 56565.0884, Val MSE: 9167262596.5410, Val R2: 0.5342\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1059, Val Loss: 0.1623\n",
      "Val RMSE: 96638.2631, Val MAE: 57228.9038, Val MSE: 9338953890.6769, Val R2: 0.5255\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1066, Val Loss: 0.1474\n",
      "Val RMSE: 93159.5473, Val MAE: 54830.9969, Val MSE: 8678701246.6800, Val R2: 0.5591\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1051, Val Loss: 0.1700\n",
      "Val RMSE: 99361.9880, Val MAE: 61557.5639, Val MSE: 9872804666.6343, Val R2: 0.4984\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1518\n",
      "Val RMSE: 94498.6305, Val MAE: 55279.0180, Val MSE: 8929991174.1248, Val R2: 0.5463\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1528\n",
      "Val RMSE: 94719.3210, Val MAE: 56015.2265, Val MSE: 8971749777.9249, Val R2: 0.5442\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1008, Val Loss: 0.1511\n",
      "Val RMSE: 95158.2238, Val MAE: 53655.5227, Val MSE: 9055087552.5113, Val R2: 0.5399\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0979, Val Loss: 0.1730\n",
      "Val RMSE: 100238.0661, Val MAE: 60778.0755, Val MSE: 10047669897.2006, Val R2: 0.4895\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0961, Val Loss: 0.1532\n",
      "Val RMSE: 94887.0797, Val MAE: 54997.0560, Val MSE: 9003557897.2819, Val R2: 0.5426\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0938, Val Loss: 0.1698\n",
      "Val RMSE: 98823.5705, Val MAE: 61276.7572, Val MSE: 9766098094.4657, Val R2: 0.5038\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0948, Val Loss: 0.1521\n",
      "Val RMSE: 94914.3596, Val MAE: 54861.3053, Val MSE: 9008735658.4186, Val R2: 0.5423\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0931, Val Loss: 0.1674\n",
      "Val RMSE: 98272.1754, Val MAE: 59783.8669, Val MSE: 9657420457.7834, Val R2: 0.5093\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0921, Val Loss: 0.1876\n",
      "Val RMSE: 102623.4384, Val MAE: 64954.2885, Val MSE: 10531570115.9912, Val R2: 0.4649\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0904, Val Loss: 0.1784\n",
      "Val RMSE: 101923.9264, Val MAE: 64641.8173, Val MSE: 10388486769.5534, Val R2: 0.4722\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1743\n",
      "Val RMSE: 99887.8762, Val MAE: 60753.4040, Val MSE: 9977587804.0338, Val R2: 0.4931\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1810\n",
      "Val RMSE: 102646.1136, Val MAE: 62871.1934, Val MSE: 10536224638.6924, Val R2: 0.4647\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1563\n",
      "Val RMSE: 94256.9518, Val MAE: 55461.9859, Val MSE: 8884372954.0763, Val R2: 0.5486\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1638\n",
      "Val RMSE: 94950.7205, Val MAE: 59698.3046, Val MSE: 9015639316.7052, Val R2: 0.5419\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1701\n",
      "Val RMSE: 97662.1936, Val MAE: 61123.4509, Val MSE: 9537904064.2525, Val R2: 0.5154\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1604\n",
      "Val RMSE: 94398.4296, Val MAE: 57067.8798, Val MSE: 8911063514.5159, Val R2: 0.5473\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1610\n",
      "Val RMSE: 95000.6744, Val MAE: 57791.6734, Val MSE: 9025128129.8560, Val R2: 0.5415\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1570\n",
      "Val RMSE: 92819.4031, Val MAE: 55879.6421, Val MSE: 8615441600.6098, Val R2: 0.5623\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0773, Val Loss: 0.1757\n",
      "Val RMSE: 96774.0713, Val MAE: 61273.0432, Val MSE: 9365220871.0227, Val R2: 0.5242\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0763, Val Loss: 0.1783\n",
      "Val RMSE: 97452.3759, Val MAE: 62863.8941, Val MSE: 9496965566.9501, Val R2: 0.5175\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1535\n",
      "Val RMSE: 89841.1571, Val MAE: 56393.7188, Val MSE: 8071433503.0970, Val R2: 0.5899\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1574\n",
      "Val RMSE: 93695.6141, Val MAE: 55428.5035, Val MSE: 8778868099.4728, Val R2: 0.5540\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1628\n",
      "Val RMSE: 94700.0738, Val MAE: 57558.4223, Val MSE: 8968103971.7587, Val R2: 0.5444\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1589\n",
      "Val RMSE: 92980.7452, Val MAE: 56552.1420, Val MSE: 8645418969.2401, Val R2: 0.5608\n",
      "Early stopping triggered after epoch 83\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 104593.9665, Test MAE: 63005.5694, Test MSE: 10939897834.5451, Test R2: 0.2987\n",
      "Inference Time: 1.8209090599646933e-05 seconds per sample\n",
      "\n",
      "Iteration 55 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3620, Val Loss: 0.2884\n",
      "Val RMSE: 143451.2014, Val MAE: 84142.2535, Val MSE: 20578247169.6481, Val R2: -0.0455\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2809, Val Loss: 0.2857\n",
      "Val RMSE: 142865.4398, Val MAE: 84268.0508, Val MSE: 20410533890.2837, Val R2: -0.0370\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2755, Val Loss: 0.2781\n",
      "Val RMSE: 142378.9518, Val MAE: 82681.9745, Val MSE: 20271765917.2332, Val R2: -0.0299\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2687, Val Loss: 0.2760\n",
      "Val RMSE: 142077.8093, Val MAE: 82616.1834, Val MSE: 20186103898.3909, Val R2: -0.0256\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2643, Val Loss: 0.2804\n",
      "Val RMSE: 141283.0771, Val MAE: 87423.9343, Val MSE: 19960907886.4367, Val R2: -0.0141\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2630, Val Loss: 0.2752\n",
      "Val RMSE: 143431.1029, Val MAE: 79851.2094, Val MSE: 20572481280.0695, Val R2: -0.0452\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2722\n",
      "Val RMSE: 141692.0932, Val MAE: 81886.9419, Val MSE: 20076649264.6072, Val R2: -0.0200\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2574, Val Loss: 0.2704\n",
      "Val RMSE: 141432.9695, Val MAE: 81822.2211, Val MSE: 20003284858.0818, Val R2: -0.0163\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2703\n",
      "Val RMSE: 140659.6247, Val MAE: 83060.8231, Val MSE: 19785130025.3759, Val R2: -0.0052\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2685\n",
      "Val RMSE: 141425.3812, Val MAE: 80255.7781, Val MSE: 20001138460.7739, Val R2: -0.0162\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2551, Val Loss: 0.2657\n",
      "Val RMSE: 141438.6865, Val MAE: 79741.0721, Val MSE: 20004902030.8498, Val R2: -0.0164\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2668\n",
      "Val RMSE: 141758.6760, Val MAE: 79127.2802, Val MSE: 20095522226.7720, Val R2: -0.0210\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2499, Val Loss: 0.2669\n",
      "Val RMSE: 138523.5128, Val MAE: 81283.6836, Val MSE: 19188763590.1516, Val R2: 0.0251\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2436, Val Loss: 0.2556\n",
      "Val RMSE: 136416.9751, Val MAE: 76963.6677, Val MSE: 18609591105.7228, Val R2: 0.0545\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2390, Val Loss: 0.2486\n",
      "Val RMSE: 134784.6381, Val MAE: 75148.3606, Val MSE: 18166898677.6810, Val R2: 0.0770\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2359, Val Loss: 0.2552\n",
      "Val RMSE: 136133.6954, Val MAE: 74526.5616, Val MSE: 18532383025.0424, Val R2: 0.0584\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2325, Val Loss: 0.2603\n",
      "Val RMSE: 133711.3522, Val MAE: 80580.3765, Val MSE: 17878725704.5116, Val R2: 0.0916\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2462\n",
      "Val RMSE: 133315.9399, Val MAE: 77216.7922, Val MSE: 17773139831.7829, Val R2: 0.0970\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2109, Val Loss: 0.2476\n",
      "Val RMSE: 137376.3273, Val MAE: 71406.9510, Val MSE: 18872255306.8495, Val R2: 0.0412\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2122, Val Loss: 0.2568\n",
      "Val RMSE: 140325.5409, Val MAE: 79053.8256, Val MSE: 19691257416.2819, Val R2: -0.0004\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2068, Val Loss: 0.2292\n",
      "Val RMSE: 130952.4488, Val MAE: 72116.8989, Val MSE: 17148543839.5311, Val R2: 0.1287\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2300\n",
      "Val RMSE: 131228.4923, Val MAE: 71261.0257, Val MSE: 17220917183.6739, Val R2: 0.1251\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2036, Val Loss: 0.2397\n",
      "Val RMSE: 134431.4044, Val MAE: 72428.2136, Val MSE: 18071802478.1221, Val R2: 0.0818\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2002, Val Loss: 0.2293\n",
      "Val RMSE: 131204.5904, Val MAE: 72170.9275, Val MSE: 17214644551.6659, Val R2: 0.1254\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1956, Val Loss: 0.2252\n",
      "Val RMSE: 128772.6895, Val MAE: 70838.2339, Val MSE: 16582405548.9051, Val R2: 0.1575\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1907, Val Loss: 0.2149\n",
      "Val RMSE: 126080.1532, Val MAE: 67755.0665, Val MSE: 15896205036.2542, Val R2: 0.1924\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1888, Val Loss: 0.2118\n",
      "Val RMSE: 120625.8246, Val MAE: 69999.9948, Val MSE: 14550589565.1229, Val R2: 0.2607\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1803, Val Loss: 0.2088\n",
      "Val RMSE: 120185.3157, Val MAE: 66419.5875, Val MSE: 14444510101.7495, Val R2: 0.2661\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1854, Val Loss: 0.2053\n",
      "Val RMSE: 116427.6174, Val MAE: 65559.0066, Val MSE: 13555390098.3085, Val R2: 0.3113\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1787, Val Loss: 0.1971\n",
      "Val RMSE: 111968.4069, Val MAE: 65365.6427, Val MSE: 12536924142.6281, Val R2: 0.3630\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1702, Val Loss: 0.1937\n",
      "Val RMSE: 110381.2611, Val MAE: 64924.7019, Val MSE: 12184022800.4377, Val R2: 0.3810\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1667, Val Loss: 0.1845\n",
      "Val RMSE: 107005.3574, Val MAE: 62041.6733, Val MSE: 11450146512.4506, Val R2: 0.4183\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1650, Val Loss: 0.1821\n",
      "Val RMSE: 104771.9904, Val MAE: 62444.2747, Val MSE: 10977169964.2986, Val R2: 0.4423\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1633, Val Loss: 0.1753\n",
      "Val RMSE: 101767.0224, Val MAE: 59884.4294, Val MSE: 10356526840.2881, Val R2: 0.4738\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1603, Val Loss: 0.1860\n",
      "Val RMSE: 105953.9804, Val MAE: 61391.2027, Val MSE: 11226245972.2126, Val R2: 0.4296\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1572, Val Loss: 0.1798\n",
      "Val RMSE: 104329.4397, Val MAE: 60579.0692, Val MSE: 10884631982.5282, Val R2: 0.4470\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1559, Val Loss: 0.1780\n",
      "Val RMSE: 101345.0136, Val MAE: 60794.3232, Val MSE: 10270811786.4052, Val R2: 0.4782\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1780\n",
      "Val RMSE: 103239.4969, Val MAE: 59559.7684, Val MSE: 10658393728.5254, Val R2: 0.4585\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1500, Val Loss: 0.1697\n",
      "Val RMSE: 100624.5154, Val MAE: 58607.8870, Val MSE: 10125293105.8783, Val R2: 0.4856\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1470, Val Loss: 0.1698\n",
      "Val RMSE: 99768.5893, Val MAE: 57758.1199, Val MSE: 9953771407.1231, Val R2: 0.4943\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1697\n",
      "Val RMSE: 100953.7957, Val MAE: 55911.9127, Val MSE: 10191668859.8513, Val R2: 0.4822\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1358, Val Loss: 0.1754\n",
      "Val RMSE: 98566.0920, Val MAE: 58746.8595, Val MSE: 9715274498.5252, Val R2: 0.5064\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1296, Val Loss: 0.3591\n",
      "Val RMSE: 183414.7904, Val MAE: 90331.0757, Val MSE: 33640985325.2907, Val R2: -0.7092\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1312, Val Loss: 0.1775\n",
      "Val RMSE: 98254.1872, Val MAE: 60753.2988, Val MSE: 9653885303.2546, Val R2: 0.5095\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1272, Val Loss: 0.1613\n",
      "Val RMSE: 97206.2098, Val MAE: 58774.7496, Val MSE: 9449047231.0598, Val R2: 0.5199\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1239, Val Loss: 0.1611\n",
      "Val RMSE: 98429.3412, Val MAE: 54737.2392, Val MSE: 9688335214.4423, Val R2: 0.5078\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1208, Val Loss: 0.1531\n",
      "Val RMSE: 94896.7547, Val MAE: 55061.7731, Val MSE: 9005394058.6044, Val R2: 0.5425\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1177, Val Loss: 0.1495\n",
      "Val RMSE: 94154.2811, Val MAE: 53606.6956, Val MSE: 8865028643.2608, Val R2: 0.5496\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1122, Val Loss: 0.1544\n",
      "Val RMSE: 95813.0894, Val MAE: 52518.4096, Val MSE: 9180148096.4192, Val R2: 0.5336\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1105, Val Loss: 0.1450\n",
      "Val RMSE: 91483.9211, Val MAE: 54078.2117, Val MSE: 8369307828.3630, Val R2: 0.5748\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1475\n",
      "Val RMSE: 92981.3933, Val MAE: 52725.5938, Val MSE: 8645539506.3079, Val R2: 0.5608\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1077, Val Loss: 0.1398\n",
      "Val RMSE: 90529.9484, Val MAE: 50807.6529, Val MSE: 8195671552.9166, Val R2: 0.5836\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1041, Val Loss: 0.1636\n",
      "Val RMSE: 95831.9770, Val MAE: 55668.0149, Val MSE: 9183767824.4723, Val R2: 0.5334\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1019, Val Loss: 0.1456\n",
      "Val RMSE: 91870.6090, Val MAE: 53089.7521, Val MSE: 8440208803.9135, Val R2: 0.5712\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1501\n",
      "Val RMSE: 94159.2502, Val MAE: 52085.3519, Val MSE: 8865964402.1457, Val R2: 0.5496\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0992, Val Loss: 0.1460\n",
      "Val RMSE: 93233.1785, Val MAE: 50822.2477, Val MSE: 8692425576.3871, Val R2: 0.5584\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1565\n",
      "Val RMSE: 96002.6108, Val MAE: 55191.7947, Val MSE: 9216501275.9127, Val R2: 0.5317\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1516\n",
      "Val RMSE: 94299.5379, Val MAE: 52258.2979, Val MSE: 8892402856.8779, Val R2: 0.5482\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1579\n",
      "Val RMSE: 95163.0344, Val MAE: 55912.3794, Val MSE: 9056003115.7496, Val R2: 0.5399\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0915, Val Loss: 0.1578\n",
      "Val RMSE: 97246.8707, Val MAE: 52731.3826, Val MSE: 9456953852.6557, Val R2: 0.5195\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0912, Val Loss: 0.1489\n",
      "Val RMSE: 93616.4107, Val MAE: 53160.0706, Val MSE: 8764032351.8251, Val R2: 0.5547\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.1706\n",
      "Val RMSE: 98926.0741, Val MAE: 58082.8125, Val MSE: 9786368131.1943, Val R2: 0.5028\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1558\n",
      "Val RMSE: 97000.4699, Val MAE: 53208.7624, Val MSE: 9409091157.0009, Val R2: 0.5220\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0861, Val Loss: 0.1609\n",
      "Val RMSE: 95030.0252, Val MAE: 56310.4886, Val MSE: 9030705684.0523, Val R2: 0.5412\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1529\n",
      "Val RMSE: 94843.6533, Val MAE: 51926.7684, Val MSE: 8995318564.8132, Val R2: 0.5430\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1661\n",
      "Val RMSE: 97498.9860, Val MAE: 57420.5790, Val MSE: 9506052272.6429, Val R2: 0.5170\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0831, Val Loss: 0.1550\n",
      "Val RMSE: 93696.3638, Val MAE: 52629.3379, Val MSE: 8779008583.0261, Val R2: 0.5540\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.1565\n",
      "Val RMSE: 93181.6480, Val MAE: 56662.3606, Val MSE: 8682819531.1826, Val R2: 0.5589\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.1472\n",
      "Val RMSE: 89037.8017, Val MAE: 50251.2755, Val MSE: 7927730135.6602, Val R2: 0.5972\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1704\n",
      "Val RMSE: 94685.3972, Val MAE: 55577.3951, Val MSE: 8965324441.1596, Val R2: 0.5445\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1512\n",
      "Val RMSE: 87950.9838, Val MAE: 50741.7872, Val MSE: 7735375552.9269, Val R2: 0.6070\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1415\n",
      "Val RMSE: 86066.3088, Val MAE: 48631.9290, Val MSE: 7407409502.4991, Val R2: 0.6237\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0728, Val Loss: 0.1512\n",
      "Val RMSE: 87559.5743, Val MAE: 51972.4175, Val MSE: 7666679048.5908, Val R2: 0.6105\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0724, Val Loss: 0.1588\n",
      "Val RMSE: 91924.5550, Val MAE: 52147.8687, Val MSE: 8450123808.6754, Val R2: 0.5707\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1506\n",
      "Val RMSE: 89141.2651, Val MAE: 52041.9804, Val MSE: 7946165150.8442, Val R2: 0.5963\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0684, Val Loss: 0.1404\n",
      "Val RMSE: 85411.0612, Val MAE: 50617.6402, Val MSE: 7295049374.8034, Val R2: 0.6294\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1640\n",
      "Val RMSE: 92056.8503, Val MAE: 55854.7341, Val MSE: 8474463691.7884, Val R2: 0.5694\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0686, Val Loss: 0.1457\n",
      "Val RMSE: 89328.7848, Val MAE: 51779.9535, Val MSE: 7979631792.8983, Val R2: 0.5946\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1584\n",
      "Val RMSE: 88313.3237, Val MAE: 51324.0040, Val MSE: 7799243145.2518, Val R2: 0.6037\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1493\n",
      "Val RMSE: 88060.2435, Val MAE: 51709.1206, Val MSE: 7754606486.3756, Val R2: 0.6060\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1406\n",
      "Val RMSE: 85594.0351, Val MAE: 50115.8345, Val MSE: 7326338845.1789, Val R2: 0.6278\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1825\n",
      "Val RMSE: 90222.5845, Val MAE: 56197.8801, Val MSE: 8140114756.7093, Val R2: 0.5864\n",
      "Early stopping triggered after epoch 82\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 100130.2482, Test MAE: 59514.1883, Test MSE: 10026066597.2207, Test R2: 0.3573\n",
      "Inference Time: 1.8691172966590294e-05 seconds per sample\n",
      "\n",
      "Iteration 56 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3908, Val Loss: 0.3058\n",
      "Val RMSE: 148077.9378, Val MAE: 82063.1090, Val MSE: 21927075676.3382, Val R2: -0.1140\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2811, Val Loss: 0.2800\n",
      "Val RMSE: 141706.3241, Val MAE: 84611.0640, Val MSE: 20080682279.5381, Val R2: -0.0202\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2718, Val Loss: 0.2761\n",
      "Val RMSE: 141719.8773, Val MAE: 83654.6034, Val MSE: 20084523622.9675, Val R2: -0.0204\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2785\n",
      "Val RMSE: 141775.3098, Val MAE: 85264.7010, Val MSE: 20100238472.8280, Val R2: -0.0212\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2627, Val Loss: 0.2723\n",
      "Val RMSE: 141378.4981, Val MAE: 83208.1445, Val MSE: 19987879711.9346, Val R2: -0.0155\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2745\n",
      "Val RMSE: 141709.4293, Val MAE: 83853.1631, Val MSE: 20081562358.5035, Val R2: -0.0203\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2700\n",
      "Val RMSE: 142161.4021, Val MAE: 79890.7082, Val MSE: 20209864243.6827, Val R2: -0.0268\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2727\n",
      "Val RMSE: 140376.8843, Val MAE: 85031.5026, Val MSE: 19705669656.8696, Val R2: -0.0012\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2551, Val Loss: 0.2846\n",
      "Val RMSE: 142030.8854, Val MAE: 86963.5516, Val MSE: 20172772410.2348, Val R2: -0.0249\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2727\n",
      "Val RMSE: 140329.9731, Val MAE: 83513.3077, Val MSE: 19692501355.8751, Val R2: -0.0005\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2644\n",
      "Val RMSE: 139602.8799, Val MAE: 80213.1601, Val MSE: 19488964069.5035, Val R2: 0.0098\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2460, Val Loss: 0.2575\n",
      "Val RMSE: 138266.8255, Val MAE: 75190.6713, Val MSE: 19117715022.1596, Val R2: 0.0287\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2613\n",
      "Val RMSE: 137338.4075, Val MAE: 75719.7399, Val MSE: 18861838185.1919, Val R2: 0.0417\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2398, Val Loss: 0.2604\n",
      "Val RMSE: 137486.6946, Val MAE: 77200.7613, Val MSE: 18902591201.6157, Val R2: 0.0396\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2361, Val Loss: 0.2529\n",
      "Val RMSE: 136309.3444, Val MAE: 74727.1623, Val MSE: 18580237376.5210, Val R2: 0.0560\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2299, Val Loss: 0.2337\n",
      "Val RMSE: 130930.0907, Val MAE: 72451.2410, Val MSE: 17142688649.2675, Val R2: 0.1290\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2190, Val Loss: 0.2301\n",
      "Val RMSE: 128757.5174, Val MAE: 75991.1583, Val MSE: 16578498298.2680, Val R2: 0.1577\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2095, Val Loss: 0.2411\n",
      "Val RMSE: 134670.4959, Val MAE: 74921.6142, Val MSE: 18136142465.5692, Val R2: 0.0786\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2104, Val Loss: 0.2290\n",
      "Val RMSE: 129291.7397, Val MAE: 72657.3899, Val MSE: 16716353943.9737, Val R2: 0.1507\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2064, Val Loss: 0.2326\n",
      "Val RMSE: 130801.9457, Val MAE: 72802.7551, Val MSE: 17109148995.4973, Val R2: 0.1307\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2049, Val Loss: 0.2265\n",
      "Val RMSE: 129169.6721, Val MAE: 71535.2555, Val MSE: 16684804196.0549, Val R2: 0.1523\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2376\n",
      "Val RMSE: 129815.8657, Val MAE: 76152.2655, Val MSE: 16852158993.1797, Val R2: 0.1438\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2009, Val Loss: 0.2447\n",
      "Val RMSE: 136195.2862, Val MAE: 74353.2719, Val MSE: 18549155976.1856, Val R2: 0.0576\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1970, Val Loss: 0.2354\n",
      "Val RMSE: 129326.1627, Val MAE: 75390.7746, Val MSE: 16725256370.5478, Val R2: 0.1503\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1948, Val Loss: 0.2179\n",
      "Val RMSE: 121221.8295, Val MAE: 71505.7231, Val MSE: 14694731944.8656, Val R2: 0.2534\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1881, Val Loss: 0.2063\n",
      "Val RMSE: 116352.9433, Val MAE: 66429.7116, Val MSE: 13538007409.9570, Val R2: 0.3122\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.1920\n",
      "Val RMSE: 109457.8266, Val MAE: 65028.6205, Val MSE: 11981015807.8663, Val R2: 0.3913\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1791, Val Loss: 0.1977\n",
      "Val RMSE: 110897.7226, Val MAE: 66262.3760, Val MSE: 12298304872.6567, Val R2: 0.3752\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1739, Val Loss: 0.1909\n",
      "Val RMSE: 106286.9622, Val MAE: 65637.7100, Val MSE: 11296918327.1966, Val R2: 0.4260\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1740, Val Loss: 0.1919\n",
      "Val RMSE: 103604.9004, Val MAE: 65848.1340, Val MSE: 10733975384.5832, Val R2: 0.4546\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1691, Val Loss: 0.1814\n",
      "Val RMSE: 102309.3448, Val MAE: 63519.9329, Val MSE: 10467202023.2699, Val R2: 0.4682\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1634, Val Loss: 0.1795\n",
      "Val RMSE: 102592.2124, Val MAE: 60565.3576, Val MSE: 10525162047.2893, Val R2: 0.4653\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1604, Val Loss: 0.1656\n",
      "Val RMSE: 99610.0547, Val MAE: 58032.9818, Val MSE: 9922162997.0030, Val R2: 0.4959\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1561, Val Loss: 0.1651\n",
      "Val RMSE: 99400.7323, Val MAE: 56245.0009, Val MSE: 9880505587.9322, Val R2: 0.4980\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1531, Val Loss: 0.1586\n",
      "Val RMSE: 97800.2933, Val MAE: 57120.8848, Val MSE: 9564897375.9649, Val R2: 0.5140\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1492, Val Loss: 0.1594\n",
      "Val RMSE: 96632.6569, Val MAE: 58400.1047, Val MSE: 9337870381.1729, Val R2: 0.5256\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1421, Val Loss: 0.1604\n",
      "Val RMSE: 98193.3012, Val MAE: 56527.7260, Val MSE: 9641924395.4731, Val R2: 0.5101\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1424, Val Loss: 0.1472\n",
      "Val RMSE: 94720.6628, Val MAE: 52974.1388, Val MSE: 8972003960.6614, Val R2: 0.5442\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1398, Val Loss: 0.1492\n",
      "Val RMSE: 94760.0109, Val MAE: 54932.1027, Val MSE: 8979459673.8096, Val R2: 0.5438\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1346, Val Loss: 0.1455\n",
      "Val RMSE: 93497.5972, Val MAE: 51849.8377, Val MSE: 8741800683.0290, Val R2: 0.5559\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1331, Val Loss: 0.1556\n",
      "Val RMSE: 96292.2804, Val MAE: 54616.2310, Val MSE: 9272203261.5991, Val R2: 0.5289\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1249, Val Loss: 0.1440\n",
      "Val RMSE: 92999.1724, Val MAE: 50457.2481, Val MSE: 8648846060.7283, Val R2: 0.5606\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1359, Val Loss: 0.1711\n",
      "Val RMSE: 101479.5113, Val MAE: 59131.7213, Val MSE: 10298091210.7835, Val R2: 0.4768\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1504, Val Loss: 0.1646\n",
      "Val RMSE: 99420.9894, Val MAE: 56524.2582, Val MSE: 9884533124.8472, Val R2: 0.4978\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1524\n",
      "Val RMSE: 96842.4653, Val MAE: 52398.3748, Val MSE: 9378463085.0745, Val R2: 0.5235\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1238, Val Loss: 0.1578\n",
      "Val RMSE: 97378.8836, Val MAE: 55210.4561, Val MSE: 9482646975.1178, Val R2: 0.5182\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1171, Val Loss: 0.1512\n",
      "Val RMSE: 96407.6966, Val MAE: 53670.6647, Val MSE: 9294443962.0681, Val R2: 0.5278\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1141, Val Loss: 0.1494\n",
      "Val RMSE: 95575.9989, Val MAE: 51437.0014, Val MSE: 9134771566.0478, Val R2: 0.5359\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1124, Val Loss: 0.1487\n",
      "Val RMSE: 94609.1360, Val MAE: 51921.4122, Val MSE: 8950888619.8188, Val R2: 0.5452\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1439\n",
      "Val RMSE: 94194.5872, Val MAE: 49919.8310, Val MSE: 8872620264.7615, Val R2: 0.5492\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1061, Val Loss: 0.1517\n",
      "Val RMSE: 95174.1343, Val MAE: 51579.7877, Val MSE: 9058115838.2355, Val R2: 0.5398\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1049, Val Loss: 0.1569\n",
      "Val RMSE: 96946.2425, Val MAE: 52296.3608, Val MSE: 9398573943.7738, Val R2: 0.5225\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1044, Val Loss: 0.1385\n",
      "Val RMSE: 92709.0945, Val MAE: 50701.5931, Val MSE: 8594976207.3385, Val R2: 0.5633\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1000, Val Loss: 0.1484\n",
      "Val RMSE: 95074.5337, Val MAE: 50126.0380, Val MSE: 9039166964.5956, Val R2: 0.5408\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1000, Val Loss: 0.1570\n",
      "Val RMSE: 95551.8068, Val MAE: 50246.5907, Val MSE: 9130147778.3868, Val R2: 0.5361\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1406\n",
      "Val RMSE: 92704.9059, Val MAE: 51197.1954, Val MSE: 8594199570.8092, Val R2: 0.5634\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0957, Val Loss: 0.1542\n",
      "Val RMSE: 95630.9404, Val MAE: 51364.1462, Val MSE: 9145276754.0855, Val R2: 0.5354\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0960, Val Loss: 0.1407\n",
      "Val RMSE: 91095.8831, Val MAE: 52042.2481, Val MSE: 8298459920.5618, Val R2: 0.5784\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0902, Val Loss: 0.1449\n",
      "Val RMSE: 92587.2262, Val MAE: 49252.0427, Val MSE: 8572394446.6562, Val R2: 0.5645\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1428\n",
      "Val RMSE: 90730.6143, Val MAE: 52347.4480, Val MSE: 8232044379.4898, Val R2: 0.5818\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0877, Val Loss: 0.1341\n",
      "Val RMSE: 85019.4519, Val MAE: 46434.3978, Val MSE: 7228307194.1879, Val R2: 0.6328\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1342\n",
      "Val RMSE: 87103.9250, Val MAE: 48210.9446, Val MSE: 7587093745.1638, Val R2: 0.6145\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0819, Val Loss: 0.1311\n",
      "Val RMSE: 85870.2034, Val MAE: 48814.1014, Val MSE: 7373691835.4705, Val R2: 0.6254\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1387\n",
      "Val RMSE: 87784.2386, Val MAE: 48080.0684, Val MSE: 7706072549.8397, Val R2: 0.6085\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1310\n",
      "Val RMSE: 84066.6041, Val MAE: 46624.7091, Val MSE: 7067193927.8326, Val R2: 0.6409\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1401\n",
      "Val RMSE: 86943.6445, Val MAE: 48622.7834, Val MSE: 7559197323.3846, Val R2: 0.6159\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1265\n",
      "Val RMSE: 81211.3375, Val MAE: 48753.5974, Val MSE: 6595281335.6431, Val R2: 0.6649\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1269\n",
      "Val RMSE: 80806.4416, Val MAE: 45022.6647, Val MSE: 6529681007.6513, Val R2: 0.6683\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1333\n",
      "Val RMSE: 84452.4666, Val MAE: 46755.5404, Val MSE: 7132219118.6088, Val R2: 0.6376\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0747, Val Loss: 0.1333\n",
      "Val RMSE: 85243.5756, Val MAE: 46401.0563, Val MSE: 7266467179.0129, Val R2: 0.6308\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0741, Val Loss: 0.1260\n",
      "Val RMSE: 81776.7092, Val MAE: 46636.3311, Val MSE: 6687430174.2871, Val R2: 0.6602\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1295\n",
      "Val RMSE: 81413.5315, Val MAE: 44458.6638, Val MSE: 6628163108.6559, Val R2: 0.6632\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0705, Val Loss: 0.1190\n",
      "Val RMSE: 80062.1457, Val MAE: 45648.1168, Val MSE: 6409947172.4474, Val R2: 0.6743\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1275\n",
      "Val RMSE: 81886.2884, Val MAE: 46352.6517, Val MSE: 6705364234.4473, Val R2: 0.6593\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1311\n",
      "Val RMSE: 84801.3200, Val MAE: 45112.2818, Val MSE: 7191263876.3652, Val R2: 0.6346\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1265\n",
      "Val RMSE: 82614.7192, Val MAE: 44414.4083, Val MSE: 6825191823.8647, Val R2: 0.6532\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1294\n",
      "Val RMSE: 81380.8240, Val MAE: 47084.7127, Val MSE: 6622838517.3591, Val R2: 0.6635\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0646, Val Loss: 0.1220\n",
      "Val RMSE: 80290.0650, Val MAE: 44446.9925, Val MSE: 6446494530.1193, Val R2: 0.6725\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1308\n",
      "Val RMSE: 83586.3230, Val MAE: 44420.6108, Val MSE: 6986673393.7137, Val R2: 0.6450\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1254\n",
      "Val RMSE: 80931.8634, Val MAE: 45106.6637, Val MSE: 6549966514.2320, Val R2: 0.6672\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1327\n",
      "Val RMSE: 82765.8933, Val MAE: 47305.4969, Val MSE: 6850193095.1812, Val R2: 0.6520\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1256\n",
      "Val RMSE: 81194.1560, Val MAE: 43955.0605, Val MSE: 6592490965.1209, Val R2: 0.6651\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1292\n",
      "Val RMSE: 81599.4581, Val MAE: 46924.4816, Val MSE: 6658471565.2277, Val R2: 0.6617\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1224\n",
      "Val RMSE: 79738.5759, Val MAE: 43193.3639, Val MSE: 6358240486.5349, Val R2: 0.6770\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1187\n",
      "Val RMSE: 80013.6934, Val MAE: 43353.4223, Val MSE: 6402191126.9997, Val R2: 0.6747\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1128\n",
      "Val RMSE: 75739.1332, Val MAE: 43762.9076, Val MSE: 5736416291.0500, Val R2: 0.7086\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1217\n",
      "Val RMSE: 79923.4955, Val MAE: 43036.7376, Val MSE: 6387765131.5902, Val R2: 0.6755\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1215\n",
      "Val RMSE: 80589.2120, Val MAE: 43679.8945, Val MSE: 6494621087.3136, Val R2: 0.6700\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1218\n",
      "Val RMSE: 81248.6835, Val MAE: 44644.5755, Val MSE: 6601348567.6246, Val R2: 0.6646\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1116\n",
      "Val RMSE: 76620.7761, Val MAE: 40387.8694, Val MSE: 5870743329.2029, Val R2: 0.7017\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1101\n",
      "Val RMSE: 74948.5259, Val MAE: 40637.7928, Val MSE: 5617281535.9258, Val R2: 0.7146\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1216\n",
      "Val RMSE: 79758.3217, Val MAE: 44145.3081, Val MSE: 6361389883.5998, Val R2: 0.6768\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1005\n",
      "Val RMSE: 71004.4616, Val MAE: 38761.4842, Val MSE: 5041633570.6063, Val R2: 0.7439\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1166\n",
      "Val RMSE: 80291.8115, Val MAE: 45345.0813, Val MSE: 6446774991.4858, Val R2: 0.6725\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0548, Val Loss: 0.1035\n",
      "Val RMSE: 71682.0571, Val MAE: 39720.2161, Val MSE: 5138317310.2804, Val R2: 0.7389\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1095\n",
      "Val RMSE: 74295.6525, Val MAE: 41541.5361, Val MSE: 5519843981.8779, Val R2: 0.7196\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1194\n",
      "Val RMSE: 79267.0264, Val MAE: 44268.1423, Val MSE: 6283261477.4754, Val R2: 0.6808\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1121\n",
      "Val RMSE: 74352.8988, Val MAE: 40654.3626, Val MSE: 5528353567.3593, Val R2: 0.7191\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1136\n",
      "Val RMSE: 77771.3104, Val MAE: 41983.2498, Val MSE: 6048376724.8993, Val R2: 0.6927\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1111\n",
      "Val RMSE: 76627.1497, Val MAE: 40000.3743, Val MSE: 5871720075.1368, Val R2: 0.7017\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 79814.5435, Test MAE: 43603.9463, Test MSE: 6370361350.2858, Test R2: 0.5917\n",
      "Inference Time: 1.9077374384953425e-05 seconds per sample\n",
      "\n",
      "Iteration 57 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3461, Val Loss: 0.2962\n",
      "Val RMSE: 146794.2249, Val MAE: 80667.7612, Val MSE: 21548544469.3556, Val R2: -0.0948\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2729, Val Loss: 0.2756\n",
      "Val RMSE: 141096.9482, Val MAE: 84523.0970, Val MSE: 19908348778.1556, Val R2: -0.0115\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2708, Val Loss: 0.2763\n",
      "Val RMSE: 141653.1734, Val MAE: 83497.8034, Val MSE: 20065621521.8459, Val R2: -0.0195\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2659, Val Loss: 0.2799\n",
      "Val RMSE: 142737.1184, Val MAE: 82724.7080, Val MSE: 20373884957.9084, Val R2: -0.0351\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2768\n",
      "Val RMSE: 142196.5117, Val MAE: 84263.7210, Val MSE: 20219847947.6812, Val R2: -0.0273\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2737\n",
      "Val RMSE: 142382.9948, Val MAE: 81040.3427, Val MSE: 20272917220.9833, Val R2: -0.0300\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2748\n",
      "Val RMSE: 142267.9492, Val MAE: 82646.5177, Val MSE: 20240169379.9652, Val R2: -0.0283\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2557, Val Loss: 0.2739\n",
      "Val RMSE: 142814.4720, Val MAE: 79467.0661, Val MSE: 20395973417.3941, Val R2: -0.0362\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2676\n",
      "Val RMSE: 141089.8954, Val MAE: 81057.4226, Val MSE: 19906358576.2954, Val R2: -0.0114\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2538, Val Loss: 0.2677\n",
      "Val RMSE: 140826.1250, Val MAE: 81638.7152, Val MSE: 19831997469.3757, Val R2: -0.0076\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2650\n",
      "Val RMSE: 138085.0497, Val MAE: 81432.0417, Val MSE: 19067480961.8713, Val R2: 0.0313\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2441, Val Loss: 0.2564\n",
      "Val RMSE: 136869.3766, Val MAE: 77489.4427, Val MSE: 18733226261.8340, Val R2: 0.0482\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2566\n",
      "Val RMSE: 136049.8476, Val MAE: 77241.2765, Val MSE: 18509561019.5207, Val R2: 0.0596\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2421, Val Loss: 0.2486\n",
      "Val RMSE: 133655.0882, Val MAE: 77506.7461, Val MSE: 17863682589.6261, Val R2: 0.0924\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2354, Val Loss: 0.2517\n",
      "Val RMSE: 133959.4235, Val MAE: 76805.4302, Val MSE: 17945127146.6793, Val R2: 0.0883\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2379, Val Loss: 0.2495\n",
      "Val RMSE: 133553.8180, Val MAE: 77233.2956, Val MSE: 17836622308.0126, Val R2: 0.0938\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2363, Val Loss: 0.2496\n",
      "Val RMSE: 134238.9761, Val MAE: 76178.5624, Val MSE: 18020102698.1658, Val R2: 0.0845\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2352, Val Loss: 0.2504\n",
      "Val RMSE: 131830.9196, Val MAE: 80390.3009, Val MSE: 17379391357.7703, Val R2: 0.1170\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2318, Val Loss: 0.2507\n",
      "Val RMSE: 132236.2743, Val MAE: 80469.4143, Val MSE: 17486432237.5017, Val R2: 0.1116\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2282, Val Loss: 0.2345\n",
      "Val RMSE: 133184.7580, Val MAE: 71471.5568, Val MSE: 17738179772.7442, Val R2: 0.0988\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2257\n",
      "Val RMSE: 130569.8785, Val MAE: 70112.4820, Val MSE: 17048493159.6488, Val R2: 0.1338\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2108, Val Loss: 0.2273\n",
      "Val RMSE: 129659.7774, Val MAE: 72008.0665, Val MSE: 16811657883.7037, Val R2: 0.1459\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2082, Val Loss: 0.2446\n",
      "Val RMSE: 132701.7235, Val MAE: 72652.7405, Val MSE: 17609747414.2085, Val R2: 0.1053\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2125, Val Loss: 0.2323\n",
      "Val RMSE: 129154.9449, Val MAE: 73852.0631, Val MSE: 16680999804.2491, Val R2: 0.1525\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2277\n",
      "Val RMSE: 128607.3596, Val MAE: 73273.7593, Val MSE: 16539852945.8103, Val R2: 0.1597\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2061, Val Loss: 0.2423\n",
      "Val RMSE: 130611.2671, Val MAE: 75220.9077, Val MSE: 17059303099.4669, Val R2: 0.1333\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2048, Val Loss: 0.2243\n",
      "Val RMSE: 127559.7739, Val MAE: 73302.5240, Val MSE: 16271495907.7336, Val R2: 0.1733\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2028, Val Loss: 0.2299\n",
      "Val RMSE: 131600.8329, Val MAE: 70802.9062, Val MSE: 17318779229.4250, Val R2: 0.1201\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2008, Val Loss: 0.2256\n",
      "Val RMSE: 127209.0627, Val MAE: 73725.5533, Val MSE: 16182145629.6874, Val R2: 0.1778\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1987, Val Loss: 0.2246\n",
      "Val RMSE: 127819.6375, Val MAE: 70969.9375, Val MSE: 16337859731.7237, Val R2: 0.1699\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1934, Val Loss: 0.2139\n",
      "Val RMSE: 119901.2743, Val MAE: 71045.1063, Val MSE: 14376315575.1367, Val R2: 0.2696\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1854, Val Loss: 0.2134\n",
      "Val RMSE: 119362.3496, Val MAE: 69045.4892, Val MSE: 14247370509.2154, Val R2: 0.2761\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1803, Val Loss: 0.2051\n",
      "Val RMSE: 110708.3639, Val MAE: 70121.0717, Val MSE: 12256341844.9689, Val R2: 0.3773\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1771, Val Loss: 0.1859\n",
      "Val RMSE: 104258.0668, Val MAE: 62218.6539, Val MSE: 10869744502.3354, Val R2: 0.4477\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1700, Val Loss: 0.1987\n",
      "Val RMSE: 110225.5261, Val MAE: 64946.7887, Val MSE: 12149666610.3690, Val R2: 0.3827\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1660, Val Loss: 0.1884\n",
      "Val RMSE: 105586.9039, Val MAE: 63386.5022, Val MSE: 11148594268.4047, Val R2: 0.4336\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1564, Val Loss: 0.1841\n",
      "Val RMSE: 102647.9026, Val MAE: 65541.1896, Val MSE: 10536591908.0284, Val R2: 0.4647\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1541, Val Loss: 0.1817\n",
      "Val RMSE: 104645.2138, Val MAE: 62518.0704, Val MSE: 10950620767.5947, Val R2: 0.4436\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1689\n",
      "Val RMSE: 99816.6072, Val MAE: 59818.6665, Val MSE: 9963355077.2650, Val R2: 0.4938\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1477, Val Loss: 0.1765\n",
      "Val RMSE: 101805.9921, Val MAE: 62429.3263, Val MSE: 10364460030.7800, Val R2: 0.4734\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1429, Val Loss: 0.1795\n",
      "Val RMSE: 101493.0753, Val MAE: 59159.1482, Val MSE: 10300844334.4362, Val R2: 0.4767\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1415, Val Loss: 0.1702\n",
      "Val RMSE: 98422.8457, Val MAE: 63638.3316, Val MSE: 9687056550.6972, Val R2: 0.5078\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1348, Val Loss: 0.1532\n",
      "Val RMSE: 95198.2357, Val MAE: 53960.0236, Val MSE: 9062704085.6411, Val R2: 0.5396\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1307, Val Loss: 0.1500\n",
      "Val RMSE: 94299.4197, Val MAE: 56381.2902, Val MSE: 8892380546.6551, Val R2: 0.5482\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1270, Val Loss: 0.1507\n",
      "Val RMSE: 94559.6733, Val MAE: 53816.2045, Val MSE: 8941531805.3863, Val R2: 0.5457\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1224, Val Loss: 0.1425\n",
      "Val RMSE: 93294.4712, Val MAE: 51365.5957, Val MSE: 8703858359.3771, Val R2: 0.5578\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1668\n",
      "Val RMSE: 98101.3468, Val MAE: 57215.6072, Val MSE: 9623874250.9681, Val R2: 0.5110\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1163, Val Loss: 0.1612\n",
      "Val RMSE: 93996.8659, Val MAE: 57087.2283, Val MSE: 8835410802.3121, Val R2: 0.5511\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1147, Val Loss: 0.1391\n",
      "Val RMSE: 90368.4531, Val MAE: 51519.0708, Val MSE: 8166457320.0918, Val R2: 0.5851\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1123, Val Loss: 0.1510\n",
      "Val RMSE: 93043.7506, Val MAE: 55444.3559, Val MSE: 8657139518.9192, Val R2: 0.5602\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1077, Val Loss: 0.1482\n",
      "Val RMSE: 92705.0839, Val MAE: 52832.8569, Val MSE: 8594232578.7499, Val R2: 0.5634\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1101, Val Loss: 0.1874\n",
      "Val RMSE: 99377.2569, Val MAE: 65444.8126, Val MSE: 9875839182.8381, Val R2: 0.4982\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1062, Val Loss: 0.1551\n",
      "Val RMSE: 94035.4840, Val MAE: 56112.1778, Val MSE: 8842672258.4720, Val R2: 0.5507\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1480\n",
      "Val RMSE: 91861.7866, Val MAE: 52816.0314, Val MSE: 8438587830.8798, Val R2: 0.5713\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1051, Val Loss: 0.1875\n",
      "Val RMSE: 97488.4661, Val MAE: 59467.1428, Val MSE: 9504001031.8420, Val R2: 0.5171\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1022, Val Loss: 0.1894\n",
      "Val RMSE: 99772.2709, Val MAE: 64252.6837, Val MSE: 9954506043.8523, Val R2: 0.4942\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0982, Val Loss: 0.1739\n",
      "Val RMSE: 95883.8688, Val MAE: 60923.6334, Val MSE: 9193716305.2416, Val R2: 0.5329\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0934, Val Loss: 0.1601\n",
      "Val RMSE: 95421.6536, Val MAE: 57888.2910, Val MSE: 9105291980.5925, Val R2: 0.5374\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0929, Val Loss: 0.1523\n",
      "Val RMSE: 95215.1517, Val MAE: 54487.3653, Val MSE: 9065925120.6123, Val R2: 0.5394\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0911, Val Loss: 0.1402\n",
      "Val RMSE: 90919.8601, Val MAE: 52318.7061, Val MSE: 8266420952.1958, Val R2: 0.5800\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1864\n",
      "Val RMSE: 98115.3420, Val MAE: 60891.0810, Val MSE: 9626620326.0111, Val R2: 0.5109\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0876, Val Loss: 0.1561\n",
      "Val RMSE: 93961.6741, Val MAE: 52912.6125, Val MSE: 8828796194.5658, Val R2: 0.5514\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0874, Val Loss: 0.1613\n",
      "Val RMSE: 94083.7582, Val MAE: 55829.5881, Val MSE: 8851753554.4430, Val R2: 0.5503\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0860, Val Loss: 0.1443\n",
      "Val RMSE: 91216.3370, Val MAE: 52025.3658, Val MSE: 8320420134.2417, Val R2: 0.5773\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0825, Val Loss: 0.1455\n",
      "Val RMSE: 92348.1932, Val MAE: 51330.9310, Val MSE: 8528188793.9144, Val R2: 0.5667\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0826, Val Loss: 0.1572\n",
      "Val RMSE: 94719.9366, Val MAE: 55801.5151, Val MSE: 8971866395.5787, Val R2: 0.5442\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0793, Val Loss: 0.1832\n",
      "Val RMSE: 96569.2655, Val MAE: 59702.7306, Val MSE: 9325623039.4952, Val R2: 0.5262\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0787, Val Loss: 0.1742\n",
      "Val RMSE: 96865.8734, Val MAE: 57816.4280, Val MSE: 9382997424.3997, Val R2: 0.5233\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1579\n",
      "Val RMSE: 92918.4956, Val MAE: 52727.2189, Val MSE: 8633846821.3245, Val R2: 0.5613\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1607\n",
      "Val RMSE: 91954.7950, Val MAE: 54178.6706, Val MSE: 8455684330.1138, Val R2: 0.5704\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1797\n",
      "Val RMSE: 95625.2510, Val MAE: 56443.9461, Val MSE: 9144188635.3253, Val R2: 0.5354\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0724, Val Loss: 0.1707\n",
      "Val RMSE: 93135.3498, Val MAE: 56476.8231, Val MSE: 8674193389.2667, Val R2: 0.5593\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0718, Val Loss: 0.1539\n",
      "Val RMSE: 89235.2682, Val MAE: 51172.7784, Val MSE: 7962933082.3071, Val R2: 0.5954\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.2037\n",
      "Val RMSE: 98305.6434, Val MAE: 62041.6134, Val MSE: 9663999522.7095, Val R2: 0.5090\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1789\n",
      "Val RMSE: 90322.6154, Val MAE: 54728.9481, Val MSE: 8158174858.0064, Val R2: 0.5855\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1456\n",
      "Val RMSE: 84227.3737, Val MAE: 50203.1238, Val MSE: 7094250483.1309, Val R2: 0.6396\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1377\n",
      "Val RMSE: 84652.8580, Val MAE: 50217.4033, Val MSE: 7166106375.8059, Val R2: 0.6359\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.2346\n",
      "Val RMSE: 100376.7416, Val MAE: 66343.6423, Val MSE: 10075490259.4845, Val R2: 0.4881\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1323\n",
      "Val RMSE: 80495.6409, Val MAE: 47710.2181, Val MSE: 6479548198.5323, Val R2: 0.6708\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1825\n",
      "Val RMSE: 92714.6665, Val MAE: 60810.8075, Val MSE: 8596009385.5708, Val R2: 0.5633\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0611, Val Loss: 0.1547\n",
      "Val RMSE: 86653.8821, Val MAE: 52618.5610, Val MSE: 7508895283.4916, Val R2: 0.6185\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1426\n",
      "Val RMSE: 81684.1508, Val MAE: 47843.3201, Val MSE: 6672300497.6503, Val R2: 0.6610\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1548\n",
      "Val RMSE: 85646.8056, Val MAE: 53079.3693, Val MSE: 7335375315.3753, Val R2: 0.6273\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1856\n",
      "Val RMSE: 93538.2925, Val MAE: 57168.4219, Val MSE: 8749412155.0315, Val R2: 0.5555\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1293\n",
      "Val RMSE: 80779.0199, Val MAE: 45341.7015, Val MSE: 6525250050.7990, Val R2: 0.6685\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1373\n",
      "Val RMSE: 83674.2000, Val MAE: 47999.0412, Val MSE: 7001371752.2797, Val R2: 0.6443\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1663\n",
      "Val RMSE: 86705.6144, Val MAE: 54682.6474, Val MSE: 7517863573.5886, Val R2: 0.6180\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1789\n",
      "Val RMSE: 89337.5022, Val MAE: 55020.6792, Val MSE: 7981189290.8802, Val R2: 0.5945\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1696\n",
      "Val RMSE: 88497.6994, Val MAE: 52390.8209, Val MSE: 7831842791.2812, Val R2: 0.6021\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1578\n",
      "Val RMSE: 85431.2872, Val MAE: 50198.3104, Val MSE: 7298504828.0965, Val R2: 0.6292\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1210\n",
      "Val RMSE: 77297.3735, Val MAE: 44257.5254, Val MSE: 5974883947.8100, Val R2: 0.6964\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1514\n",
      "Val RMSE: 84310.4233, Val MAE: 51054.4045, Val MSE: 7108247476.1030, Val R2: 0.6389\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1169\n",
      "Val RMSE: 74417.7954, Val MAE: 43643.1672, Val MSE: 5538008275.6684, Val R2: 0.7186\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1171\n",
      "Val RMSE: 76691.4030, Val MAE: 43011.9427, Val MSE: 5881571297.8765, Val R2: 0.7012\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1313\n",
      "Val RMSE: 80448.5594, Val MAE: 46277.9124, Val MSE: 6471970713.9615, Val R2: 0.6712\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1208\n",
      "Val RMSE: 78338.0205, Val MAE: 43024.1661, Val MSE: 6136845463.2744, Val R2: 0.6882\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1225\n",
      "Val RMSE: 79693.0970, Val MAE: 45008.3836, Val MSE: 6350989709.0096, Val R2: 0.6773\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1179\n",
      "Val RMSE: 76001.3859, Val MAE: 45355.0956, Val MSE: 5776210662.8074, Val R2: 0.7065\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1242\n",
      "Val RMSE: 78892.3516, Val MAE: 44393.5848, Val MSE: 6224003136.1691, Val R2: 0.6838\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1244\n",
      "Val RMSE: 79223.8057, Val MAE: 43378.8583, Val MSE: 6276411395.4997, Val R2: 0.6811\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 78532.0368, Test MAE: 43130.4816, Test MSE: 6167280806.1319, Test R2: 0.6047\n",
      "Inference Time: 2.348489027756911e-05 seconds per sample\n",
      "\n",
      "Iteration 58 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3868, Val Loss: 0.2908\n",
      "Val RMSE: 144135.5851, Val MAE: 83657.1774, Val MSE: 20775066879.7911, Val R2: -0.0555\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2860, Val Loss: 0.2886\n",
      "Val RMSE: 143646.8656, Val MAE: 83777.1650, Val MSE: 20634421997.1802, Val R2: -0.0484\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2767, Val Loss: 0.2816\n",
      "Val RMSE: 142601.6634, Val MAE: 83112.9949, Val MSE: 20335234404.0710, Val R2: -0.0332\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2702, Val Loss: 0.2756\n",
      "Val RMSE: 141508.6833, Val MAE: 83619.9863, Val MSE: 20024707436.0779, Val R2: -0.0174\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2668, Val Loss: 0.2741\n",
      "Val RMSE: 140986.4717, Val MAE: 85163.6269, Val MSE: 19877185193.7815, Val R2: -0.0099\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2729\n",
      "Val RMSE: 142846.5683, Val MAE: 80039.0494, Val MSE: 20405142063.0255, Val R2: -0.0367\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2717\n",
      "Val RMSE: 141238.9532, Val MAE: 82696.5596, Val MSE: 19948441891.3838, Val R2: -0.0135\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2699\n",
      "Val RMSE: 140815.7600, Val MAE: 83197.7674, Val MSE: 19829078255.6558, Val R2: -0.0074\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2820\n",
      "Val RMSE: 141970.9936, Val MAE: 86064.2225, Val MSE: 20155763029.6397, Val R2: -0.0240\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2732\n",
      "Val RMSE: 140505.1601, Val MAE: 83759.3551, Val MSE: 19741700006.5837, Val R2: -0.0030\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2509, Val Loss: 0.2714\n",
      "Val RMSE: 141113.8119, Val MAE: 82665.0134, Val MSE: 19913107916.4648, Val R2: -0.0117\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2492, Val Loss: 0.2641\n",
      "Val RMSE: 140797.4992, Val MAE: 79491.3475, Val MSE: 19823935784.4573, Val R2: -0.0072\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2496, Val Loss: 0.2762\n",
      "Val RMSE: 139599.4336, Val MAE: 86285.2163, Val MSE: 19488001853.5066, Val R2: 0.0099\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2464, Val Loss: 0.2632\n",
      "Val RMSE: 139520.7592, Val MAE: 82363.2785, Val MSE: 19466042236.6818, Val R2: 0.0110\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2462, Val Loss: 0.2657\n",
      "Val RMSE: 140196.8314, Val MAE: 80902.0310, Val MSE: 19655151522.9586, Val R2: 0.0014\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2489\n",
      "Val RMSE: 134134.1930, Val MAE: 78655.6656, Val MSE: 17991981720.3649, Val R2: 0.0859\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2304, Val Loss: 0.2502\n",
      "Val RMSE: 132730.8503, Val MAE: 77620.3557, Val MSE: 17617478622.9797, Val R2: 0.1049\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2254, Val Loss: 0.2374\n",
      "Val RMSE: 133817.8729, Val MAE: 71941.5153, Val MSE: 17907223095.2072, Val R2: 0.0902\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2175, Val Loss: 0.2544\n",
      "Val RMSE: 139421.4571, Val MAE: 79927.8451, Val MSE: 19438342694.1004, Val R2: 0.0124\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2144, Val Loss: 0.2412\n",
      "Val RMSE: 134009.4802, Val MAE: 72552.7839, Val MSE: 17958540782.5682, Val R2: 0.0876\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2156, Val Loss: 0.2400\n",
      "Val RMSE: 129023.0715, Val MAE: 80823.2636, Val MSE: 16646952980.8255, Val R2: 0.1542\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2129, Val Loss: 0.2245\n",
      "Val RMSE: 126774.1759, Val MAE: 74887.5144, Val MSE: 16071691674.1840, Val R2: 0.1835\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2228\n",
      "Val RMSE: 126896.1086, Val MAE: 72662.7288, Val MSE: 16102622365.3058, Val R2: 0.1819\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2071, Val Loss: 0.2323\n",
      "Val RMSE: 131401.5074, Val MAE: 71800.9356, Val MSE: 17266356144.5175, Val R2: 0.1228\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1957, Val Loss: 0.2223\n",
      "Val RMSE: 125786.2511, Val MAE: 72768.6578, Val MSE: 15822180957.3978, Val R2: 0.1961\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2184\n",
      "Val RMSE: 122612.6594, Val MAE: 70514.7016, Val MSE: 15033864255.1720, Val R2: 0.2362\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1855, Val Loss: 0.1979\n",
      "Val RMSE: 109581.9399, Val MAE: 67163.5061, Val MSE: 12008201553.4840, Val R2: 0.3899\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1820, Val Loss: 0.2129\n",
      "Val RMSE: 118022.9078, Val MAE: 67276.6220, Val MSE: 13929406758.8698, Val R2: 0.2923\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1779, Val Loss: 0.2177\n",
      "Val RMSE: 120740.4120, Val MAE: 68198.0700, Val MSE: 14578247080.5028, Val R2: 0.2593\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1792, Val Loss: 0.2049\n",
      "Val RMSE: 113533.0648, Val MAE: 68521.6729, Val MSE: 12889756792.6196, Val R2: 0.3451\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1714, Val Loss: 0.2005\n",
      "Val RMSE: 107411.5753, Val MAE: 64308.0632, Val MSE: 11537246498.7592, Val R2: 0.4138\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1678, Val Loss: 0.1962\n",
      "Val RMSE: 106932.9205, Val MAE: 62043.2113, Val MSE: 11434649487.0809, Val R2: 0.4190\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1651, Val Loss: 0.1726\n",
      "Val RMSE: 99890.1082, Val MAE: 60131.0713, Val MSE: 9978033716.5829, Val R2: 0.4931\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1616, Val Loss: 0.1768\n",
      "Val RMSE: 101548.7730, Val MAE: 61286.9176, Val MSE: 10312153303.3336, Val R2: 0.4761\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1578, Val Loss: 0.1702\n",
      "Val RMSE: 99313.6261, Val MAE: 60009.4537, Val MSE: 9863196320.1463, Val R2: 0.4989\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1555, Val Loss: 0.1665\n",
      "Val RMSE: 99068.1531, Val MAE: 58643.3230, Val MSE: 9814498961.7870, Val R2: 0.5014\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1558, Val Loss: 0.1705\n",
      "Val RMSE: 99484.7156, Val MAE: 58205.2254, Val MSE: 9897208644.1139, Val R2: 0.4972\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1518, Val Loss: 0.1651\n",
      "Val RMSE: 99360.9964, Val MAE: 56913.5030, Val MSE: 9872607604.4392, Val R2: 0.4984\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1503, Val Loss: 0.1728\n",
      "Val RMSE: 99620.5226, Val MAE: 59166.2968, Val MSE: 9924248516.5849, Val R2: 0.4958\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1443, Val Loss: 0.1559\n",
      "Val RMSE: 95487.6673, Val MAE: 55167.1594, Val MSE: 9117894614.2343, Val R2: 0.5368\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1387, Val Loss: 0.1530\n",
      "Val RMSE: 95502.7375, Val MAE: 54978.5164, Val MSE: 9120772875.3700, Val R2: 0.5366\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1337, Val Loss: 0.1537\n",
      "Val RMSE: 94581.9245, Val MAE: 52489.7737, Val MSE: 8945740442.1571, Val R2: 0.5455\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1286, Val Loss: 0.1570\n",
      "Val RMSE: 96566.0103, Val MAE: 55575.7354, Val MSE: 9324994343.3538, Val R2: 0.5262\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1271, Val Loss: 0.1504\n",
      "Val RMSE: 92627.5982, Val MAE: 56257.9443, Val MSE: 8579871953.6880, Val R2: 0.5641\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1216, Val Loss: 0.1395\n",
      "Val RMSE: 90219.1429, Val MAE: 50695.0786, Val MSE: 8139493740.0405, Val R2: 0.5865\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1176, Val Loss: 0.1490\n",
      "Val RMSE: 92473.7314, Val MAE: 51869.8826, Val MSE: 8551390996.5228, Val R2: 0.5655\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1178, Val Loss: 0.1602\n",
      "Val RMSE: 95029.5068, Val MAE: 53336.9540, Val MSE: 9030607155.8821, Val R2: 0.5412\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1122, Val Loss: 0.1455\n",
      "Val RMSE: 92177.4896, Val MAE: 51526.4449, Val MSE: 8496689595.0771, Val R2: 0.5683\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1558\n",
      "Val RMSE: 93468.6809, Val MAE: 53759.3419, Val MSE: 8736394313.0965, Val R2: 0.5561\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1076, Val Loss: 0.1546\n",
      "Val RMSE: 94062.5196, Val MAE: 55213.4973, Val MSE: 8847757597.6616, Val R2: 0.5505\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1465\n",
      "Val RMSE: 92248.4912, Val MAE: 50261.0378, Val MSE: 8509784136.7014, Val R2: 0.5676\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1041, Val Loss: 0.1457\n",
      "Val RMSE: 91998.8036, Val MAE: 51344.0832, Val MSE: 8463779860.0716, Val R2: 0.5700\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1027, Val Loss: 0.1648\n",
      "Val RMSE: 94653.5219, Val MAE: 55565.2358, Val MSE: 8959289217.0719, Val R2: 0.5448\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1483\n",
      "Val RMSE: 92552.4612, Val MAE: 50537.5683, Val MSE: 8565958069.1813, Val R2: 0.5648\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0965, Val Loss: 0.1558\n",
      "Val RMSE: 94974.3113, Val MAE: 53999.5881, Val MSE: 9020119807.5271, Val R2: 0.5417\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1374\n",
      "Val RMSE: 89421.9307, Val MAE: 49704.4018, Val MSE: 7996281697.7550, Val R2: 0.5937\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1505\n",
      "Val RMSE: 93068.3840, Val MAE: 51548.5745, Val MSE: 8661724094.1354, Val R2: 0.5599\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0928, Val Loss: 0.1425\n",
      "Val RMSE: 90851.4432, Val MAE: 50005.0113, Val MSE: 8253984727.1658, Val R2: 0.5806\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0914, Val Loss: 0.1356\n",
      "Val RMSE: 89492.2510, Val MAE: 51397.9922, Val MSE: 8008862996.9816, Val R2: 0.5931\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0908, Val Loss: 0.1483\n",
      "Val RMSE: 93199.9600, Val MAE: 52829.4944, Val MSE: 8686232547.6549, Val R2: 0.5587\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1575\n",
      "Val RMSE: 93125.8714, Val MAE: 51803.4961, Val MSE: 8672427917.7891, Val R2: 0.5594\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1500\n",
      "Val RMSE: 94335.3638, Val MAE: 50353.0479, Val MSE: 8899160867.5510, Val R2: 0.5479\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.1500\n",
      "Val RMSE: 91247.0855, Val MAE: 50769.7433, Val MSE: 8326030616.9265, Val R2: 0.5770\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1542\n",
      "Val RMSE: 93849.2012, Val MAE: 50558.8380, Val MSE: 8807672557.2948, Val R2: 0.5525\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1458\n",
      "Val RMSE: 91255.5327, Val MAE: 50209.6186, Val MSE: 8327572241.6112, Val R2: 0.5769\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0763, Val Loss: 0.1408\n",
      "Val RMSE: 89209.5521, Val MAE: 49959.6542, Val MSE: 7958344188.9369, Val R2: 0.5957\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0746, Val Loss: 0.1428\n",
      "Val RMSE: 89316.6507, Val MAE: 49590.4446, Val MSE: 7977464084.7375, Val R2: 0.5947\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1398\n",
      "Val RMSE: 87472.6825, Val MAE: 49647.7679, Val MSE: 7651470191.3850, Val R2: 0.6113\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1582\n",
      "Val RMSE: 92383.8232, Val MAE: 51355.6853, Val MSE: 8534770787.6617, Val R2: 0.5664\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1313\n",
      "Val RMSE: 84751.2463, Val MAE: 48239.4073, Val MSE: 7182773750.9518, Val R2: 0.6351\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0705, Val Loss: 0.1233\n",
      "Val RMSE: 79717.5862, Val MAE: 47735.6814, Val MSE: 6354893549.7003, Val R2: 0.6771\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1252\n",
      "Val RMSE: 78839.4038, Val MAE: 48089.3377, Val MSE: 6215651598.7071, Val R2: 0.6842\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1518\n",
      "Val RMSE: 87300.3213, Val MAE: 53024.8192, Val MSE: 7621346099.4513, Val R2: 0.6128\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1407\n",
      "Val RMSE: 84724.5225, Val MAE: 46534.4863, Val MSE: 7178244705.7720, Val R2: 0.6353\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1247\n",
      "Val RMSE: 78519.9107, Val MAE: 47056.3449, Val MSE: 6165376368.6146, Val R2: 0.6868\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1252\n",
      "Val RMSE: 79157.0173, Val MAE: 47881.2252, Val MSE: 6265833380.5679, Val R2: 0.6817\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1311\n",
      "Val RMSE: 80096.2090, Val MAE: 45692.8737, Val MSE: 6415402703.9642, Val R2: 0.6741\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1262\n",
      "Val RMSE: 79904.2666, Val MAE: 48346.6410, Val MSE: 6384691823.3237, Val R2: 0.6756\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1350\n",
      "Val RMSE: 83470.5594, Val MAE: 50781.9745, Val MSE: 6967334292.9308, Val R2: 0.6460\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1311\n",
      "Val RMSE: 80395.2712, Val MAE: 45160.4974, Val MSE: 6463399623.3759, Val R2: 0.6716\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.1480\n",
      "Val RMSE: 85813.5983, Val MAE: 50291.7323, Val MSE: 7363973659.1281, Val R2: 0.6259\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1230\n",
      "Val RMSE: 78795.4872, Val MAE: 46107.9023, Val MSE: 6208728795.9712, Val R2: 0.6846\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1261\n",
      "Val RMSE: 79488.3169, Val MAE: 47319.9169, Val MSE: 6318392530.8779, Val R2: 0.6790\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1576\n",
      "Val RMSE: 89052.5271, Val MAE: 53587.7087, Val MSE: 7930352575.5980, Val R2: 0.5971\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1296\n",
      "Val RMSE: 79173.6322, Val MAE: 47633.8433, Val MSE: 6268464037.5583, Val R2: 0.6815\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1267\n",
      "Val RMSE: 79312.9499, Val MAE: 47105.1725, Val MSE: 6290544020.0997, Val R2: 0.6804\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1288\n",
      "Val RMSE: 79037.0945, Val MAE: 46308.6275, Val MSE: 6246862302.5983, Val R2: 0.6826\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1335\n",
      "Val RMSE: 79156.0962, Val MAE: 47324.1095, Val MSE: 6265687572.0079, Val R2: 0.6817\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1374\n",
      "Val RMSE: 81969.5296, Val MAE: 50905.6584, Val MSE: 6719003789.1671, Val R2: 0.6586\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1271\n",
      "Val RMSE: 78879.0751, Val MAE: 48852.4795, Val MSE: 6221908490.9911, Val R2: 0.6839\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1322\n",
      "Val RMSE: 80738.4731, Val MAE: 47198.6083, Val MSE: 6518701044.5160, Val R2: 0.6688\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1464\n",
      "Val RMSE: 87118.4121, Val MAE: 52953.3137, Val MSE: 7589617724.5242, Val R2: 0.6144\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1180\n",
      "Val RMSE: 73250.7672, Val MAE: 45232.5647, Val MSE: 5365674892.2229, Val R2: 0.7274\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1205\n",
      "Val RMSE: 76350.0725, Val MAE: 47451.7087, Val MSE: 5829333577.8472, Val R2: 0.7038\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1263\n",
      "Val RMSE: 77503.7783, Val MAE: 46670.0757, Val MSE: 6006835646.5950, Val R2: 0.6948\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1107\n",
      "Val RMSE: 71780.9438, Val MAE: 43602.0944, Val MSE: 5152503889.1470, Val R2: 0.7382\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1187\n",
      "Val RMSE: 75761.4674, Val MAE: 45333.2170, Val MSE: 5739799941.0418, Val R2: 0.7084\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1350\n",
      "Val RMSE: 83921.9405, Val MAE: 48471.4388, Val MSE: 7042892100.9947, Val R2: 0.6422\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1060\n",
      "Val RMSE: 70243.5101, Val MAE: 42724.0834, Val MSE: 4934150712.9418, Val R2: 0.7493\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1258\n",
      "Val RMSE: 77291.2513, Val MAE: 46141.0856, Val MSE: 5973937534.3828, Val R2: 0.6965\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 72984.8934, Test MAE: 40618.2650, Test MSE: 5326794662.4468, Test R2: 0.6585\n",
      "Inference Time: 1.9637548006497896e-05 seconds per sample\n",
      "\n",
      "Iteration 59 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3335, Val Loss: 0.2776\n",
      "Val RMSE: 142038.3654, Val MAE: 83169.5992, Val MSE: 20174897243.3485, Val R2: -0.0250\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2757\n",
      "Val RMSE: 141489.5051, Val MAE: 83595.3733, Val MSE: 20019280065.7407, Val R2: -0.0171\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2682, Val Loss: 0.2758\n",
      "Val RMSE: 141576.4616, Val MAE: 83352.6486, Val MSE: 20043894487.1812, Val R2: -0.0184\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2649, Val Loss: 0.2760\n",
      "Val RMSE: 141782.7177, Val MAE: 83044.2806, Val MSE: 20102339042.9918, Val R2: -0.0213\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2645, Val Loss: 0.2850\n",
      "Val RMSE: 144798.1166, Val MAE: 80516.2378, Val MSE: 20966494574.1290, Val R2: -0.0652\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2631, Val Loss: 0.2811\n",
      "Val RMSE: 143942.7272, Val MAE: 81023.9677, Val MSE: 20719508724.5918, Val R2: -0.0527\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2768\n",
      "Val RMSE: 143027.8710, Val MAE: 80922.4188, Val MSE: 20456971870.7345, Val R2: -0.0393\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2551, Val Loss: 0.3089\n",
      "Val RMSE: 149357.3490, Val MAE: 81355.4433, Val MSE: 22307617691.7700, Val R2: -0.1334\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2620, Val Loss: 0.2690\n",
      "Val RMSE: 141136.3335, Val MAE: 81297.1879, Val MSE: 19919464623.4957, Val R2: -0.0120\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2723\n",
      "Val RMSE: 141797.9626, Val MAE: 82315.4684, Val MSE: 20106662208.1203, Val R2: -0.0215\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2504, Val Loss: 0.2679\n",
      "Val RMSE: 141737.8160, Val MAE: 80243.7695, Val MSE: 20089608487.4884, Val R2: -0.0207\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2781\n",
      "Val RMSE: 144092.0363, Val MAE: 79132.1571, Val MSE: 20762514937.1781, Val R2: -0.0549\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2691\n",
      "Val RMSE: 142527.4242, Val MAE: 79002.3889, Val MSE: 20314066655.6288, Val R2: -0.0321\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2509, Val Loss: 0.2688\n",
      "Val RMSE: 140666.6653, Val MAE: 82229.0938, Val MSE: 19787110722.4505, Val R2: -0.0053\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2483, Val Loss: 0.2673\n",
      "Val RMSE: 143062.5895, Val MAE: 77528.6734, Val MSE: 20466904511.4149, Val R2: -0.0398\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2449, Val Loss: 0.2636\n",
      "Val RMSE: 141276.2309, Val MAE: 78644.9951, Val MSE: 19958973418.9342, Val R2: -0.0140\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2426, Val Loss: 0.2771\n",
      "Val RMSE: 140278.4346, Val MAE: 84812.3156, Val MSE: 19678039216.6852, Val R2: 0.0002\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2428, Val Loss: 0.2657\n",
      "Val RMSE: 142049.5432, Val MAE: 77969.2672, Val MSE: 20178072726.3292, Val R2: -0.0252\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2406, Val Loss: 0.2644\n",
      "Val RMSE: 141349.0142, Val MAE: 78872.1267, Val MSE: 19979543812.2928, Val R2: -0.0151\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2681\n",
      "Val RMSE: 140011.1591, Val MAE: 81669.3997, Val MSE: 19603124677.6973, Val R2: 0.0040\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2625\n",
      "Val RMSE: 141502.8896, Val MAE: 77985.6033, Val MSE: 20023067753.4961, Val R2: -0.0173\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2346, Val Loss: 0.2515\n",
      "Val RMSE: 137133.6981, Val MAE: 75393.9598, Val MSE: 18805651150.9156, Val R2: 0.0446\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2285, Val Loss: 0.2472\n",
      "Val RMSE: 135485.9940, Val MAE: 73547.1795, Val MSE: 18356454578.4947, Val R2: 0.0674\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2357\n",
      "Val RMSE: 131145.5483, Val MAE: 72522.2012, Val MSE: 17199154845.1646, Val R2: 0.1262\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2306\n",
      "Val RMSE: 131761.3731, Val MAE: 72157.2321, Val MSE: 17361059442.2459, Val R2: 0.1179\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2111, Val Loss: 0.2338\n",
      "Val RMSE: 132245.9259, Val MAE: 73276.4308, Val MSE: 17488984929.0469, Val R2: 0.1114\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2090, Val Loss: 0.2282\n",
      "Val RMSE: 128833.1322, Val MAE: 74619.1443, Val MSE: 16597975958.3409, Val R2: 0.1567\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2475\n",
      "Val RMSE: 133246.3066, Val MAE: 78854.3112, Val MSE: 17754578227.6642, Val R2: 0.0980\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2001, Val Loss: 0.2157\n",
      "Val RMSE: 124737.2040, Val MAE: 70440.9790, Val MSE: 15559370057.4684, Val R2: 0.2095\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1935, Val Loss: 0.2012\n",
      "Val RMSE: 115371.9070, Val MAE: 66986.8100, Val MSE: 13310676923.1811, Val R2: 0.3237\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1872, Val Loss: 0.2206\n",
      "Val RMSE: 119712.6889, Val MAE: 72163.2225, Val MSE: 14331127875.9002, Val R2: 0.2719\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1790, Val Loss: 0.1921\n",
      "Val RMSE: 107817.8270, Val MAE: 64865.1815, Val MSE: 11624683813.8761, Val R2: 0.4094\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1724, Val Loss: 0.1952\n",
      "Val RMSE: 109363.3429, Val MAE: 64024.0136, Val MSE: 11960340761.0166, Val R2: 0.3923\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1659, Val Loss: 0.1761\n",
      "Val RMSE: 101591.7737, Val MAE: 61237.8579, Val MSE: 10320888477.3395, Val R2: 0.4756\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1649, Val Loss: 0.1780\n",
      "Val RMSE: 102178.6333, Val MAE: 61307.3075, Val MSE: 10440473100.9056, Val R2: 0.4696\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1616, Val Loss: 0.1685\n",
      "Val RMSE: 99239.6897, Val MAE: 58972.4596, Val MSE: 9848516016.2069, Val R2: 0.4996\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1590, Val Loss: 0.1775\n",
      "Val RMSE: 103634.1915, Val MAE: 61423.4014, Val MSE: 10740045652.0232, Val R2: 0.4543\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1572, Val Loss: 0.1631\n",
      "Val RMSE: 98637.3678, Val MAE: 58506.6007, Val MSE: 9729330320.4449, Val R2: 0.5057\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1538, Val Loss: 0.1753\n",
      "Val RMSE: 101318.8918, Val MAE: 58511.3483, Val MSE: 10265517843.6309, Val R2: 0.4784\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1523, Val Loss: 0.1514\n",
      "Val RMSE: 95543.8018, Val MAE: 54464.3779, Val MSE: 9128618065.2326, Val R2: 0.5362\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1476, Val Loss: 0.1509\n",
      "Val RMSE: 95333.1270, Val MAE: 54772.4414, Val MSE: 9088405104.2092, Val R2: 0.5383\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1480, Val Loss: 0.1535\n",
      "Val RMSE: 96657.9213, Val MAE: 54481.7083, Val MSE: 9342753752.6208, Val R2: 0.5253\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1422, Val Loss: 0.1394\n",
      "Val RMSE: 91602.8553, Val MAE: 52033.1971, Val MSE: 8391083100.2535, Val R2: 0.5737\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1406, Val Loss: 0.1510\n",
      "Val RMSE: 93825.9399, Val MAE: 53472.7408, Val MSE: 8803307004.9883, Val R2: 0.5527\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1401\n",
      "Val RMSE: 91134.4157, Val MAE: 50944.6760, Val MSE: 8305481724.8717, Val R2: 0.5780\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1468\n",
      "Val RMSE: 91806.5635, Val MAE: 53928.2240, Val MSE: 8428445099.2807, Val R2: 0.5718\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1273, Val Loss: 0.1424\n",
      "Val RMSE: 92348.8180, Val MAE: 52284.7848, Val MSE: 8528304181.2716, Val R2: 0.5667\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1990\n",
      "Val RMSE: 99663.5657, Val MAE: 60337.3195, Val MSE: 9932826335.2258, Val R2: 0.4953\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1171, Val Loss: 0.1437\n",
      "Val RMSE: 95532.2493, Val MAE: 50336.4722, Val MSE: 9126410661.5196, Val R2: 0.5363\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1143, Val Loss: 0.1329\n",
      "Val RMSE: 91264.6011, Val MAE: 49088.2828, Val MSE: 8329227417.4980, Val R2: 0.5768\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1139, Val Loss: 0.1422\n",
      "Val RMSE: 93935.0458, Val MAE: 51585.4765, Val MSE: 8823792836.3941, Val R2: 0.5517\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1057, Val Loss: 0.1289\n",
      "Val RMSE: 90117.0184, Val MAE: 47461.1982, Val MSE: 8121077013.6065, Val R2: 0.5874\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0992, Val Loss: 0.1389\n",
      "Val RMSE: 90287.0730, Val MAE: 51324.1705, Val MSE: 8151755545.8068, Val R2: 0.5858\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0976, Val Loss: 0.1357\n",
      "Val RMSE: 90723.2745, Val MAE: 49930.4962, Val MSE: 8230712533.4154, Val R2: 0.5818\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0965, Val Loss: 0.1346\n",
      "Val RMSE: 91876.3784, Val MAE: 47792.5353, Val MSE: 8441268911.7486, Val R2: 0.5711\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1370\n",
      "Val RMSE: 92278.6791, Val MAE: 48991.0581, Val MSE: 8515354619.9453, Val R2: 0.5674\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1352\n",
      "Val RMSE: 91323.4744, Val MAE: 49610.3986, Val MSE: 8339976982.2038, Val R2: 0.5763\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1354\n",
      "Val RMSE: 93043.6466, Val MAE: 48550.6138, Val MSE: 8657120181.3969, Val R2: 0.5602\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1357\n",
      "Val RMSE: 92754.5075, Val MAE: 48269.9732, Val MSE: 8603398660.5307, Val R2: 0.5629\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0828, Val Loss: 0.1333\n",
      "Val RMSE: 89860.1338, Val MAE: 48273.5656, Val MSE: 8074843646.4559, Val R2: 0.5897\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1309\n",
      "Val RMSE: 89796.2570, Val MAE: 48529.5489, Val MSE: 8063367780.0368, Val R2: 0.5903\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0814, Val Loss: 0.1288\n",
      "Val RMSE: 88483.5534, Val MAE: 46542.7328, Val MSE: 7829339214.0222, Val R2: 0.6022\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1294\n",
      "Val RMSE: 89411.5207, Val MAE: 46410.4941, Val MSE: 7994420039.6276, Val R2: 0.5938\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1297\n",
      "Val RMSE: 90405.7106, Val MAE: 47117.2935, Val MSE: 8173192501.8990, Val R2: 0.5848\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1273\n",
      "Val RMSE: 87891.1018, Val MAE: 44886.3278, Val MSE: 7724845781.6048, Val R2: 0.6075\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1255\n",
      "Val RMSE: 86352.9206, Val MAE: 45891.5677, Val MSE: 7456826897.7707, Val R2: 0.6211\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1310\n",
      "Val RMSE: 88774.6687, Val MAE: 47185.2015, Val MSE: 7880941796.6858, Val R2: 0.5996\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1365\n",
      "Val RMSE: 89355.3214, Val MAE: 46827.7039, Val MSE: 7984373455.8746, Val R2: 0.5943\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1386\n",
      "Val RMSE: 88904.2107, Val MAE: 46199.0173, Val MSE: 7903958683.8302, Val R2: 0.5984\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1271\n",
      "Val RMSE: 87357.3638, Val MAE: 44913.1143, Val MSE: 7631309004.7270, Val R2: 0.6123\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1199\n",
      "Val RMSE: 81930.1244, Val MAE: 44426.6458, Val MSE: 6712545284.1238, Val R2: 0.6590\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1209\n",
      "Val RMSE: 82988.0161, Val MAE: 44463.3051, Val MSE: 6887010823.8267, Val R2: 0.6501\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1213\n",
      "Val RMSE: 82677.0998, Val MAE: 43609.1899, Val MSE: 6835502828.3504, Val R2: 0.6527\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1213\n",
      "Val RMSE: 81986.0072, Val MAE: 42599.0257, Val MSE: 6721705379.2986, Val R2: 0.6585\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1132\n",
      "Val RMSE: 78439.0082, Val MAE: 42849.7383, Val MSE: 6152678007.9438, Val R2: 0.6874\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1188\n",
      "Val RMSE: 81033.1569, Val MAE: 43494.0878, Val MSE: 6566372515.9787, Val R2: 0.6664\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1143\n",
      "Val RMSE: 79852.3579, Val MAE: 41685.2066, Val MSE: 6376399058.3540, Val R2: 0.6760\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1188\n",
      "Val RMSE: 81547.6756, Val MAE: 42992.6826, Val MSE: 6650023389.7005, Val R2: 0.6621\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1248\n",
      "Val RMSE: 81464.4380, Val MAE: 45657.1344, Val MSE: 6636454658.9635, Val R2: 0.6628\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1143\n",
      "Val RMSE: 80138.9562, Val MAE: 42058.7753, Val MSE: 6422252295.3659, Val R2: 0.6737\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1201\n",
      "Val RMSE: 79701.6196, Val MAE: 41740.0702, Val MSE: 6352348167.2416, Val R2: 0.6773\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1151\n",
      "Val RMSE: 79899.3149, Val MAE: 42953.1085, Val MSE: 6383900518.6693, Val R2: 0.6757\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1179\n",
      "Val RMSE: 77466.4413, Val MAE: 41961.2554, Val MSE: 6001049521.6409, Val R2: 0.6951\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1154\n",
      "Val RMSE: 79863.6723, Val MAE: 40950.4629, Val MSE: 6378206157.8233, Val R2: 0.6759\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1156\n",
      "Val RMSE: 80306.9282, Val MAE: 43863.3097, Val MSE: 6449202709.7202, Val R2: 0.6723\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1098\n",
      "Val RMSE: 77854.0194, Val MAE: 41543.5089, Val MSE: 6061248340.6666, Val R2: 0.6921\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1108\n",
      "Val RMSE: 77031.8745, Val MAE: 40632.8091, Val MSE: 5933909690.7072, Val R2: 0.6985\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1133\n",
      "Val RMSE: 77654.0037, Val MAE: 39625.0919, Val MSE: 6030144286.8891, Val R2: 0.6936\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1088\n",
      "Val RMSE: 77446.0949, Val MAE: 39643.6287, Val MSE: 5997897618.5188, Val R2: 0.6953\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1069\n",
      "Val RMSE: 76418.7111, Val MAE: 39162.9519, Val MSE: 5839819403.1300, Val R2: 0.7033\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1107\n",
      "Val RMSE: 78416.5072, Val MAE: 40099.3466, Val MSE: 6149148608.8309, Val R2: 0.6876\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1087\n",
      "Val RMSE: 77003.7840, Val MAE: 39215.2030, Val MSE: 5929582743.4042, Val R2: 0.6987\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1105\n",
      "Val RMSE: 76328.8536, Val MAE: 41041.0312, Val MSE: 5826093896.8674, Val R2: 0.7040\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1124\n",
      "Val RMSE: 77904.5938, Val MAE: 41506.2259, Val MSE: 6069125731.9486, Val R2: 0.6917\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1062\n",
      "Val RMSE: 73124.2964, Val MAE: 39693.6711, Val MSE: 5347162727.7308, Val R2: 0.7283\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1116\n",
      "Val RMSE: 77478.6799, Val MAE: 39433.5105, Val MSE: 6002945842.3082, Val R2: 0.6950\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1142\n",
      "Val RMSE: 75311.0243, Val MAE: 40293.0025, Val MSE: 5671750375.8918, Val R2: 0.7118\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1087\n",
      "Val RMSE: 73529.0363, Val MAE: 38556.9384, Val MSE: 5406519186.0194, Val R2: 0.7253\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1170\n",
      "Val RMSE: 77771.1656, Val MAE: 41299.7774, Val MSE: 6048354197.5137, Val R2: 0.6927\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1100\n",
      "Val RMSE: 74709.0660, Val MAE: 40069.7054, Val MSE: 5581444542.3197, Val R2: 0.7164\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75265.3871, Test MAE: 39252.1515, Test MSE: 5664878487.8772, Test R2: 0.6369\n",
      "Inference Time: 1.889646970308744e-05 seconds per sample\n",
      "\n",
      "Iteration 60 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3724, Val Loss: 0.2793\n",
      "Val RMSE: 141763.1483, Val MAE: 84332.6725, Val MSE: 20096790207.7246, Val R2: -0.0210\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2852, Val Loss: 0.2785\n",
      "Val RMSE: 142811.4596, Val MAE: 82075.2384, Val MSE: 20395112997.9752, Val R2: -0.0362\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2752, Val Loss: 0.2785\n",
      "Val RMSE: 142837.0867, Val MAE: 82025.4405, Val MSE: 20402433345.2135, Val R2: -0.0366\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2728, Val Loss: 0.2751\n",
      "Val RMSE: 140909.3612, Val MAE: 85102.8347, Val MSE: 19855448067.6412, Val R2: -0.0088\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2664, Val Loss: 0.2893\n",
      "Val RMSE: 144957.9628, Val MAE: 81334.4779, Val MSE: 21012810987.1708, Val R2: -0.0676\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2825\n",
      "Val RMSE: 144935.7745, Val MAE: 79819.6369, Val MSE: 21006378732.9749, Val R2: -0.0673\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2727\n",
      "Val RMSE: 143383.5268, Val MAE: 79842.7412, Val MSE: 20558835767.7200, Val R2: -0.0445\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2562, Val Loss: 0.2851\n",
      "Val RMSE: 144819.1861, Val MAE: 80325.2566, Val MSE: 20972596662.1297, Val R2: -0.0655\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2780\n",
      "Val RMSE: 144149.2133, Val MAE: 78977.1130, Val MSE: 20778995698.4990, Val R2: -0.0557\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2672\n",
      "Val RMSE: 142352.5133, Val MAE: 78816.1745, Val MSE: 20264238044.2105, Val R2: -0.0296\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2677\n",
      "Val RMSE: 141170.8554, Val MAE: 80961.6697, Val MSE: 19929210422.4649, Val R2: -0.0125\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2701\n",
      "Val RMSE: 142088.6272, Val MAE: 81281.3038, Val MSE: 20189177966.2585, Val R2: -0.0257\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2474, Val Loss: 0.2803\n",
      "Val RMSE: 145003.2198, Val MAE: 78198.8037, Val MSE: 21025933755.6548, Val R2: -0.0683\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2453, Val Loss: 0.2669\n",
      "Val RMSE: 141255.0430, Val MAE: 80164.3420, Val MSE: 19952987185.1980, Val R2: -0.0137\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2435, Val Loss: 0.2781\n",
      "Val RMSE: 144881.8135, Val MAE: 77955.3951, Val MSE: 20990739869.1350, Val R2: -0.0665\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2426, Val Loss: 0.2688\n",
      "Val RMSE: 141480.4454, Val MAE: 80290.1981, Val MSE: 20016716431.4668, Val R2: -0.0170\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2403, Val Loss: 0.2605\n",
      "Val RMSE: 140540.3954, Val MAE: 78637.6410, Val MSE: 19751602730.8042, Val R2: -0.0035\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2379, Val Loss: 0.2649\n",
      "Val RMSE: 143457.4832, Val MAE: 76904.2599, Val MSE: 20580049487.1136, Val R2: -0.0456\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2370, Val Loss: 0.2815\n",
      "Val RMSE: 142128.5490, Val MAE: 82674.2829, Val MSE: 20200524435.2004, Val R2: -0.0263\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2389, Val Loss: 0.2596\n",
      "Val RMSE: 140826.7326, Val MAE: 77872.1315, Val MSE: 19832168625.7754, Val R2: -0.0076\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2359, Val Loss: 0.2609\n",
      "Val RMSE: 141158.3616, Val MAE: 77849.1358, Val MSE: 19925683052.5325, Val R2: -0.0124\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2350, Val Loss: 0.2631\n",
      "Val RMSE: 142941.8963, Val MAE: 76564.6505, Val MSE: 20432385724.3875, Val R2: -0.0381\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2363, Val Loss: 0.2645\n",
      "Val RMSE: 140569.6548, Val MAE: 79732.4205, Val MSE: 19759827862.5409, Val R2: -0.0039\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2360, Val Loss: 0.2607\n",
      "Val RMSE: 140835.7104, Val MAE: 78533.3582, Val MSE: 19834697327.0381, Val R2: -0.0077\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2358, Val Loss: 0.2734\n",
      "Val RMSE: 144680.7904, Val MAE: 77281.5474, Val MSE: 20932531119.9901, Val R2: -0.0635\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2372, Val Loss: 0.2642\n",
      "Val RMSE: 143464.4719, Val MAE: 76612.7823, Val MSE: 20582054693.2895, Val R2: -0.0457\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2385, Val Loss: 0.2738\n",
      "Val RMSE: 140609.5820, Val MAE: 82887.8960, Val MSE: 19771054541.5036, Val R2: -0.0045\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2369, Val Loss: 0.2601\n",
      "Val RMSE: 141613.4531, Val MAE: 77033.9815, Val MSE: 20054370089.5129, Val R2: -0.0189\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2372, Val Loss: 0.2642\n",
      "Val RMSE: 142508.3754, Val MAE: 76754.6620, Val MSE: 20308637067.4533, Val R2: -0.0318\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2306, Val Loss: 0.2526\n",
      "Val RMSE: 138559.5057, Val MAE: 74439.7993, Val MSE: 19198736624.7320, Val R2: 0.0246\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2276, Val Loss: 0.2492\n",
      "Val RMSE: 137282.0076, Val MAE: 73837.9309, Val MSE: 18846349614.8755, Val R2: 0.0425\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2184, Val Loss: 0.2381\n",
      "Val RMSE: 132858.6199, Val MAE: 70788.3131, Val MSE: 17651412870.3581, Val R2: 0.1032\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2265\n",
      "Val RMSE: 129702.4610, Val MAE: 70957.4510, Val MSE: 16822728378.2217, Val R2: 0.1453\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.2053, Val Loss: 0.2434\n",
      "Val RMSE: 133539.7889, Val MAE: 71843.7422, Val MSE: 17832875230.9146, Val R2: 0.0940\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2445\n",
      "Val RMSE: 130976.1533, Val MAE: 73107.2337, Val MSE: 17154752740.0854, Val R2: 0.1284\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.2167, Val Loss: 0.2428\n",
      "Val RMSE: 122444.4065, Val MAE: 70128.2233, Val MSE: 14992632674.0153, Val R2: 0.2383\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1952, Val Loss: 0.2195\n",
      "Val RMSE: 114720.7847, Val MAE: 65424.1360, Val MSE: 13160858438.0910, Val R2: 0.3313\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1773, Val Loss: 0.2071\n",
      "Val RMSE: 111645.9709, Val MAE: 63860.7134, Val MSE: 12464822821.3455, Val R2: 0.3667\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1699, Val Loss: 0.1904\n",
      "Val RMSE: 105674.3387, Val MAE: 62601.4429, Val MSE: 11167065860.6985, Val R2: 0.4326\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1606, Val Loss: 0.1852\n",
      "Val RMSE: 105752.1138, Val MAE: 61485.4547, Val MSE: 11183509565.9983, Val R2: 0.4318\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1576, Val Loss: 0.1905\n",
      "Val RMSE: 106332.6744, Val MAE: 62181.3700, Val MSE: 11306637643.1885, Val R2: 0.4256\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1552, Val Loss: 0.1793\n",
      "Val RMSE: 103445.8965, Val MAE: 60335.8049, Val MSE: 10701053500.3506, Val R2: 0.4563\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1511, Val Loss: 0.1710\n",
      "Val RMSE: 101753.5436, Val MAE: 58168.2860, Val MSE: 10353783642.1178, Val R2: 0.4740\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1484, Val Loss: 0.1669\n",
      "Val RMSE: 101384.3065, Val MAE: 57362.8834, Val MSE: 10278777614.1425, Val R2: 0.4778\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1430, Val Loss: 0.1666\n",
      "Val RMSE: 101435.4748, Val MAE: 57758.7878, Val MSE: 10289155539.7625, Val R2: 0.4772\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1410, Val Loss: 0.1603\n",
      "Val RMSE: 99354.2941, Val MAE: 57074.3193, Val MSE: 9871275762.5161, Val R2: 0.4985\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1398, Val Loss: 0.1695\n",
      "Val RMSE: 102058.5142, Val MAE: 57180.7835, Val MSE: 10415940310.5912, Val R2: 0.4708\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1624\n",
      "Val RMSE: 99378.1288, Val MAE: 56804.1463, Val MSE: 9876012482.5167, Val R2: 0.4982\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1358, Val Loss: 0.1540\n",
      "Val RMSE: 97203.3438, Val MAE: 53842.3971, Val MSE: 9448490044.7644, Val R2: 0.5200\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1346, Val Loss: 0.1598\n",
      "Val RMSE: 99373.5698, Val MAE: 54134.1748, Val MSE: 9875106377.2102, Val R2: 0.4983\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1274, Val Loss: 0.1543\n",
      "Val RMSE: 96751.9382, Val MAE: 54234.0839, Val MSE: 9360937553.6551, Val R2: 0.5244\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1540\n",
      "Val RMSE: 97656.0597, Val MAE: 52499.7137, Val MSE: 9536705999.3015, Val R2: 0.5155\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1195, Val Loss: 0.1486\n",
      "Val RMSE: 96929.8607, Val MAE: 50364.1075, Val MSE: 9395397902.7033, Val R2: 0.5227\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1157, Val Loss: 0.1513\n",
      "Val RMSE: 97006.0999, Val MAE: 51489.6249, Val MSE: 9410183416.9220, Val R2: 0.5219\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1490\n",
      "Val RMSE: 94255.7104, Val MAE: 51920.6784, Val MSE: 8884138942.4023, Val R2: 0.5486\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1065, Val Loss: 0.1549\n",
      "Val RMSE: 97859.1557, Val MAE: 52066.0591, Val MSE: 9576414347.3185, Val R2: 0.5135\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1051, Val Loss: 0.1358\n",
      "Val RMSE: 91288.6505, Val MAE: 48835.2027, Val MSE: 8333617717.1720, Val R2: 0.5766\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1018, Val Loss: 0.1184\n",
      "Val RMSE: 89710.9178, Val MAE: 44459.3290, Val MSE: 8048048766.9801, Val R2: 0.5911\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0967, Val Loss: 0.1200\n",
      "Val RMSE: 88302.1298, Val MAE: 44508.6861, Val MSE: 7797266134.5807, Val R2: 0.6038\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1607\n",
      "Val RMSE: 103206.8487, Val MAE: 52369.7628, Val MSE: 10651653609.6890, Val R2: 0.4588\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0928, Val Loss: 0.1106\n",
      "Val RMSE: 84607.6774, Val MAE: 42288.9271, Val MSE: 7158459069.6130, Val R2: 0.6363\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1178\n",
      "Val RMSE: 86567.7926, Val MAE: 44061.0280, Val MSE: 7493982716.5007, Val R2: 0.6193\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1040\n",
      "Val RMSE: 85080.0132, Val MAE: 40038.1891, Val MSE: 7238608640.4853, Val R2: 0.6322\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0880, Val Loss: 0.2103\n",
      "Val RMSE: 108110.7624, Val MAE: 62052.6635, Val MSE: 11687936954.4294, Val R2: 0.4062\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1422, Val Loss: 0.1705\n",
      "Val RMSE: 100493.9894, Val MAE: 56399.1251, Val MSE: 10099041910.6422, Val R2: 0.4869\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1196, Val Loss: 0.1585\n",
      "Val RMSE: 98209.5095, Val MAE: 54072.8635, Val MSE: 9645107759.6263, Val R2: 0.5100\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1306\n",
      "Val RMSE: 89462.9729, Val MAE: 47732.4791, Val MSE: 8003623523.6124, Val R2: 0.5934\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0956, Val Loss: 0.1183\n",
      "Val RMSE: 83017.7180, Val MAE: 44687.1806, Val MSE: 6891941499.4881, Val R2: 0.6498\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1398\n",
      "Val RMSE: 90185.7383, Val MAE: 49130.4566, Val MSE: 8133467389.3076, Val R2: 0.5868\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1275\n",
      "Val RMSE: 83997.6967, Val MAE: 45967.2536, Val MSE: 7055613051.0458, Val R2: 0.6415\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0862, Val Loss: 0.1090\n",
      "Val RMSE: 79488.0387, Val MAE: 42424.4377, Val MSE: 6318348301.9681, Val R2: 0.6790\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1151\n",
      "Val RMSE: 84318.3477, Val MAE: 42758.5518, Val MSE: 7109583756.6908, Val R2: 0.6388\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1236\n",
      "Val RMSE: 90417.8610, Val MAE: 43754.7477, Val MSE: 8175389589.6360, Val R2: 0.5846\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1065\n",
      "Val RMSE: 82597.3592, Val MAE: 41069.6393, Val MSE: 6822323741.9867, Val R2: 0.6534\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0796, Val Loss: 0.1066\n",
      "Val RMSE: 81645.5047, Val MAE: 40728.9425, Val MSE: 6665988439.3744, Val R2: 0.6613\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1042\n",
      "Val RMSE: 81671.8876, Val MAE: 40145.2567, Val MSE: 6670297225.6950, Val R2: 0.6611\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0737, Val Loss: 0.1013\n",
      "Val RMSE: 80275.8202, Val MAE: 40039.6816, Val MSE: 6444207302.5862, Val R2: 0.6726\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1055\n",
      "Val RMSE: 80991.1590, Val MAE: 40414.5999, Val MSE: 6559567833.7951, Val R2: 0.6667\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0702, Val Loss: 0.1093\n",
      "Val RMSE: 80387.2532, Val MAE: 40950.8108, Val MSE: 6462110480.7108, Val R2: 0.6717\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1131\n",
      "Val RMSE: 82934.4684, Val MAE: 42452.6178, Val MSE: 6878126052.3086, Val R2: 0.6505\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.0975\n",
      "Val RMSE: 78632.4984, Val MAE: 37449.8691, Val MSE: 6183069801.4747, Val R2: 0.6859\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1109\n",
      "Val RMSE: 80906.7547, Val MAE: 41098.7567, Val MSE: 6545902948.6297, Val R2: 0.6674\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.0984\n",
      "Val RMSE: 76085.6826, Val MAE: 38687.3137, Val MSE: 5789031094.1220, Val R2: 0.7059\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.0986\n",
      "Val RMSE: 78938.9333, Val MAE: 37651.1655, Val MSE: 6231355191.6009, Val R2: 0.6834\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.0985\n",
      "Val RMSE: 78475.6165, Val MAE: 37541.8309, Val MSE: 6158422384.9739, Val R2: 0.6871\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1009\n",
      "Val RMSE: 78445.7046, Val MAE: 40207.0892, Val MSE: 6153728569.6808, Val R2: 0.6874\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1015\n",
      "Val RMSE: 77555.6631, Val MAE: 40121.0283, Val MSE: 6014880881.6521, Val R2: 0.6944\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.0949\n",
      "Val RMSE: 75403.5810, Val MAE: 37810.7934, Val MSE: 5685700027.1151, Val R2: 0.7111\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.0965\n",
      "Val RMSE: 77071.7993, Val MAE: 36677.7716, Val MSE: 5940062251.0888, Val R2: 0.6982\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.0956\n",
      "Val RMSE: 78830.6301, Val MAE: 35923.2960, Val MSE: 6214268236.9323, Val R2: 0.6843\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.0920\n",
      "Val RMSE: 74900.7349, Val MAE: 35335.2464, Val MSE: 5610120093.8609, Val R2: 0.7150\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.0998\n",
      "Val RMSE: 76437.9458, Val MAE: 39628.5274, Val MSE: 5842759555.6070, Val R2: 0.7032\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.0859\n",
      "Val RMSE: 71688.9257, Val MAE: 34214.5921, Val MSE: 5139302062.5317, Val R2: 0.7389\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.0978\n",
      "Val RMSE: 78132.5860, Val MAE: 36851.3174, Val MSE: 6104701002.2714, Val R2: 0.6898\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.0992\n",
      "Val RMSE: 79000.3813, Val MAE: 37053.4075, Val MSE: 6241060241.2238, Val R2: 0.6829\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1092\n",
      "Val RMSE: 82575.8949, Val MAE: 40923.6253, Val MSE: 6818778422.8167, Val R2: 0.6536\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.0936\n",
      "Val RMSE: 77781.8280, Val MAE: 34909.8904, Val MSE: 6050012762.2844, Val R2: 0.6926\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1040\n",
      "Val RMSE: 81719.9941, Val MAE: 38647.1478, Val MSE: 6678157431.5193, Val R2: 0.6607\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1011\n",
      "Val RMSE: 81306.3483, Val MAE: 37643.8963, Val MSE: 6610722269.0340, Val R2: 0.6641\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.0972\n",
      "Val RMSE: 78832.3281, Val MAE: 35706.1194, Val MSE: 6214535955.3256, Val R2: 0.6843\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75788.7542, Test MAE: 38710.7311, Test MSE: 5743935269.7202, Test R2: 0.6318\n",
      "Inference Time: 2.1488446455735427e-05 seconds per sample\n",
      "\n",
      "Iteration 61 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4012, Val Loss: 0.2833\n",
      "Val RMSE: 143169.1526, Val MAE: 82992.4708, Val MSE: 20497406261.7466, Val R2: -0.0414\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2822, Val Loss: 0.2767\n",
      "Val RMSE: 140746.7704, Val MAE: 86117.8656, Val MSE: 19809653381.3205, Val R2: -0.0065\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2720, Val Loss: 0.2760\n",
      "Val RMSE: 141553.6304, Val MAE: 83470.8633, Val MSE: 20037430278.2760, Val R2: -0.0180\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2676, Val Loss: 0.2776\n",
      "Val RMSE: 142335.8211, Val MAE: 82247.9251, Val MSE: 20259485963.2212, Val R2: -0.0293\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2665, Val Loss: 0.2755\n",
      "Val RMSE: 141621.9613, Val MAE: 83225.7611, Val MSE: 20056779920.5332, Val R2: -0.0190\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2637, Val Loss: 0.2771\n",
      "Val RMSE: 142125.5501, Val MAE: 82586.5900, Val MSE: 20199671983.3163, Val R2: -0.0263\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2613, Val Loss: 0.2774\n",
      "Val RMSE: 142860.4988, Val MAE: 81327.9404, Val MSE: 20409122128.6192, Val R2: -0.0369\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2583, Val Loss: 0.2787\n",
      "Val RMSE: 142635.3818, Val MAE: 81419.5803, Val MSE: 20344852135.6913, Val R2: -0.0336\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2715\n",
      "Val RMSE: 140784.9290, Val MAE: 82820.2885, Val MSE: 19820396241.8377, Val R2: -0.0070\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2733\n",
      "Val RMSE: 140591.6782, Val MAE: 84276.7152, Val MSE: 19766019986.8480, Val R2: -0.0042\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2549, Val Loss: 0.2696\n",
      "Val RMSE: 140245.0925, Val MAE: 83293.6105, Val MSE: 19668685978.3916, Val R2: 0.0007\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2698\n",
      "Val RMSE: 139643.6473, Val MAE: 83108.6269, Val MSE: 19500348218.1117, Val R2: 0.0093\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2684\n",
      "Val RMSE: 141943.7717, Val MAE: 78919.4800, Val MSE: 20148034311.5088, Val R2: -0.0236\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2778\n",
      "Val RMSE: 140102.9165, Val MAE: 85905.2602, Val MSE: 19628827225.5032, Val R2: 0.0027\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2457, Val Loss: 0.2757\n",
      "Val RMSE: 137950.2483, Val MAE: 83385.0886, Val MSE: 19030271018.0279, Val R2: 0.0331\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2525\n",
      "Val RMSE: 135664.9858, Val MAE: 73897.2751, Val MSE: 18404988361.1778, Val R2: 0.0649\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2306, Val Loss: 0.2385\n",
      "Val RMSE: 130315.4852, Val MAE: 76296.8427, Val MSE: 16982125678.6928, Val R2: 0.1372\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2222, Val Loss: 0.2383\n",
      "Val RMSE: 132766.5745, Val MAE: 73888.1724, Val MSE: 17626963296.0461, Val R2: 0.1044\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2151, Val Loss: 0.2317\n",
      "Val RMSE: 130005.8052, Val MAE: 76134.1092, Val MSE: 16901509389.3830, Val R2: 0.1413\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2268\n",
      "Val RMSE: 129141.0610, Val MAE: 72805.4568, Val MSE: 16677413645.8606, Val R2: 0.1527\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2078, Val Loss: 0.2278\n",
      "Val RMSE: 130924.2933, Val MAE: 71034.1676, Val MSE: 17141170574.0791, Val R2: 0.1291\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2049, Val Loss: 0.2379\n",
      "Val RMSE: 132496.4993, Val MAE: 70487.0568, Val MSE: 17555322328.6521, Val R2: 0.1081\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2011, Val Loss: 0.2312\n",
      "Val RMSE: 132204.6839, Val MAE: 69919.8250, Val MSE: 17478078448.8169, Val R2: 0.1120\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1964, Val Loss: 0.2276\n",
      "Val RMSE: 128182.0929, Val MAE: 71560.4557, Val MSE: 16430648928.9721, Val R2: 0.1652\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1969, Val Loss: 0.2167\n",
      "Val RMSE: 127206.7877, Val MAE: 71057.4378, Val MSE: 16181566841.2736, Val R2: 0.1779\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1993, Val Loss: 0.2149\n",
      "Val RMSE: 128013.9838, Val MAE: 69619.6314, Val MSE: 16387580057.5995, Val R2: 0.1674\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1907, Val Loss: 0.2068\n",
      "Val RMSE: 126769.9929, Val MAE: 65823.8602, Val MSE: 16070631088.2692, Val R2: 0.1835\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1891, Val Loss: 0.2395\n",
      "Val RMSE: 131084.8139, Val MAE: 70430.3320, Val MSE: 17183228443.6834, Val R2: 0.1270\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1863, Val Loss: 0.2051\n",
      "Val RMSE: 120196.3081, Val MAE: 66533.6278, Val MSE: 14447152492.4295, Val R2: 0.2660\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1785, Val Loss: 0.1985\n",
      "Val RMSE: 116311.1772, Val MAE: 65832.8348, Val MSE: 13528289932.9870, Val R2: 0.3127\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1722, Val Loss: 0.1910\n",
      "Val RMSE: 111475.6834, Val MAE: 61602.4461, Val MSE: 12426827992.9180, Val R2: 0.3686\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1677\n",
      "Val RMSE: 101268.3991, Val MAE: 59221.7390, Val MSE: 10255288654.3657, Val R2: 0.4790\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1607, Val Loss: 0.1636\n",
      "Val RMSE: 99314.3060, Val MAE: 57233.3603, Val MSE: 9863331379.7791, Val R2: 0.4989\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1602, Val Loss: 0.1719\n",
      "Val RMSE: 102003.3652, Val MAE: 59146.5896, Val MSE: 10404686503.4270, Val R2: 0.4714\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1523, Val Loss: 0.1585\n",
      "Val RMSE: 97732.8808, Val MAE: 55720.2586, Val MSE: 9551715999.1485, Val R2: 0.5147\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1495, Val Loss: 0.1590\n",
      "Val RMSE: 97483.2390, Val MAE: 56030.9004, Val MSE: 9502981883.6662, Val R2: 0.5172\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1419, Val Loss: 0.1523\n",
      "Val RMSE: 96207.0978, Val MAE: 53915.8524, Val MSE: 9255805675.3027, Val R2: 0.5297\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1419, Val Loss: 0.1508\n",
      "Val RMSE: 94777.9572, Val MAE: 53229.1951, Val MSE: 8982861179.8322, Val R2: 0.5436\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1363, Val Loss: 0.1557\n",
      "Val RMSE: 96621.0231, Val MAE: 53763.4048, Val MSE: 9335622109.0068, Val R2: 0.5257\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1328, Val Loss: 0.1331\n",
      "Val RMSE: 89313.9723, Val MAE: 48561.8040, Val MSE: 7976985655.9472, Val R2: 0.5947\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1578\n",
      "Val RMSE: 96449.0375, Val MAE: 51795.4186, Val MSE: 9302416841.4464, Val R2: 0.5274\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1218, Val Loss: 0.1515\n",
      "Val RMSE: 93827.7927, Val MAE: 52475.9887, Val MSE: 8803654678.5456, Val R2: 0.5527\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1146, Val Loss: 0.1307\n",
      "Val RMSE: 89098.6052, Val MAE: 46366.0454, Val MSE: 7938561448.0616, Val R2: 0.5967\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1094, Val Loss: 0.1293\n",
      "Val RMSE: 87846.3940, Val MAE: 49668.1133, Val MSE: 7716988931.8634, Val R2: 0.6079\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1085, Val Loss: 0.1264\n",
      "Val RMSE: 86571.2194, Val MAE: 45258.4164, Val MSE: 7494576034.0632, Val R2: 0.6192\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1028, Val Loss: 0.1237\n",
      "Val RMSE: 84969.0818, Val MAE: 46295.9977, Val MSE: 7219744862.7908, Val R2: 0.6332\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1258\n",
      "Val RMSE: 87241.5459, Val MAE: 46029.0649, Val MSE: 7611087336.0008, Val R2: 0.6133\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0956, Val Loss: 0.1193\n",
      "Val RMSE: 83619.0678, Val MAE: 42778.7285, Val MSE: 6992148503.6301, Val R2: 0.6448\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1140\n",
      "Val RMSE: 81336.8362, Val MAE: 44376.4722, Val MSE: 6615680920.2689, Val R2: 0.6639\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1224\n",
      "Val RMSE: 84442.0299, Val MAE: 44156.9772, Val MSE: 7130456419.0450, Val R2: 0.6377\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1180\n",
      "Val RMSE: 82454.6800, Val MAE: 43245.5014, Val MSE: 6798774254.0524, Val R2: 0.6546\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0851, Val Loss: 0.1265\n",
      "Val RMSE: 84059.5449, Val MAE: 46764.1402, Val MSE: 7066007095.8936, Val R2: 0.6410\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1256\n",
      "Val RMSE: 80094.9738, Val MAE: 47413.1460, Val MSE: 6415204835.9065, Val R2: 0.6741\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.1193\n",
      "Val RMSE: 81289.4866, Val MAE: 44279.6850, Val MSE: 6607980624.2878, Val R2: 0.6643\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0798, Val Loss: 0.1229\n",
      "Val RMSE: 83197.3078, Val MAE: 44533.6234, Val MSE: 6921792030.1501, Val R2: 0.6483\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1167\n",
      "Val RMSE: 80343.0160, Val MAE: 42977.9589, Val MSE: 6455000222.7736, Val R2: 0.6720\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1075\n",
      "Val RMSE: 75462.4255, Val MAE: 42067.8784, Val MSE: 5694577658.0130, Val R2: 0.7107\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0718, Val Loss: 0.1112\n",
      "Val RMSE: 76231.4834, Val MAE: 43036.2738, Val MSE: 5811239059.5452, Val R2: 0.7048\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1158\n",
      "Val RMSE: 77333.3658, Val MAE: 44222.3488, Val MSE: 5980449473.3565, Val R2: 0.6962\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.1172\n",
      "Val RMSE: 79561.1943, Val MAE: 43438.0665, Val MSE: 6329983630.6117, Val R2: 0.6784\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1114\n",
      "Val RMSE: 75232.3237, Val MAE: 41379.6694, Val MSE: 5659902534.5995, Val R2: 0.7124\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1139\n",
      "Val RMSE: 76711.4444, Val MAE: 43765.2183, Val MSE: 5884645702.3343, Val R2: 0.7010\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1225\n",
      "Val RMSE: 78087.7585, Val MAE: 42632.0522, Val MSE: 6097698023.2713, Val R2: 0.6902\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.1133\n",
      "Val RMSE: 77574.7698, Val MAE: 41564.5572, Val MSE: 6017844916.0605, Val R2: 0.6943\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1179\n",
      "Val RMSE: 78914.7851, Val MAE: 45029.9513, Val MSE: 6227543300.6087, Val R2: 0.6836\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1156\n",
      "Val RMSE: 78120.2178, Val MAE: 42095.3304, Val MSE: 6102768430.5094, Val R2: 0.6899\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1219\n",
      "Val RMSE: 78026.2927, Val MAE: 42967.2001, Val MSE: 6088102354.3765, Val R2: 0.6907\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1058\n",
      "Val RMSE: 74090.4395, Val MAE: 40773.9090, Val MSE: 5489393220.8065, Val R2: 0.7211\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1049\n",
      "Val RMSE: 72712.9143, Val MAE: 38818.8140, Val MSE: 5287167904.4675, Val R2: 0.7314\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1154\n",
      "Val RMSE: 75702.4447, Val MAE: 40889.9030, Val MSE: 5730860134.2935, Val R2: 0.7088\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.1404\n",
      "Val RMSE: 80572.1160, Val MAE: 47594.6322, Val MSE: 6491865872.0151, Val R2: 0.6702\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1146\n",
      "Val RMSE: 76514.2742, Val MAE: 43269.5215, Val MSE: 5854434151.6905, Val R2: 0.7026\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1262\n",
      "Val RMSE: 80467.2463, Val MAE: 46929.1023, Val MSE: 6474977721.6736, Val R2: 0.6710\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1146\n",
      "Val RMSE: 76602.7192, Val MAE: 44473.7701, Val MSE: 5867976581.7275, Val R2: 0.7019\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1120\n",
      "Val RMSE: 75423.6002, Val MAE: 41435.3026, Val MSE: 5688719471.3547, Val R2: 0.7110\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1525\n",
      "Val RMSE: 98918.3532, Val MAE: 50047.0962, Val MSE: 9784840607.4854, Val R2: 0.5029\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1228\n",
      "Val RMSE: 81018.3770, Val MAE: 41857.5615, Val MSE: 6563977418.4775, Val R2: 0.6665\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1102\n",
      "Val RMSE: 75195.0571, Val MAE: 40830.2442, Val MSE: 5654296613.1138, Val R2: 0.7127\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1639\n",
      "Val RMSE: 100351.4307, Val MAE: 51672.4584, Val MSE: 10070409640.7925, Val R2: 0.4884\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1316\n",
      "Val RMSE: 87301.5384, Val MAE: 45815.3963, Val MSE: 7621558606.4615, Val R2: 0.6128\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1239\n",
      "Val RMSE: 80571.3950, Val MAE: 42703.0052, Val MSE: 6491749694.9357, Val R2: 0.6702\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1249\n",
      "Val RMSE: 79911.2709, Val MAE: 43866.4118, Val MSE: 6385811216.2433, Val R2: 0.6756\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1149\n",
      "Val RMSE: 77436.1466, Val MAE: 41986.9992, Val MSE: 5996356803.1581, Val R2: 0.6953\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1136\n",
      "Val RMSE: 76463.0193, Val MAE: 41170.6713, Val MSE: 5846593324.3972, Val R2: 0.7030\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1340\n",
      "Val RMSE: 89407.3228, Val MAE: 45036.6605, Val MSE: 7993669370.2961, Val R2: 0.5939\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1362\n",
      "Val RMSE: 88835.2261, Val MAE: 45260.7882, Val MSE: 7891697396.5881, Val R2: 0.5991\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1674\n",
      "Val RMSE: 100711.2353, Val MAE: 49118.0677, Val MSE: 10142752917.0123, Val R2: 0.4847\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1553\n",
      "Val RMSE: 96777.9593, Val MAE: 48336.8511, Val MSE: 9365973401.7059, Val R2: 0.5241\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1252\n",
      "Val RMSE: 78394.1738, Val MAE: 44775.6392, Val MSE: 6145646488.9197, Val R2: 0.6878\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1650\n",
      "Val RMSE: 104072.6892, Val MAE: 50089.7590, Val MSE: 10831124639.1372, Val R2: 0.4497\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1275\n",
      "Val RMSE: 81463.5671, Val MAE: 45905.3847, Val MSE: 6636312759.7155, Val R2: 0.6628\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1368\n",
      "Val RMSE: 89246.1215, Val MAE: 45719.7478, Val MSE: 7964870208.6511, Val R2: 0.5953\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1658\n",
      "Val RMSE: 105798.3617, Val MAE: 53044.6352, Val MSE: 11193293348.1818, Val R2: 0.4313\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.1256\n",
      "Val RMSE: 82961.1577, Val MAE: 44893.8776, Val MSE: 6882553687.2500, Val R2: 0.6503\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1154\n",
      "Val RMSE: 76256.4574, Val MAE: 42718.9668, Val MSE: 5815047299.9293, Val R2: 0.7046\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.1266\n",
      "Val RMSE: 82629.8375, Val MAE: 46832.5549, Val MSE: 6827690041.0797, Val R2: 0.6531\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0429, Val Loss: 0.1767\n",
      "Val RMSE: 111389.9059, Val MAE: 54381.3001, Val MSE: 12407711140.6087, Val R2: 0.3696\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.2238\n",
      "Val RMSE: 130962.4111, Val MAE: 62489.3677, Val MSE: 17151153120.0299, Val R2: 0.1286\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0418, Val Loss: 0.1758\n",
      "Val RMSE: 112104.6953, Val MAE: 53208.6589, Val MSE: 12567462699.1690, Val R2: 0.3615\n",
      "Early stopping triggered after epoch 99\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76769.0665, Test MAE: 42109.5182, Test MSE: 5893489568.9010, Test R2: 0.6222\n",
      "Inference Time: 2.3426055908203125e-05 seconds per sample\n",
      "\n",
      "Iteration 62 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3263, Val Loss: 0.2840\n",
      "Val RMSE: 141593.2258, Val MAE: 86828.1699, Val MSE: 20048641590.4160, Val R2: -0.0186\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2807, Val Loss: 0.2936\n",
      "Val RMSE: 144955.9027, Val MAE: 83152.3096, Val MSE: 21012213720.5200, Val R2: -0.0676\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2763, Val Loss: 0.2774\n",
      "Val RMSE: 141090.0413, Val MAE: 85531.2456, Val MSE: 19906399767.4531, Val R2: -0.0114\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2674, Val Loss: 0.2783\n",
      "Val RMSE: 143017.2774, Val MAE: 81590.8954, Val MSE: 20453941620.6198, Val R2: -0.0392\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2746\n",
      "Val RMSE: 142368.9152, Val MAE: 82262.1752, Val MSE: 20268908015.0402, Val R2: -0.0298\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2634, Val Loss: 0.2731\n",
      "Val RMSE: 141094.5729, Val MAE: 83835.7968, Val MSE: 19907678509.4645, Val R2: -0.0114\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2646, Val Loss: 0.2750\n",
      "Val RMSE: 141269.0804, Val MAE: 84378.6725, Val MSE: 19956953079.8048, Val R2: -0.0139\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2595, Val Loss: 0.2734\n",
      "Val RMSE: 141276.0926, Val MAE: 82386.4904, Val MSE: 19958934327.4496, Val R2: -0.0140\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2696\n",
      "Val RMSE: 140503.3799, Val MAE: 82771.5595, Val MSE: 19741199762.9559, Val R2: -0.0030\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2519, Val Loss: 0.2725\n",
      "Val RMSE: 140647.5621, Val MAE: 83538.0097, Val MSE: 19781736713.8218, Val R2: -0.0050\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2521, Val Loss: 0.2674\n",
      "Val RMSE: 141194.1477, Val MAE: 80439.4099, Val MSE: 19935787344.9364, Val R2: -0.0129\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2489, Val Loss: 0.2853\n",
      "Val RMSE: 144995.8905, Val MAE: 79769.4211, Val MSE: 21023808274.5254, Val R2: -0.0681\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2481, Val Loss: 0.2657\n",
      "Val RMSE: 140894.9197, Val MAE: 80254.4345, Val MSE: 19851378411.2767, Val R2: -0.0086\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2448, Val Loss: 0.2670\n",
      "Val RMSE: 143093.4747, Val MAE: 77733.7593, Val MSE: 20475742510.7367, Val R2: -0.0403\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2441, Val Loss: 0.2726\n",
      "Val RMSE: 142108.5449, Val MAE: 81620.2634, Val MSE: 20194838531.3885, Val R2: -0.0260\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2433, Val Loss: 0.2715\n",
      "Val RMSE: 139970.9521, Val MAE: 83627.1519, Val MSE: 19591867445.7202, Val R2: 0.0046\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2421, Val Loss: 0.2616\n",
      "Val RMSE: 141247.8627, Val MAE: 78581.6935, Val MSE: 19950958705.6175, Val R2: -0.0136\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2340, Val Loss: 0.2539\n",
      "Val RMSE: 133464.1795, Val MAE: 78156.1480, Val MSE: 17812687210.7661, Val R2: 0.0950\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2255, Val Loss: 0.2600\n",
      "Val RMSE: 139308.1394, Val MAE: 79385.5311, Val MSE: 19406757712.8135, Val R2: 0.0140\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2153, Val Loss: 0.2261\n",
      "Val RMSE: 129821.8968, Val MAE: 72559.2679, Val MSE: 16853724889.8642, Val R2: 0.1437\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2093, Val Loss: 0.2313\n",
      "Val RMSE: 131486.1755, Val MAE: 71099.0862, Val MSE: 17288614355.5497, Val R2: 0.1216\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2259\n",
      "Val RMSE: 126480.7664, Val MAE: 76413.8197, Val MSE: 15997384262.7453, Val R2: 0.1872\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2007, Val Loss: 0.2269\n",
      "Val RMSE: 128740.1078, Val MAE: 69890.3618, Val MSE: 16574015364.4759, Val R2: 0.1579\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1934, Val Loss: 0.2373\n",
      "Val RMSE: 133940.3380, Val MAE: 73569.0370, Val MSE: 17940014132.8951, Val R2: 0.0885\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2028\n",
      "Val RMSE: 113735.7059, Val MAE: 68665.1374, Val MSE: 12935810803.3769, Val R2: 0.3428\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1739, Val Loss: 0.1861\n",
      "Val RMSE: 106088.2884, Val MAE: 63957.8726, Val MSE: 11254724928.7668, Val R2: 0.4282\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1635, Val Loss: 0.1816\n",
      "Val RMSE: 103602.0876, Val MAE: 61848.8460, Val MSE: 10733392546.7798, Val R2: 0.4547\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1558, Val Loss: 0.1676\n",
      "Val RMSE: 100586.7477, Val MAE: 59134.8953, Val MSE: 10117693821.0969, Val R2: 0.4860\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1430, Val Loss: 0.1566\n",
      "Val RMSE: 97558.4407, Val MAE: 56864.9883, Val MSE: 9517649361.4056, Val R2: 0.5164\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1519, Val Loss: 0.1511\n",
      "Val RMSE: 95676.3796, Val MAE: 56628.4945, Val MSE: 9153969611.5963, Val R2: 0.5349\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1435, Val Loss: 0.1584\n",
      "Val RMSE: 99245.4279, Val MAE: 56969.0193, Val MSE: 9849654960.4042, Val R2: 0.4996\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1494\n",
      "Val RMSE: 97535.9631, Val MAE: 51870.4024, Val MSE: 9513264106.3353, Val R2: 0.5167\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1223, Val Loss: 0.1394\n",
      "Val RMSE: 96170.4238, Val MAE: 50229.7393, Val MSE: 9248750417.4192, Val R2: 0.5301\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1188, Val Loss: 0.1241\n",
      "Val RMSE: 92075.4396, Val MAE: 46535.7378, Val MSE: 8477886568.8635, Val R2: 0.5693\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1104, Val Loss: 0.1172\n",
      "Val RMSE: 90052.3591, Val MAE: 46116.9951, Val MSE: 8109427370.7599, Val R2: 0.5880\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1143\n",
      "Val RMSE: 88413.2554, Val MAE: 46870.3767, Val MSE: 7816903722.4367, Val R2: 0.6029\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1008, Val Loss: 0.1145\n",
      "Val RMSE: 89142.9959, Val MAE: 43581.3068, Val MSE: 7946473716.9745, Val R2: 0.5963\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.0980, Val Loss: 0.1022\n",
      "Val RMSE: 85371.1909, Val MAE: 40167.6174, Val MSE: 7288240242.4166, Val R2: 0.6297\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.0996\n",
      "Val RMSE: 83378.1256, Val MAE: 39487.9131, Val MSE: 6951911834.1876, Val R2: 0.6468\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0908, Val Loss: 0.1034\n",
      "Val RMSE: 83757.9904, Val MAE: 40476.5947, Val MSE: 7015400949.1202, Val R2: 0.6436\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.0994\n",
      "Val RMSE: 83404.2292, Val MAE: 41119.5671, Val MSE: 6956265445.1237, Val R2: 0.6466\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.0942\n",
      "Val RMSE: 80413.1017, Val MAE: 37066.2741, Val MSE: 6466266924.7554, Val R2: 0.6715\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0842, Val Loss: 0.0953\n",
      "Val RMSE: 79807.9415, Val MAE: 38272.9911, Val MSE: 6369307521.3081, Val R2: 0.6764\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1034\n",
      "Val RMSE: 81931.6009, Val MAE: 41389.4161, Val MSE: 6712787229.9160, Val R2: 0.6589\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0799, Val Loss: 0.0965\n",
      "Val RMSE: 80556.6271, Val MAE: 38360.4305, Val MSE: 6489370162.9008, Val R2: 0.6703\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.0971\n",
      "Val RMSE: 80914.3736, Val MAE: 40050.7775, Val MSE: 6547135852.7207, Val R2: 0.6674\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0773, Val Loss: 0.0915\n",
      "Val RMSE: 75880.7145, Val MAE: 35400.4445, Val MSE: 5757882834.1281, Val R2: 0.7075\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.0813\n",
      "Val RMSE: 72522.7493, Val MAE: 34061.1402, Val MSE: 5259549170.5665, Val R2: 0.7328\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.0829\n",
      "Val RMSE: 71444.4607, Val MAE: 33213.6111, Val MSE: 5104310958.9986, Val R2: 0.7407\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.0824\n",
      "Val RMSE: 73190.0825, Val MAE: 33253.0745, Val MSE: 5356788172.9340, Val R2: 0.7278\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0741, Val Loss: 0.0839\n",
      "Val RMSE: 74574.1961, Val MAE: 33681.9351, Val MSE: 5561310718.6235, Val R2: 0.7175\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.0970\n",
      "Val RMSE: 79513.0953, Val MAE: 37989.9298, Val MSE: 6322332330.1927, Val R2: 0.6788\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.0823\n",
      "Val RMSE: 72344.1590, Val MAE: 36382.6396, Val MSE: 5233677345.7436, Val R2: 0.7341\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.0796\n",
      "Val RMSE: 69380.5955, Val MAE: 32476.5865, Val MSE: 4813667035.9663, Val R2: 0.7554\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.0769\n",
      "Val RMSE: 71226.2491, Val MAE: 31887.9118, Val MSE: 5073178555.8114, Val R2: 0.7423\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.0793\n",
      "Val RMSE: 70242.9498, Val MAE: 32474.2586, Val MSE: 4934071995.1365, Val R2: 0.7493\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.0815\n",
      "Val RMSE: 68248.8122, Val MAE: 34431.0647, Val MSE: 4657900373.4216, Val R2: 0.7633\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.0770\n",
      "Val RMSE: 67920.2801, Val MAE: 31239.1769, Val MSE: 4613164449.6245, Val R2: 0.7656\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.0769\n",
      "Val RMSE: 66970.2134, Val MAE: 31892.4741, Val MSE: 4485009486.3512, Val R2: 0.7721\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.0799\n",
      "Val RMSE: 71403.1540, Val MAE: 31845.0413, Val MSE: 5098410403.6726, Val R2: 0.7410\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.0811\n",
      "Val RMSE: 70008.1011, Val MAE: 31138.5623, Val MSE: 4901134220.4625, Val R2: 0.7510\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.0870\n",
      "Val RMSE: 73574.9500, Val MAE: 34724.5398, Val MSE: 5413273260.6024, Val R2: 0.7250\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.0835\n",
      "Val RMSE: 68868.8674, Val MAE: 34744.6521, Val MSE: 4742920897.2004, Val R2: 0.7590\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.0771\n",
      "Val RMSE: 66628.7447, Val MAE: 32081.2769, Val MSE: 4439389615.8624, Val R2: 0.7745\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.0865\n",
      "Val RMSE: 71311.7329, Val MAE: 35900.3408, Val MSE: 5085363243.5235, Val R2: 0.7416\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.0736\n",
      "Val RMSE: 63940.7559, Val MAE: 31499.4708, Val MSE: 4088420265.5728, Val R2: 0.7923\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.0839\n",
      "Val RMSE: 70137.5309, Val MAE: 33120.3384, Val MSE: 4919273244.9458, Val R2: 0.7501\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.0767\n",
      "Val RMSE: 66060.4617, Val MAE: 32504.5260, Val MSE: 4363984602.6064, Val R2: 0.7783\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.0873\n",
      "Val RMSE: 68796.6431, Val MAE: 36730.2549, Val MSE: 4732978095.0102, Val R2: 0.7595\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.0707\n",
      "Val RMSE: 63191.4681, Val MAE: 30413.3529, Val MSE: 3993161645.5635, Val R2: 0.7971\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.0766\n",
      "Val RMSE: 65361.3875, Val MAE: 33475.4492, Val MSE: 4272110972.2256, Val R2: 0.7829\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.0726\n",
      "Val RMSE: 63314.7686, Val MAE: 31374.8412, Val MSE: 4008759921.5775, Val R2: 0.7963\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.0873\n",
      "Val RMSE: 71708.2464, Val MAE: 35689.2784, Val MSE: 5142072598.6856, Val R2: 0.7388\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.0775\n",
      "Val RMSE: 64138.1604, Val MAE: 33970.2498, Val MSE: 4113703615.0281, Val R2: 0.7910\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.0848\n",
      "Val RMSE: 66990.0076, Val MAE: 36185.7412, Val MSE: 4487661123.3354, Val R2: 0.7720\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.0839\n",
      "Val RMSE: 67677.6992, Val MAE: 37030.7066, Val MSE: 4580270974.0367, Val R2: 0.7673\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.0747\n",
      "Val RMSE: 65201.7944, Val MAE: 32399.8381, Val MSE: 4251273994.2905, Val R2: 0.7840\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.0775\n",
      "Val RMSE: 64611.1707, Val MAE: 31414.1344, Val MSE: 4174603380.5112, Val R2: 0.7879\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.0695\n",
      "Val RMSE: 61747.7959, Val MAE: 29894.3558, Val MSE: 3812790303.1943, Val R2: 0.8063\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.0922\n",
      "Val RMSE: 69895.4668, Val MAE: 40034.5868, Val MSE: 4885376277.4724, Val R2: 0.7518\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.0837\n",
      "Val RMSE: 67920.7864, Val MAE: 35198.7902, Val MSE: 4613233224.8521, Val R2: 0.7656\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.0742\n",
      "Val RMSE: 63396.1626, Val MAE: 33565.0583, Val MSE: 4019073429.9791, Val R2: 0.7958\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.0774\n",
      "Val RMSE: 65368.6611, Val MAE: 33619.0506, Val MSE: 4273061860.0318, Val R2: 0.7829\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.0760\n",
      "Val RMSE: 64149.1708, Val MAE: 31440.4831, Val MSE: 4115116118.0476, Val R2: 0.7909\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.0787\n",
      "Val RMSE: 65810.2351, Val MAE: 31975.3090, Val MSE: 4330987044.5276, Val R2: 0.7800\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.0755\n",
      "Val RMSE: 64398.6886, Val MAE: 30389.7117, Val MSE: 4147191098.6633, Val R2: 0.7893\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.0717\n",
      "Val RMSE: 61605.6200, Val MAE: 31094.9194, Val MSE: 3795252415.9939, Val R2: 0.8072\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.0698\n",
      "Val RMSE: 60991.7682, Val MAE: 30375.6708, Val MSE: 3719995789.9235, Val R2: 0.8110\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.0726\n",
      "Val RMSE: 61343.7224, Val MAE: 33078.5244, Val MSE: 3763052272.5547, Val R2: 0.8088\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.0740\n",
      "Val RMSE: 63921.4780, Val MAE: 31876.1901, Val MSE: 4085955348.7581, Val R2: 0.7924\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.0749\n",
      "Val RMSE: 64331.0103, Val MAE: 31663.3921, Val MSE: 4138478891.4295, Val R2: 0.7897\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.0735\n",
      "Val RMSE: 62392.7287, Val MAE: 31058.8541, Val MSE: 3892852591.0283, Val R2: 0.8022\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.0730\n",
      "Val RMSE: 62677.9717, Val MAE: 31781.0462, Val MSE: 3928528142.5759, Val R2: 0.8004\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0424, Val Loss: 0.0740\n",
      "Val RMSE: 62730.5492, Val MAE: 33634.1556, Val MSE: 3935121799.3676, Val R2: 0.8001\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0419, Val Loss: 0.0799\n",
      "Val RMSE: 67443.4307, Val MAE: 32216.9375, Val MSE: 4548616340.8737, Val R2: 0.7689\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.0798\n",
      "Val RMSE: 66727.4007, Val MAE: 33821.9193, Val MSE: 4452546009.8611, Val R2: 0.7738\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.0775\n",
      "Val RMSE: 65385.2838, Val MAE: 30620.6535, Val MSE: 4275235334.7755, Val R2: 0.7828\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.0777\n",
      "Val RMSE: 65700.8181, Val MAE: 32494.1497, Val MSE: 4316597500.3980, Val R2: 0.7807\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0416, Val Loss: 0.0782\n",
      "Val RMSE: 66276.1479, Val MAE: 31995.8296, Val MSE: 4392527779.4335, Val R2: 0.7768\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0408, Val Loss: 0.0701\n",
      "Val RMSE: 61002.9114, Val MAE: 28411.6969, Val MSE: 3721355193.7238, Val R2: 0.8109\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 61519.9866, Test MAE: 31178.3699, Test MSE: 3784708754.0725, Test R2: 0.7574\n",
      "Inference Time: 3.1880672161395736e-05 seconds per sample\n",
      "\n",
      "Iteration 63 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3823, Val Loss: 0.2850\n",
      "Val RMSE: 139944.5287, Val MAE: 92740.8327, Val MSE: 19584471117.3863, Val R2: 0.0050\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2840, Val Loss: 0.2828\n",
      "Val RMSE: 144032.3453, Val MAE: 81294.6855, Val MSE: 20745316505.9662, Val R2: -0.0540\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2742, Val Loss: 0.2782\n",
      "Val RMSE: 142796.7373, Val MAE: 82060.5255, Val MSE: 20390908197.2843, Val R2: -0.0360\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2701, Val Loss: 0.2755\n",
      "Val RMSE: 141509.2717, Val MAE: 83629.3123, Val MSE: 20024873981.0360, Val R2: -0.0174\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2769\n",
      "Val RMSE: 142613.6042, Val MAE: 82172.2597, Val MSE: 20338640091.4600, Val R2: -0.0333\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2653, Val Loss: 0.3029\n",
      "Val RMSE: 146929.2265, Val MAE: 81643.0416, Val MSE: 21588197598.6727, Val R2: -0.0968\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2623, Val Loss: 0.2719\n",
      "Val RMSE: 140399.2071, Val MAE: 85270.8084, Val MSE: 19711937355.1773, Val R2: -0.0015\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2615, Val Loss: 0.2724\n",
      "Val RMSE: 141904.0378, Val MAE: 81842.2735, Val MSE: 20136755953.1026, Val R2: -0.0231\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2587, Val Loss: 0.2701\n",
      "Val RMSE: 141206.8559, Val MAE: 81734.5677, Val MSE: 19939376144.4936, Val R2: -0.0130\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2548, Val Loss: 0.2695\n",
      "Val RMSE: 141992.9313, Val MAE: 81194.6415, Val MSE: 20161992546.3336, Val R2: -0.0244\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2724\n",
      "Val RMSE: 141594.9191, Val MAE: 81577.9198, Val MSE: 20049121107.9801, Val R2: -0.0186\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2686\n",
      "Val RMSE: 141999.4990, Val MAE: 79311.9079, Val MSE: 20163857724.8150, Val R2: -0.0245\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2507, Val Loss: 0.2665\n",
      "Val RMSE: 141225.1409, Val MAE: 80370.4159, Val MSE: 19944540428.9455, Val R2: -0.0133\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2490, Val Loss: 0.2663\n",
      "Val RMSE: 140437.4768, Val MAE: 81799.8359, Val MSE: 19722684902.2423, Val R2: -0.0020\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2642\n",
      "Val RMSE: 138602.8140, Val MAE: 78158.0945, Val MSE: 19210740043.5304, Val R2: 0.0240\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2392, Val Loss: 0.2560\n",
      "Val RMSE: 137878.9348, Val MAE: 77385.1734, Val MSE: 19010600670.9382, Val R2: 0.0341\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2393, Val Loss: 0.2554\n",
      "Val RMSE: 137648.7733, Val MAE: 76194.5956, Val MSE: 18947184779.7656, Val R2: 0.0374\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2352, Val Loss: 0.2548\n",
      "Val RMSE: 136409.5145, Val MAE: 75897.2948, Val MSE: 18607555635.5429, Val R2: 0.0546\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2263, Val Loss: 0.2458\n",
      "Val RMSE: 133727.7628, Val MAE: 74547.0227, Val MSE: 17883114536.0809, Val R2: 0.0914\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2209, Val Loss: 0.2375\n",
      "Val RMSE: 132551.7978, Val MAE: 74081.6449, Val MSE: 17569979109.9433, Val R2: 0.1073\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2200, Val Loss: 0.2502\n",
      "Val RMSE: 138913.8285, Val MAE: 75000.5856, Val MSE: 19297051750.8740, Val R2: 0.0196\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2302\n",
      "Val RMSE: 128154.1990, Val MAE: 71981.0866, Val MSE: 16423498724.9302, Val R2: 0.1656\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2008, Val Loss: 0.2315\n",
      "Val RMSE: 127954.6085, Val MAE: 75172.9444, Val MSE: 16372381835.0002, Val R2: 0.1682\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1959, Val Loss: 0.2201\n",
      "Val RMSE: 121510.5893, Val MAE: 67229.8978, Val MSE: 14764823309.9383, Val R2: 0.2499\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1856, Val Loss: 0.2029\n",
      "Val RMSE: 115349.8415, Val MAE: 65283.6072, Val MSE: 13305585934.0269, Val R2: 0.3240\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1753, Val Loss: 0.1897\n",
      "Val RMSE: 106693.5098, Val MAE: 64150.7129, Val MSE: 11383505025.7144, Val R2: 0.4216\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1719, Val Loss: 0.2015\n",
      "Val RMSE: 113176.4026, Val MAE: 64502.5543, Val MSE: 12808898111.0146, Val R2: 0.3492\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1633, Val Loss: 0.1752\n",
      "Val RMSE: 101492.2978, Val MAE: 59551.2197, Val MSE: 10300686522.8710, Val R2: 0.4767\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1559, Val Loss: 0.1834\n",
      "Val RMSE: 105366.1975, Val MAE: 60457.1402, Val MSE: 11102035576.5451, Val R2: 0.4359\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1474, Val Loss: 0.1605\n",
      "Val RMSE: 96870.1426, Val MAE: 57989.4254, Val MSE: 9383824535.4334, Val R2: 0.5232\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1438, Val Loss: 0.1557\n",
      "Val RMSE: 97247.6408, Val MAE: 57280.6881, Val MSE: 9457103642.0326, Val R2: 0.5195\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1378, Val Loss: 0.1510\n",
      "Val RMSE: 93489.6800, Val MAE: 55487.8312, Val MSE: 8740320259.0331, Val R2: 0.5559\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1334, Val Loss: 0.1572\n",
      "Val RMSE: 96597.2989, Val MAE: 55118.4189, Val MSE: 9331038156.7988, Val R2: 0.5259\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1252, Val Loss: 0.1375\n",
      "Val RMSE: 91609.7622, Val MAE: 50931.2972, Val MSE: 8392348528.5091, Val R2: 0.5736\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1192, Val Loss: 0.1484\n",
      "Val RMSE: 94133.6713, Val MAE: 54448.6878, Val MSE: 8861148064.0666, Val R2: 0.5498\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1343\n",
      "Val RMSE: 91843.7758, Val MAE: 49749.2720, Val MSE: 8435279144.5354, Val R2: 0.5714\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1491\n",
      "Val RMSE: 93900.2902, Val MAE: 54695.6698, Val MSE: 8817264502.8345, Val R2: 0.5520\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1031, Val Loss: 0.1440\n",
      "Val RMSE: 93783.6222, Val MAE: 51279.1253, Val MSE: 8795367797.6736, Val R2: 0.5531\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1318\n",
      "Val RMSE: 90846.5793, Val MAE: 49274.9568, Val MSE: 8253100962.5566, Val R2: 0.5807\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0961, Val Loss: 0.1378\n",
      "Val RMSE: 92278.2319, Val MAE: 49731.1151, Val MSE: 8515272085.6469, Val R2: 0.5674\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1360\n",
      "Val RMSE: 92125.2559, Val MAE: 48985.3246, Val MSE: 8487062767.7381, Val R2: 0.5688\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1365\n",
      "Val RMSE: 91907.9078, Val MAE: 47212.0018, Val MSE: 8447063509.6682, Val R2: 0.5708\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1274\n",
      "Val RMSE: 87427.8407, Val MAE: 46281.7310, Val MSE: 7643627322.9588, Val R2: 0.6117\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1332\n",
      "Val RMSE: 85731.8699, Val MAE: 47540.3720, Val MSE: 7349953522.0874, Val R2: 0.6266\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1393\n",
      "Val RMSE: 89954.6387, Val MAE: 49504.0775, Val MSE: 8091837027.3703, Val R2: 0.5889\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1316\n",
      "Val RMSE: 84579.1601, Val MAE: 47917.2285, Val MSE: 7153634320.6227, Val R2: 0.6366\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1395\n",
      "Val RMSE: 87720.8958, Val MAE: 48309.3703, Val MSE: 7694955564.0832, Val R2: 0.6090\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1384\n",
      "Val RMSE: 87198.5329, Val MAE: 47681.9451, Val MSE: 7603584141.7972, Val R2: 0.6137\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0777, Val Loss: 0.1369\n",
      "Val RMSE: 85857.6058, Val MAE: 48000.1393, Val MSE: 7371528474.6722, Val R2: 0.6255\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0785, Val Loss: 0.1226\n",
      "Val RMSE: 78854.5019, Val MAE: 44595.5491, Val MSE: 6218032462.9053, Val R2: 0.6841\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0744, Val Loss: 0.1349\n",
      "Val RMSE: 85199.4907, Val MAE: 47055.9062, Val MSE: 7258953213.8730, Val R2: 0.6312\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1193\n",
      "Val RMSE: 73843.1635, Val MAE: 44632.6723, Val MSE: 5452812795.9586, Val R2: 0.7230\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1186\n",
      "Val RMSE: 73886.1720, Val MAE: 45407.6071, Val MSE: 5459166409.0632, Val R2: 0.7226\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1281\n",
      "Val RMSE: 79320.8193, Val MAE: 46057.4513, Val MSE: 6291792373.2996, Val R2: 0.6803\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1248\n",
      "Val RMSE: 76594.2077, Val MAE: 45577.1879, Val MSE: 5866672659.3467, Val R2: 0.7019\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1270\n",
      "Val RMSE: 79233.3430, Val MAE: 44468.9721, Val MSE: 6277922642.3934, Val R2: 0.6810\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1208\n",
      "Val RMSE: 75773.1908, Val MAE: 44009.6956, Val MSE: 5741576437.7416, Val R2: 0.7083\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1231\n",
      "Val RMSE: 75278.9344, Val MAE: 44445.5819, Val MSE: 5666917970.3933, Val R2: 0.7121\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1213\n",
      "Val RMSE: 77042.5401, Val MAE: 43613.8220, Val MSE: 5935552983.7507, Val R2: 0.6984\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1278\n",
      "Val RMSE: 77974.4451, Val MAE: 46649.4639, Val MSE: 6080014085.1255, Val R2: 0.6911\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1196\n",
      "Val RMSE: 74735.3055, Val MAE: 44257.3304, Val MSE: 5585365888.0712, Val R2: 0.7162\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1265\n",
      "Val RMSE: 78426.6940, Val MAE: 44087.0352, Val MSE: 6150746337.2844, Val R2: 0.6875\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1270\n",
      "Val RMSE: 79349.0297, Val MAE: 45911.1607, Val MSE: 6296268510.3285, Val R2: 0.6801\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1231\n",
      "Val RMSE: 77981.5892, Val MAE: 43384.7376, Val MSE: 6081128247.9860, Val R2: 0.6910\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1207\n",
      "Val RMSE: 77237.8171, Val MAE: 43041.1427, Val MSE: 5965680392.6493, Val R2: 0.6969\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1125\n",
      "Val RMSE: 73776.6227, Val MAE: 42524.4757, Val MSE: 5442990059.7474, Val R2: 0.7235\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1268\n",
      "Val RMSE: 78142.7008, Val MAE: 45102.3188, Val MSE: 6106281682.4972, Val R2: 0.6898\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1219\n",
      "Val RMSE: 75483.2687, Val MAE: 42975.3238, Val MSE: 5697723851.4806, Val R2: 0.7105\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1158\n",
      "Val RMSE: 74545.3353, Val MAE: 43206.9877, Val MSE: 5557007016.7884, Val R2: 0.7177\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1145\n",
      "Val RMSE: 73998.6085, Val MAE: 42455.6361, Val MSE: 5475794053.9635, Val R2: 0.7218\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1293\n",
      "Val RMSE: 77919.7005, Val MAE: 45209.3493, Val MSE: 6071479727.0287, Val R2: 0.6915\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1096\n",
      "Val RMSE: 72017.8014, Val MAE: 41020.3194, Val MSE: 5186563723.9731, Val R2: 0.7365\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1130\n",
      "Val RMSE: 74816.4248, Val MAE: 41950.3331, Val MSE: 5597497426.8665, Val R2: 0.7156\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1216\n",
      "Val RMSE: 76607.3784, Val MAE: 44372.5295, Val MSE: 5868690429.5740, Val R2: 0.7018\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1178\n",
      "Val RMSE: 76525.6707, Val MAE: 43165.8840, Val MSE: 5856178281.3934, Val R2: 0.7025\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1236\n",
      "Val RMSE: 78413.4232, Val MAE: 42926.5379, Val MSE: 6148664939.6839, Val R2: 0.6876\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1157\n",
      "Val RMSE: 77088.9251, Val MAE: 41334.0202, Val MSE: 5942702377.4857, Val R2: 0.6981\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1180\n",
      "Val RMSE: 76760.0710, Val MAE: 43382.7680, Val MSE: 5892108495.4175, Val R2: 0.7006\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1191\n",
      "Val RMSE: 76484.6233, Val MAE: 42924.9583, Val MSE: 5849897597.0498, Val R2: 0.7028\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1197\n",
      "Val RMSE: 77086.7596, Val MAE: 42311.7306, Val MSE: 5942368501.2367, Val R2: 0.6981\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1208\n",
      "Val RMSE: 78396.8084, Val MAE: 43038.8485, Val MSE: 6146059568.5742, Val R2: 0.6877\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1210\n",
      "Val RMSE: 78221.4833, Val MAE: 42946.4804, Val MSE: 6118600452.8949, Val R2: 0.6891\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1229\n",
      "Val RMSE: 79439.6069, Val MAE: 45271.2233, Val MSE: 6310651145.7383, Val R2: 0.6794\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1183\n",
      "Val RMSE: 77427.0006, Val MAE: 43602.4054, Val MSE: 5994940426.0194, Val R2: 0.6954\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1263\n",
      "Val RMSE: 79741.1908, Val MAE: 44802.8920, Val MSE: 6358657516.8963, Val R2: 0.6769\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1207\n",
      "Val RMSE: 75988.4611, Val MAE: 42551.9996, Val MSE: 5774246221.8270, Val R2: 0.7066\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1157\n",
      "Val RMSE: 75409.7430, Val MAE: 42019.0588, Val MSE: 5686629337.2611, Val R2: 0.7111\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1243\n",
      "Val RMSE: 79950.0136, Val MAE: 43985.4785, Val MSE: 6392004667.0559, Val R2: 0.6752\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.1212\n",
      "Val RMSE: 77439.0852, Val MAE: 42413.4373, Val MSE: 5996811914.5488, Val R2: 0.6953\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1270\n",
      "Val RMSE: 81741.4561, Val MAE: 44438.7987, Val MSE: 6681665639.2089, Val R2: 0.6605\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.1135\n",
      "Val RMSE: 78180.6824, Val MAE: 41153.0135, Val MSE: 6112219099.6160, Val R2: 0.6895\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0423, Val Loss: 0.1194\n",
      "Val RMSE: 75798.3840, Val MAE: 43829.0428, Val MSE: 5745395016.2117, Val R2: 0.7081\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0403, Val Loss: 0.1240\n",
      "Val RMSE: 80655.0994, Val MAE: 45016.9959, Val MSE: 6505245059.9668, Val R2: 0.6695\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0416, Val Loss: 0.1168\n",
      "Val RMSE: 76702.2614, Val MAE: 42819.1768, Val MSE: 5883236907.8336, Val R2: 0.7011\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0410, Val Loss: 0.1166\n",
      "Val RMSE: 77614.8271, Val MAE: 42466.5431, Val MSE: 6024061389.8243, Val R2: 0.6939\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0399, Val Loss: 0.1195\n",
      "Val RMSE: 77763.9130, Val MAE: 44603.4433, Val MSE: 6047226161.7626, Val R2: 0.6928\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0401, Val Loss: 0.1226\n",
      "Val RMSE: 81520.3783, Val MAE: 43802.0424, Val MSE: 6645572083.9654, Val R2: 0.6624\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0403, Val Loss: 0.1172\n",
      "Val RMSE: 77884.6109, Val MAE: 43906.0474, Val MSE: 6066012612.1796, Val R2: 0.6918\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0395, Val Loss: 0.1106\n",
      "Val RMSE: 76903.6894, Val MAE: 40822.6829, Val MSE: 5914177445.0735, Val R2: 0.6995\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0381, Val Loss: 0.1129\n",
      "Val RMSE: 76222.7537, Val MAE: 40317.2876, Val MSE: 5809908182.6267, Val R2: 0.7048\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75618.8176, Test MAE: 40802.1203, Test MSE: 5718205576.9268, Test R2: 0.6335\n",
      "Inference Time: 2.5955640352689302e-05 seconds per sample\n",
      "\n",
      "Iteration 64 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3661, Val Loss: 0.3041\n",
      "Val RMSE: 147809.5753, Val MAE: 81847.1541, Val MSE: 21847670555.9995, Val R2: -0.1100\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2826, Val Loss: 0.2779\n",
      "Val RMSE: 141824.9815, Val MAE: 83723.0089, Val MSE: 20114325376.9400, Val R2: -0.0219\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2714, Val Loss: 0.2776\n",
      "Val RMSE: 142427.2294, Val MAE: 82370.1623, Val MSE: 20285515662.5772, Val R2: -0.0306\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2689, Val Loss: 0.2759\n",
      "Val RMSE: 141629.5335, Val MAE: 83230.7831, Val MSE: 20058924751.2385, Val R2: -0.0191\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2642, Val Loss: 0.2790\n",
      "Val RMSE: 142356.9479, Val MAE: 82563.5357, Val MSE: 20265500615.4926, Val R2: -0.0296\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2621, Val Loss: 0.2748\n",
      "Val RMSE: 143028.3986, Val MAE: 80248.5573, Val MSE: 20457122816.0736, Val R2: -0.0394\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2706\n",
      "Val RMSE: 141298.2774, Val MAE: 81569.0119, Val MSE: 19965203207.7539, Val R2: -0.0144\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2817\n",
      "Val RMSE: 142003.7566, Val MAE: 86066.0852, Val MSE: 20165066896.8050, Val R2: -0.0245\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2692\n",
      "Val RMSE: 142535.7713, Val MAE: 79649.4742, Val MSE: 20316446094.0509, Val R2: -0.0322\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2677\n",
      "Val RMSE: 141258.2524, Val MAE: 79850.0927, Val MSE: 19953893871.0431, Val R2: -0.0138\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2673\n",
      "Val RMSE: 141502.9889, Val MAE: 80434.4388, Val MSE: 20023095869.0136, Val R2: -0.0173\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2508, Val Loss: 0.2681\n",
      "Val RMSE: 141617.4763, Val MAE: 80180.8904, Val MSE: 20055509605.0414, Val R2: -0.0189\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2494, Val Loss: 0.2639\n",
      "Val RMSE: 142205.4960, Val MAE: 77727.0641, Val MSE: 20222403101.8957, Val R2: -0.0274\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2481, Val Loss: 0.2649\n",
      "Val RMSE: 141593.2676, Val MAE: 78531.9902, Val MSE: 20048653424.2909, Val R2: -0.0186\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2468, Val Loss: 0.2592\n",
      "Val RMSE: 139648.0643, Val MAE: 77904.1385, Val MSE: 19501581864.5897, Val R2: 0.0092\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2375, Val Loss: 0.2574\n",
      "Val RMSE: 132782.7742, Val MAE: 80545.9505, Val MSE: 17631265125.9233, Val R2: 0.1042\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2392, Val Loss: 0.2508\n",
      "Val RMSE: 134676.9373, Val MAE: 77429.2718, Val MSE: 18137877429.5743, Val R2: 0.0785\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2238, Val Loss: 0.2491\n",
      "Val RMSE: 136969.8386, Val MAE: 71761.2996, Val MSE: 18760736680.9226, Val R2: 0.0468\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2219, Val Loss: 0.2262\n",
      "Val RMSE: 130215.7698, Val MAE: 72133.2987, Val MSE: 16956146696.4283, Val R2: 0.1385\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2166, Val Loss: 0.2294\n",
      "Val RMSE: 130180.5117, Val MAE: 72648.1920, Val MSE: 16946965627.9858, Val R2: 0.1390\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2361\n",
      "Val RMSE: 132198.9191, Val MAE: 71864.7807, Val MSE: 17476554203.0456, Val R2: 0.1121\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2073, Val Loss: 0.2419\n",
      "Val RMSE: 134468.2941, Val MAE: 70170.4676, Val MSE: 18081722119.1578, Val R2: 0.0813\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2017, Val Loss: 0.2310\n",
      "Val RMSE: 128328.1485, Val MAE: 69664.2430, Val MSE: 16468113709.5356, Val R2: 0.1633\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1911, Val Loss: 0.2072\n",
      "Val RMSE: 115934.0612, Val MAE: 70011.8780, Val MSE: 13440706542.6122, Val R2: 0.3171\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1806, Val Loss: 0.2255\n",
      "Val RMSE: 120260.4653, Val MAE: 67729.4165, Val MSE: 14462579522.6496, Val R2: 0.2652\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1760, Val Loss: 0.2042\n",
      "Val RMSE: 113070.2168, Val MAE: 67937.4584, Val MSE: 12784873934.7185, Val R2: 0.3504\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.2024\n",
      "Val RMSE: 109412.0622, Val MAE: 64675.7888, Val MSE: 11970999361.5611, Val R2: 0.3918\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1687, Val Loss: 0.1910\n",
      "Val RMSE: 107079.2777, Val MAE: 63866.0812, Val MSE: 11465971711.2031, Val R2: 0.4175\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1672, Val Loss: 0.1756\n",
      "Val RMSE: 103460.5246, Val MAE: 61404.9868, Val MSE: 10704080140.4540, Val R2: 0.4562\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1622, Val Loss: 0.1784\n",
      "Val RMSE: 104603.7486, Val MAE: 60357.2817, Val MSE: 10941944230.0314, Val R2: 0.4441\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1653\n",
      "Val RMSE: 100743.8641, Val MAE: 57963.1541, Val MSE: 10149326156.7925, Val R2: 0.4844\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1556, Val Loss: 0.1616\n",
      "Val RMSE: 98765.6760, Val MAE: 57289.8212, Val MSE: 9754658765.4897, Val R2: 0.5044\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1537, Val Loss: 0.1677\n",
      "Val RMSE: 99845.4412, Val MAE: 58475.7491, Val MSE: 9969112132.7253, Val R2: 0.4935\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1532\n",
      "Val RMSE: 96959.0376, Val MAE: 54929.4527, Val MSE: 9401054976.1577, Val R2: 0.5224\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1444, Val Loss: 0.1456\n",
      "Val RMSE: 93995.0754, Val MAE: 53732.2292, Val MSE: 8835074196.1771, Val R2: 0.5511\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1403, Val Loss: 0.1509\n",
      "Val RMSE: 96699.6760, Val MAE: 53750.0317, Val MSE: 9350827330.5034, Val R2: 0.5249\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1371, Val Loss: 0.1366\n",
      "Val RMSE: 92419.5476, Val MAE: 50667.6607, Val MSE: 8541372772.7505, Val R2: 0.5660\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1335, Val Loss: 0.1426\n",
      "Val RMSE: 93524.7165, Val MAE: 51477.1036, Val MSE: 8746872599.3243, Val R2: 0.5556\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1443\n",
      "Val RMSE: 94842.7238, Val MAE: 51221.1077, Val MSE: 8995142262.9754, Val R2: 0.5430\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1251, Val Loss: 0.1477\n",
      "Val RMSE: 92557.3437, Val MAE: 56961.6126, Val MSE: 8566861864.0445, Val R2: 0.5647\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1196, Val Loss: 0.1458\n",
      "Val RMSE: 94670.1342, Val MAE: 50874.3684, Val MSE: 8962434304.6055, Val R2: 0.5447\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1431\n",
      "Val RMSE: 92146.8806, Val MAE: 51247.5224, Val MSE: 8491047604.9499, Val R2: 0.5686\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1108, Val Loss: 0.1324\n",
      "Val RMSE: 90049.1107, Val MAE: 49086.9643, Val MSE: 8108842344.7961, Val R2: 0.5880\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1321\n",
      "Val RMSE: 89818.8941, Val MAE: 48981.2946, Val MSE: 8067433742.7882, Val R2: 0.5901\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1329\n",
      "Val RMSE: 89644.0260, Val MAE: 49671.2487, Val MSE: 8036051404.6940, Val R2: 0.5917\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0991, Val Loss: 0.1348\n",
      "Val RMSE: 91320.3030, Val MAE: 48271.2561, Val MSE: 8339397745.2618, Val R2: 0.5763\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1001, Val Loss: 0.1296\n",
      "Val RMSE: 88818.4676, Val MAE: 47415.9611, Val MSE: 7888720185.3323, Val R2: 0.5992\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1396\n",
      "Val RMSE: 91780.1677, Val MAE: 48535.3062, Val MSE: 8423599178.1819, Val R2: 0.5720\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1384\n",
      "Val RMSE: 91473.2320, Val MAE: 47801.4879, Val MSE: 8367352165.1266, Val R2: 0.5749\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0916, Val Loss: 0.1209\n",
      "Val RMSE: 83836.0370, Val MAE: 46642.3586, Val MSE: 7028481093.3217, Val R2: 0.6429\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1282\n",
      "Val RMSE: 85454.8655, Val MAE: 47921.7550, Val MSE: 7302534037.0405, Val R2: 0.6290\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1251\n",
      "Val RMSE: 84306.0742, Val MAE: 47112.5479, Val MSE: 7107514153.0681, Val R2: 0.6389\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1295\n",
      "Val RMSE: 84280.5847, Val MAE: 47290.7202, Val MSE: 7103216949.4350, Val R2: 0.6391\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1190\n",
      "Val RMSE: 78046.0450, Val MAE: 45122.9868, Val MSE: 6091185141.1048, Val R2: 0.6905\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1259\n",
      "Val RMSE: 81008.4204, Val MAE: 45800.5688, Val MSE: 6562364181.3996, Val R2: 0.6666\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1179\n",
      "Val RMSE: 77363.1587, Val MAE: 47368.5053, Val MSE: 5985058327.8487, Val R2: 0.6959\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1115\n",
      "Val RMSE: 75761.6506, Val MAE: 44610.9004, Val MSE: 5739827696.9920, Val R2: 0.7084\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1135\n",
      "Val RMSE: 78139.8116, Val MAE: 43629.9989, Val MSE: 6105830150.2634, Val R2: 0.6898\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1086\n",
      "Val RMSE: 72834.6460, Val MAE: 42760.5812, Val MSE: 5304885653.0876, Val R2: 0.7305\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1141\n",
      "Val RMSE: 74705.2806, Val MAE: 43261.2645, Val MSE: 5580878946.1219, Val R2: 0.7165\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1240\n",
      "Val RMSE: 79536.0851, Val MAE: 48191.4428, Val MSE: 6325988834.0256, Val R2: 0.6786\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1136\n",
      "Val RMSE: 74368.0659, Val MAE: 43415.6787, Val MSE: 5530609222.2179, Val R2: 0.7190\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1179\n",
      "Val RMSE: 78020.3188, Val MAE: 44918.8763, Val MSE: 6087170145.5880, Val R2: 0.6907\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1064\n",
      "Val RMSE: 73968.6426, Val MAE: 44542.6782, Val MSE: 5471360084.9021, Val R2: 0.7220\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0649, Val Loss: 0.1052\n",
      "Val RMSE: 75350.1690, Val MAE: 41467.6117, Val MSE: 5677647967.7818, Val R2: 0.7115\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1136\n",
      "Val RMSE: 74505.4036, Val MAE: 43579.7669, Val MSE: 5551055163.8568, Val R2: 0.7180\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1026\n",
      "Val RMSE: 73707.0605, Val MAE: 41585.7457, Val MSE: 5432730772.2515, Val R2: 0.7240\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1162\n",
      "Val RMSE: 75296.2566, Val MAE: 43012.8706, Val MSE: 5669526261.1473, Val R2: 0.7120\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1107\n",
      "Val RMSE: 76116.1473, Val MAE: 42729.1260, Val MSE: 5793667883.8818, Val R2: 0.7056\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1077\n",
      "Val RMSE: 73992.5438, Val MAE: 42787.8665, Val MSE: 5474896533.4221, Val R2: 0.7218\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1050\n",
      "Val RMSE: 72852.3967, Val MAE: 41123.6693, Val MSE: 5307471706.5621, Val R2: 0.7303\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.1122\n",
      "Val RMSE: 76486.4678, Val MAE: 43714.4787, Val MSE: 5850179749.7842, Val R2: 0.7028\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1001\n",
      "Val RMSE: 69550.4085, Val MAE: 41361.1265, Val MSE: 4837259328.7457, Val R2: 0.7542\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1023\n",
      "Val RMSE: 71392.1464, Val MAE: 42692.0800, Val MSE: 5096838571.8468, Val R2: 0.7410\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1047\n",
      "Val RMSE: 73998.9926, Val MAE: 42514.8502, Val MSE: 5475850912.6730, Val R2: 0.7218\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.0967\n",
      "Val RMSE: 70504.7222, Val MAE: 39594.9373, Val MSE: 4970915858.2615, Val R2: 0.7474\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1057\n",
      "Val RMSE: 72168.6436, Val MAE: 42068.9680, Val MSE: 5208313117.0495, Val R2: 0.7354\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1089\n",
      "Val RMSE: 74762.6657, Val MAE: 41132.0007, Val MSE: 5589456184.1862, Val R2: 0.7160\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1064\n",
      "Val RMSE: 75498.3331, Val MAE: 42020.5221, Val MSE: 5699998297.1481, Val R2: 0.7104\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.0922\n",
      "Val RMSE: 67704.8416, Val MAE: 38837.9205, Val MSE: 4583945577.4550, Val R2: 0.7671\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.0943\n",
      "Val RMSE: 66815.9207, Val MAE: 40719.6368, Val MSE: 4464367262.2691, Val R2: 0.7732\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1127\n",
      "Val RMSE: 73903.1760, Val MAE: 41876.4428, Val MSE: 5461679427.3901, Val R2: 0.7225\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.0973\n",
      "Val RMSE: 67590.9675, Val MAE: 40213.5414, Val MSE: 4568538887.9725, Val R2: 0.7679\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1048\n",
      "Val RMSE: 73071.6257, Val MAE: 41597.1481, Val MSE: 5339462488.1836, Val R2: 0.7287\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1054\n",
      "Val RMSE: 71841.3871, Val MAE: 41904.6586, Val MSE: 5161184904.5012, Val R2: 0.7378\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1066\n",
      "Val RMSE: 75204.4694, Val MAE: 41701.6941, Val MSE: 5655712215.6263, Val R2: 0.7127\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.0984\n",
      "Val RMSE: 69921.2470, Val MAE: 42336.8505, Val MSE: 4888980777.9824, Val R2: 0.7516\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1012\n",
      "Val RMSE: 71400.0603, Val MAE: 42938.2228, Val MSE: 5097968615.5182, Val R2: 0.7410\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.0949\n",
      "Val RMSE: 69271.8741, Val MAE: 40497.2576, Val MSE: 4798592542.6186, Val R2: 0.7562\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.0930\n",
      "Val RMSE: 67300.2591, Val MAE: 38783.1095, Val MSE: 4529324879.1522, Val R2: 0.7699\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.0993\n",
      "Val RMSE: 69517.9401, Val MAE: 41520.3845, Val MSE: 4832743994.7867, Val R2: 0.7545\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.1057\n",
      "Val RMSE: 72224.3562, Val MAE: 41483.6787, Val MSE: 5216357630.5984, Val R2: 0.7350\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1083\n",
      "Val RMSE: 74328.8141, Val MAE: 42398.6222, Val MSE: 5524772608.0504, Val R2: 0.7193\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.0951\n",
      "Val RMSE: 68525.8030, Val MAE: 40079.6252, Val MSE: 4695785670.9521, Val R2: 0.7614\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.0994\n",
      "Val RMSE: 71214.8246, Val MAE: 39274.2361, Val MSE: 5071551246.7467, Val R2: 0.7423\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.1048\n",
      "Val RMSE: 72215.0597, Val MAE: 40477.3248, Val MSE: 5215014853.5727, Val R2: 0.7350\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1048\n",
      "Val RMSE: 71210.6883, Val MAE: 43822.6581, Val MSE: 5070962128.9064, Val R2: 0.7424\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.1133\n",
      "Val RMSE: 75730.4395, Val MAE: 43320.2656, Val MSE: 5735099463.2085, Val R2: 0.7086\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.1249\n",
      "Val RMSE: 77915.7089, Val MAE: 43434.7782, Val MSE: 6070857699.1476, Val R2: 0.6916\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.1036\n",
      "Val RMSE: 71005.2025, Val MAE: 40583.0418, Val MSE: 5041738777.8826, Val R2: 0.7438\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76063.2857, Test MAE: 41095.0914, Test MSE: 5785623423.9972, Test R2: 0.6291\n",
      "Inference Time: 2.8793518359844503e-05 seconds per sample\n",
      "\n",
      "Iteration 65 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3539, Val Loss: 0.2841\n",
      "Val RMSE: 141658.1697, Val MAE: 86650.3373, Val MSE: 20067037033.0788, Val R2: -0.0195\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2810, Val Loss: 0.2855\n",
      "Val RMSE: 142687.1367, Val MAE: 84612.7524, Val MSE: 20359618972.5751, Val R2: -0.0344\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2738, Val Loss: 0.2801\n",
      "Val RMSE: 142107.6062, Val MAE: 83991.1475, Val MSE: 20194571734.6156, Val R2: -0.0260\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2703, Val Loss: 0.2754\n",
      "Val RMSE: 141088.1744, Val MAE: 84562.1408, Val MSE: 19905872968.4636, Val R2: -0.0113\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2645, Val Loss: 0.2780\n",
      "Val RMSE: 142662.4471, Val MAE: 82381.9107, Val MSE: 20352573809.2637, Val R2: -0.0340\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2625, Val Loss: 0.2749\n",
      "Val RMSE: 141846.1314, Val MAE: 83347.7368, Val MSE: 20120324982.6282, Val R2: -0.0222\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2796\n",
      "Val RMSE: 143256.3644, Val MAE: 81463.4424, Val MSE: 20522385939.0827, Val R2: -0.0427\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2731\n",
      "Val RMSE: 141917.4012, Val MAE: 82837.4094, Val MSE: 20140548751.3387, Val R2: -0.0233\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2568, Val Loss: 0.2791\n",
      "Val RMSE: 140990.1067, Val MAE: 87497.4181, Val MSE: 19878210184.0018, Val R2: -0.0099\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2728\n",
      "Val RMSE: 142546.5646, Val MAE: 79809.8928, Val MSE: 20319523084.8691, Val R2: -0.0324\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2778\n",
      "Val RMSE: 141218.8082, Val MAE: 85931.9064, Val MSE: 19942751799.4079, Val R2: -0.0132\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2699\n",
      "Val RMSE: 140735.4770, Val MAE: 82348.3926, Val MSE: 19806474485.8198, Val R2: -0.0063\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2730\n",
      "Val RMSE: 141688.3602, Val MAE: 81547.5077, Val MSE: 20075591418.8122, Val R2: -0.0200\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2489, Val Loss: 0.2670\n",
      "Val RMSE: 141355.0639, Val MAE: 79393.3595, Val MSE: 19981254086.6555, Val R2: -0.0152\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2468, Val Loss: 0.2584\n",
      "Val RMSE: 138268.9660, Val MAE: 76954.7317, Val MSE: 19118306950.7496, Val R2: 0.0287\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2368, Val Loss: 0.2476\n",
      "Val RMSE: 133202.9721, Val MAE: 77382.4055, Val MSE: 17743031763.5743, Val R2: 0.0985\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2302, Val Loss: 0.2387\n",
      "Val RMSE: 131493.3741, Val MAE: 76805.0363, Val MSE: 17290507442.7212, Val R2: 0.1215\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2238, Val Loss: 0.2347\n",
      "Val RMSE: 133731.8093, Val MAE: 72733.3592, Val MSE: 17884196825.1737, Val R2: 0.0914\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2167, Val Loss: 0.2528\n",
      "Val RMSE: 135740.2810, Val MAE: 72965.7336, Val MSE: 18425423888.4865, Val R2: 0.0639\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2373\n",
      "Val RMSE: 130337.0288, Val MAE: 74783.2749, Val MSE: 16987741088.9802, Val R2: 0.1369\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2104, Val Loss: 0.2489\n",
      "Val RMSE: 135202.2610, Val MAE: 71782.4111, Val MSE: 18279651368.6707, Val R2: 0.0713\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2084, Val Loss: 0.2424\n",
      "Val RMSE: 133100.6487, Val MAE: 70555.7894, Val MSE: 17715782690.5610, Val R2: 0.0999\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2029, Val Loss: 0.2300\n",
      "Val RMSE: 130031.3998, Val MAE: 71606.0834, Val MSE: 16908164924.1017, Val R2: 0.1410\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2000, Val Loss: 0.2266\n",
      "Val RMSE: 129519.5956, Val MAE: 69506.2385, Val MSE: 16775325650.6118, Val R2: 0.1477\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1980, Val Loss: 0.2244\n",
      "Val RMSE: 127162.6976, Val MAE: 73050.9325, Val MSE: 16170351652.9218, Val R2: 0.1784\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1933, Val Loss: 0.2218\n",
      "Val RMSE: 127550.8843, Val MAE: 69068.7486, Val MSE: 16269228084.6959, Val R2: 0.1734\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1835, Val Loss: 0.2055\n",
      "Val RMSE: 112773.9175, Val MAE: 65317.1381, Val MSE: 12717956457.5466, Val R2: 0.3538\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1847, Val Loss: 0.1897\n",
      "Val RMSE: 108099.0518, Val MAE: 62178.1447, Val MSE: 11685404995.1872, Val R2: 0.4063\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1730, Val Loss: 0.1928\n",
      "Val RMSE: 108176.4380, Val MAE: 63031.7894, Val MSE: 11702141733.4935, Val R2: 0.4055\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1688, Val Loss: 0.1779\n",
      "Val RMSE: 102442.0967, Val MAE: 61074.9561, Val MSE: 10494383183.2105, Val R2: 0.4668\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1668, Val Loss: 0.1751\n",
      "Val RMSE: 101897.1521, Val MAE: 60061.9234, Val MSE: 10383029597.8959, Val R2: 0.4725\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1621, Val Loss: 0.1719\n",
      "Val RMSE: 100781.1100, Val MAE: 59026.0917, Val MSE: 10156832141.6815, Val R2: 0.4840\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1621, Val Loss: 0.1612\n",
      "Val RMSE: 98202.4926, Val MAE: 58259.2493, Val MSE: 9643729547.6058, Val R2: 0.5100\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1619, Val Loss: 0.1600\n",
      "Val RMSE: 98249.3153, Val MAE: 58552.9680, Val MSE: 9652927961.5354, Val R2: 0.5096\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1586, Val Loss: 0.1591\n",
      "Val RMSE: 97746.5539, Val MAE: 58861.5287, Val MSE: 9554388804.3120, Val R2: 0.5146\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1537, Val Loss: 0.1624\n",
      "Val RMSE: 98264.0374, Val MAE: 57769.2902, Val MSE: 9655821050.5152, Val R2: 0.5094\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1520, Val Loss: 0.1564\n",
      "Val RMSE: 96670.9292, Val MAE: 57333.1376, Val MSE: 9345268560.1139, Val R2: 0.5252\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1514, Val Loss: 0.1758\n",
      "Val RMSE: 100703.7740, Val MAE: 59392.0131, Val MSE: 10141250096.4213, Val R2: 0.4848\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1599\n",
      "Val RMSE: 97261.5510, Val MAE: 54408.4473, Val MSE: 9459809311.8623, Val R2: 0.5194\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1446, Val Loss: 0.1517\n",
      "Val RMSE: 95063.5933, Val MAE: 54808.9709, Val MSE: 9037086778.8467, Val R2: 0.5409\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1509\n",
      "Val RMSE: 96513.1630, Val MAE: 53589.7241, Val MSE: 9314790626.3807, Val R2: 0.5267\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1376, Val Loss: 0.1375\n",
      "Val RMSE: 90976.1712, Val MAE: 51439.2801, Val MSE: 8276663719.0432, Val R2: 0.5795\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1313, Val Loss: 0.1421\n",
      "Val RMSE: 92885.8105, Val MAE: 50904.3838, Val MSE: 8627773800.4352, Val R2: 0.5617\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1282, Val Loss: 0.1467\n",
      "Val RMSE: 95212.6519, Val MAE: 50685.3749, Val MSE: 9065449087.9233, Val R2: 0.5394\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1250, Val Loss: 0.1470\n",
      "Val RMSE: 92906.0823, Val MAE: 53146.9621, Val MSE: 8631540135.3810, Val R2: 0.5615\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1205, Val Loss: 0.1343\n",
      "Val RMSE: 90688.6114, Val MAE: 48275.5090, Val MSE: 8224424233.8178, Val R2: 0.5821\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1183, Val Loss: 0.1364\n",
      "Val RMSE: 92053.1529, Val MAE: 48950.8657, Val MSE: 8473782960.5674, Val R2: 0.5695\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1146, Val Loss: 0.1413\n",
      "Val RMSE: 93890.6917, Val MAE: 49558.2659, Val MSE: 8815461980.0241, Val R2: 0.5521\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1131, Val Loss: 0.1355\n",
      "Val RMSE: 91172.0504, Val MAE: 49320.1449, Val MSE: 8312342765.8129, Val R2: 0.5777\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1314\n",
      "Val RMSE: 89542.0164, Val MAE: 47291.4677, Val MSE: 8017772708.2765, Val R2: 0.5926\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1084, Val Loss: 0.1391\n",
      "Val RMSE: 91810.4961, Val MAE: 49124.8629, Val MSE: 8429167196.1306, Val R2: 0.5717\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1039, Val Loss: 0.1634\n",
      "Val RMSE: 97902.6516, Val MAE: 53063.0393, Val MSE: 9584929191.9438, Val R2: 0.5130\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1052, Val Loss: 0.1305\n",
      "Val RMSE: 89527.0771, Val MAE: 44919.0639, Val MSE: 8015097538.3203, Val R2: 0.5928\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1414\n",
      "Val RMSE: 92847.5331, Val MAE: 50280.3054, Val MSE: 8620664395.5334, Val R2: 0.5620\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1340\n",
      "Val RMSE: 91191.0171, Val MAE: 48732.3803, Val MSE: 8315801599.7072, Val R2: 0.5775\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1317\n",
      "Val RMSE: 89534.4189, Val MAE: 47182.5830, Val MSE: 8016412160.0821, Val R2: 0.5927\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1361\n",
      "Val RMSE: 90402.6158, Val MAE: 47621.9858, Val MSE: 8172632948.3839, Val R2: 0.5848\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1356\n",
      "Val RMSE: 90372.4792, Val MAE: 48409.1380, Val MSE: 8167184995.0708, Val R2: 0.5851\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1314\n",
      "Val RMSE: 88420.3826, Val MAE: 47421.8947, Val MSE: 7818164061.1722, Val R2: 0.6028\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1264\n",
      "Val RMSE: 88254.1462, Val MAE: 45686.8102, Val MSE: 7788794319.2129, Val R2: 0.6043\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1248\n",
      "Val RMSE: 85574.1839, Val MAE: 43904.1276, Val MSE: 7322940949.1318, Val R2: 0.6279\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0816, Val Loss: 0.1388\n",
      "Val RMSE: 91096.2333, Val MAE: 47692.8143, Val MSE: 8298523719.7611, Val R2: 0.5784\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1289\n",
      "Val RMSE: 85294.3577, Val MAE: 46108.7266, Val MSE: 7275127463.5011, Val R2: 0.6304\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0786, Val Loss: 0.1332\n",
      "Val RMSE: 86388.5049, Val MAE: 45302.3070, Val MSE: 7462973778.4897, Val R2: 0.6208\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0777, Val Loss: 0.1311\n",
      "Val RMSE: 77561.2313, Val MAE: 48583.0135, Val MSE: 6015744605.2024, Val R2: 0.6944\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1413\n",
      "Val RMSE: 87643.9367, Val MAE: 51445.6183, Val MSE: 7681459644.4543, Val R2: 0.6097\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1155\n",
      "Val RMSE: 75672.0248, Val MAE: 43323.0355, Val MSE: 5726255343.6610, Val R2: 0.7091\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1197\n",
      "Val RMSE: 81276.8633, Val MAE: 45120.4592, Val MSE: 6605928508.5148, Val R2: 0.6644\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1278\n",
      "Val RMSE: 84284.9770, Val MAE: 43439.7425, Val MSE: 7103957355.2655, Val R2: 0.6391\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1178\n",
      "Val RMSE: 80542.9451, Val MAE: 43638.1940, Val MSE: 6487166007.1835, Val R2: 0.6704\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1084\n",
      "Val RMSE: 73931.3968, Val MAE: 41906.9215, Val MSE: 5465851428.2330, Val R2: 0.7223\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0664, Val Loss: 0.1182\n",
      "Val RMSE: 77225.4758, Val MAE: 45258.2950, Val MSE: 5963774114.5147, Val R2: 0.6970\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1209\n",
      "Val RMSE: 83857.0067, Val MAE: 45004.5918, Val MSE: 7031997571.1660, Val R2: 0.6427\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1112\n",
      "Val RMSE: 78354.2457, Val MAE: 43323.1068, Val MSE: 6139387813.2286, Val R2: 0.6881\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1062\n",
      "Val RMSE: 72694.4163, Val MAE: 44104.4160, Val MSE: 5284478155.6709, Val R2: 0.7315\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1076\n",
      "Val RMSE: 75224.5352, Val MAE: 40294.1329, Val MSE: 5658730690.8566, Val R2: 0.7125\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1171\n",
      "Val RMSE: 76772.2951, Val MAE: 43031.7929, Val MSE: 5893985294.7886, Val R2: 0.7005\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1118\n",
      "Val RMSE: 75504.2460, Val MAE: 39503.9174, Val MSE: 5700891167.0264, Val R2: 0.7104\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1146\n",
      "Val RMSE: 77841.3898, Val MAE: 43261.5937, Val MSE: 6059281971.7552, Val R2: 0.6922\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1093\n",
      "Val RMSE: 74548.6979, Val MAE: 39588.7845, Val MSE: 5557508359.7803, Val R2: 0.7176\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0571, Val Loss: 0.1261\n",
      "Val RMSE: 83853.9860, Val MAE: 45371.6363, Val MSE: 7031490959.9666, Val R2: 0.6428\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1147\n",
      "Val RMSE: 77441.8610, Val MAE: 43236.2334, Val MSE: 5997241827.4276, Val R2: 0.6953\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1093\n",
      "Val RMSE: 75648.6763, Val MAE: 41364.7511, Val MSE: 5722722233.0921, Val R2: 0.7092\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1152\n",
      "Val RMSE: 79330.8849, Val MAE: 42075.0398, Val MSE: 6293389294.9518, Val R2: 0.6803\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1168\n",
      "Val RMSE: 75859.5633, Val MAE: 44430.9617, Val MSE: 5754673340.0323, Val R2: 0.7076\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1099\n",
      "Val RMSE: 75909.7984, Val MAE: 43960.7192, Val MSE: 5762297500.0348, Val R2: 0.7072\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1109\n",
      "Val RMSE: 77335.1161, Val MAE: 38798.7567, Val MSE: 5980720179.5365, Val R2: 0.6961\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1079\n",
      "Val RMSE: 73196.0908, Val MAE: 43094.1886, Val MSE: 5357667704.1630, Val R2: 0.7278\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1097\n",
      "Val RMSE: 75294.9874, Val MAE: 40985.9873, Val MSE: 5669335126.0015, Val R2: 0.7120\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1094\n",
      "Val RMSE: 75846.9237, Val MAE: 40262.0497, Val MSE: 5752755834.3432, Val R2: 0.7077\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1178\n",
      "Val RMSE: 77952.4914, Val MAE: 45334.3265, Val MSE: 6076590909.1200, Val R2: 0.6913\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1115\n",
      "Val RMSE: 74677.5138, Val MAE: 42346.7663, Val MSE: 5576731061.6234, Val R2: 0.7167\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1171\n",
      "Val RMSE: 76891.6636, Val MAE: 44682.3019, Val MSE: 5912327925.3688, Val R2: 0.6996\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1142\n",
      "Val RMSE: 80478.3506, Val MAE: 42034.3021, Val MSE: 6476764911.9011, Val R2: 0.6709\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1213\n",
      "Val RMSE: 81958.2011, Val MAE: 42951.3666, Val MSE: 6717146719.6776, Val R2: 0.6587\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1053\n",
      "Val RMSE: 75269.4163, Val MAE: 38487.1418, Val MSE: 5665485037.1993, Val R2: 0.7122\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1055\n",
      "Val RMSE: 73319.5296, Val MAE: 41061.0852, Val MSE: 5375753423.5367, Val R2: 0.7269\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1036\n",
      "Val RMSE: 72784.6917, Val MAE: 40929.1658, Val MSE: 5297611347.5220, Val R2: 0.7308\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1113\n",
      "Val RMSE: 77629.5571, Val MAE: 40802.4445, Val MSE: 6026348127.8895, Val R2: 0.6938\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1064\n",
      "Val RMSE: 76255.5743, Val MAE: 39826.4757, Val MSE: 5814912611.2862, Val R2: 0.7046\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75675.3339, Test MAE: 43748.9976, Test MSE: 5726756164.4857, Test R2: 0.6329\n",
      "Inference Time: 3.535145979661208e-05 seconds per sample\n",
      "\n",
      "Iteration 66 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3326, Val Loss: 0.2907\n",
      "Val RMSE: 144784.4305, Val MAE: 82278.8426, Val MSE: 20962531318.2805, Val R2: -0.0650\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2758, Val Loss: 0.2747\n",
      "Val RMSE: 140642.1667, Val MAE: 86009.1885, Val MSE: 19780219052.5074, Val R2: -0.0050\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2684, Val Loss: 0.2733\n",
      "Val RMSE: 141797.9614, Val MAE: 82904.2336, Val MSE: 20106661849.3815, Val R2: -0.0215\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2639, Val Loss: 0.2784\n",
      "Val RMSE: 141768.9962, Val MAE: 87083.9018, Val MSE: 20098448289.4094, Val R2: -0.0211\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2611, Val Loss: 0.2725\n",
      "Val RMSE: 142740.7465, Val MAE: 81059.1897, Val MSE: 20374920705.6078, Val R2: -0.0352\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2588, Val Loss: 0.2771\n",
      "Val RMSE: 143103.7405, Val MAE: 81367.4824, Val MSE: 20478680538.1690, Val R2: -0.0404\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2737\n",
      "Val RMSE: 142778.2212, Val MAE: 81054.3609, Val MSE: 20385620434.8336, Val R2: -0.0357\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2625, Val Loss: 0.2721\n",
      "Val RMSE: 140928.2054, Val MAE: 83747.0252, Val MSE: 19860759088.8938, Val R2: -0.0091\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2585, Val Loss: 0.2710\n",
      "Val RMSE: 141461.0506, Val MAE: 82120.1467, Val MSE: 20011228844.3196, Val R2: -0.0167\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2723\n",
      "Val RMSE: 140499.6173, Val MAE: 84670.9092, Val MSE: 19740142457.0165, Val R2: -0.0029\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2727\n",
      "Val RMSE: 141562.5157, Val MAE: 83136.7550, Val MSE: 20039945846.1917, Val R2: -0.0182\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2758\n",
      "Val RMSE: 141375.1027, Val MAE: 84399.4477, Val MSE: 19986919670.2040, Val R2: -0.0155\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2729\n",
      "Val RMSE: 142477.7056, Val MAE: 79678.5966, Val MSE: 20299896604.6486, Val R2: -0.0314\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2739\n",
      "Val RMSE: 140691.2707, Val MAE: 84322.3870, Val MSE: 19794033649.9111, Val R2: -0.0057\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2663\n",
      "Val RMSE: 141514.5534, Val MAE: 79287.3228, Val MSE: 20026368814.5776, Val R2: -0.0175\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2664\n",
      "Val RMSE: 139825.5314, Val MAE: 82290.0466, Val MSE: 19551179243.3207, Val R2: 0.0067\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2499, Val Loss: 0.2702\n",
      "Val RMSE: 142558.8043, Val MAE: 77757.3488, Val MSE: 20323012679.9791, Val R2: -0.0325\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2450, Val Loss: 0.2630\n",
      "Val RMSE: 138964.4125, Val MAE: 76690.4983, Val MSE: 19311107927.8460, Val R2: 0.0189\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2532\n",
      "Val RMSE: 134549.3082, Val MAE: 78225.4681, Val MSE: 18103516326.4483, Val R2: 0.0802\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2372, Val Loss: 0.2571\n",
      "Val RMSE: 135730.1396, Val MAE: 78715.1992, Val MSE: 18422670792.9937, Val R2: 0.0640\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2407, Val Loss: 0.2606\n",
      "Val RMSE: 138374.6901, Val MAE: 76201.8273, Val MSE: 19147554855.7893, Val R2: 0.0272\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2335, Val Loss: 0.2450\n",
      "Val RMSE: 134269.1758, Val MAE: 74889.2325, Val MSE: 18028211576.3588, Val R2: 0.0841\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2276, Val Loss: 0.2392\n",
      "Val RMSE: 131803.7591, Val MAE: 73861.7622, Val MSE: 17372230923.5490, Val R2: 0.1174\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2238, Val Loss: 0.2314\n",
      "Val RMSE: 131435.9692, Val MAE: 73333.6961, Val MSE: 17275414003.9274, Val R2: 0.1223\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2264, Val Loss: 0.2449\n",
      "Val RMSE: 134658.2324, Val MAE: 74473.4446, Val MSE: 18132839554.1305, Val R2: 0.0787\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2341\n",
      "Val RMSE: 131213.4960, Val MAE: 75588.7634, Val MSE: 17216981521.1667, Val R2: 0.1253\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2074, Val Loss: 0.2274\n",
      "Val RMSE: 125667.3753, Val MAE: 73588.7623, Val MSE: 15792289208.4115, Val R2: 0.1977\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1972, Val Loss: 0.2266\n",
      "Val RMSE: 127922.2334, Val MAE: 73022.8914, Val MSE: 16364097802.5422, Val R2: 0.1686\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1958, Val Loss: 0.2267\n",
      "Val RMSE: 123599.9292, Val MAE: 68794.7478, Val MSE: 15276942504.2375, Val R2: 0.2238\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1976, Val Loss: 0.2523\n",
      "Val RMSE: 132502.5712, Val MAE: 71992.8642, Val MSE: 17556931370.4296, Val R2: 0.1080\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2001, Val Loss: 0.2295\n",
      "Val RMSE: 126592.6674, Val MAE: 70663.3640, Val MSE: 16025703436.5672, Val R2: 0.1858\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1876, Val Loss: 0.2223\n",
      "Val RMSE: 121184.1147, Val MAE: 67987.9673, Val MSE: 14685589648.6935, Val R2: 0.2539\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1870, Val Loss: 0.1916\n",
      "Val RMSE: 108929.0458, Val MAE: 63210.3802, Val MSE: 11865537027.4435, Val R2: 0.3972\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1857, Val Loss: 0.1918\n",
      "Val RMSE: 106952.6084, Val MAE: 66988.3458, Val MSE: 11438860443.1563, Val R2: 0.4188\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1775, Val Loss: 0.1944\n",
      "Val RMSE: 106680.1909, Val MAE: 64293.1227, Val MSE: 11380663123.4261, Val R2: 0.4218\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1743, Val Loss: 0.1922\n",
      "Val RMSE: 105422.2987, Val MAE: 63861.7086, Val MSE: 11113861063.6826, Val R2: 0.4353\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1695, Val Loss: 0.1875\n",
      "Val RMSE: 104553.2075, Val MAE: 63679.0534, Val MSE: 10931373200.9614, Val R2: 0.4446\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1657, Val Loss: 0.1768\n",
      "Val RMSE: 100100.0694, Val MAE: 61300.4519, Val MSE: 10020023888.4468, Val R2: 0.4909\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1614, Val Loss: 0.1804\n",
      "Val RMSE: 101489.1497, Val MAE: 60351.2993, Val MSE: 10300047505.4086, Val R2: 0.4767\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1627, Val Loss: 0.1833\n",
      "Val RMSE: 102274.3591, Val MAE: 63644.5737, Val MSE: 10460044530.4968, Val R2: 0.4686\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1601, Val Loss: 0.1848\n",
      "Val RMSE: 102466.4553, Val MAE: 61868.1692, Val MSE: 10499374463.2992, Val R2: 0.4666\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1537, Val Loss: 0.1907\n",
      "Val RMSE: 98914.6745, Val MAE: 61802.6182, Val MSE: 9784112835.5915, Val R2: 0.5029\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1499, Val Loss: 0.1743\n",
      "Val RMSE: 99298.9206, Val MAE: 60388.6629, Val MSE: 9860275624.8803, Val R2: 0.4990\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1398, Val Loss: 0.1814\n",
      "Val RMSE: 100350.3802, Val MAE: 60839.9584, Val MSE: 10070198811.9877, Val R2: 0.4884\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1337, Val Loss: 0.1616\n",
      "Val RMSE: 97760.9066, Val MAE: 56611.9859, Val MSE: 9557194849.8460, Val R2: 0.5144\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1267, Val Loss: 0.1722\n",
      "Val RMSE: 98382.0995, Val MAE: 56255.5301, Val MSE: 9679037499.8522, Val R2: 0.5082\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1250, Val Loss: 0.1600\n",
      "Val RMSE: 95705.5520, Val MAE: 55048.8612, Val MSE: 9159552677.5169, Val R2: 0.5346\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1209, Val Loss: 0.1552\n",
      "Val RMSE: 94267.6423, Val MAE: 55157.5444, Val MSE: 8886388381.2072, Val R2: 0.5485\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1160, Val Loss: 0.1645\n",
      "Val RMSE: 96418.2728, Val MAE: 58224.1462, Val MSE: 9296483331.0555, Val R2: 0.5277\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1140, Val Loss: 0.1809\n",
      "Val RMSE: 99428.1422, Val MAE: 63730.6012, Val MSE: 9885955455.4888, Val R2: 0.4977\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1114, Val Loss: 0.1662\n",
      "Val RMSE: 96433.0625, Val MAE: 59673.3568, Val MSE: 9299335550.4827, Val R2: 0.5275\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1077, Val Loss: 0.1725\n",
      "Val RMSE: 96638.2209, Val MAE: 62308.0286, Val MSE: 9338945742.9607, Val R2: 0.5255\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1257, Val Loss: 0.1794\n",
      "Val RMSE: 102464.4745, Val MAE: 61290.1346, Val MSE: 10498968538.8344, Val R2: 0.4666\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1224, Val Loss: 0.1740\n",
      "Val RMSE: 99233.7396, Val MAE: 62574.9110, Val MSE: 9847335065.1211, Val R2: 0.4997\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1175, Val Loss: 0.1637\n",
      "Val RMSE: 96149.6301, Val MAE: 58812.6223, Val MSE: 9244751364.3943, Val R2: 0.5303\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1088, Val Loss: 0.1628\n",
      "Val RMSE: 95917.1438, Val MAE: 59461.3824, Val MSE: 9200098480.8797, Val R2: 0.5326\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1047, Val Loss: 0.1903\n",
      "Val RMSE: 101401.2896, Val MAE: 64525.4397, Val MSE: 10282221542.3586, Val R2: 0.4776\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1025, Val Loss: 0.1609\n",
      "Val RMSE: 95715.8639, Val MAE: 57158.7726, Val MSE: 9161526593.4950, Val R2: 0.5345\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1771\n",
      "Val RMSE: 100385.4795, Val MAE: 57955.5217, Val MSE: 10077244491.6431, Val R2: 0.4880\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1784\n",
      "Val RMSE: 101154.9224, Val MAE: 63230.7259, Val MSE: 10232318330.9684, Val R2: 0.4801\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0939, Val Loss: 0.1577\n",
      "Val RMSE: 95678.5436, Val MAE: 56292.7620, Val MSE: 9154383697.9037, Val R2: 0.5349\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.2145\n",
      "Val RMSE: 106655.4692, Val MAE: 68574.3640, Val MSE: 11375389112.4023, Val R2: 0.4221\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1704\n",
      "Val RMSE: 99326.5111, Val MAE: 58546.4440, Val MSE: 9865755799.1822, Val R2: 0.4988\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1721\n",
      "Val RMSE: 99825.3672, Val MAE: 59258.9262, Val MSE: 9965103932.3018, Val R2: 0.4937\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0849, Val Loss: 0.1786\n",
      "Val RMSE: 98706.8862, Val MAE: 63547.6528, Val MSE: 9743049381.9428, Val R2: 0.5050\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1687\n",
      "Val RMSE: 99660.2871, Val MAE: 59325.3318, Val MSE: 9932172834.3753, Val R2: 0.4954\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0847, Val Loss: 0.1716\n",
      "Val RMSE: 98597.2141, Val MAE: 59258.5015, Val MSE: 9721410621.5650, Val R2: 0.5061\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1711\n",
      "Val RMSE: 99766.0091, Val MAE: 60067.2684, Val MSE: 9953256563.2639, Val R2: 0.4943\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1714\n",
      "Val RMSE: 98335.2511, Val MAE: 60444.0038, Val MSE: 9669821603.0350, Val R2: 0.5087\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1726\n",
      "Val RMSE: 99966.0439, Val MAE: 61671.9012, Val MSE: 9993209926.1941, Val R2: 0.4923\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1724\n",
      "Val RMSE: 99218.3853, Val MAE: 61022.8955, Val MSE: 9844287989.8728, Val R2: 0.4998\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0735, Val Loss: 0.1592\n",
      "Val RMSE: 96632.3904, Val MAE: 55605.6506, Val MSE: 9337818879.8361, Val R2: 0.5256\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1618\n",
      "Val RMSE: 95477.6153, Val MAE: 57901.2408, Val MSE: 9115975023.0278, Val R2: 0.5369\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1899\n",
      "Val RMSE: 101890.3365, Val MAE: 64753.9952, Val MSE: 10381640676.9599, Val R2: 0.4725\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1675\n",
      "Val RMSE: 98103.0375, Val MAE: 58590.6182, Val MSE: 9624205958.5849, Val R2: 0.5110\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1775\n",
      "Val RMSE: 100143.3156, Val MAE: 58513.1192, Val MSE: 10028683657.2426, Val R2: 0.4905\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1897\n",
      "Val RMSE: 98997.9932, Val MAE: 63979.5592, Val MSE: 9800602659.0502, Val R2: 0.5021\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1615\n",
      "Val RMSE: 94589.1788, Val MAE: 57531.9768, Val MSE: 8947112749.3468, Val R2: 0.5454\n",
      "Early stopping triggered after epoch 78\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 106162.1153, Test MAE: 62998.3872, Test MSE: 11270394719.5420, Test R2: 0.2776\n",
      "Inference Time: 2.8751850128173827e-05 seconds per sample\n",
      "\n",
      "Iteration 67 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3419, Val Loss: 0.2824\n",
      "Val RMSE: 140330.6791, Val MAE: 89691.9587, Val MSE: 19692699492.6138, Val R2: -0.0005\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2766, Val Loss: 0.2844\n",
      "Val RMSE: 143571.2649, Val MAE: 82114.6982, Val MSE: 20612708104.1846, Val R2: -0.0473\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2710, Val Loss: 0.2753\n",
      "Val RMSE: 141453.1534, Val MAE: 83665.3708, Val MSE: 20008994615.6286, Val R2: -0.0166\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2657, Val Loss: 0.2759\n",
      "Val RMSE: 141682.2621, Val MAE: 84111.1954, Val MSE: 20073863405.7182, Val R2: -0.0199\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2709\n",
      "Val RMSE: 142206.7874, Val MAE: 80672.4673, Val MSE: 20222770389.1715, Val R2: -0.0274\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2602, Val Loss: 0.2725\n",
      "Val RMSE: 141480.9028, Val MAE: 80467.9166, Val MSE: 20016845853.7347, Val R2: -0.0170\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2587, Val Loss: 0.2742\n",
      "Val RMSE: 140591.4884, Val MAE: 84479.0809, Val MSE: 19765966607.1346, Val R2: -0.0042\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2569, Val Loss: 0.2742\n",
      "Val RMSE: 143673.0993, Val MAE: 78157.2480, Val MSE: 20641959454.5593, Val R2: -0.0487\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2712\n",
      "Val RMSE: 140663.3084, Val MAE: 83112.6667, Val MSE: 19786166339.7524, Val R2: -0.0053\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2810\n",
      "Val RMSE: 141555.9480, Val MAE: 86283.8152, Val MSE: 20038086406.8985, Val R2: -0.0181\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2784\n",
      "Val RMSE: 143895.0445, Val MAE: 78805.9547, Val MSE: 20705783838.3893, Val R2: -0.0520\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2498, Val Loss: 0.2608\n",
      "Val RMSE: 139422.8535, Val MAE: 77441.8966, Val MSE: 19438732087.8982, Val R2: 0.0124\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2457, Val Loss: 0.2575\n",
      "Val RMSE: 136324.5761, Val MAE: 77116.1045, Val MSE: 18584390038.7188, Val R2: 0.0558\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2611\n",
      "Val RMSE: 137175.1834, Val MAE: 77889.8667, Val MSE: 18817030953.7744, Val R2: 0.0440\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2360, Val Loss: 0.2593\n",
      "Val RMSE: 136704.2219, Val MAE: 75590.8427, Val MSE: 18688044271.8091, Val R2: 0.0505\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2275, Val Loss: 0.2325\n",
      "Val RMSE: 129954.5535, Val MAE: 75594.5196, Val MSE: 16888185971.6743, Val R2: 0.1420\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2171, Val Loss: 0.2412\n",
      "Val RMSE: 131303.2479, Val MAE: 75069.3551, Val MSE: 17240542908.6343, Val R2: 0.1241\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2112, Val Loss: 0.2453\n",
      "Val RMSE: 134969.1244, Val MAE: 77609.3133, Val MSE: 18216664545.6468, Val R2: 0.0745\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2126, Val Loss: 0.2386\n",
      "Val RMSE: 132661.2330, Val MAE: 74140.1263, Val MSE: 17599002747.1568, Val R2: 0.1059\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2260\n",
      "Val RMSE: 128563.7729, Val MAE: 72884.9135, Val MSE: 16528643706.7785, Val R2: 0.1602\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2053, Val Loss: 0.2306\n",
      "Val RMSE: 129378.1564, Val MAE: 74751.3849, Val MSE: 16738707355.6269, Val R2: 0.1496\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1978, Val Loss: 0.2184\n",
      "Val RMSE: 127382.4249, Val MAE: 69213.6529, Val MSE: 16226282171.9952, Val R2: 0.1756\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1956, Val Loss: 0.2123\n",
      "Val RMSE: 119674.8481, Val MAE: 69731.7078, Val MSE: 14322069266.4715, Val R2: 0.2723\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1934, Val Loss: 0.2063\n",
      "Val RMSE: 114523.0941, Val MAE: 67204.7702, Val MSE: 13115539077.2285, Val R2: 0.3336\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1780, Val Loss: 0.1892\n",
      "Val RMSE: 103398.5214, Val MAE: 67708.8753, Val MSE: 10691254228.1739, Val R2: 0.4568\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1750, Val Loss: 0.1877\n",
      "Val RMSE: 107081.8715, Val MAE: 63513.8147, Val MSE: 11466527194.7063, Val R2: 0.4174\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1665, Val Loss: 0.1768\n",
      "Val RMSE: 101961.4469, Val MAE: 62707.3547, Val MSE: 10396136660.9576, Val R2: 0.4718\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1599, Val Loss: 0.1744\n",
      "Val RMSE: 101868.6159, Val MAE: 61552.1829, Val MSE: 10377214898.5970, Val R2: 0.4728\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1554, Val Loss: 0.1667\n",
      "Val RMSE: 99852.5739, Val MAE: 58457.2948, Val MSE: 9970536519.6949, Val R2: 0.4934\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1539, Val Loss: 0.1867\n",
      "Val RMSE: 100814.4763, Val MAE: 65965.7806, Val MSE: 10163558639.7254, Val R2: 0.4836\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1553, Val Loss: 0.1521\n",
      "Val RMSE: 95088.8666, Val MAE: 57129.5868, Val MSE: 9041892551.3916, Val R2: 0.5406\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1502, Val Loss: 0.1489\n",
      "Val RMSE: 95274.2736, Val MAE: 54562.5645, Val MSE: 9077187209.4683, Val R2: 0.5388\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1455, Val Loss: 0.1487\n",
      "Val RMSE: 95277.7886, Val MAE: 53606.8687, Val MSE: 9077856995.0260, Val R2: 0.5388\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1374, Val Loss: 0.1493\n",
      "Val RMSE: 95030.9269, Val MAE: 53295.1453, Val MSE: 9030877070.0574, Val R2: 0.5412\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1308, Val Loss: 0.1598\n",
      "Val RMSE: 99977.2070, Val MAE: 55378.3576, Val MSE: 9995441929.4899, Val R2: 0.4922\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1192, Val Loss: 0.1443\n",
      "Val RMSE: 92416.5056, Val MAE: 53478.7538, Val MSE: 8540810509.7729, Val R2: 0.5661\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1092, Val Loss: 0.1435\n",
      "Val RMSE: 94083.3007, Val MAE: 53473.1015, Val MSE: 8851667466.2917, Val R2: 0.5503\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1401\n",
      "Val RMSE: 94687.9495, Val MAE: 49462.4503, Val MSE: 8965807788.6113, Val R2: 0.5445\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1388\n",
      "Val RMSE: 90569.9208, Val MAE: 50860.6646, Val MSE: 8202910554.5644, Val R2: 0.5832\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1375\n",
      "Val RMSE: 90485.3193, Val MAE: 50252.6347, Val MSE: 8187593014.9895, Val R2: 0.5840\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0934, Val Loss: 0.1471\n",
      "Val RMSE: 94094.1461, Val MAE: 51169.0273, Val MSE: 8853708325.0064, Val R2: 0.5502\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1452\n",
      "Val RMSE: 92239.5191, Val MAE: 53435.5247, Val MSE: 8508128883.8527, Val R2: 0.5677\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0876, Val Loss: 0.1471\n",
      "Val RMSE: 91295.9463, Val MAE: 57113.8259, Val MSE: 8334949805.6677, Val R2: 0.5765\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0858, Val Loss: 0.1395\n",
      "Val RMSE: 89627.0748, Val MAE: 50178.1151, Val MSE: 8033012545.0246, Val R2: 0.5919\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.1373\n",
      "Val RMSE: 87610.9424, Val MAE: 49549.6319, Val MSE: 7675677229.0676, Val R2: 0.6100\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0814, Val Loss: 0.1415\n",
      "Val RMSE: 90964.7556, Val MAE: 50844.5710, Val MSE: 8274586766.0990, Val R2: 0.5796\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0795, Val Loss: 0.1400\n",
      "Val RMSE: 88127.7145, Val MAE: 48412.0265, Val MSE: 7766494059.1986, Val R2: 0.6054\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1342\n",
      "Val RMSE: 86981.0863, Val MAE: 48742.6725, Val MSE: 7565709382.6234, Val R2: 0.6156\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1328\n",
      "Val RMSE: 83466.7325, Val MAE: 49385.0292, Val MSE: 6966695428.6320, Val R2: 0.6460\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1333\n",
      "Val RMSE: 84289.6864, Val MAE: 50286.7782, Val MSE: 7104751234.4223, Val R2: 0.6390\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1275\n",
      "Val RMSE: 81401.5606, Val MAE: 46231.6579, Val MSE: 6626214060.0388, Val R2: 0.6633\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1284\n",
      "Val RMSE: 83046.3560, Val MAE: 48468.6199, Val MSE: 6896697245.6638, Val R2: 0.6496\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1422\n",
      "Val RMSE: 88454.7378, Val MAE: 53097.5817, Val MSE: 7824240643.6456, Val R2: 0.6025\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1300\n",
      "Val RMSE: 83239.8990, Val MAE: 47550.1185, Val MSE: 6928880779.3071, Val R2: 0.6480\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0682, Val Loss: 0.1319\n",
      "Val RMSE: 83274.9328, Val MAE: 47935.3843, Val MSE: 6934714435.4963, Val R2: 0.6477\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1282\n",
      "Val RMSE: 82458.7538, Val MAE: 46665.1890, Val MSE: 6799446085.0134, Val R2: 0.6545\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0661, Val Loss: 0.1401\n",
      "Val RMSE: 86861.9167, Val MAE: 52674.8171, Val MSE: 7544992577.6657, Val R2: 0.6167\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1379\n",
      "Val RMSE: 86948.5661, Val MAE: 47661.7670, Val MSE: 7560053151.7193, Val R2: 0.6159\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1217\n",
      "Val RMSE: 79628.2656, Val MAE: 45788.1014, Val MSE: 6340660676.7015, Val R2: 0.6779\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1222\n",
      "Val RMSE: 80825.5890, Val MAE: 43935.6419, Val MSE: 6532775830.2622, Val R2: 0.6681\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1161\n",
      "Val RMSE: 77797.5889, Val MAE: 45065.2651, Val MSE: 6052464835.5899, Val R2: 0.6925\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1214\n",
      "Val RMSE: 80937.5221, Val MAE: 44253.4101, Val MSE: 6550882490.6873, Val R2: 0.6672\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1313\n",
      "Val RMSE: 83303.7386, Val MAE: 48584.4320, Val MSE: 6939512860.5544, Val R2: 0.6474\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1254\n",
      "Val RMSE: 82359.7567, Val MAE: 45117.7333, Val MSE: 6783129528.3297, Val R2: 0.6554\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0568, Val Loss: 0.1173\n",
      "Val RMSE: 77100.7696, Val MAE: 44718.3290, Val MSE: 5944528665.5401, Val R2: 0.6980\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1190\n",
      "Val RMSE: 77271.4373, Val MAE: 45565.1645, Val MSE: 5970875028.8162, Val R2: 0.6966\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1256\n",
      "Val RMSE: 81764.3299, Val MAE: 45424.4333, Val MSE: 6685405645.9577, Val R2: 0.6603\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1239\n",
      "Val RMSE: 80228.6890, Val MAE: 47486.6847, Val MSE: 6436642540.3223, Val R2: 0.6730\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1231\n",
      "Val RMSE: 81275.1107, Val MAE: 46073.9505, Val MSE: 6605643623.9092, Val R2: 0.6644\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1280\n",
      "Val RMSE: 80506.1603, Val MAE: 47535.4774, Val MSE: 6481241849.0428, Val R2: 0.6707\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1110\n",
      "Val RMSE: 75750.8576, Val MAE: 43356.1149, Val MSE: 5738192421.0061, Val R2: 0.7085\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.1409\n",
      "Val RMSE: 85160.2118, Val MAE: 52461.5204, Val MSE: 7252261674.1275, Val R2: 0.6315\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1217\n",
      "Val RMSE: 79758.5641, Val MAE: 45675.8119, Val MSE: 6361428540.6617, Val R2: 0.6768\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1245\n",
      "Val RMSE: 81217.6831, Val MAE: 46233.2083, Val MSE: 6596312041.4552, Val R2: 0.6649\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1177\n",
      "Val RMSE: 77645.7759, Val MAE: 43446.0597, Val MSE: 6028866508.5902, Val R2: 0.6937\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1135\n",
      "Val RMSE: 77744.2106, Val MAE: 43308.1697, Val MSE: 6044162278.2365, Val R2: 0.6929\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1162\n",
      "Val RMSE: 76406.6764, Val MAE: 44260.2539, Val MSE: 5837980191.5438, Val R2: 0.7034\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1226\n",
      "Val RMSE: 80460.4080, Val MAE: 46086.0412, Val MSE: 6473877247.4843, Val R2: 0.6711\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1369\n",
      "Val RMSE: 83711.2176, Val MAE: 50721.4867, Val MSE: 7007567953.0530, Val R2: 0.6440\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1196\n",
      "Val RMSE: 78506.9922, Val MAE: 45731.0348, Val MSE: 6163347824.4223, Val R2: 0.6869\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1076\n",
      "Val RMSE: 73763.7400, Val MAE: 40143.6325, Val MSE: 5441089333.8286, Val R2: 0.7236\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1146\n",
      "Val RMSE: 76748.3305, Val MAE: 45721.1778, Val MSE: 5890306229.7057, Val R2: 0.7007\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1090\n",
      "Val RMSE: 75923.7407, Val MAE: 42494.6604, Val MSE: 5764414408.9857, Val R2: 0.7071\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1076\n",
      "Val RMSE: 75592.5065, Val MAE: 40146.6205, Val MSE: 5714227035.2326, Val R2: 0.7097\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1057\n",
      "Val RMSE: 74673.3194, Val MAE: 39286.7836, Val MSE: 5576104637.2271, Val R2: 0.7167\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.1084\n",
      "Val RMSE: 78147.5992, Val MAE: 40743.2956, Val MSE: 6107047261.8723, Val R2: 0.6897\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1111\n",
      "Val RMSE: 77844.7042, Val MAE: 42298.6338, Val MSE: 6059797971.4120, Val R2: 0.6921\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1088\n",
      "Val RMSE: 76196.4687, Val MAE: 42722.9610, Val MSE: 5805901843.9846, Val R2: 0.7050\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0431, Val Loss: 0.1007\n",
      "Val RMSE: 72246.9467, Val MAE: 40347.7293, Val MSE: 5219621304.9156, Val R2: 0.7348\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.1071\n",
      "Val RMSE: 75619.6498, Val MAE: 41649.1377, Val MSE: 5718331432.1674, Val R2: 0.7095\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0408, Val Loss: 0.1006\n",
      "Val RMSE: 72795.5665, Val MAE: 39550.2731, Val MSE: 5299194497.0382, Val R2: 0.7308\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0426, Val Loss: 0.1142\n",
      "Val RMSE: 77805.1328, Val MAE: 43658.5837, Val MSE: 6053638692.3395, Val R2: 0.6924\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0416, Val Loss: 0.1177\n",
      "Val RMSE: 78844.4782, Val MAE: 45478.5826, Val MSE: 6216451744.1019, Val R2: 0.6842\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0404, Val Loss: 0.1106\n",
      "Val RMSE: 77460.8493, Val MAE: 42770.4235, Val MSE: 6000183181.6785, Val R2: 0.6952\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0414, Val Loss: 0.1142\n",
      "Val RMSE: 76992.8210, Val MAE: 43900.4605, Val MSE: 5927894478.7696, Val R2: 0.6988\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0402, Val Loss: 0.1240\n",
      "Val RMSE: 79290.4278, Val MAE: 47371.4498, Val MSE: 6286971940.2548, Val R2: 0.6806\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0399, Val Loss: 0.1054\n",
      "Val RMSE: 74802.7495, Val MAE: 40920.9928, Val MSE: 5595451335.6802, Val R2: 0.7157\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0405, Val Loss: 0.1093\n",
      "Val RMSE: 79380.0544, Val MAE: 38883.7534, Val MSE: 6301193043.7313, Val R2: 0.6799\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0392, Val Loss: 0.1092\n",
      "Val RMSE: 75876.3033, Val MAE: 44693.8431, Val MSE: 5757213396.0024, Val R2: 0.7075\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0383, Val Loss: 0.1212\n",
      "Val RMSE: 81927.9940, Val MAE: 47090.4604, Val MSE: 6712196197.8777, Val R2: 0.6590\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75527.6712, Test MAE: 41452.0652, Test MSE: 5704429120.9204, Test R2: 0.6343\n",
      "Inference Time: 2.30711790231558e-05 seconds per sample\n",
      "\n",
      "Iteration 68 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3643, Val Loss: 0.2754\n",
      "Val RMSE: 140781.3700, Val MAE: 85703.2957, Val MSE: 19819394129.9576, Val R2: -0.0070\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2794, Val Loss: 0.2808\n",
      "Val RMSE: 143671.4319, Val MAE: 81147.6385, Val MSE: 20641480348.8416, Val R2: -0.0487\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2705, Val Loss: 0.2745\n",
      "Val RMSE: 141163.0943, Val MAE: 84247.8106, Val MSE: 19927019203.9872, Val R2: -0.0124\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2682, Val Loss: 0.2737\n",
      "Val RMSE: 140738.7986, Val MAE: 85036.3283, Val MSE: 19807409427.7789, Val R2: -0.0063\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2655, Val Loss: 0.2788\n",
      "Val RMSE: 140755.5068, Val MAE: 87023.1878, Val MSE: 19812112688.2714, Val R2: -0.0066\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2727\n",
      "Val RMSE: 141393.4615, Val MAE: 83316.5762, Val MSE: 19992110949.2502, Val R2: -0.0157\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2613, Val Loss: 0.2792\n",
      "Val RMSE: 141593.2851, Val MAE: 86925.2882, Val MSE: 20048658389.1541, Val R2: -0.0186\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2714\n",
      "Val RMSE: 141705.4231, Val MAE: 81137.4416, Val MSE: 20080426945.8452, Val R2: -0.0202\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2549, Val Loss: 0.2730\n",
      "Val RMSE: 141989.4897, Val MAE: 81153.2559, Val MSE: 20161015193.6356, Val R2: -0.0243\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2551, Val Loss: 0.2692\n",
      "Val RMSE: 142014.4597, Val MAE: 79204.2173, Val MSE: 20168106755.3514, Val R2: -0.0247\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2512, Val Loss: 0.2667\n",
      "Val RMSE: 140463.9810, Val MAE: 81174.8200, Val MSE: 19730129945.9691, Val R2: -0.0024\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2502, Val Loss: 0.2767\n",
      "Val RMSE: 139693.3372, Val MAE: 86810.6177, Val MSE: 19514228467.7735, Val R2: 0.0086\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2504, Val Loss: 0.2614\n",
      "Val RMSE: 139939.2436, Val MAE: 79122.9035, Val MSE: 19582991890.3486, Val R2: 0.0051\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2442, Val Loss: 0.2513\n",
      "Val RMSE: 136729.2678, Val MAE: 76198.7361, Val MSE: 18694892678.5478, Val R2: 0.0502\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2319, Val Loss: 0.2352\n",
      "Val RMSE: 130906.7035, Val MAE: 75802.3276, Val MSE: 17136565019.1059, Val R2: 0.1294\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2236, Val Loss: 0.2304\n",
      "Val RMSE: 132429.9043, Val MAE: 71241.3060, Val MSE: 17537679557.1916, Val R2: 0.1090\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2187, Val Loss: 0.2413\n",
      "Val RMSE: 130187.0307, Val MAE: 78803.6348, Val MSE: 16948662971.0682, Val R2: 0.1389\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2137, Val Loss: 0.2342\n",
      "Val RMSE: 132048.6040, Val MAE: 71477.1620, Val MSE: 17436833830.3731, Val R2: 0.1141\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2112, Val Loss: 0.2293\n",
      "Val RMSE: 130593.2572, Val MAE: 72335.7007, Val MSE: 17054598836.3641, Val R2: 0.1335\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2351\n",
      "Val RMSE: 132411.3293, Val MAE: 72812.6358, Val MSE: 17532760126.3742, Val R2: 0.1092\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2053, Val Loss: 0.2365\n",
      "Val RMSE: 134736.4411, Val MAE: 70326.7067, Val MSE: 18153908558.9215, Val R2: 0.0777\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2109, Val Loss: 0.2364\n",
      "Val RMSE: 129100.5030, Val MAE: 78427.4605, Val MSE: 16666939869.4607, Val R2: 0.1532\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2262\n",
      "Val RMSE: 129262.3238, Val MAE: 71455.2551, Val MSE: 16708748354.4067, Val R2: 0.1511\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1960, Val Loss: 0.2158\n",
      "Val RMSE: 121497.6543, Val MAE: 68943.1934, Val MSE: 14761679994.9591, Val R2: 0.2500\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1999, Val Loss: 0.2340\n",
      "Val RMSE: 121805.4511, Val MAE: 75439.2801, Val MSE: 14836567918.3595, Val R2: 0.2462\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2130, Val Loss: 0.2329\n",
      "Val RMSE: 122449.1970, Val MAE: 71088.9577, Val MSE: 14993805845.0458, Val R2: 0.2382\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2463, Val Loss: 0.2599\n",
      "Val RMSE: 135055.5542, Val MAE: 80893.3867, Val MSE: 18240002731.5616, Val R2: 0.0733\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2502, Val Loss: 0.2595\n",
      "Val RMSE: 132900.2344, Val MAE: 84122.7782, Val MSE: 17662472296.1815, Val R2: 0.1026\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2478\n",
      "Val RMSE: 134283.6504, Val MAE: 73341.1479, Val MSE: 18032098765.3202, Val R2: 0.0839\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2324, Val Loss: 0.2435\n",
      "Val RMSE: 130939.0048, Val MAE: 77018.4555, Val MSE: 17145022972.2614, Val R2: 0.1289\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2276, Val Loss: 0.2432\n",
      "Val RMSE: 133188.1525, Val MAE: 72217.2749, Val MSE: 17739083954.2351, Val R2: 0.0987\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2197, Val Loss: 0.2449\n",
      "Val RMSE: 133896.6385, Val MAE: 71620.9042, Val MSE: 17928309800.6383, Val R2: 0.0891\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.2156, Val Loss: 0.2288\n",
      "Val RMSE: 130139.9488, Val MAE: 71320.1409, Val MSE: 16936406276.5040, Val R2: 0.1395\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2286\n",
      "Val RMSE: 129734.4293, Val MAE: 72472.5953, Val MSE: 16831022141.3331, Val R2: 0.1449\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2266\n",
      "Val RMSE: 129119.0943, Val MAE: 71211.1293, Val MSE: 16671740517.0758, Val R2: 0.1530\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.2016, Val Loss: 0.2208\n",
      "Val RMSE: 126980.6812, Val MAE: 70949.3649, Val MSE: 16124093391.1798, Val R2: 0.1808\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1970, Val Loss: 0.2152\n",
      "Val RMSE: 125023.5518, Val MAE: 69851.1338, Val MSE: 15630888493.3174, Val R2: 0.2059\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1898, Val Loss: 0.2180\n",
      "Val RMSE: 120044.6488, Val MAE: 68863.4227, Val MSE: 14410717708.1244, Val R2: 0.2678\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1871, Val Loss: 0.2185\n",
      "Val RMSE: 121989.6623, Val MAE: 67141.8031, Val MSE: 14881477710.4366, Val R2: 0.2439\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1829, Val Loss: 0.2200\n",
      "Val RMSE: 120825.3717, Val MAE: 66593.9455, Val MSE: 14598770449.4726, Val R2: 0.2583\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1830, Val Loss: 0.2228\n",
      "Val RMSE: 120691.9794, Val MAE: 67151.4211, Val MSE: 14566553892.2879, Val R2: 0.2599\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1786, Val Loss: 0.2098\n",
      "Val RMSE: 118025.9086, Val MAE: 65577.5506, Val MSE: 13930115103.4298, Val R2: 0.2923\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1764, Val Loss: 0.1968\n",
      "Val RMSE: 109908.5286, Val MAE: 67860.4202, Val MSE: 12079884653.3090, Val R2: 0.3863\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1737, Val Loss: 0.1869\n",
      "Val RMSE: 106673.7466, Val MAE: 64426.2768, Val MSE: 11379288207.2816, Val R2: 0.4219\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1719, Val Loss: 0.1863\n",
      "Val RMSE: 106130.8697, Val MAE: 64079.4753, Val MSE: 11263761497.1735, Val R2: 0.4277\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1673, Val Loss: 0.2041\n",
      "Val RMSE: 111294.0283, Val MAE: 64671.8264, Val MSE: 12386360745.1115, Val R2: 0.3707\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1657, Val Loss: 0.1857\n",
      "Val RMSE: 105156.0780, Val MAE: 62499.9352, Val MSE: 11057800739.9630, Val R2: 0.4382\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1654, Val Loss: 0.1816\n",
      "Val RMSE: 103151.8832, Val MAE: 63149.6020, Val MSE: 10640311016.3332, Val R2: 0.4594\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1620, Val Loss: 0.1815\n",
      "Val RMSE: 104016.7697, Val MAE: 61124.5421, Val MSE: 10819488387.5602, Val R2: 0.4503\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1591, Val Loss: 0.1838\n",
      "Val RMSE: 102802.2127, Val MAE: 62679.3711, Val MSE: 10568294931.5177, Val R2: 0.4631\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1562, Val Loss: 0.1798\n",
      "Val RMSE: 103280.0020, Val MAE: 62922.8638, Val MSE: 10666758806.3339, Val R2: 0.4581\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1542, Val Loss: 0.1640\n",
      "Val RMSE: 97267.3527, Val MAE: 59760.2537, Val MSE: 9460937892.7383, Val R2: 0.5193\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1531, Val Loss: 0.1632\n",
      "Val RMSE: 97591.7007, Val MAE: 58000.0789, Val MSE: 9524140045.7658, Val R2: 0.5161\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1508, Val Loss: 0.1590\n",
      "Val RMSE: 97271.2734, Val MAE: 57459.0167, Val MSE: 9461700630.6020, Val R2: 0.5193\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1471, Val Loss: 0.1545\n",
      "Val RMSE: 96415.9455, Val MAE: 55961.4192, Val MSE: 9296034545.4247, Val R2: 0.5277\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1452, Val Loss: 0.1490\n",
      "Val RMSE: 94203.4651, Val MAE: 55088.8813, Val MSE: 8874292831.1262, Val R2: 0.5491\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1408, Val Loss: 0.1446\n",
      "Val RMSE: 92353.8080, Val MAE: 54464.2048, Val MSE: 8529225846.1840, Val R2: 0.5667\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1385, Val Loss: 0.1442\n",
      "Val RMSE: 92182.0853, Val MAE: 53899.2437, Val MSE: 8497536848.5106, Val R2: 0.5683\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1380, Val Loss: 0.1403\n",
      "Val RMSE: 92629.9645, Val MAE: 51828.5398, Val MSE: 8580310317.7467, Val R2: 0.5641\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1352, Val Loss: 0.1454\n",
      "Val RMSE: 91737.7391, Val MAE: 53621.1153, Val MSE: 8415812781.4627, Val R2: 0.5724\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1343, Val Loss: 0.1451\n",
      "Val RMSE: 92106.6114, Val MAE: 53259.3701, Val MSE: 8483627859.5696, Val R2: 0.5690\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1326, Val Loss: 0.1335\n",
      "Val RMSE: 90855.7264, Val MAE: 49952.0800, Val MSE: 8254763027.0611, Val R2: 0.5806\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1295, Val Loss: 0.1358\n",
      "Val RMSE: 90919.3675, Val MAE: 49111.5029, Val MSE: 8266331383.3665, Val R2: 0.5800\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1280, Val Loss: 0.1319\n",
      "Val RMSE: 89859.7875, Val MAE: 50192.1152, Val MSE: 8074781412.0580, Val R2: 0.5898\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1271, Val Loss: 0.1288\n",
      "Val RMSE: 89339.4927, Val MAE: 49894.2724, Val MSE: 7981544962.6328, Val R2: 0.5945\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1251, Val Loss: 0.1298\n",
      "Val RMSE: 90171.8094, Val MAE: 49407.8468, Val MSE: 8130955214.4964, Val R2: 0.5869\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.1258, Val Loss: 0.1317\n",
      "Val RMSE: 88622.5218, Val MAE: 52124.1893, Val MSE: 7853951368.1150, Val R2: 0.6010\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.1227, Val Loss: 0.1259\n",
      "Val RMSE: 89200.1450, Val MAE: 47206.8425, Val MSE: 7956665867.6651, Val R2: 0.5958\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.1216, Val Loss: 0.1385\n",
      "Val RMSE: 91559.9886, Val MAE: 53314.4708, Val MSE: 8383231511.9590, Val R2: 0.5741\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.1258, Val Loss: 0.1380\n",
      "Val RMSE: 90905.8099, Val MAE: 54914.7675, Val MSE: 8263866266.5457, Val R2: 0.5801\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.1222, Val Loss: 0.1189\n",
      "Val RMSE: 86492.6329, Val MAE: 47524.0008, Val MSE: 7480975548.5776, Val R2: 0.6199\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.1177, Val Loss: 0.1168\n",
      "Val RMSE: 85959.3607, Val MAE: 48164.5055, Val MSE: 7389011684.5444, Val R2: 0.6246\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.1162, Val Loss: 0.1279\n",
      "Val RMSE: 89245.3595, Val MAE: 49225.1545, Val MSE: 7964734197.0689, Val R2: 0.5953\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.1142, Val Loss: 0.1181\n",
      "Val RMSE: 87013.2429, Val MAE: 45627.9968, Val MSE: 7571304433.6146, Val R2: 0.6153\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.1124, Val Loss: 0.1254\n",
      "Val RMSE: 88573.1596, Val MAE: 48962.9578, Val MSE: 7845204596.5995, Val R2: 0.6014\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.1118, Val Loss: 0.1087\n",
      "Val RMSE: 83058.8749, Val MAE: 45421.3893, Val MSE: 6898776701.9928, Val R2: 0.6495\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.1066, Val Loss: 0.1195\n",
      "Val RMSE: 86478.8333, Val MAE: 46955.3862, Val MSE: 7478588605.0162, Val R2: 0.6200\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.1064, Val Loss: 0.1111\n",
      "Val RMSE: 83851.3630, Val MAE: 46552.3422, Val MSE: 7031051078.7314, Val R2: 0.6428\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.1029, Val Loss: 0.1178\n",
      "Val RMSE: 86604.5916, Val MAE: 44617.3732, Val MSE: 7500355292.3012, Val R2: 0.6189\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0995, Val Loss: 0.1066\n",
      "Val RMSE: 83728.2617, Val MAE: 45188.1232, Val MSE: 7010421814.1698, Val R2: 0.6438\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0991, Val Loss: 0.1053\n",
      "Val RMSE: 83396.7958, Val MAE: 41705.3559, Val MSE: 6955025555.4341, Val R2: 0.6466\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0976, Val Loss: 0.1174\n",
      "Val RMSE: 86380.6449, Val MAE: 48223.4854, Val MSE: 7461615819.3363, Val R2: 0.6209\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0962, Val Loss: 0.1190\n",
      "Val RMSE: 87974.0156, Val MAE: 44842.3969, Val MSE: 7739427414.4521, Val R2: 0.6068\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1047\n",
      "Val RMSE: 82548.2795, Val MAE: 44045.5421, Val MSE: 6814218441.1277, Val R2: 0.6538\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1169\n",
      "Val RMSE: 85409.3636, Val MAE: 45399.4255, Val MSE: 7294759389.3494, Val R2: 0.6294\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0916, Val Loss: 0.1121\n",
      "Val RMSE: 84478.0310, Val MAE: 45198.3457, Val MSE: 7136537722.6167, Val R2: 0.6374\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0885, Val Loss: 0.1139\n",
      "Val RMSE: 86678.5436, Val MAE: 43808.1828, Val MSE: 7513169918.1556, Val R2: 0.6183\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1148\n",
      "Val RMSE: 85742.7836, Val MAE: 44423.9413, Val MSE: 7351824935.7753, Val R2: 0.6265\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0882, Val Loss: 0.1028\n",
      "Val RMSE: 80472.9439, Val MAE: 44508.5878, Val MSE: 6475894694.7244, Val R2: 0.6710\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1076\n",
      "Val RMSE: 81397.4654, Val MAE: 43491.1429, Val MSE: 6625547381.0670, Val R2: 0.6634\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1074\n",
      "Val RMSE: 81105.6363, Val MAE: 43468.9468, Val MSE: 6578124238.7051, Val R2: 0.6658\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1071\n",
      "Val RMSE: 79702.8140, Val MAE: 44039.1166, Val MSE: 6352538565.7180, Val R2: 0.6773\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.0951\n",
      "Val RMSE: 78770.9748, Val MAE: 39030.6987, Val MSE: 6204866475.8257, Val R2: 0.6848\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1089\n",
      "Val RMSE: 82730.4707, Val MAE: 42601.8414, Val MSE: 6844330779.5219, Val R2: 0.6523\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1050\n",
      "Val RMSE: 80507.8095, Val MAE: 42243.8842, Val MSE: 6481507389.7249, Val R2: 0.6707\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0779, Val Loss: 0.0958\n",
      "Val RMSE: 76220.8688, Val MAE: 41549.4253, Val MSE: 5809620844.0624, Val R2: 0.7048\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.0993\n",
      "Val RMSE: 78779.4349, Val MAE: 39450.3249, Val MSE: 6206199363.8068, Val R2: 0.6847\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.0984\n",
      "Val RMSE: 78794.4161, Val MAE: 41773.5434, Val MSE: 6208560014.0010, Val R2: 0.6846\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1123\n",
      "Val RMSE: 83548.2150, Val MAE: 43083.7244, Val MSE: 6980304223.8404, Val R2: 0.6454\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.0989\n",
      "Val RMSE: 79494.3752, Val MAE: 41965.5656, Val MSE: 6319355693.7800, Val R2: 0.6789\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 82178.2741, Test MAE: 40595.6335, Test MSE: 6753268730.3967, Test R2: 0.5671\n",
      "Inference Time: 3.233003616333008e-05 seconds per sample\n",
      "\n",
      "Iteration 69 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3701, Val Loss: 0.2930\n",
      "Val RMSE: 146497.5353, Val MAE: 80527.3133, Val MSE: 21461527843.3360, Val R2: -0.0904\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2771, Val Loss: 0.2755\n",
      "Val RMSE: 141153.2459, Val MAE: 84632.2556, Val MSE: 19924238820.2548, Val R2: -0.0123\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2726, Val Loss: 0.2796\n",
      "Val RMSE: 143270.3051, Val MAE: 81631.1503, Val MSE: 20526380317.0862, Val R2: -0.0429\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2684, Val Loss: 0.2747\n",
      "Val RMSE: 140909.3265, Val MAE: 84583.5611, Val MSE: 19855438307.7685, Val R2: -0.0088\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2668, Val Loss: 0.2767\n",
      "Val RMSE: 142176.8954, Val MAE: 82581.9077, Val MSE: 20214269582.5711, Val R2: -0.0270\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2628, Val Loss: 0.2764\n",
      "Val RMSE: 142747.8590, Val MAE: 81957.2015, Val MSE: 20376951262.5268, Val R2: -0.0353\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2620, Val Loss: 0.2727\n",
      "Val RMSE: 142011.7559, Val MAE: 81283.0773, Val MSE: 20167338819.4224, Val R2: -0.0246\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2756\n",
      "Val RMSE: 141676.3010, Val MAE: 83652.3956, Val MSE: 20072174253.8508, Val R2: -0.0198\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2732\n",
      "Val RMSE: 140112.4426, Val MAE: 85560.1601, Val MSE: 19631496577.5150, Val R2: 0.0026\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2815\n",
      "Val RMSE: 143322.0816, Val MAE: 80342.9886, Val MSE: 20541219085.5975, Val R2: -0.0436\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2676\n",
      "Val RMSE: 139489.0487, Val MAE: 83509.2833, Val MSE: 19457194698.7210, Val R2: 0.0115\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2517, Val Loss: 0.2641\n",
      "Val RMSE: 140872.4855, Val MAE: 79254.5454, Val MSE: 19845057174.7534, Val R2: -0.0083\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2495, Val Loss: 0.2671\n",
      "Val RMSE: 139708.8171, Val MAE: 81285.2795, Val MSE: 19518553576.2665, Val R2: 0.0083\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2569\n",
      "Val RMSE: 137388.1429, Val MAE: 76751.6617, Val MSE: 18875501822.3563, Val R2: 0.0410\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2352, Val Loss: 0.2522\n",
      "Val RMSE: 135466.7636, Val MAE: 74866.6268, Val MSE: 18351244046.8336, Val R2: 0.0676\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2319, Val Loss: 0.2514\n",
      "Val RMSE: 131363.5158, Val MAE: 82043.4930, Val MSE: 17256373282.2900, Val R2: 0.1233\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2221, Val Loss: 0.2402\n",
      "Val RMSE: 132953.5101, Val MAE: 73786.4964, Val MSE: 17676635835.4089, Val R2: 0.1019\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2180, Val Loss: 0.2492\n",
      "Val RMSE: 136060.3831, Val MAE: 72219.9996, Val MSE: 18512427841.4396, Val R2: 0.0595\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2105, Val Loss: 0.2444\n",
      "Val RMSE: 135855.4718, Val MAE: 71820.0687, Val MSE: 18456709220.6908, Val R2: 0.0623\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2037, Val Loss: 0.2448\n",
      "Val RMSE: 132202.7356, Val MAE: 72243.5150, Val MSE: 17477563308.1841, Val R2: 0.1120\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2015, Val Loss: 0.2241\n",
      "Val RMSE: 131196.4144, Val MAE: 69669.8198, Val MSE: 17212499152.9107, Val R2: 0.1255\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1943, Val Loss: 0.2249\n",
      "Val RMSE: 130421.4328, Val MAE: 69022.2471, Val MSE: 17009750136.7366, Val R2: 0.1358\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1940, Val Loss: 0.2263\n",
      "Val RMSE: 130475.2544, Val MAE: 69616.9261, Val MSE: 17023792017.6106, Val R2: 0.1351\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1900, Val Loss: 0.2322\n",
      "Val RMSE: 133645.4918, Val MAE: 71382.6007, Val MSE: 17861117474.6791, Val R2: 0.0925\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1879, Val Loss: 0.2193\n",
      "Val RMSE: 129292.6492, Val MAE: 67502.1871, Val MSE: 16716589127.4849, Val R2: 0.1507\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1872, Val Loss: 0.2140\n",
      "Val RMSE: 122039.5770, Val MAE: 68917.5100, Val MSE: 14893658350.3491, Val R2: 0.2433\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1774, Val Loss: 0.1970\n",
      "Val RMSE: 116185.6751, Val MAE: 62336.3426, Val MSE: 13499111092.1260, Val R2: 0.3142\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1696, Val Loss: 0.1890\n",
      "Val RMSE: 108996.8197, Val MAE: 64409.5733, Val MSE: 11880306705.5789, Val R2: 0.3964\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1633, Val Loss: 0.1803\n",
      "Val RMSE: 106289.3849, Val MAE: 60363.5946, Val MSE: 11297433342.1341, Val R2: 0.4260\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1588, Val Loss: 0.1773\n",
      "Val RMSE: 105112.6337, Val MAE: 59533.2870, Val MSE: 11048665768.7874, Val R2: 0.4387\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1820\n",
      "Val RMSE: 104918.5930, Val MAE: 59741.8515, Val MSE: 11007911159.4707, Val R2: 0.4407\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1509, Val Loss: 0.1827\n",
      "Val RMSE: 104807.6853, Val MAE: 58961.5169, Val MSE: 10984650900.1634, Val R2: 0.4419\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1503, Val Loss: 0.1663\n",
      "Val RMSE: 100457.7871, Val MAE: 55526.9995, Val MSE: 10091766979.0849, Val R2: 0.4873\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1542\n",
      "Val RMSE: 97565.1418, Val MAE: 53808.1141, Val MSE: 9518956891.1002, Val R2: 0.5164\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1423, Val Loss: 0.1590\n",
      "Val RMSE: 98963.4732, Val MAE: 54940.5547, Val MSE: 9793769026.0035, Val R2: 0.5024\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1399, Val Loss: 0.1553\n",
      "Val RMSE: 98025.1380, Val MAE: 54202.9503, Val MSE: 9608927684.9968, Val R2: 0.5118\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1388, Val Loss: 0.1572\n",
      "Val RMSE: 98363.8485, Val MAE: 55292.7775, Val MSE: 9675446700.2055, Val R2: 0.5084\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1384, Val Loss: 0.1505\n",
      "Val RMSE: 96387.2235, Val MAE: 53142.7319, Val MSE: 9290496849.7399, Val R2: 0.5280\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1358, Val Loss: 0.1538\n",
      "Val RMSE: 97371.1150, Val MAE: 53018.4977, Val MSE: 9481134034.9408, Val R2: 0.5183\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1357, Val Loss: 0.1395\n",
      "Val RMSE: 92784.6345, Val MAE: 51160.7625, Val MSE: 8608988401.2573, Val R2: 0.5626\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1320, Val Loss: 0.1372\n",
      "Val RMSE: 92474.7966, Val MAE: 50728.1325, Val MSE: 8551588010.0289, Val R2: 0.5655\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1335, Val Loss: 0.1391\n",
      "Val RMSE: 92051.9548, Val MAE: 51241.3957, Val MSE: 8473562387.4776, Val R2: 0.5695\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1294, Val Loss: 0.1427\n",
      "Val RMSE: 94441.5194, Val MAE: 50930.9294, Val MSE: 8919200577.6461, Val R2: 0.5468\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1565\n",
      "Val RMSE: 97846.6405, Val MAE: 52876.0690, Val MSE: 9573965049.6906, Val R2: 0.5136\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1148, Val Loss: 0.1222\n",
      "Val RMSE: 87164.2108, Val MAE: 45809.4309, Val MSE: 7597599651.6955, Val R2: 0.6140\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1091, Val Loss: 0.1429\n",
      "Val RMSE: 92761.6957, Val MAE: 48906.4110, Val MSE: 8604732180.2306, Val R2: 0.5628\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1269\n",
      "Val RMSE: 86149.3310, Val MAE: 46670.2013, Val MSE: 7421707233.6342, Val R2: 0.6229\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1026, Val Loss: 0.1167\n",
      "Val RMSE: 85262.9958, Val MAE: 44113.4553, Val MSE: 7269778450.2764, Val R2: 0.6306\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0979, Val Loss: 0.1211\n",
      "Val RMSE: 85445.9089, Val MAE: 44019.0028, Val MSE: 7301003344.7914, Val R2: 0.6291\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1214\n",
      "Val RMSE: 84561.8869, Val MAE: 45127.2936, Val MSE: 7150712720.1702, Val R2: 0.6367\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1301\n",
      "Val RMSE: 84461.3779, Val MAE: 45453.6077, Val MSE: 7133724359.0370, Val R2: 0.6376\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0882, Val Loss: 0.1181\n",
      "Val RMSE: 81873.4405, Val MAE: 45207.8584, Val MSE: 6703260255.3991, Val R2: 0.6594\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0866, Val Loss: 0.1149\n",
      "Val RMSE: 79443.4682, Val MAE: 42369.5828, Val MSE: 6311264637.5510, Val R2: 0.6793\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1119\n",
      "Val RMSE: 81331.2203, Val MAE: 42785.5231, Val MSE: 6614767397.8709, Val R2: 0.6639\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0827, Val Loss: 0.1275\n",
      "Val RMSE: 83703.5310, Val MAE: 44492.0133, Val MSE: 7006281105.7999, Val R2: 0.6440\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1185\n",
      "Val RMSE: 78726.7840, Val MAE: 43119.4029, Val MSE: 6197906515.2366, Val R2: 0.6851\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0805, Val Loss: 0.1231\n",
      "Val RMSE: 85030.7627, Val MAE: 44053.4602, Val MSE: 7230230610.0327, Val R2: 0.6327\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1195\n",
      "Val RMSE: 81883.6336, Val MAE: 43272.4249, Val MSE: 6704929449.9558, Val R2: 0.6593\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0740, Val Loss: 0.1146\n",
      "Val RMSE: 78905.6138, Val MAE: 42132.4757, Val MSE: 6226095893.2177, Val R2: 0.6837\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1230\n",
      "Val RMSE: 83540.0627, Val MAE: 44004.8513, Val MSE: 6978942074.3659, Val R2: 0.6454\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1119\n",
      "Val RMSE: 76381.9645, Val MAE: 41561.1605, Val MSE: 5834204503.6744, Val R2: 0.7036\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0713, Val Loss: 0.1169\n",
      "Val RMSE: 79091.3470, Val MAE: 43652.5863, Val MSE: 6255441175.6088, Val R2: 0.6822\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1248\n",
      "Val RMSE: 81586.0514, Val MAE: 45582.7949, Val MSE: 6656283781.1181, Val R2: 0.6618\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1081\n",
      "Val RMSE: 72371.0434, Val MAE: 41567.1413, Val MSE: 5237567923.2838, Val R2: 0.7339\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1052\n",
      "Val RMSE: 72982.6701, Val MAE: 39482.5719, Val MSE: 5326470134.4015, Val R2: 0.7294\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1179\n",
      "Val RMSE: 79495.3688, Val MAE: 42807.1356, Val MSE: 6319513659.7066, Val R2: 0.6789\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1089\n",
      "Val RMSE: 76608.9488, Val MAE: 41674.9617, Val MSE: 5868931033.9721, Val R2: 0.7018\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1061\n",
      "Val RMSE: 71607.1342, Val MAE: 39324.7828, Val MSE: 5127581673.8918, Val R2: 0.7395\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1104\n",
      "Val RMSE: 74523.3839, Val MAE: 41863.7574, Val MSE: 5553734750.3066, Val R2: 0.7178\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1059\n",
      "Val RMSE: 74207.5117, Val MAE: 39937.8184, Val MSE: 5506754785.8148, Val R2: 0.7202\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1081\n",
      "Val RMSE: 74497.3087, Val MAE: 39792.6480, Val MSE: 5549848996.3747, Val R2: 0.7180\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.0985\n",
      "Val RMSE: 69176.5200, Val MAE: 37763.6270, Val MSE: 4785390922.6235, Val R2: 0.7569\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1108\n",
      "Val RMSE: 74928.0238, Val MAE: 40711.2433, Val MSE: 5614208748.0946, Val R2: 0.7148\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1032\n",
      "Val RMSE: 73010.7201, Val MAE: 38469.6335, Val MSE: 5330565243.2212, Val R2: 0.7292\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1010\n",
      "Val RMSE: 68949.4371, Val MAE: 38158.7546, Val MSE: 4754024880.2480, Val R2: 0.7585\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1018\n",
      "Val RMSE: 72495.7029, Val MAE: 38229.8441, Val MSE: 5255626938.3272, Val R2: 0.7330\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1013\n",
      "Val RMSE: 69711.9862, Val MAE: 38955.9723, Val MSE: 4859761025.6385, Val R2: 0.7531\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1147\n",
      "Val RMSE: 76626.1325, Val MAE: 42405.3388, Val MSE: 5871564178.8006, Val R2: 0.7017\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1054\n",
      "Val RMSE: 73504.9722, Val MAE: 40058.5175, Val MSE: 5402980941.8599, Val R2: 0.7255\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1039\n",
      "Val RMSE: 71201.7169, Val MAE: 39120.2191, Val MSE: 5069684489.4202, Val R2: 0.7424\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.0974\n",
      "Val RMSE: 71314.9529, Val MAE: 36814.5815, Val MSE: 5085822513.1951, Val R2: 0.7416\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.0944\n",
      "Val RMSE: 67329.5059, Val MAE: 36213.4062, Val MSE: 4533262362.2200, Val R2: 0.7697\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.0950\n",
      "Val RMSE: 67969.4341, Val MAE: 37211.2257, Val MSE: 4619843973.8121, Val R2: 0.7653\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.0938\n",
      "Val RMSE: 66608.6880, Val MAE: 36640.7081, Val MSE: 4436717313.5245, Val R2: 0.7746\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.0934\n",
      "Val RMSE: 66757.8356, Val MAE: 35917.8412, Val MSE: 4456608615.8334, Val R2: 0.7736\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1012\n",
      "Val RMSE: 69976.3389, Val MAE: 38223.7218, Val MSE: 4896688008.2882, Val R2: 0.7512\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1048\n",
      "Val RMSE: 70733.4297, Val MAE: 37744.7794, Val MSE: 5003218084.1890, Val R2: 0.7458\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1012\n",
      "Val RMSE: 72150.9942, Val MAE: 38177.7557, Val MSE: 5205765960.8151, Val R2: 0.7355\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.0974\n",
      "Val RMSE: 70615.0143, Val MAE: 36671.0622, Val MSE: 4986480244.1382, Val R2: 0.7467\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.0966\n",
      "Val RMSE: 68333.0657, Val MAE: 37624.9157, Val MSE: 4669407866.3761, Val R2: 0.7628\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.0955\n",
      "Val RMSE: 68743.9117, Val MAE: 36369.6618, Val MSE: 4725725390.2539, Val R2: 0.7599\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.0936\n",
      "Val RMSE: 68692.2959, Val MAE: 35896.0062, Val MSE: 4718631517.7720, Val R2: 0.7603\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.0897\n",
      "Val RMSE: 66316.2303, Val MAE: 34829.7538, Val MSE: 4397842396.0515, Val R2: 0.7766\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.0967\n",
      "Val RMSE: 70101.8992, Val MAE: 36004.4720, Val MSE: 4914276268.4318, Val R2: 0.7503\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.0947\n",
      "Val RMSE: 69253.5215, Val MAE: 36035.8248, Val MSE: 4796050234.1001, Val R2: 0.7563\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.0892\n",
      "Val RMSE: 66700.3882, Val MAE: 34945.4549, Val MSE: 4448941791.5802, Val R2: 0.7740\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1014\n",
      "Val RMSE: 74139.6459, Val MAE: 37401.5269, Val MSE: 5496687089.4943, Val R2: 0.7207\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.0929\n",
      "Val RMSE: 67579.7965, Val MAE: 34998.8032, Val MSE: 4567028899.7087, Val R2: 0.7680\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.0912\n",
      "Val RMSE: 68073.0366, Val MAE: 34572.4494, Val MSE: 4633938312.6385, Val R2: 0.7646\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.0908\n",
      "Val RMSE: 67211.3135, Val MAE: 34753.8253, Val MSE: 4517360661.0096, Val R2: 0.7705\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 73059.8286, Test MAE: 39251.6970, Test MSE: 5337738554.6504, Test R2: 0.6578\n",
      "Inference Time: 3.466092623197116e-05 seconds per sample\n",
      "\n",
      "Iteration 70 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3170, Val Loss: 0.2848\n",
      "Val RMSE: 143980.0485, Val MAE: 81697.8025, Val MSE: 20730254360.8733, Val R2: -0.0532\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2761, Val Loss: 0.2756\n",
      "Val RMSE: 141632.0802, Val MAE: 83681.9157, Val MSE: 20059646141.4991, Val R2: -0.0192\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2690, Val Loss: 0.2787\n",
      "Val RMSE: 143351.5084, Val MAE: 81391.4440, Val MSE: 20549654947.4254, Val R2: -0.0441\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2664, Val Loss: 0.2752\n",
      "Val RMSE: 142004.8512, Val MAE: 83148.5373, Val MSE: 20165377761.3121, Val R2: -0.0245\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2646, Val Loss: 0.2756\n",
      "Val RMSE: 141405.5445, Val MAE: 83451.5566, Val MSE: 19995528024.3199, Val R2: -0.0159\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2629, Val Loss: 0.2751\n",
      "Val RMSE: 140784.8677, Val MAE: 84569.6943, Val MSE: 19820378963.3765, Val R2: -0.0070\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2593, Val Loss: 0.2805\n",
      "Val RMSE: 144609.4258, Val MAE: 79399.7967, Val MSE: 20911886038.7912, Val R2: -0.0625\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2586, Val Loss: 0.2840\n",
      "Val RMSE: 141243.7292, Val MAE: 89161.9995, Val MSE: 19949791034.2330, Val R2: -0.0136\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2617, Val Loss: 0.2716\n",
      "Val RMSE: 140679.0083, Val MAE: 83341.8394, Val MSE: 19790583365.2733, Val R2: -0.0055\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2531, Val Loss: 0.2728\n",
      "Val RMSE: 141033.7670, Val MAE: 83689.1282, Val MSE: 19890523429.3506, Val R2: -0.0106\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2546, Val Loss: 0.2752\n",
      "Val RMSE: 142084.9271, Val MAE: 79530.9864, Val MSE: 20188126511.7407, Val R2: -0.0257\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2500, Val Loss: 0.2738\n",
      "Val RMSE: 141624.8238, Val MAE: 82039.6793, Val MSE: 20057590713.7902, Val R2: -0.0191\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2876\n",
      "Val RMSE: 141290.9066, Val MAE: 86077.1776, Val MSE: 19963120295.2780, Val R2: -0.0143\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2442, Val Loss: 0.2630\n",
      "Val RMSE: 140168.5567, Val MAE: 79983.5123, Val MSE: 19647224289.2766, Val R2: 0.0018\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2416, Val Loss: 0.2684\n",
      "Val RMSE: 143195.9652, Val MAE: 77142.2890, Val MSE: 20505084440.8644, Val R2: -0.0418\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2324, Val Loss: 0.2453\n",
      "Val RMSE: 133488.5475, Val MAE: 74591.7937, Val MSE: 17819192324.5069, Val R2: 0.0947\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2258, Val Loss: 0.2306\n",
      "Val RMSE: 131128.8094, Val MAE: 72370.7015, Val MSE: 17194764657.5189, Val R2: 0.1264\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2164, Val Loss: 0.2325\n",
      "Val RMSE: 130058.0976, Val MAE: 76011.1161, Val MSE: 16915108748.4530, Val R2: 0.1406\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2133, Val Loss: 0.2518\n",
      "Val RMSE: 132397.3489, Val MAE: 76197.5993, Val MSE: 17529058002.1031, Val R2: 0.1094\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2085, Val Loss: 0.2468\n",
      "Val RMSE: 138511.1307, Val MAE: 73651.2781, Val MSE: 19185333333.1070, Val R2: 0.0253\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2036, Val Loss: 0.2214\n",
      "Val RMSE: 127726.4467, Val MAE: 70775.0948, Val MSE: 16314045192.2620, Val R2: 0.1711\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1976, Val Loss: 0.2333\n",
      "Val RMSE: 133248.6676, Val MAE: 71691.2453, Val MSE: 17755207414.6016, Val R2: 0.0979\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1898, Val Loss: 0.2075\n",
      "Val RMSE: 121184.5701, Val MAE: 67619.7107, Val MSE: 14685700037.1922, Val R2: 0.2539\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1855, Val Loss: 0.2068\n",
      "Val RMSE: 116797.4145, Val MAE: 67780.8339, Val MSE: 13641636023.0883, Val R2: 0.3069\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1778, Val Loss: 0.1881\n",
      "Val RMSE: 105295.3068, Val MAE: 63604.8873, Val MSE: 11087101634.5662, Val R2: 0.4367\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1728, Val Loss: 0.1807\n",
      "Val RMSE: 101946.9040, Val MAE: 65507.5367, Val MSE: 10393171233.8860, Val R2: 0.4720\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1698, Val Loss: 0.1774\n",
      "Val RMSE: 101563.1917, Val MAE: 61033.1005, Val MSE: 10315081916.2312, Val R2: 0.4759\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1612, Val Loss: 0.1643\n",
      "Val RMSE: 97542.4232, Val MAE: 61662.6036, Val MSE: 9514524330.7239, Val R2: 0.5166\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1600, Val Loss: 0.1728\n",
      "Val RMSE: 100830.8213, Val MAE: 60507.1126, Val MSE: 10166854532.4450, Val R2: 0.4835\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1557, Val Loss: 0.1618\n",
      "Val RMSE: 97860.9113, Val MAE: 59312.4456, Val MSE: 9576757962.9985, Val R2: 0.5134\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1504, Val Loss: 0.1662\n",
      "Val RMSE: 99252.8386, Val MAE: 59525.4176, Val MSE: 9851125963.8779, Val R2: 0.4995\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1789\n",
      "Val RMSE: 100876.3270, Val MAE: 59930.6889, Val MSE: 10176033348.8892, Val R2: 0.4830\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1438, Val Loss: 0.1796\n",
      "Val RMSE: 102950.5447, Val MAE: 58111.7131, Val MSE: 10598814659.5101, Val R2: 0.4615\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1438, Val Loss: 0.1513\n",
      "Val RMSE: 95367.0517, Val MAE: 53233.9402, Val MSE: 9094874553.6811, Val R2: 0.5379\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1395, Val Loss: 0.1466\n",
      "Val RMSE: 93942.0643, Val MAE: 52322.3007, Val MSE: 8825111444.1601, Val R2: 0.5516\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1373, Val Loss: 0.1549\n",
      "Val RMSE: 97211.3001, Val MAE: 54964.0235, Val MSE: 9450036873.0211, Val R2: 0.5199\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.2017\n",
      "Val RMSE: 103269.9901, Val MAE: 60893.5150, Val MSE: 10664690855.7530, Val R2: 0.4582\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1299, Val Loss: 0.1530\n",
      "Val RMSE: 95665.3588, Val MAE: 53207.6651, Val MSE: 9151860868.4085, Val R2: 0.5350\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1234, Val Loss: 0.1387\n",
      "Val RMSE: 91908.8798, Val MAE: 50450.5666, Val MSE: 8447242188.0590, Val R2: 0.5708\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1205, Val Loss: 0.1498\n",
      "Val RMSE: 95638.7093, Val MAE: 53661.2485, Val MSE: 9146762718.9107, Val R2: 0.5353\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1150, Val Loss: 0.1915\n",
      "Val RMSE: 101434.9991, Val MAE: 61719.6196, Val MSE: 10289059048.2710, Val R2: 0.4773\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1127, Val Loss: 0.1550\n",
      "Val RMSE: 95783.1570, Val MAE: 53284.0423, Val MSE: 9174413170.1927, Val R2: 0.5339\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1095, Val Loss: 0.1530\n",
      "Val RMSE: 96502.7579, Val MAE: 53105.1603, Val MSE: 9312782281.5513, Val R2: 0.5269\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1061, Val Loss: 0.1765\n",
      "Val RMSE: 100536.0403, Val MAE: 59348.1786, Val MSE: 10107495406.4386, Val R2: 0.4865\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1029, Val Loss: 0.2041\n",
      "Val RMSE: 104798.9444, Val MAE: 62283.5959, Val MSE: 10982818746.4028, Val R2: 0.4420\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1003, Val Loss: 0.2038\n",
      "Val RMSE: 104565.7287, Val MAE: 62364.5138, Val MSE: 10933991613.2077, Val R2: 0.4445\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1860\n",
      "Val RMSE: 102171.2861, Val MAE: 59147.0448, Val MSE: 10438971693.2892, Val R2: 0.4696\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1431\n",
      "Val RMSE: 93413.9919, Val MAE: 50500.6126, Val MSE: 8726173880.7421, Val R2: 0.5567\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0933, Val Loss: 0.2797\n",
      "Val RMSE: 116190.2192, Val MAE: 73929.4832, Val MSE: 13500167038.0314, Val R2: 0.3141\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0938, Val Loss: 0.1932\n",
      "Val RMSE: 97290.1074, Val MAE: 60947.6401, Val MSE: 9465365007.1572, Val R2: 0.5191\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0886, Val Loss: 0.1687\n",
      "Val RMSE: 94715.4950, Val MAE: 56495.4554, Val MSE: 8971025001.8449, Val R2: 0.5442\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0861, Val Loss: 0.1493\n",
      "Val RMSE: 91108.0019, Val MAE: 52113.1764, Val MSE: 8300668013.0806, Val R2: 0.5783\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0858, Val Loss: 0.1521\n",
      "Val RMSE: 91754.5805, Val MAE: 52862.2511, Val MSE: 8418903037.0244, Val R2: 0.5723\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0827, Val Loss: 0.1502\n",
      "Val RMSE: 88169.2022, Val MAE: 49701.3175, Val MSE: 7773808214.1725, Val R2: 0.6050\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0805, Val Loss: 0.1699\n",
      "Val RMSE: 89282.0043, Val MAE: 54380.6787, Val MSE: 7971276300.4009, Val R2: 0.5950\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0792, Val Loss: 0.1356\n",
      "Val RMSE: 81412.4967, Val MAE: 48586.6816, Val MSE: 6627994614.1934, Val R2: 0.6633\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.2639\n",
      "Val RMSE: 108044.8232, Val MAE: 70469.9918, Val MSE: 11673683811.3418, Val R2: 0.4069\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1384\n",
      "Val RMSE: 78163.3209, Val MAE: 48414.1656, Val MSE: 6109504736.2313, Val R2: 0.6896\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1432\n",
      "Val RMSE: 84750.4796, Val MAE: 49257.4387, Val MSE: 7182643789.2567, Val R2: 0.6351\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1433\n",
      "Val RMSE: 84177.3532, Val MAE: 48539.5548, Val MSE: 7085826796.7474, Val R2: 0.6400\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1491\n",
      "Val RMSE: 82712.4506, Val MAE: 49881.7313, Val MSE: 6841349486.5845, Val R2: 0.6524\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1450\n",
      "Val RMSE: 83142.1762, Val MAE: 48023.8791, Val MSE: 6912621458.0537, Val R2: 0.6488\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1586\n",
      "Val RMSE: 86606.0366, Val MAE: 52665.7945, Val MSE: 7500605577.6834, Val R2: 0.6189\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1674\n",
      "Val RMSE: 87079.3221, Val MAE: 53402.6086, Val MSE: 7582808331.2810, Val R2: 0.6147\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0670, Val Loss: 0.1488\n",
      "Val RMSE: 83690.3333, Val MAE: 50746.6749, Val MSE: 7004071891.3527, Val R2: 0.6441\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.2362\n",
      "Val RMSE: 120995.7102, Val MAE: 65564.3400, Val MSE: 14639961882.3552, Val R2: 0.2562\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1339\n",
      "Val RMSE: 79134.7702, Val MAE: 46912.4340, Val MSE: 6262311853.1261, Val R2: 0.6818\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1536\n",
      "Val RMSE: 87218.1686, Val MAE: 51873.6667, Val MSE: 7607008933.0755, Val R2: 0.6135\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1292\n",
      "Val RMSE: 79569.0091, Val MAE: 46441.7510, Val MSE: 6331227212.5983, Val R2: 0.6783\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.2584\n",
      "Val RMSE: 125332.5428, Val MAE: 69545.3372, Val MSE: 15708246286.3152, Val R2: 0.2019\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1206\n",
      "Val RMSE: 78437.7718, Val MAE: 44854.5638, Val MSE: 6152484044.6982, Val R2: 0.6874\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0611, Val Loss: 0.1296\n",
      "Val RMSE: 81089.2892, Val MAE: 45652.5034, Val MSE: 6575472824.4577, Val R2: 0.6659\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1208\n",
      "Val RMSE: 76506.1409, Val MAE: 45886.1387, Val MSE: 5853189595.4455, Val R2: 0.7026\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1156\n",
      "Val RMSE: 74881.4672, Val MAE: 43606.5616, Val MSE: 5607234130.2163, Val R2: 0.7151\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0642, Val Loss: 0.1361\n",
      "Val RMSE: 84481.1564, Val MAE: 48278.8986, Val MSE: 7137065780.5793, Val R2: 0.6374\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1560\n",
      "Val RMSE: 86874.0066, Val MAE: 51521.3728, Val MSE: 7547093022.2524, Val R2: 0.6166\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0684, Val Loss: 0.1292\n",
      "Val RMSE: 80569.6945, Val MAE: 47133.3197, Val MSE: 6491475664.3340, Val R2: 0.6702\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1827\n",
      "Val RMSE: 88864.2543, Val MAE: 55408.0197, Val MSE: 7896855692.0157, Val R2: 0.5988\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1194\n",
      "Val RMSE: 76581.4164, Val MAE: 44013.8378, Val MSE: 5864713343.3995, Val R2: 0.7020\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1120\n",
      "Val RMSE: 74135.3261, Val MAE: 43152.6949, Val MSE: 5496046579.8226, Val R2: 0.7208\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1215\n",
      "Val RMSE: 76272.4620, Val MAE: 44264.7370, Val MSE: 5817488465.1284, Val R2: 0.7044\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1651\n",
      "Val RMSE: 86725.6732, Val MAE: 52678.8610, Val MSE: 7521342399.2548, Val R2: 0.6179\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1288\n",
      "Val RMSE: 81776.0459, Val MAE: 46777.0873, Val MSE: 6687321687.7615, Val R2: 0.6602\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1197\n",
      "Val RMSE: 76933.0520, Val MAE: 43648.6319, Val MSE: 5918694489.5374, Val R2: 0.6993\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1109\n",
      "Val RMSE: 73319.1910, Val MAE: 41988.3931, Val MSE: 5375703765.3816, Val R2: 0.7269\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1180\n",
      "Val RMSE: 75726.7707, Val MAE: 43421.5851, Val MSE: 5734543797.4287, Val R2: 0.7086\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1162\n",
      "Val RMSE: 75278.6718, Val MAE: 43641.3784, Val MSE: 5666878424.3763, Val R2: 0.7121\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1473\n",
      "Val RMSE: 83222.9565, Val MAE: 49847.5174, Val MSE: 6926060494.7096, Val R2: 0.6481\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1280\n",
      "Val RMSE: 79273.6302, Val MAE: 45416.0534, Val MSE: 6284308449.2174, Val R2: 0.6807\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1245\n",
      "Val RMSE: 79445.1739, Val MAE: 46486.8215, Val MSE: 6311535653.3378, Val R2: 0.6793\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1181\n",
      "Val RMSE: 77056.7567, Val MAE: 43688.4066, Val MSE: 5937743758.3178, Val R2: 0.6983\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1178\n",
      "Val RMSE: 77370.4665, Val MAE: 43944.5950, Val MSE: 5986189093.8307, Val R2: 0.6959\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.4746\n",
      "Val RMSE: 178428.4079, Val MAE: 100844.3047, Val MSE: 31836696747.2352, Val R2: -0.6175\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.1302\n",
      "Val RMSE: 78239.1164, Val MAE: 47602.9553, Val MSE: 6121359337.8679, Val R2: 0.6890\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.2242\n",
      "Val RMSE: 111484.9630, Val MAE: 64710.8337, Val MSE: 12428896982.7197, Val R2: 0.3685\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.2856\n",
      "Val RMSE: 143714.4027, Val MAE: 75097.7209, Val MSE: 20653829542.0663, Val R2: -0.0493\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1227\n",
      "Val RMSE: 76032.2384, Val MAE: 45866.5423, Val MSE: 5780901281.7500, Val R2: 0.7063\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1271\n",
      "Val RMSE: 76927.4646, Val MAE: 46540.5800, Val MSE: 5917834806.7845, Val R2: 0.6993\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1182\n",
      "Val RMSE: 74741.2984, Val MAE: 44215.7064, Val MSE: 5586261689.2875, Val R2: 0.7162\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1145\n",
      "Val RMSE: 74317.3306, Val MAE: 44903.9078, Val MSE: 5523065633.1458, Val R2: 0.7194\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76603.9086, Test MAE: 42321.4758, Test MSE: 5868158813.8784, Test R2: 0.6238\n",
      "Inference Time: 3.344227717472957e-05 seconds per sample\n",
      "\n",
      "Iteration 71 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3853, Val Loss: 0.2768\n",
      "Val RMSE: 140028.2408, Val MAE: 87853.6253, Val MSE: 19607908218.5810, Val R2: 0.0038\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2844, Val Loss: 0.2796\n",
      "Val RMSE: 142980.4571, Val MAE: 81803.2061, Val MSE: 20443411106.7288, Val R2: -0.0387\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2748, Val Loss: 0.2772\n",
      "Val RMSE: 142127.1084, Val MAE: 82673.6126, Val MSE: 20200114934.4350, Val R2: -0.0263\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2705, Val Loss: 0.2786\n",
      "Val RMSE: 142740.5390, Val MAE: 82106.9845, Val MSE: 20374861473.9671, Val R2: -0.0352\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2772\n",
      "Val RMSE: 141623.9551, Val MAE: 84534.7857, Val MSE: 20057344649.2136, Val R2: -0.0190\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2634, Val Loss: 0.2738\n",
      "Val RMSE: 142058.1308, Val MAE: 82622.3720, Val MSE: 20180512516.7151, Val R2: -0.0253\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2714\n",
      "Val RMSE: 141159.1610, Val MAE: 82977.7641, Val MSE: 19925908723.6631, Val R2: -0.0124\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2951\n",
      "Val RMSE: 145406.0064, Val MAE: 81384.5667, Val MSE: 21142906683.0170, Val R2: -0.0742\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2694\n",
      "Val RMSE: 140203.8221, Val MAE: 83863.7774, Val MSE: 19657111745.0422, Val R2: 0.0013\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2806\n",
      "Val RMSE: 144598.8268, Val MAE: 78896.7098, Val MSE: 20908820702.3763, Val R2: -0.0623\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2713\n",
      "Val RMSE: 142002.4821, Val MAE: 79370.4494, Val MSE: 20164704926.0077, Val R2: -0.0245\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2659\n",
      "Val RMSE: 141926.0109, Val MAE: 78310.2097, Val MSE: 20142992578.5862, Val R2: -0.0234\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2480, Val Loss: 0.2615\n",
      "Val RMSE: 139949.5645, Val MAE: 79134.5673, Val MSE: 19585880589.7781, Val R2: 0.0049\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2574\n",
      "Val RMSE: 137156.5861, Val MAE: 78468.9576, Val MSE: 18811929112.3944, Val R2: 0.0442\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2428, Val Loss: 0.2584\n",
      "Val RMSE: 137204.3172, Val MAE: 75820.5906, Val MSE: 18825024660.2551, Val R2: 0.0436\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2396, Val Loss: 0.2519\n",
      "Val RMSE: 135546.6520, Val MAE: 74984.9270, Val MSE: 18372894875.9972, Val R2: 0.0665\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2364, Val Loss: 0.2461\n",
      "Val RMSE: 132873.9131, Val MAE: 77593.8937, Val MSE: 17655476771.6576, Val R2: 0.1030\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2352, Val Loss: 0.2542\n",
      "Val RMSE: 135861.9066, Val MAE: 75184.7114, Val MSE: 18458457677.0927, Val R2: 0.0622\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2317, Val Loss: 0.2514\n",
      "Val RMSE: 133858.2563, Val MAE: 76041.3131, Val MSE: 17918032788.3713, Val R2: 0.0897\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2294, Val Loss: 0.2539\n",
      "Val RMSE: 130872.6194, Val MAE: 79239.7877, Val MSE: 17127642521.1062, Val R2: 0.1298\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2172, Val Loss: 0.2344\n",
      "Val RMSE: 130881.4585, Val MAE: 72963.2653, Val MSE: 17129956184.6264, Val R2: 0.1297\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2367\n",
      "Val RMSE: 132913.1073, Val MAE: 72523.2643, Val MSE: 17665894095.9669, Val R2: 0.1025\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2130, Val Loss: 0.2475\n",
      "Val RMSE: 135804.2568, Val MAE: 72733.1210, Val MSE: 18442796157.0713, Val R2: 0.0630\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2174, Val Loss: 0.2418\n",
      "Val RMSE: 133840.2783, Val MAE: 75412.1343, Val MSE: 17913220084.1074, Val R2: 0.0899\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2148, Val Loss: 0.2340\n",
      "Val RMSE: 131314.5581, Val MAE: 73342.9874, Val MSE: 17243513170.6961, Val R2: 0.1239\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2116, Val Loss: 0.2341\n",
      "Val RMSE: 131855.1080, Val MAE: 74920.5187, Val MSE: 17385769518.5709, Val R2: 0.1167\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2105, Val Loss: 0.2599\n",
      "Val RMSE: 139237.6245, Val MAE: 76193.1604, Val MSE: 19387116075.4986, Val R2: 0.0150\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2084, Val Loss: 0.2355\n",
      "Val RMSE: 133340.7340, Val MAE: 72855.4947, Val MSE: 17779751354.8527, Val R2: 0.0967\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2366\n",
      "Val RMSE: 132761.4796, Val MAE: 70925.0796, Val MSE: 17625610464.5311, Val R2: 0.1045\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2010, Val Loss: 0.2216\n",
      "Val RMSE: 128125.6723, Val MAE: 68664.6623, Val MSE: 16416187899.2907, Val R2: 0.1660\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1976, Val Loss: 0.2203\n",
      "Val RMSE: 123226.7922, Val MAE: 71264.9459, Val MSE: 15184842315.2829, Val R2: 0.2285\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2009, Val Loss: 0.2573\n",
      "Val RMSE: 133060.5909, Val MAE: 71575.4932, Val MSE: 17705120860.9652, Val R2: 0.1005\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.2122, Val Loss: 0.2652\n",
      "Val RMSE: 135026.3326, Val MAE: 73517.3119, Val MSE: 18232110499.7538, Val R2: 0.0737\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.2032, Val Loss: 0.2168\n",
      "Val RMSE: 122489.8740, Val MAE: 68942.3419, Val MSE: 15003769223.4523, Val R2: 0.2377\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2037\n",
      "Val RMSE: 114600.9088, Val MAE: 67019.5940, Val MSE: 13133368296.4824, Val R2: 0.3327\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1794, Val Loss: 0.1927\n",
      "Val RMSE: 109963.9350, Val MAE: 64740.4085, Val MSE: 12092066998.8707, Val R2: 0.3856\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1733, Val Loss: 0.1916\n",
      "Val RMSE: 108707.6879, Val MAE: 64015.3271, Val MSE: 11817361418.3608, Val R2: 0.3996\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1746, Val Loss: 0.2017\n",
      "Val RMSE: 110526.8834, Val MAE: 63625.5254, Val MSE: 12216191943.8605, Val R2: 0.3793\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1732, Val Loss: 0.1873\n",
      "Val RMSE: 106688.9462, Val MAE: 62379.1035, Val MSE: 11382531239.6458, Val R2: 0.4217\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1691, Val Loss: 0.1809\n",
      "Val RMSE: 103988.6101, Val MAE: 60463.7446, Val MSE: 10813631029.9530, Val R2: 0.4506\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1665, Val Loss: 0.1861\n",
      "Val RMSE: 105896.2359, Val MAE: 63096.2130, Val MSE: 11214012787.5916, Val R2: 0.4303\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1679, Val Loss: 0.1764\n",
      "Val RMSE: 101893.8773, Val MAE: 61778.7733, Val MSE: 10382362221.0766, Val R2: 0.4725\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1630, Val Loss: 0.1771\n",
      "Val RMSE: 102379.6457, Val MAE: 60176.0478, Val MSE: 10481591856.0572, Val R2: 0.4675\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1627, Val Loss: 0.1730\n",
      "Val RMSE: 100898.7356, Val MAE: 59421.4148, Val MSE: 10180554845.6410, Val R2: 0.4828\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1605, Val Loss: 0.1757\n",
      "Val RMSE: 103766.6485, Val MAE: 59307.9036, Val MSE: 10767517348.7118, Val R2: 0.4529\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1601, Val Loss: 0.1826\n",
      "Val RMSE: 104227.9058, Val MAE: 59424.7589, Val MSE: 10863456348.3487, Val R2: 0.4481\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1583, Val Loss: 0.1655\n",
      "Val RMSE: 99808.9110, Val MAE: 58667.7303, Val MSE: 9961818718.4586, Val R2: 0.4939\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1512, Val Loss: 0.1711\n",
      "Val RMSE: 101998.0466, Val MAE: 58884.6232, Val MSE: 10403601508.6942, Val R2: 0.4714\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1478, Val Loss: 0.1647\n",
      "Val RMSE: 99343.5065, Val MAE: 57955.7414, Val MSE: 9869132290.4897, Val R2: 0.4986\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1464, Val Loss: 0.1698\n",
      "Val RMSE: 100663.0297, Val MAE: 58490.6213, Val MSE: 10133045541.8108, Val R2: 0.4852\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1449, Val Loss: 0.1703\n",
      "Val RMSE: 101339.2706, Val MAE: 57058.1346, Val MSE: 10269647768.7677, Val R2: 0.4782\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1443, Val Loss: 0.1564\n",
      "Val RMSE: 96836.0485, Val MAE: 56923.0970, Val MSE: 9377220287.7424, Val R2: 0.5236\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1567\n",
      "Val RMSE: 96989.5282, Val MAE: 55673.7929, Val MSE: 9406968586.7264, Val R2: 0.5221\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1533\n",
      "Val RMSE: 94254.1049, Val MAE: 55222.3489, Val MSE: 8883836298.4539, Val R2: 0.5486\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1427, Val Loss: 0.1542\n",
      "Val RMSE: 96250.5946, Val MAE: 55741.4977, Val MSE: 9264176959.6644, Val R2: 0.5293\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1548\n",
      "Val RMSE: 96818.8533, Val MAE: 55266.4485, Val MSE: 9373890349.0192, Val R2: 0.5237\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1344, Val Loss: 0.1426\n",
      "Val RMSE: 93152.9790, Val MAE: 53148.4740, Val MSE: 8677477502.6882, Val R2: 0.5591\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1325, Val Loss: 0.1470\n",
      "Val RMSE: 93679.7010, Val MAE: 55399.5838, Val MSE: 8775886378.6039, Val R2: 0.5541\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1320, Val Loss: 0.1461\n",
      "Val RMSE: 94499.4593, Val MAE: 51318.1025, Val MSE: 8930147800.0882, Val R2: 0.5463\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1240, Val Loss: 0.1399\n",
      "Val RMSE: 92416.5693, Val MAE: 50219.8770, Val MSE: 8540822285.3509, Val R2: 0.5661\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1430\n",
      "Val RMSE: 91967.5260, Val MAE: 53458.6417, Val MSE: 8458025835.7565, Val R2: 0.5703\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1163, Val Loss: 0.1463\n",
      "Val RMSE: 93475.2588, Val MAE: 53297.3764, Val MSE: 8737624011.7339, Val R2: 0.5561\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1136, Val Loss: 0.1422\n",
      "Val RMSE: 92518.1862, Val MAE: 51054.8549, Val MSE: 8559614780.1156, Val R2: 0.5651\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1119, Val Loss: 0.1395\n",
      "Val RMSE: 91436.5121, Val MAE: 51897.7851, Val MSE: 8360635753.7177, Val R2: 0.5752\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1087, Val Loss: 0.1436\n",
      "Val RMSE: 92663.2798, Val MAE: 51011.0216, Val MSE: 8586483419.6579, Val R2: 0.5638\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1047, Val Loss: 0.1454\n",
      "Val RMSE: 92360.0036, Val MAE: 54614.6555, Val MSE: 8530370266.6054, Val R2: 0.5666\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.1030, Val Loss: 0.1473\n",
      "Val RMSE: 93360.9703, Val MAE: 53832.8878, Val MSE: 8716270781.4950, Val R2: 0.5572\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.1025, Val Loss: 0.1456\n",
      "Val RMSE: 92695.9048, Val MAE: 50220.6644, Val MSE: 8592530772.5557, Val R2: 0.5634\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1466\n",
      "Val RMSE: 91356.2685, Val MAE: 54197.2821, Val MSE: 8345967793.5836, Val R2: 0.5760\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0988, Val Loss: 0.1455\n",
      "Val RMSE: 92916.2322, Val MAE: 52876.2456, Val MSE: 8633426212.9679, Val R2: 0.5614\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0971, Val Loss: 0.1407\n",
      "Val RMSE: 91000.8416, Val MAE: 53254.3606, Val MSE: 8281153168.9505, Val R2: 0.5793\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0958, Val Loss: 0.1493\n",
      "Val RMSE: 93147.0211, Val MAE: 54263.6676, Val MSE: 8676367533.1677, Val R2: 0.5592\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0929, Val Loss: 0.1353\n",
      "Val RMSE: 89279.3006, Val MAE: 49291.7983, Val MSE: 7970793516.8330, Val R2: 0.5950\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1446\n",
      "Val RMSE: 91615.9915, Val MAE: 53050.6922, Val MSE: 8393489897.7268, Val R2: 0.5736\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0933, Val Loss: 0.1606\n",
      "Val RMSE: 95432.8605, Val MAE: 60590.3682, Val MSE: 9107430866.3474, Val R2: 0.5373\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0895, Val Loss: 0.1397\n",
      "Val RMSE: 89684.4474, Val MAE: 50704.9381, Val MSE: 8043300108.3218, Val R2: 0.5913\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1547\n",
      "Val RMSE: 93144.9515, Val MAE: 55755.2988, Val MSE: 8675981986.1477, Val R2: 0.5592\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1456\n",
      "Val RMSE: 90551.9625, Val MAE: 54139.3541, Val MSE: 8199657908.2336, Val R2: 0.5834\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1589\n",
      "Val RMSE: 92810.1361, Val MAE: 55168.5994, Val MSE: 8613721360.0557, Val R2: 0.5624\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1440\n",
      "Val RMSE: 90027.9195, Val MAE: 52748.1856, Val MSE: 8105026291.2958, Val R2: 0.5882\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0826, Val Loss: 0.1468\n",
      "Val RMSE: 90563.1912, Val MAE: 52979.2068, Val MSE: 8201691607.8418, Val R2: 0.5833\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1472\n",
      "Val RMSE: 91292.5574, Val MAE: 53373.8417, Val MSE: 8334331043.8441, Val R2: 0.5766\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0787, Val Loss: 0.1445\n",
      "Val RMSE: 88425.7040, Val MAE: 50530.7413, Val MSE: 7819105121.1121, Val R2: 0.6027\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0783, Val Loss: 0.1431\n",
      "Val RMSE: 88478.1713, Val MAE: 50360.9480, Val MSE: 7828386788.0870, Val R2: 0.6023\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1423\n",
      "Val RMSE: 88079.2129, Val MAE: 53420.9376, Val MSE: 7757947747.9318, Val R2: 0.6058\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1505\n",
      "Val RMSE: 91666.5370, Val MAE: 51846.5612, Val MSE: 8402753997.0718, Val R2: 0.5731\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1427\n",
      "Val RMSE: 88874.4297, Val MAE: 49919.8985, Val MSE: 7898664254.5744, Val R2: 0.5987\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1510\n",
      "Val RMSE: 90627.9498, Val MAE: 50171.7678, Val MSE: 8213425291.2582, Val R2: 0.5827\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1410\n",
      "Val RMSE: 87361.5969, Val MAE: 50267.4145, Val MSE: 7632048612.6219, Val R2: 0.6122\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1337\n",
      "Val RMSE: 84417.6984, Val MAE: 50066.4364, Val MSE: 7126347806.4686, Val R2: 0.6379\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1645\n",
      "Val RMSE: 91661.2375, Val MAE: 51653.3381, Val MSE: 8401782457.0715, Val R2: 0.5731\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1545\n",
      "Val RMSE: 88479.4284, Val MAE: 49625.6922, Val MSE: 7828609246.4407, Val R2: 0.6023\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1338\n",
      "Val RMSE: 82778.0022, Val MAE: 52198.8259, Val MSE: 6852197649.8517, Val R2: 0.6519\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1574\n",
      "Val RMSE: 91930.0619, Val MAE: 52440.9360, Val MSE: 8451136286.9670, Val R2: 0.5706\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1367\n",
      "Val RMSE: 87044.2282, Val MAE: 48522.5483, Val MSE: 7576697658.7373, Val R2: 0.6151\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1293\n",
      "Val RMSE: 82135.8573, Val MAE: 48127.1884, Val MSE: 6746299054.1532, Val R2: 0.6572\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1514\n",
      "Val RMSE: 87738.1378, Val MAE: 53534.0331, Val MSE: 7697980825.6764, Val R2: 0.6089\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1296\n",
      "Val RMSE: 81606.6837, Val MAE: 48770.6964, Val MSE: 6659650820.0179, Val R2: 0.6616\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1358\n",
      "Val RMSE: 84350.8527, Val MAE: 50961.2744, Val MSE: 7115066359.6122, Val R2: 0.6385\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1331\n",
      "Val RMSE: 82440.5113, Val MAE: 49473.4356, Val MSE: 6796437900.1107, Val R2: 0.6547\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 89311.3363, Test MAE: 52166.4619, Test MSE: 7976514798.0395, Test R2: 0.4887\n",
      "Inference Time: 2.4880482600285457e-05 seconds per sample\n",
      "\n",
      "Iteration 72 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4005, Val Loss: 0.2967\n",
      "Val RMSE: 145560.9040, Val MAE: 83169.8350, Val MSE: 21187976775.7925, Val R2: -0.0765\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2839, Val Loss: 0.2866\n",
      "Val RMSE: 142632.7250, Val MAE: 85211.3572, Val MSE: 20344094248.4272, Val R2: -0.0336\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2782, Val Loss: 0.2851\n",
      "Val RMSE: 142045.4995, Val MAE: 86081.5181, Val MSE: 20176923929.3678, Val R2: -0.0251\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2762, Val Loss: 0.2863\n",
      "Val RMSE: 142540.0896, Val MAE: 85304.2951, Val MSE: 20317677149.8919, Val R2: -0.0323\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2739, Val Loss: 0.2848\n",
      "Val RMSE: 142001.0589, Val MAE: 86071.4669, Val MSE: 20164300736.6863, Val R2: -0.0245\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2757, Val Loss: 0.2864\n",
      "Val RMSE: 142745.3719, Val MAE: 84825.9539, Val MSE: 20376241199.0467, Val R2: -0.0352\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2716, Val Loss: 0.2780\n",
      "Val RMSE: 142224.2315, Val MAE: 82786.6144, Val MSE: 20227732013.5203, Val R2: -0.0277\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2675, Val Loss: 0.2748\n",
      "Val RMSE: 140425.2957, Val MAE: 85759.7191, Val MSE: 19719263679.3060, Val R2: -0.0019\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2638, Val Loss: 0.2762\n",
      "Val RMSE: 141305.2768, Val MAE: 85166.7752, Val MSE: 19967181239.1775, Val R2: -0.0145\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2615, Val Loss: 0.2734\n",
      "Val RMSE: 141036.0001, Val MAE: 84365.5480, Val MSE: 19891153324.6658, Val R2: -0.0106\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2569, Val Loss: 0.2786\n",
      "Val RMSE: 140765.4397, Val MAE: 87414.9665, Val MSE: 19814909005.6928, Val R2: -0.0067\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2552, Val Loss: 0.2758\n",
      "Val RMSE: 142063.8958, Val MAE: 81954.3904, Val MSE: 20182150481.2965, Val R2: -0.0254\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2548, Val Loss: 0.2719\n",
      "Val RMSE: 141492.9634, Val MAE: 82925.2580, Val MSE: 20020258694.0339, Val R2: -0.0172\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2712\n",
      "Val RMSE: 142538.5589, Val MAE: 79102.5794, Val MSE: 20317240761.9552, Val R2: -0.0322\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2501, Val Loss: 0.2667\n",
      "Val RMSE: 140911.9951, Val MAE: 80965.0699, Val MSE: 19856190359.7233, Val R2: -0.0088\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2478, Val Loss: 0.2640\n",
      "Val RMSE: 139759.7433, Val MAE: 80172.8617, Val MSE: 19532785842.1273, Val R2: 0.0076\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2410, Val Loss: 0.2637\n",
      "Val RMSE: 134987.2310, Val MAE: 82459.1959, Val MSE: 18221552521.5822, Val R2: 0.0742\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2408, Val Loss: 0.2609\n",
      "Val RMSE: 133698.9125, Val MAE: 84001.8476, Val MSE: 17875399196.1568, Val R2: 0.0918\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2375, Val Loss: 0.2494\n",
      "Val RMSE: 134994.7825, Val MAE: 79283.0594, Val MSE: 18223591290.6185, Val R2: 0.0741\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2264, Val Loss: 0.2347\n",
      "Val RMSE: 130786.1597, Val MAE: 78037.3273, Val MSE: 17105019577.3873, Val R2: 0.1310\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2188, Val Loss: 0.2283\n",
      "Val RMSE: 129555.0997, Val MAE: 74047.5094, Val MSE: 16784523858.1494, Val R2: 0.1472\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2157, Val Loss: 0.2292\n",
      "Val RMSE: 131149.2959, Val MAE: 72175.2171, Val MSE: 17200137806.5491, Val R2: 0.1261\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2123, Val Loss: 0.2298\n",
      "Val RMSE: 132088.6905, Val MAE: 71072.6194, Val MSE: 17447422162.9052, Val R2: 0.1136\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2139, Val Loss: 0.2300\n",
      "Val RMSE: 131233.8219, Val MAE: 72345.8292, Val MSE: 17222316005.7878, Val R2: 0.1250\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2153, Val Loss: 0.2273\n",
      "Val RMSE: 129967.8680, Val MAE: 72030.9001, Val MSE: 16891646711.0971, Val R2: 0.1418\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2073, Val Loss: 0.2322\n",
      "Val RMSE: 129033.3477, Val MAE: 74094.6402, Val MSE: 16649604819.4786, Val R2: 0.1541\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2410\n",
      "Val RMSE: 127605.1221, Val MAE: 72044.4982, Val MSE: 16283067179.3782, Val R2: 0.1727\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2403\n",
      "Val RMSE: 128073.0006, Val MAE: 72353.4909, Val MSE: 16402693492.8491, Val R2: 0.1666\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1985, Val Loss: 0.2174\n",
      "Val RMSE: 122131.6832, Val MAE: 67978.0360, Val MSE: 14916148049.8767, Val R2: 0.2422\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1924, Val Loss: 0.2113\n",
      "Val RMSE: 122710.0930, Val MAE: 66790.2347, Val MSE: 15057766934.2938, Val R2: 0.2350\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1886, Val Loss: 0.2079\n",
      "Val RMSE: 114871.1151, Val MAE: 67664.7070, Val MSE: 13195373075.2819, Val R2: 0.3296\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2039\n",
      "Val RMSE: 115427.9650, Val MAE: 67517.1202, Val MSE: 13323615112.9560, Val R2: 0.3231\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1823, Val Loss: 0.1882\n",
      "Val RMSE: 107932.7182, Val MAE: 64626.9529, Val MSE: 11649471658.5113, Val R2: 0.4081\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1745, Val Loss: 0.1726\n",
      "Val RMSE: 104973.0940, Val MAE: 61367.8485, Val MSE: 11019350465.7941, Val R2: 0.4401\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1686, Val Loss: 0.1693\n",
      "Val RMSE: 103809.1262, Val MAE: 58354.2123, Val MSE: 10776334689.6853, Val R2: 0.4525\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1615, Val Loss: 0.1499\n",
      "Val RMSE: 95086.0434, Val MAE: 56996.1779, Val MSE: 9041355647.2448, Val R2: 0.5406\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1566\n",
      "Val RMSE: 97024.7596, Val MAE: 57733.4076, Val MSE: 9413803983.9428, Val R2: 0.5217\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1468\n",
      "Val RMSE: 94277.5866, Val MAE: 55109.5105, Val MSE: 8888263335.6705, Val R2: 0.5484\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1455, Val Loss: 0.1533\n",
      "Val RMSE: 94769.3240, Val MAE: 57830.4288, Val MSE: 8981224780.0542, Val R2: 0.5437\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1429, Val Loss: 0.1418\n",
      "Val RMSE: 92422.9994, Val MAE: 53841.9463, Val MSE: 8542010817.2481, Val R2: 0.5660\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1390, Val Loss: 0.1453\n",
      "Val RMSE: 94402.9597, Val MAE: 53090.8617, Val MSE: 8911918795.0335, Val R2: 0.5472\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1360, Val Loss: 0.1395\n",
      "Val RMSE: 93138.1496, Val MAE: 52136.1491, Val MSE: 8674714911.3354, Val R2: 0.5593\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1362, Val Loss: 0.2034\n",
      "Val RMSE: 101153.8326, Val MAE: 65447.6254, Val MSE: 10232097843.2278, Val R2: 0.4801\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1312, Val Loss: 0.1320\n",
      "Val RMSE: 89688.1701, Val MAE: 52600.2990, Val MSE: 8043967859.6286, Val R2: 0.5913\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1230, Val Loss: 0.1297\n",
      "Val RMSE: 89371.1070, Val MAE: 49628.0481, Val MSE: 7987194766.0699, Val R2: 0.5942\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1178, Val Loss: 0.1234\n",
      "Val RMSE: 88470.6735, Val MAE: 47715.2768, Val MSE: 7827060078.2982, Val R2: 0.6023\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1155, Val Loss: 0.1274\n",
      "Val RMSE: 89617.6553, Val MAE: 49291.4421, Val MSE: 8031324149.5182, Val R2: 0.5920\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1158, Val Loss: 0.1279\n",
      "Val RMSE: 89223.3727, Val MAE: 49460.9970, Val MSE: 7960810234.5093, Val R2: 0.5955\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1127, Val Loss: 0.1337\n",
      "Val RMSE: 91162.9923, Val MAE: 49317.1161, Val MSE: 8310691165.1057, Val R2: 0.5778\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1115, Val Loss: 0.1431\n",
      "Val RMSE: 93045.8377, Val MAE: 56023.9554, Val MSE: 8657527915.7768, Val R2: 0.5601\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1287\n",
      "Val RMSE: 89521.7136, Val MAE: 49871.4228, Val MSE: 8014137210.6405, Val R2: 0.5928\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1269\n",
      "Val RMSE: 89663.2809, Val MAE: 48180.9461, Val MSE: 8039503936.6621, Val R2: 0.5915\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1039, Val Loss: 0.1226\n",
      "Val RMSE: 87013.1448, Val MAE: 47015.3865, Val MSE: 7571287371.5770, Val R2: 0.6153\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1299\n",
      "Val RMSE: 90712.7535, Val MAE: 48078.5235, Val MSE: 8228803648.5792, Val R2: 0.5819\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1276\n",
      "Val RMSE: 88606.9058, Val MAE: 48032.5715, Val MSE: 7851183759.5767, Val R2: 0.6011\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1280\n",
      "Val RMSE: 83618.4458, Val MAE: 53220.4807, Val MSE: 6992044480.4114, Val R2: 0.6448\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0973, Val Loss: 0.1368\n",
      "Val RMSE: 90889.0207, Val MAE: 51029.6022, Val MSE: 8260814081.8046, Val R2: 0.5803\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1160\n",
      "Val RMSE: 81221.0524, Val MAE: 45961.7292, Val MSE: 6596859348.9546, Val R2: 0.6648\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0896, Val Loss: 0.1331\n",
      "Val RMSE: 87992.6334, Val MAE: 49608.5682, Val MSE: 7742703540.6469, Val R2: 0.6066\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0864, Val Loss: 0.1176\n",
      "Val RMSE: 81957.5814, Val MAE: 45183.7870, Val MSE: 6717045152.8319, Val R2: 0.6587\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0837, Val Loss: 0.1208\n",
      "Val RMSE: 82356.7313, Val MAE: 47771.6683, Val MSE: 6782631191.3950, Val R2: 0.6554\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0862, Val Loss: 0.1219\n",
      "Val RMSE: 82766.4168, Val MAE: 46156.9305, Val MSE: 6850279751.4895, Val R2: 0.6520\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1039\n",
      "Val RMSE: 75979.7056, Val MAE: 41764.3028, Val MSE: 5772915664.0856, Val R2: 0.7067\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1162\n",
      "Val RMSE: 80995.1972, Val MAE: 46854.2418, Val MSE: 6560221966.5478, Val R2: 0.6667\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0764, Val Loss: 0.1185\n",
      "Val RMSE: 79544.9738, Val MAE: 46513.5342, Val MSE: 6327402857.1358, Val R2: 0.6785\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1111\n",
      "Val RMSE: 76941.9787, Val MAE: 44690.6691, Val MSE: 5920068079.8348, Val R2: 0.6992\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0748, Val Loss: 0.1173\n",
      "Val RMSE: 78786.0389, Val MAE: 46702.2170, Val MSE: 6207239921.4203, Val R2: 0.6846\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1111\n",
      "Val RMSE: 77063.8962, Val MAE: 41773.3080, Val MSE: 5938844105.1404, Val R2: 0.6983\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1162\n",
      "Val RMSE: 77893.0686, Val MAE: 46901.3744, Val MSE: 6067330142.7209, Val R2: 0.6917\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1117\n",
      "Val RMSE: 78068.6711, Val MAE: 44472.7429, Val MSE: 6094717410.8402, Val R2: 0.6903\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1133\n",
      "Val RMSE: 78930.8733, Val MAE: 43086.4637, Val MSE: 6230082754.3450, Val R2: 0.6835\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1192\n",
      "Val RMSE: 77727.3902, Val MAE: 43359.5576, Val MSE: 6041547184.1785, Val R2: 0.6931\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1124\n",
      "Val RMSE: 78669.2999, Val MAE: 47063.5097, Val MSE: 6188858749.6404, Val R2: 0.6856\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1150\n",
      "Val RMSE: 79257.6229, Val MAE: 43609.8004, Val MSE: 6281770791.8167, Val R2: 0.6808\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0626, Val Loss: 0.1084\n",
      "Val RMSE: 75276.6914, Val MAE: 43874.9186, Val MSE: 5666580262.0173, Val R2: 0.7121\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1172\n",
      "Val RMSE: 78441.0901, Val MAE: 44981.9750, Val MSE: 6153004614.9949, Val R2: 0.6874\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1050\n",
      "Val RMSE: 74410.4650, Val MAE: 42922.7947, Val MSE: 5536917300.7152, Val R2: 0.7187\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1095\n",
      "Val RMSE: 73762.1340, Val MAE: 44795.2324, Val MSE: 5440852412.3926, Val R2: 0.7236\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0588, Val Loss: 0.1050\n",
      "Val RMSE: 73000.0883, Val MAE: 43859.0668, Val MSE: 5329012896.3794, Val R2: 0.7293\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0579, Val Loss: 0.0981\n",
      "Val RMSE: 70702.7477, Val MAE: 39737.1835, Val MSE: 4998878532.4598, Val R2: 0.7460\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1074\n",
      "Val RMSE: 73624.9068, Val MAE: 40397.6808, Val MSE: 5420626899.5000, Val R2: 0.7246\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1107\n",
      "Val RMSE: 74887.8293, Val MAE: 44950.3648, Val MSE: 5608186977.3963, Val R2: 0.7151\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1017\n",
      "Val RMSE: 74118.3923, Val MAE: 40866.8747, Val MSE: 5493536073.6390, Val R2: 0.7209\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1191\n",
      "Val RMSE: 76512.6664, Val MAE: 47253.9687, Val MSE: 5854188122.0246, Val R2: 0.7026\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.0946\n",
      "Val RMSE: 69617.8604, Val MAE: 39768.1500, Val MSE: 4846646492.6979, Val R2: 0.7538\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1045\n",
      "Val RMSE: 74832.1236, Val MAE: 41249.4544, Val MSE: 5599846715.2142, Val R2: 0.7155\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1070\n",
      "Val RMSE: 73718.5326, Val MAE: 41506.0177, Val MSE: 5434422052.8794, Val R2: 0.7239\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1332\n",
      "Val RMSE: 92756.8892, Val MAE: 47166.6490, Val MSE: 8603840492.4051, Val R2: 0.5629\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.1007, Val Loss: 0.1166\n",
      "Val RMSE: 80905.0548, Val MAE: 46171.2589, Val MSE: 6545627885.9811, Val R2: 0.6674\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1226\n",
      "Val RMSE: 79258.8214, Val MAE: 49685.0313, Val MSE: 6281960771.2590, Val R2: 0.6808\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0639, Val Loss: 0.1149\n",
      "Val RMSE: 76309.9448, Val MAE: 45769.3661, Val MSE: 5823207671.7543, Val R2: 0.7041\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1103\n",
      "Val RMSE: 75337.9485, Val MAE: 46043.8156, Val MSE: 5675806490.3560, Val R2: 0.7116\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1045\n",
      "Val RMSE: 73416.0030, Val MAE: 43696.3247, Val MSE: 5389909495.0381, Val R2: 0.7262\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1090\n",
      "Val RMSE: 75218.1965, Val MAE: 43944.3687, Val MSE: 5657777085.8983, Val R2: 0.7125\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1151\n",
      "Val RMSE: 77464.2075, Val MAE: 45948.6109, Val MSE: 6000703437.5498, Val R2: 0.6951\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1084\n",
      "Val RMSE: 74893.9584, Val MAE: 44143.2178, Val MSE: 5609105003.7879, Val R2: 0.7150\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1236\n",
      "Val RMSE: 80901.0025, Val MAE: 49433.4820, Val MSE: 6544972202.9464, Val R2: 0.6675\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1094\n",
      "Val RMSE: 76537.6419, Val MAE: 43600.0234, Val MSE: 5858010631.8789, Val R2: 0.7024\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1136\n",
      "Val RMSE: 77200.9207, Val MAE: 46174.0352, Val MSE: 5959982161.8706, Val R2: 0.6972\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1033\n",
      "Val RMSE: 74327.2947, Val MAE: 41663.8820, Val MSE: 5524546740.2403, Val R2: 0.7193\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 175197.7825, Test MAE: 79999.2117, Test MSE: 30694262979.2703, Test R2: -0.9675\n",
      "Inference Time: 3.5909616030179536e-05 seconds per sample\n",
      "\n",
      "Iteration 73 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3326, Val Loss: 0.2852\n",
      "Val RMSE: 142887.4899, Val MAE: 84113.5086, Val MSE: 20416834759.6117, Val R2: -0.0373\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2770, Val Loss: 0.2761\n",
      "Val RMSE: 141331.7466, Val MAE: 84454.5863, Val MSE: 19974662606.4092, Val R2: -0.0148\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2713, Val Loss: 0.2744\n",
      "Val RMSE: 142062.7204, Val MAE: 82739.4259, Val MSE: 20181816517.4745, Val R2: -0.0254\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2657, Val Loss: 0.2722\n",
      "Val RMSE: 141882.7658, Val MAE: 83151.2328, Val MSE: 20130719237.6394, Val R2: -0.0228\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2625, Val Loss: 0.2966\n",
      "Val RMSE: 143299.8808, Val MAE: 90987.6301, Val MSE: 20534855847.8616, Val R2: -0.0433\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2616, Val Loss: 0.2746\n",
      "Val RMSE: 140122.8454, Val MAE: 86557.6845, Val MSE: 19634411809.7332, Val R2: 0.0024\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2721\n",
      "Val RMSE: 141331.5828, Val MAE: 82875.9322, Val MSE: 19974616308.8955, Val R2: -0.0148\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2562, Val Loss: 0.2689\n",
      "Val RMSE: 141029.3229, Val MAE: 81910.9000, Val MSE: 19889269918.5417, Val R2: -0.0105\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2707\n",
      "Val RMSE: 141436.8858, Val MAE: 80340.2346, Val MSE: 20004392660.6140, Val R2: -0.0163\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2514, Val Loss: 0.2733\n",
      "Val RMSE: 142516.4610, Val MAE: 79247.9636, Val MSE: 20310941657.3809, Val R2: -0.0319\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2696\n",
      "Val RMSE: 139113.4538, Val MAE: 82666.2380, Val MSE: 19352553027.3439, Val R2: 0.0168\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2439, Val Loss: 0.2576\n",
      "Val RMSE: 137819.5015, Val MAE: 75125.4670, Val MSE: 18994214986.2998, Val R2: 0.0350\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2411, Val Loss: 0.2522\n",
      "Val RMSE: 134972.7236, Val MAE: 77802.3955, Val MSE: 18217636129.0672, Val R2: 0.0744\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2294, Val Loss: 0.2386\n",
      "Val RMSE: 131893.7475, Val MAE: 73580.8061, Val MSE: 17395960621.1677, Val R2: 0.1162\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2200, Val Loss: 0.2337\n",
      "Val RMSE: 130819.9550, Val MAE: 74940.0480, Val MSE: 17113860624.9977, Val R2: 0.1305\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2181, Val Loss: 0.2503\n",
      "Val RMSE: 137818.6509, Val MAE: 74132.4286, Val MSE: 18993980546.2979, Val R2: 0.0350\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2169, Val Loss: 0.2338\n",
      "Val RMSE: 131438.3580, Val MAE: 73196.3353, Val MSE: 17276041963.4966, Val R2: 0.1223\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2345\n",
      "Val RMSE: 132155.6343, Val MAE: 72674.4086, Val MSE: 17465111686.7262, Val R2: 0.1127\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2131, Val Loss: 0.2348\n",
      "Val RMSE: 128147.0597, Val MAE: 77675.4819, Val MSE: 16421668911.1941, Val R2: 0.1657\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2096, Val Loss: 0.2256\n",
      "Val RMSE: 129205.8868, Val MAE: 71070.5021, Val MSE: 16694161184.6564, Val R2: 0.1518\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2080, Val Loss: 0.2170\n",
      "Val RMSE: 126585.9561, Val MAE: 69740.5512, Val MSE: 16024004286.8015, Val R2: 0.1859\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2045, Val Loss: 0.2210\n",
      "Val RMSE: 126010.0873, Val MAE: 70570.8041, Val MSE: 15878542093.2490, Val R2: 0.1933\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2957, Val Loss: 0.2812\n",
      "Val RMSE: 138105.7008, Val MAE: 88891.3873, Val MSE: 19073184580.2979, Val R2: 0.0310\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2667, Val Loss: 0.2695\n",
      "Val RMSE: 139131.1185, Val MAE: 81533.9221, Val MSE: 19357468138.2712, Val R2: 0.0165\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2616, Val Loss: 0.2739\n",
      "Val RMSE: 140901.4545, Val MAE: 80663.2719, Val MSE: 19853219881.1018, Val R2: -0.0087\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2694\n",
      "Val RMSE: 139421.0478, Val MAE: 81247.2581, Val MSE: 19438228562.1768, Val R2: 0.0124\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2728\n",
      "Val RMSE: 140658.2530, Val MAE: 80109.5070, Val MSE: 19784744142.1261, Val R2: -0.0052\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2661\n",
      "Val RMSE: 137468.8351, Val MAE: 79229.8732, Val MSE: 18897680616.8542, Val R2: 0.0399\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2698\n",
      "Val RMSE: 136671.5299, Val MAE: 82123.6550, Val MSE: 18679107088.0247, Val R2: 0.0510\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2730\n",
      "Val RMSE: 137665.1678, Val MAE: 80789.1292, Val MSE: 18951698424.4144, Val R2: 0.0371\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2553, Val Loss: 0.2657\n",
      "Val RMSE: 139156.5768, Val MAE: 77511.9430, Val MSE: 19364552874.6728, Val R2: 0.0162\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2500, Val Loss: 0.2524\n",
      "Val RMSE: 134299.1092, Val MAE: 77273.6660, Val MSE: 18036250737.8228, Val R2: 0.0836\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.2480, Val Loss: 0.2556\n",
      "Val RMSE: 136110.2144, Val MAE: 74721.1922, Val MSE: 18525990470.7079, Val R2: 0.0588\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.2469, Val Loss: 0.2517\n",
      "Val RMSE: 134806.5840, Val MAE: 75615.2202, Val MSE: 18172815093.8689, Val R2: 0.0767\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.2432, Val Loss: 0.2575\n",
      "Val RMSE: 134321.2874, Val MAE: 79119.0995, Val MSE: 18042208260.8773, Val R2: 0.0833\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.2477, Val Loss: 0.2623\n",
      "Val RMSE: 134743.7094, Val MAE: 79981.0409, Val MSE: 18155867227.8231, Val R2: 0.0776\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.2424, Val Loss: 0.2556\n",
      "Val RMSE: 133748.3545, Val MAE: 79349.8642, Val MSE: 17888622322.8725, Val R2: 0.0911\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.2431, Val Loss: 0.2539\n",
      "Val RMSE: 133213.4954, Val MAE: 79328.4265, Val MSE: 17745835369.2703, Val R2: 0.0984\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.2356, Val Loss: 0.2454\n",
      "Val RMSE: 132343.3488, Val MAE: 74272.2605, Val MSE: 17514761980.1564, Val R2: 0.1101\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.2290, Val Loss: 0.2441\n",
      "Val RMSE: 131883.2661, Val MAE: 74399.7902, Val MSE: 17393195879.4086, Val R2: 0.1163\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.2302, Val Loss: 0.2461\n",
      "Val RMSE: 132931.4329, Val MAE: 74622.7357, Val MSE: 17670765847.5279, Val R2: 0.1022\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.2251, Val Loss: 0.2431\n",
      "Val RMSE: 129844.4263, Val MAE: 76453.0970, Val MSE: 16859575037.9451, Val R2: 0.1434\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.2154, Val Loss: 0.2339\n",
      "Val RMSE: 131995.9612, Val MAE: 70810.8411, Val MSE: 17422933765.2580, Val R2: 0.1148\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.2057, Val Loss: 0.2581\n",
      "Val RMSE: 134070.1900, Val MAE: 74640.2876, Val MSE: 17974815845.7239, Val R2: 0.0868\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.2001, Val Loss: 0.2262\n",
      "Val RMSE: 127530.1673, Val MAE: 70919.2130, Val MSE: 16263943577.6539, Val R2: 0.1737\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1906, Val Loss: 0.2143\n",
      "Val RMSE: 120938.9773, Val MAE: 68784.7220, Val MSE: 14626236235.0665, Val R2: 0.2569\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1836, Val Loss: 0.2151\n",
      "Val RMSE: 121372.5760, Val MAE: 68644.5095, Val MSE: 14731302213.0101, Val R2: 0.2516\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1808, Val Loss: 0.2116\n",
      "Val RMSE: 117779.0336, Val MAE: 67613.0548, Val MSE: 13871900765.6657, Val R2: 0.2952\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1776, Val Loss: 0.2047\n",
      "Val RMSE: 114683.8584, Val MAE: 66966.6822, Val MSE: 13152387375.3407, Val R2: 0.3318\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1775, Val Loss: 0.2098\n",
      "Val RMSE: 116363.8451, Val MAE: 67795.2081, Val MSE: 13540544445.5729, Val R2: 0.3121\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1759, Val Loss: 0.1921\n",
      "Val RMSE: 108852.1645, Val MAE: 64670.7156, Val MSE: 11848793719.6875, Val R2: 0.3980\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1724, Val Loss: 0.1896\n",
      "Val RMSE: 107200.9538, Val MAE: 63476.0391, Val MSE: 11492044502.7618, Val R2: 0.4161\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1694, Val Loss: 0.1817\n",
      "Val RMSE: 103948.6020, Val MAE: 63376.2442, Val MSE: 10805311848.4988, Val R2: 0.4510\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1684, Val Loss: 0.1766\n",
      "Val RMSE: 102026.2710, Val MAE: 61101.7389, Val MSE: 10409359982.9215, Val R2: 0.4711\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1638, Val Loss: 0.1765\n",
      "Val RMSE: 102865.8839, Val MAE: 60112.5435, Val MSE: 10581390064.6041, Val R2: 0.4624\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1620, Val Loss: 0.1701\n",
      "Val RMSE: 99624.8569, Val MAE: 58806.4245, Val MSE: 9925112115.4657, Val R2: 0.4957\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1614, Val Loss: 0.1681\n",
      "Val RMSE: 101870.7176, Val MAE: 58116.3596, Val MSE: 10377643096.0381, Val R2: 0.4728\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1556, Val Loss: 0.1632\n",
      "Val RMSE: 98207.1842, Val MAE: 56843.0158, Val MSE: 9644651021.9279, Val R2: 0.5100\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1503, Val Loss: 0.1663\n",
      "Val RMSE: 100443.1030, Val MAE: 57159.3924, Val MSE: 10088816936.4988, Val R2: 0.4874\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1491, Val Loss: 0.1458\n",
      "Val RMSE: 94773.6556, Val MAE: 53248.4276, Val MSE: 8982045798.9569, Val R2: 0.5437\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1444, Val Loss: 0.1583\n",
      "Val RMSE: 99936.9812, Val MAE: 54796.7034, Val MSE: 9987400214.4894, Val R2: 0.4926\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1386, Val Loss: 0.1551\n",
      "Val RMSE: 95891.6519, Val MAE: 54997.8274, Val MSE: 9195208907.1244, Val R2: 0.5328\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1396, Val Loss: 0.1642\n",
      "Val RMSE: 105182.9138, Val MAE: 56811.2720, Val MSE: 11063445353.6802, Val R2: 0.4379\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1365, Val Loss: 0.1549\n",
      "Val RMSE: 97428.4279, Val MAE: 57484.2143, Val MSE: 9492298568.8081, Val R2: 0.5177\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1297, Val Loss: 0.1624\n",
      "Val RMSE: 98597.5526, Val MAE: 54611.5722, Val MSE: 9721477383.7514, Val R2: 0.5061\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1303, Val Loss: 0.1456\n",
      "Val RMSE: 94603.6056, Val MAE: 51399.7350, Val MSE: 8949842185.2225, Val R2: 0.5453\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.1274, Val Loss: 0.1473\n",
      "Val RMSE: 97168.9518, Val MAE: 51532.9054, Val MSE: 9441805198.9255, Val R2: 0.5203\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.1251, Val Loss: 0.1473\n",
      "Val RMSE: 95353.4757, Val MAE: 52810.7662, Val MSE: 9092285330.2179, Val R2: 0.5381\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.1228, Val Loss: 0.1432\n",
      "Val RMSE: 93239.0881, Val MAE: 52425.1307, Val MSE: 8693527542.0052, Val R2: 0.5583\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.1197, Val Loss: 0.1431\n",
      "Val RMSE: 93975.7626, Val MAE: 52155.6322, Val MSE: 8831443965.5182, Val R2: 0.5513\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.1172, Val Loss: 0.1473\n",
      "Val RMSE: 94833.6935, Val MAE: 53965.7114, Val MSE: 8993429426.2522, Val R2: 0.5431\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.1161, Val Loss: 0.1503\n",
      "Val RMSE: 94433.2852, Val MAE: 51622.7925, Val MSE: 8917645352.7338, Val R2: 0.5469\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.1152, Val Loss: 0.1377\n",
      "Val RMSE: 92414.2041, Val MAE: 49346.8888, Val MSE: 8540385112.0935, Val R2: 0.5661\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.1155, Val Loss: 0.1453\n",
      "Val RMSE: 94622.0877, Val MAE: 50023.7446, Val MSE: 8953339490.1331, Val R2: 0.5451\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1574\n",
      "Val RMSE: 97328.4702, Val MAE: 54141.9868, Val MSE: 9472831103.1690, Val R2: 0.5187\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.1133, Val Loss: 0.1663\n",
      "Val RMSE: 97691.7911, Val MAE: 55214.3902, Val MSE: 9543686045.6723, Val R2: 0.5151\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.1098, Val Loss: 0.1404\n",
      "Val RMSE: 92441.2722, Val MAE: 52591.5921, Val MSE: 8545388808.6411, Val R2: 0.5658\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.1087, Val Loss: 0.1508\n",
      "Val RMSE: 95762.1461, Val MAE: 54080.8911, Val MSE: 9170388634.1636, Val R2: 0.5341\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.1092, Val Loss: 0.1523\n",
      "Val RMSE: 94767.4238, Val MAE: 53596.1968, Val MSE: 8980864606.5374, Val R2: 0.5437\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.1087, Val Loss: 0.1602\n",
      "Val RMSE: 98491.3497, Val MAE: 56946.3018, Val MSE: 9700545961.9242, Val R2: 0.5072\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1514\n",
      "Val RMSE: 95201.1457, Val MAE: 56342.4599, Val MSE: 9063258148.0329, Val R2: 0.5395\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1417\n",
      "Val RMSE: 93490.3870, Val MAE: 53613.0373, Val MSE: 8740452465.7607, Val R2: 0.5559\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1696\n",
      "Val RMSE: 98045.1739, Val MAE: 57525.4135, Val MSE: 9612856121.4409, Val R2: 0.5116\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1519\n",
      "Val RMSE: 94532.6722, Val MAE: 55995.8290, Val MSE: 8936426114.7713, Val R2: 0.5460\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.1018, Val Loss: 0.1417\n",
      "Val RMSE: 93749.2014, Val MAE: 50201.2906, Val MSE: 8788912761.1078, Val R2: 0.5535\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1378\n",
      "Val RMSE: 91939.9248, Val MAE: 52125.1848, Val MSE: 8452949764.2664, Val R2: 0.5705\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.1007, Val Loss: 0.1521\n",
      "Val RMSE: 94833.6494, Val MAE: 50506.0669, Val MSE: 8993421049.0726, Val R2: 0.5431\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1381\n",
      "Val RMSE: 92991.9821, Val MAE: 51794.8337, Val MSE: 8647508736.9424, Val R2: 0.5607\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0924, Val Loss: 0.1581\n",
      "Val RMSE: 97702.6989, Val MAE: 55370.1631, Val MSE: 9545817369.3688, Val R2: 0.5150\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.1378\n",
      "Val RMSE: 92882.0955, Val MAE: 50348.9258, Val MSE: 8627083667.9163, Val R2: 0.5617\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0929, Val Loss: 0.1446\n",
      "Val RMSE: 94638.2640, Val MAE: 51926.2789, Val MSE: 8956401007.2870, Val R2: 0.5450\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1643\n",
      "Val RMSE: 98824.8098, Val MAE: 55798.0471, Val MSE: 9766343036.3035, Val R2: 0.5038\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1479\n",
      "Val RMSE: 94164.9074, Val MAE: 53935.1058, Val MSE: 8867029788.9819, Val R2: 0.5495\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0882, Val Loss: 0.1438\n",
      "Val RMSE: 93813.7355, Val MAE: 53072.0441, Val MSE: 8801016962.7735, Val R2: 0.5529\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0853, Val Loss: 0.1372\n",
      "Val RMSE: 92610.5061, Val MAE: 52319.7545, Val MSE: 8576705837.6997, Val R2: 0.5642\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1435\n",
      "Val RMSE: 93948.0218, Val MAE: 51733.8795, Val MSE: 8826230794.5815, Val R2: 0.5516\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0814, Val Loss: 0.1422\n",
      "Val RMSE: 93841.5936, Val MAE: 52924.5137, Val MSE: 8806244695.5643, Val R2: 0.5526\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0825, Val Loss: 0.1455\n",
      "Val RMSE: 92911.7168, Val MAE: 49470.7338, Val MSE: 8632587113.3983, Val R2: 0.5614\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1401\n",
      "Val RMSE: 94147.0965, Val MAE: 50472.6443, Val MSE: 8863675775.4334, Val R2: 0.5497\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1423\n",
      "Val RMSE: 91036.9728, Val MAE: 51442.0934, Val MSE: 8287730415.4704, Val R2: 0.5789\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 91136.6690, Test MAE: 49898.6811, Test MSE: 8305892436.1771, Test R2: 0.4676\n",
      "Inference Time: 2.5623028094951924e-05 seconds per sample\n",
      "\n",
      "Iteration 74 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3428, Val Loss: 0.2854\n",
      "Val RMSE: 143489.1312, Val MAE: 82776.2740, Val MSE: 20589130780.0485, Val R2: -0.0461\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2752, Val Loss: 0.2769\n",
      "Val RMSE: 142055.6125, Val MAE: 83358.7757, Val MSE: 20179797046.6340, Val R2: -0.0253\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2688, Val Loss: 0.2748\n",
      "Val RMSE: 140840.2240, Val MAE: 84840.0759, Val MSE: 19835968684.1364, Val R2: -0.0078\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2663, Val Loss: 0.2764\n",
      "Val RMSE: 141921.3618, Val MAE: 83160.8513, Val MSE: 20141672937.1390, Val R2: -0.0233\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2652, Val Loss: 0.2774\n",
      "Val RMSE: 141500.4389, Val MAE: 83848.0755, Val MSE: 20022374220.3789, Val R2: -0.0173\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2621, Val Loss: 0.2732\n",
      "Val RMSE: 140667.7344, Val MAE: 84363.7304, Val MSE: 19787411491.7468, Val R2: -0.0053\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2600, Val Loss: 0.2863\n",
      "Val RMSE: 142190.7838, Val MAE: 88391.6016, Val MSE: 20218219000.5962, Val R2: -0.0272\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2737\n",
      "Val RMSE: 141075.0311, Val MAE: 84333.8802, Val MSE: 19902164392.8915, Val R2: -0.0112\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2751\n",
      "Val RMSE: 142337.5417, Val MAE: 80627.8654, Val MSE: 20259975784.6135, Val R2: -0.0293\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2542, Val Loss: 0.2694\n",
      "Val RMSE: 142048.2442, Val MAE: 79686.6312, Val MSE: 20177703687.0818, Val R2: -0.0252\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2657\n",
      "Val RMSE: 141200.1658, Val MAE: 79462.8385, Val MSE: 19937486815.2312, Val R2: -0.0130\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2519, Val Loss: 0.2661\n",
      "Val RMSE: 142523.9159, Val MAE: 77645.1158, Val MSE: 20313066614.7468, Val R2: -0.0320\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2518, Val Loss: 0.2666\n",
      "Val RMSE: 138652.2342, Val MAE: 82679.1544, Val MSE: 19224442048.6393, Val R2: 0.0233\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2406, Val Loss: 0.2510\n",
      "Val RMSE: 135385.8421, Val MAE: 75785.0661, Val MSE: 18329326245.4367, Val R2: 0.0688\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2338, Val Loss: 0.2330\n",
      "Val RMSE: 130617.9070, Val MAE: 74957.9436, Val MSE: 17061037624.8815, Val R2: 0.1332\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2258, Val Loss: 0.2448\n",
      "Val RMSE: 137575.7761, Val MAE: 71583.5628, Val MSE: 18927094155.8785, Val R2: 0.0384\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2196, Val Loss: 0.2415\n",
      "Val RMSE: 133901.8001, Val MAE: 74543.5398, Val MSE: 17929692082.9586, Val R2: 0.0891\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2128, Val Loss: 0.2628\n",
      "Val RMSE: 134200.8267, Val MAE: 82077.4513, Val MSE: 18009861887.3193, Val R2: 0.0850\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2132, Val Loss: 0.2341\n",
      "Val RMSE: 131484.1992, Val MAE: 73743.6542, Val MSE: 17288094647.2490, Val R2: 0.1217\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2083, Val Loss: 0.2511\n",
      "Val RMSE: 135692.7102, Val MAE: 78277.5161, Val MSE: 18412511605.6312, Val R2: 0.0645\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2056, Val Loss: 0.2222\n",
      "Val RMSE: 125860.5714, Val MAE: 72121.8680, Val MSE: 15840883427.6826, Val R2: 0.1952\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1943, Val Loss: 0.2184\n",
      "Val RMSE: 117165.3762, Val MAE: 75525.0292, Val MSE: 13727725381.6355, Val R2: 0.3025\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1862, Val Loss: 0.2191\n",
      "Val RMSE: 118197.1774, Val MAE: 68301.0958, Val MSE: 13970572734.7710, Val R2: 0.2902\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1740, Val Loss: 0.1979\n",
      "Val RMSE: 109892.3544, Val MAE: 65939.6378, Val MSE: 12076329556.7548, Val R2: 0.3864\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1718, Val Loss: 0.1897\n",
      "Val RMSE: 106371.3884, Val MAE: 65371.7558, Val MSE: 11314872267.9954, Val R2: 0.4251\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1645, Val Loss: 0.1850\n",
      "Val RMSE: 105918.4195, Val MAE: 63783.6886, Val MSE: 11218711587.9243, Val R2: 0.4300\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1615, Val Loss: 0.1756\n",
      "Val RMSE: 102540.4349, Val MAE: 62245.8667, Val MSE: 10514540783.3904, Val R2: 0.4658\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1551, Val Loss: 0.1715\n",
      "Val RMSE: 101118.7459, Val MAE: 59358.6748, Val MSE: 10225000777.1481, Val R2: 0.4805\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1512, Val Loss: 0.1810\n",
      "Val RMSE: 105639.6297, Val MAE: 60782.6867, Val MSE: 11159731368.6841, Val R2: 0.4330\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1496, Val Loss: 0.1622\n",
      "Val RMSE: 99169.8532, Val MAE: 56757.4889, Val MSE: 9834659784.0528, Val R2: 0.5003\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1466, Val Loss: 0.1659\n",
      "Val RMSE: 100879.1309, Val MAE: 57093.0423, Val MSE: 10176599042.0383, Val R2: 0.4830\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1446, Val Loss: 0.1676\n",
      "Val RMSE: 103127.2840, Val MAE: 56293.8112, Val MSE: 10635236695.2060, Val R2: 0.4597\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1410, Val Loss: 0.1561\n",
      "Val RMSE: 97806.6716, Val MAE: 54728.8659, Val MSE: 9566145013.4306, Val R2: 0.5140\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1382, Val Loss: 0.1573\n",
      "Val RMSE: 99251.8171, Val MAE: 53601.5811, Val MSE: 9850923187.8026, Val R2: 0.4995\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1348, Val Loss: 0.1637\n",
      "Val RMSE: 98630.2614, Val MAE: 54439.5822, Val MSE: 9727928455.9511, Val R2: 0.5058\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1530\n",
      "Val RMSE: 95790.9056, Val MAE: 53384.4655, Val MSE: 9175897602.3561, Val R2: 0.5338\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1251, Val Loss: 0.1513\n",
      "Val RMSE: 96280.8916, Val MAE: 51344.4612, Val MSE: 9270010078.8177, Val R2: 0.5290\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1221, Val Loss: 0.1429\n",
      "Val RMSE: 94106.1584, Val MAE: 50185.4725, Val MSE: 8855969053.5746, Val R2: 0.5501\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1150, Val Loss: 0.1364\n",
      "Val RMSE: 89563.2455, Val MAE: 49395.0823, Val MSE: 8021574951.0764, Val R2: 0.5925\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1373\n",
      "Val RMSE: 90401.8416, Val MAE: 49675.5911, Val MSE: 8172492960.5406, Val R2: 0.5848\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1029, Val Loss: 0.1383\n",
      "Val RMSE: 90859.9514, Val MAE: 51221.2662, Val MSE: 8255530763.9439, Val R2: 0.5806\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1409\n",
      "Val RMSE: 92919.8518, Val MAE: 51180.7531, Val MSE: 8634098854.7528, Val R2: 0.5613\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0962, Val Loss: 0.1429\n",
      "Val RMSE: 90124.6311, Val MAE: 48759.0012, Val MSE: 8122449130.7622, Val R2: 0.5873\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0944, Val Loss: 0.1441\n",
      "Val RMSE: 90892.5284, Val MAE: 53311.8202, Val MSE: 8261451716.7520, Val R2: 0.5803\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0912, Val Loss: 0.1427\n",
      "Val RMSE: 88421.5603, Val MAE: 53949.5964, Val MSE: 7818372325.0540, Val R2: 0.6028\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0892, Val Loss: 0.1357\n",
      "Val RMSE: 88188.1039, Val MAE: 50157.8366, Val MSE: 7777141674.4851, Val R2: 0.6049\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0847, Val Loss: 0.1569\n",
      "Val RMSE: 93611.1213, Val MAE: 52123.2672, Val MSE: 8763042034.6932, Val R2: 0.5548\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1423\n",
      "Val RMSE: 89816.0920, Val MAE: 52597.0656, Val MSE: 8066930390.2997, Val R2: 0.5901\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1400\n",
      "Val RMSE: 85966.2490, Val MAE: 52738.4741, Val MSE: 7390195970.2934, Val R2: 0.6245\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1343\n",
      "Val RMSE: 83429.5848, Val MAE: 49269.9238, Val MSE: 6960495612.8741, Val R2: 0.6464\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0796, Val Loss: 0.1400\n",
      "Val RMSE: 85799.3775, Val MAE: 53624.6008, Val MSE: 7361533174.0751, Val R2: 0.6260\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0780, Val Loss: 0.1397\n",
      "Val RMSE: 85664.8114, Val MAE: 51436.9455, Val MSE: 7338459918.0180, Val R2: 0.6272\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0765, Val Loss: 0.1478\n",
      "Val RMSE: 89203.7322, Val MAE: 50860.9722, Val MSE: 7957305834.8717, Val R2: 0.5957\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1485\n",
      "Val RMSE: 89066.4099, Val MAE: 51724.8146, Val MSE: 7932825376.6736, Val R2: 0.5970\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0725, Val Loss: 0.1490\n",
      "Val RMSE: 87746.6796, Val MAE: 51044.5340, Val MSE: 7699479787.6036, Val R2: 0.6088\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1349\n",
      "Val RMSE: 82839.8365, Val MAE: 50274.9249, Val MSE: 6862438511.2187, Val R2: 0.6513\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1356\n",
      "Val RMSE: 80633.2821, Val MAE: 50497.9982, Val MSE: 6501726176.2963, Val R2: 0.6697\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.1262\n",
      "Val RMSE: 78548.5879, Val MAE: 47655.7381, Val MSE: 6169880667.0189, Val R2: 0.6865\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0684, Val Loss: 0.1373\n",
      "Val RMSE: 84057.4936, Val MAE: 50106.5377, Val MSE: 7065662222.8335, Val R2: 0.6410\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1372\n",
      "Val RMSE: 83289.9425, Val MAE: 49210.4599, Val MSE: 6937214525.0907, Val R2: 0.6475\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1406\n",
      "Val RMSE: 81410.3601, Val MAE: 52443.2105, Val MSE: 6627646728.9304, Val R2: 0.6633\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1378\n",
      "Val RMSE: 83634.7107, Val MAE: 48457.5632, Val MSE: 6994764840.0802, Val R2: 0.6446\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1291\n",
      "Val RMSE: 78208.7385, Val MAE: 48544.8264, Val MSE: 6116606775.2479, Val R2: 0.6892\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1345\n",
      "Val RMSE: 81498.2590, Val MAE: 49536.3981, Val MSE: 6641966218.8342, Val R2: 0.6625\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1466\n",
      "Val RMSE: 86468.8014, Val MAE: 53743.3555, Val MSE: 7476853610.6603, Val R2: 0.6201\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0630, Val Loss: 0.1453\n",
      "Val RMSE: 85588.7711, Val MAE: 54945.5526, Val MSE: 7325437734.7267, Val R2: 0.6278\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0605, Val Loss: 0.1318\n",
      "Val RMSE: 80134.9492, Val MAE: 50764.2327, Val MSE: 6421610081.7951, Val R2: 0.6737\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0624, Val Loss: 0.1400\n",
      "Val RMSE: 82857.8707, Val MAE: 51741.9679, Val MSE: 6865426733.8066, Val R2: 0.6512\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0591, Val Loss: 0.1414\n",
      "Val RMSE: 82670.7795, Val MAE: 49375.9337, Val MSE: 6834457789.3492, Val R2: 0.6528\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0589, Val Loss: 0.1380\n",
      "Val RMSE: 82302.2270, Val MAE: 50873.8583, Val MSE: 6773656560.9879, Val R2: 0.6559\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1302\n",
      "Val RMSE: 78833.4868, Val MAE: 47033.1072, Val MSE: 6214718644.6227, Val R2: 0.6843\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1339\n",
      "Val RMSE: 80881.5614, Val MAE: 50018.6069, Val MSE: 6541826976.7864, Val R2: 0.6676\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1279\n",
      "Val RMSE: 79039.2200, Val MAE: 48028.5497, Val MSE: 6247198291.7201, Val R2: 0.6826\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1330\n",
      "Val RMSE: 79355.4421, Val MAE: 47297.9419, Val MSE: 6297286194.0254, Val R2: 0.6801\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1328\n",
      "Val RMSE: 78694.2019, Val MAE: 49902.5642, Val MSE: 6192777411.6082, Val R2: 0.6854\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1374\n",
      "Val RMSE: 83177.7055, Val MAE: 49782.7522, Val MSE: 6918530689.3667, Val R2: 0.6485\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1366\n",
      "Val RMSE: 80939.0343, Val MAE: 47839.3010, Val MSE: 6551127274.4642, Val R2: 0.6672\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1409\n",
      "Val RMSE: 83616.6897, Val MAE: 48611.9836, Val MSE: 6991750789.0576, Val R2: 0.6448\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1382\n",
      "Val RMSE: 82900.5470, Val MAE: 49576.8548, Val MSE: 6872500696.7638, Val R2: 0.6508\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1342\n",
      "Val RMSE: 81759.0428, Val MAE: 48101.1874, Val MSE: 6684541084.1804, Val R2: 0.6604\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1410\n",
      "Val RMSE: 85263.9501, Val MAE: 50327.5647, Val MSE: 7269941184.1626, Val R2: 0.6306\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1369\n",
      "Val RMSE: 84560.9993, Val MAE: 48084.6645, Val MSE: 7150562609.9293, Val R2: 0.6367\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1372\n",
      "Val RMSE: 84578.1320, Val MAE: 48418.9061, Val MSE: 7153460407.5926, Val R2: 0.6366\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1433\n",
      "Val RMSE: 84792.2024, Val MAE: 52011.4595, Val MSE: 7189717590.2689, Val R2: 0.6347\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1406\n",
      "Val RMSE: 84862.9160, Val MAE: 51415.5475, Val MSE: 7201714508.4844, Val R2: 0.6341\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1316\n",
      "Val RMSE: 81653.6655, Val MAE: 48023.4954, Val MSE: 6667321093.0406, Val R2: 0.6613\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1261\n",
      "Val RMSE: 78217.3168, Val MAE: 47917.7156, Val MSE: 6117948647.9128, Val R2: 0.6892\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1236\n",
      "Val RMSE: 79615.2812, Val MAE: 45569.3951, Val MSE: 6338593005.3087, Val R2: 0.6780\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1391\n",
      "Val RMSE: 84589.5870, Val MAE: 50441.2378, Val MSE: 7155398235.6430, Val R2: 0.6365\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1297\n",
      "Val RMSE: 82196.2049, Val MAE: 48234.4968, Val MSE: 6756216101.2459, Val R2: 0.6567\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1252\n",
      "Val RMSE: 79767.9129, Val MAE: 46763.6326, Val MSE: 6362919928.1005, Val R2: 0.6767\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1551\n",
      "Val RMSE: 87315.1026, Val MAE: 55998.2755, Val MSE: 7623927138.5592, Val R2: 0.6127\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1503\n",
      "Val RMSE: 86721.0504, Val MAE: 50342.5768, Val MSE: 7520540574.7071, Val R2: 0.6179\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1363\n",
      "Val RMSE: 83183.6242, Val MAE: 48683.0950, Val MSE: 6919515334.4212, Val R2: 0.6484\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1489\n",
      "Val RMSE: 85783.7511, Val MAE: 52070.3417, Val MSE: 7358851953.9264, Val R2: 0.6261\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1398\n",
      "Val RMSE: 84998.1234, Val MAE: 50278.5320, Val MSE: 7224680973.1059, Val R2: 0.6329\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1382\n",
      "Val RMSE: 83159.8518, Val MAE: 50629.5629, Val MSE: 6915560943.1249, Val R2: 0.6486\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1355\n",
      "Val RMSE: 83297.5967, Val MAE: 48335.7427, Val MSE: 6938489618.5463, Val R2: 0.6475\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1389\n",
      "Val RMSE: 84122.2776, Val MAE: 48354.3557, Val MSE: 7076557595.7934, Val R2: 0.6405\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0425, Val Loss: 0.1535\n",
      "Val RMSE: 85310.1486, Val MAE: 56840.6536, Val MSE: 7277821462.3683, Val R2: 0.6302\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83432.8021, Test MAE: 47047.4054, Test MSE: 6961032468.3476, Test R2: 0.5538\n",
      "Inference Time: 3.13105949988732e-05 seconds per sample\n",
      "\n",
      "Iteration 75 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3664, Val Loss: 0.2790\n",
      "Val RMSE: 140539.2351, Val MAE: 87557.8133, Val MSE: 19751276597.0701, Val R2: -0.0035\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2793, Val Loss: 0.2773\n",
      "Val RMSE: 142261.6429, Val MAE: 82909.3275, Val MSE: 20238375050.5918, Val R2: -0.0282\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2725, Val Loss: 0.2748\n",
      "Val RMSE: 141435.8357, Val MAE: 83777.1226, Val MSE: 20004095626.3384, Val R2: -0.0163\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2674, Val Loss: 0.2749\n",
      "Val RMSE: 142301.2391, Val MAE: 82327.3797, Val MSE: 20249642661.8841, Val R2: -0.0288\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2642, Val Loss: 0.2748\n",
      "Val RMSE: 140842.4104, Val MAE: 85732.3644, Val MSE: 19836584580.0363, Val R2: -0.0078\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2609, Val Loss: 0.2770\n",
      "Val RMSE: 141613.3661, Val MAE: 85215.6052, Val MSE: 20054345447.5740, Val R2: -0.0189\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2562, Val Loss: 0.2720\n",
      "Val RMSE: 141335.6900, Val MAE: 81989.4688, Val MSE: 19975777263.4762, Val R2: -0.0149\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2813\n",
      "Val RMSE: 141075.4021, Val MAE: 87862.5434, Val MSE: 19902269091.6624, Val R2: -0.0112\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2741\n",
      "Val RMSE: 143382.2036, Val MAE: 78598.4332, Val MSE: 20558456316.4263, Val R2: -0.0445\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2556, Val Loss: 0.2660\n",
      "Val RMSE: 140986.7034, Val MAE: 79972.4193, Val MSE: 19877250530.0445, Val R2: -0.0099\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2534, Val Loss: 0.2627\n",
      "Val RMSE: 140984.9908, Val MAE: 78264.0406, Val MSE: 19876767632.6110, Val R2: -0.0099\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2460, Val Loss: 0.2542\n",
      "Val RMSE: 136732.5766, Val MAE: 77114.3710, Val MSE: 18695797501.8511, Val R2: 0.0501\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2409, Val Loss: 0.2537\n",
      "Val RMSE: 134164.6905, Val MAE: 78753.2608, Val MSE: 18000164165.1211, Val R2: 0.0855\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2387, Val Loss: 0.2503\n",
      "Val RMSE: 134627.4246, Val MAE: 76773.6617, Val MSE: 18124543462.7424, Val R2: 0.0792\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2354, Val Loss: 0.2526\n",
      "Val RMSE: 133783.3358, Val MAE: 79149.8360, Val MSE: 17897980924.6703, Val R2: 0.0907\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2356, Val Loss: 0.2657\n",
      "Val RMSE: 133750.2383, Val MAE: 84426.9965, Val MSE: 17889126256.4783, Val R2: 0.0911\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2322, Val Loss: 0.2449\n",
      "Val RMSE: 133845.7368, Val MAE: 73911.8832, Val MSE: 17914681262.6433, Val R2: 0.0898\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2264, Val Loss: 0.2289\n",
      "Val RMSE: 128180.7945, Val MAE: 76047.8708, Val MSE: 16430316079.7968, Val R2: 0.1652\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2150, Val Loss: 0.2483\n",
      "Val RMSE: 130986.2765, Val MAE: 80801.7184, Val MSE: 17157404624.9526, Val R2: 0.1283\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2162, Val Loss: 0.2288\n",
      "Val RMSE: 128798.3443, Val MAE: 75296.1382, Val MSE: 16589013493.4238, Val R2: 0.1572\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2116, Val Loss: 0.2270\n",
      "Val RMSE: 129370.9936, Val MAE: 70421.5909, Val MSE: 16736853979.1293, Val R2: 0.1497\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2261\n",
      "Val RMSE: 130727.6019, Val MAE: 69337.0844, Val MSE: 17089705907.9779, Val R2: 0.1317\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2095, Val Loss: 0.2251\n",
      "Val RMSE: 129319.1427, Val MAE: 70762.4666, Val MSE: 16723440665.5981, Val R2: 0.1503\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2046, Val Loss: 0.2306\n",
      "Val RMSE: 129621.8519, Val MAE: 73259.3983, Val MSE: 16801824488.5463, Val R2: 0.1464\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2042, Val Loss: 0.2278\n",
      "Val RMSE: 129609.2105, Val MAE: 71168.3877, Val MSE: 16798547454.2087, Val R2: 0.1465\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2083, Val Loss: 0.2282\n",
      "Val RMSE: 129397.4441, Val MAE: 70381.9164, Val MSE: 16743698542.5559, Val R2: 0.1493\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2210\n",
      "Val RMSE: 121629.1515, Val MAE: 74824.5760, Val MSE: 14793650502.1532, Val R2: 0.2484\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1960, Val Loss: 0.2259\n",
      "Val RMSE: 126500.1799, Val MAE: 68661.7118, Val MSE: 16002295503.0082, Val R2: 0.1870\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1949, Val Loss: 0.2187\n",
      "Val RMSE: 121679.1537, Val MAE: 68883.0890, Val MSE: 14805816445.5277, Val R2: 0.2478\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1877, Val Loss: 0.2136\n",
      "Val RMSE: 118225.2616, Val MAE: 69294.7684, Val MSE: 13977212469.8465, Val R2: 0.2899\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1810, Val Loss: 0.2205\n",
      "Val RMSE: 119381.9696, Val MAE: 69310.0670, Val MSE: 14252054662.6887, Val R2: 0.2759\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1818, Val Loss: 0.2071\n",
      "Val RMSE: 116160.1047, Val MAE: 66166.0992, Val MSE: 13493169929.6067, Val R2: 0.3145\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1788, Val Loss: 0.2035\n",
      "Val RMSE: 111879.4138, Val MAE: 66059.4355, Val MSE: 12517003236.5837, Val R2: 0.3641\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1750, Val Loss: 0.1936\n",
      "Val RMSE: 109274.2228, Val MAE: 66123.7360, Val MSE: 11940855763.6734, Val R2: 0.3933\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1888\n",
      "Val RMSE: 107930.0856, Val MAE: 64236.4880, Val MSE: 11648903370.4842, Val R2: 0.4082\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1672, Val Loss: 0.1878\n",
      "Val RMSE: 106627.4982, Val MAE: 63549.5078, Val MSE: 11369423362.1361, Val R2: 0.4224\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1684, Val Loss: 0.1774\n",
      "Val RMSE: 102921.8367, Val MAE: 62014.0590, Val MSE: 10592904461.0260, Val R2: 0.4618\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1631, Val Loss: 0.1851\n",
      "Val RMSE: 104683.9771, Val MAE: 62203.2299, Val MSE: 10958735060.6625, Val R2: 0.4432\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1624, Val Loss: 0.1885\n",
      "Val RMSE: 105607.1203, Val MAE: 61572.2481, Val MSE: 11152863865.1016, Val R2: 0.4334\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1583, Val Loss: 0.1800\n",
      "Val RMSE: 103294.0116, Val MAE: 62962.4687, Val MSE: 10669652828.4631, Val R2: 0.4579\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1600, Val Loss: 0.1701\n",
      "Val RMSE: 101015.2244, Val MAE: 60310.7575, Val MSE: 10204075558.7090, Val R2: 0.4816\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1566, Val Loss: 0.1706\n",
      "Val RMSE: 101176.8261, Val MAE: 58490.8527, Val MSE: 10236750138.6407, Val R2: 0.4799\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1498, Val Loss: 0.1565\n",
      "Val RMSE: 97957.8450, Val MAE: 55125.2207, Val MSE: 9595739394.0964, Val R2: 0.5125\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1558, Val Loss: 0.1487\n",
      "Val RMSE: 93867.4851, Val MAE: 54105.8930, Val MSE: 8811104755.5730, Val R2: 0.5523\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1492, Val Loss: 0.1507\n",
      "Val RMSE: 95603.6714, Val MAE: 54618.7815, Val MSE: 9140061977.9000, Val R2: 0.5356\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1484, Val Loss: 0.1550\n",
      "Val RMSE: 97170.5955, Val MAE: 56805.7797, Val MSE: 9442124634.0889, Val R2: 0.5203\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1436, Val Loss: 0.1387\n",
      "Val RMSE: 90998.2819, Val MAE: 53067.6890, Val MSE: 8280687303.5629, Val R2: 0.5793\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1380, Val Loss: 0.1380\n",
      "Val RMSE: 91661.2613, Val MAE: 50405.6800, Val MSE: 8401786828.5194, Val R2: 0.5731\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1361, Val Loss: 0.1406\n",
      "Val RMSE: 93180.3990, Val MAE: 50821.9840, Val MSE: 8682586752.2548, Val R2: 0.5589\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1312, Val Loss: 0.1327\n",
      "Val RMSE: 90663.2272, Val MAE: 50018.4747, Val MSE: 8219820768.8860, Val R2: 0.5824\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1270, Val Loss: 0.1217\n",
      "Val RMSE: 87439.5934, Val MAE: 46884.6191, Val MSE: 7645682490.3605, Val R2: 0.6116\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1208, Val Loss: 0.1344\n",
      "Val RMSE: 91481.2011, Val MAE: 47172.5173, Val MSE: 8368810153.5305, Val R2: 0.5748\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1187, Val Loss: 0.1228\n",
      "Val RMSE: 87769.2815, Val MAE: 48774.7653, Val MSE: 7703446778.0996, Val R2: 0.6086\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1161, Val Loss: 0.1233\n",
      "Val RMSE: 87475.5585, Val MAE: 46836.2142, Val MSE: 7651973328.2556, Val R2: 0.6112\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1426\n",
      "Val RMSE: 90527.3393, Val MAE: 48929.9373, Val MSE: 8195199153.4422, Val R2: 0.5836\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1118, Val Loss: 0.1279\n",
      "Val RMSE: 88241.5361, Val MAE: 49714.8447, Val MSE: 7786568700.6885, Val R2: 0.6044\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1089, Val Loss: 0.1270\n",
      "Val RMSE: 89133.5488, Val MAE: 48148.2782, Val MSE: 7944789515.5191, Val R2: 0.5964\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1055, Val Loss: 0.1233\n",
      "Val RMSE: 87569.1730, Val MAE: 46372.6673, Val MSE: 7668360057.8904, Val R2: 0.6104\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1054, Val Loss: 0.1319\n",
      "Val RMSE: 88581.8946, Val MAE: 49644.7269, Val MSE: 7846752057.8006, Val R2: 0.6013\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1015, Val Loss: 0.1226\n",
      "Val RMSE: 87256.6740, Val MAE: 48223.3972, Val MSE: 7613727162.6474, Val R2: 0.6132\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1205\n",
      "Val RMSE: 86335.5595, Val MAE: 45063.3769, Val MSE: 7453828830.8219, Val R2: 0.6213\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1003, Val Loss: 0.1295\n",
      "Val RMSE: 88594.4810, Val MAE: 46500.3456, Val MSE: 7848982065.0448, Val R2: 0.6012\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0970, Val Loss: 0.1280\n",
      "Val RMSE: 88631.9734, Val MAE: 48394.7559, Val MSE: 7855626704.8317, Val R2: 0.6009\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0955, Val Loss: 0.1315\n",
      "Val RMSE: 89198.5843, Val MAE: 47597.7087, Val MSE: 7956387444.8792, Val R2: 0.5958\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1224\n",
      "Val RMSE: 87466.3100, Val MAE: 45890.1210, Val MSE: 7650355388.4217, Val R2: 0.6113\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0957, Val Loss: 0.1347\n",
      "Val RMSE: 89492.0294, Val MAE: 46685.8078, Val MSE: 8008823320.8677, Val R2: 0.5931\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0931, Val Loss: 0.1247\n",
      "Val RMSE: 88698.9842, Val MAE: 46779.9376, Val MSE: 7867509802.3766, Val R2: 0.6003\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0870, Val Loss: 0.1504\n",
      "Val RMSE: 91973.4371, Val MAE: 54015.6824, Val MSE: 8459113129.3041, Val R2: 0.5702\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1241\n",
      "Val RMSE: 86983.8721, Val MAE: 45506.7990, Val MSE: 7566194005.6562, Val R2: 0.6156\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0825, Val Loss: 0.1309\n",
      "Val RMSE: 87883.6820, Val MAE: 47860.2722, Val MSE: 7723541553.2153, Val R2: 0.6076\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0799, Val Loss: 0.1242\n",
      "Val RMSE: 85876.4497, Val MAE: 46269.7306, Val MSE: 7374764607.7889, Val R2: 0.6253\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0805, Val Loss: 0.1293\n",
      "Val RMSE: 84490.6835, Val MAE: 47176.8101, Val MSE: 7138675601.5007, Val R2: 0.6373\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.1288\n",
      "Val RMSE: 85689.0631, Val MAE: 47816.9325, Val MSE: 7342615542.9758, Val R2: 0.6269\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1222\n",
      "Val RMSE: 83462.2053, Val MAE: 47267.8787, Val MSE: 6965939715.7740, Val R2: 0.6461\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1235\n",
      "Val RMSE: 84605.3868, Val MAE: 47309.1844, Val MSE: 7158071467.2594, Val R2: 0.6363\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0744, Val Loss: 0.1263\n",
      "Val RMSE: 81832.6396, Val MAE: 48336.9350, Val MSE: 6696580904.3871, Val R2: 0.6598\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1213\n",
      "Val RMSE: 80981.6598, Val MAE: 47973.1308, Val MSE: 6558029224.5746, Val R2: 0.6668\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1274\n",
      "Val RMSE: 82624.2735, Val MAE: 50461.4849, Val MSE: 6826770576.2291, Val R2: 0.6532\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1185\n",
      "Val RMSE: 79947.4933, Val MAE: 45985.0514, Val MSE: 6391601681.2970, Val R2: 0.6753\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0687, Val Loss: 0.1188\n",
      "Val RMSE: 77858.4491, Val MAE: 48080.5984, Val MSE: 6061938101.3107, Val R2: 0.6920\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1163\n",
      "Val RMSE: 78078.3884, Val MAE: 45869.4575, Val MSE: 6096234738.3661, Val R2: 0.6903\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0670, Val Loss: 0.1167\n",
      "Val RMSE: 76451.3914, Val MAE: 45400.2851, Val MSE: 5844815248.2021, Val R2: 0.7030\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1070\n",
      "Val RMSE: 73345.7537, Val MAE: 41889.5108, Val MSE: 5379599590.1218, Val R2: 0.7267\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1186\n",
      "Val RMSE: 76022.2097, Val MAE: 45700.4204, Val MSE: 5779376364.3882, Val R2: 0.7064\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1165\n",
      "Val RMSE: 75515.6599, Val MAE: 45105.4362, Val MSE: 5702614896.3191, Val R2: 0.7103\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1038\n",
      "Val RMSE: 70515.0727, Val MAE: 40875.4360, Val MSE: 4972375480.0429, Val R2: 0.7474\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1238\n",
      "Val RMSE: 86833.4135, Val MAE: 44049.7391, Val MSE: 7540041697.8233, Val R2: 0.6169\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1211\n",
      "Val RMSE: 88556.7363, Val MAE: 44506.1700, Val MSE: 7842295545.5255, Val R2: 0.6016\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1179\n",
      "Val RMSE: 85287.1046, Val MAE: 43701.9944, Val MSE: 7273890212.8281, Val R2: 0.6304\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1253\n",
      "Val RMSE: 88751.5442, Val MAE: 44506.5294, Val MSE: 7876836591.4779, Val R2: 0.5998\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1224\n",
      "Val RMSE: 82932.5874, Val MAE: 43197.6374, Val MSE: 6877814049.6150, Val R2: 0.6506\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1205\n",
      "Val RMSE: 82183.8722, Val MAE: 46000.2344, Val MSE: 6754188851.6371, Val R2: 0.6568\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1224\n",
      "Val RMSE: 86996.1774, Val MAE: 45037.5649, Val MSE: 7568334889.8513, Val R2: 0.6155\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0548, Val Loss: 0.1227\n",
      "Val RMSE: 87362.5341, Val MAE: 46212.0408, Val MSE: 7632212363.6340, Val R2: 0.6122\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1079\n",
      "Val RMSE: 74060.9184, Val MAE: 46123.1011, Val MSE: 5485019634.3697, Val R2: 0.7213\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1047\n",
      "Val RMSE: 72536.1599, Val MAE: 44626.0877, Val MSE: 5261494488.0730, Val R2: 0.7327\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.0949\n",
      "Val RMSE: 69540.7214, Val MAE: 39420.5514, Val MSE: 4835911927.5188, Val R2: 0.7543\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1029\n",
      "Val RMSE: 72881.9409, Val MAE: 42104.7500, Val MSE: 5311777305.5730, Val R2: 0.7301\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0526, Val Loss: 0.0947\n",
      "Val RMSE: 68513.9130, Val MAE: 40486.8843, Val MSE: 4694156277.3213, Val R2: 0.7615\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.0957\n",
      "Val RMSE: 68807.7494, Val MAE: 41898.2286, Val MSE: 4734506372.0714, Val R2: 0.7595\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 73581.3024, Test MAE: 40484.1986, Test MSE: 5414208063.2459, Test R2: 0.6529\n",
      "Inference Time: 3.347180439875676e-05 seconds per sample\n",
      "\n",
      "Iteration 76 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3512, Val Loss: 0.2760\n",
      "Val RMSE: 141130.6239, Val MAE: 84893.3159, Val MSE: 19917853013.5442, Val R2: -0.0120\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2743, Val Loss: 0.2751\n",
      "Val RMSE: 141018.6742, Val MAE: 84697.8641, Val MSE: 19886266462.3643, Val R2: -0.0103\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2681, Val Loss: 0.2771\n",
      "Val RMSE: 142478.3702, Val MAE: 82345.1243, Val MSE: 20300085988.9472, Val R2: -0.0314\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2669, Val Loss: 0.2743\n",
      "Val RMSE: 141103.0072, Val MAE: 84296.2699, Val MSE: 19910058628.5372, Val R2: -0.0116\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2651, Val Loss: 0.2755\n",
      "Val RMSE: 140959.6006, Val MAE: 86498.3661, Val MSE: 19869608991.9950, Val R2: -0.0095\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2607, Val Loss: 0.2719\n",
      "Val RMSE: 141614.2276, Val MAE: 82751.5886, Val MSE: 20054589466.7342, Val R2: -0.0189\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2604, Val Loss: 0.2749\n",
      "Val RMSE: 142023.1318, Val MAE: 82969.4098, Val MSE: 20170569965.7227, Val R2: -0.0248\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2563, Val Loss: 0.2787\n",
      "Val RMSE: 141564.7892, Val MAE: 85221.2147, Val MSE: 20040589550.2575, Val R2: -0.0182\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2569, Val Loss: 0.2733\n",
      "Val RMSE: 141328.8229, Val MAE: 83475.3198, Val MSE: 19973836190.1980, Val R2: -0.0148\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2753\n",
      "Val RMSE: 140747.9010, Val MAE: 85616.4510, Val MSE: 19809971646.0644, Val R2: -0.0065\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2776\n",
      "Val RMSE: 142901.5144, Val MAE: 79950.0433, Val MSE: 20420842826.7303, Val R2: -0.0375\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2630\n",
      "Val RMSE: 137585.0041, Val MAE: 81227.6328, Val MSE: 18929633350.1989, Val R2: 0.0383\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2452, Val Loss: 0.2553\n",
      "Val RMSE: 136397.4221, Val MAE: 78960.2733, Val MSE: 18604256764.2811, Val R2: 0.0548\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2531\n",
      "Val RMSE: 134475.9465, Val MAE: 79144.6094, Val MSE: 18083780199.9278, Val R2: 0.0812\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2440, Val Loss: 0.2481\n",
      "Val RMSE: 134105.8495, Val MAE: 75292.8587, Val MSE: 17984378876.7429, Val R2: 0.0863\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2374, Val Loss: 0.2482\n",
      "Val RMSE: 130511.4669, Val MAE: 78046.4512, Val MSE: 17033242994.7879, Val R2: 0.1346\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2335, Val Loss: 0.2436\n",
      "Val RMSE: 132036.2664, Val MAE: 73538.0632, Val MSE: 17433575641.5853, Val R2: 0.1143\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2241, Val Loss: 0.2433\n",
      "Val RMSE: 133420.5668, Val MAE: 77372.8790, Val MSE: 17801047647.1622, Val R2: 0.0956\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2177, Val Loss: 0.2319\n",
      "Val RMSE: 129503.7385, Val MAE: 77014.1277, Val MSE: 16771218281.5083, Val R2: 0.1479\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2157, Val Loss: 0.2333\n",
      "Val RMSE: 132311.1610, Val MAE: 73681.7644, Val MSE: 17506243329.0837, Val R2: 0.1106\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2134, Val Loss: 0.2468\n",
      "Val RMSE: 138019.3151, Val MAE: 71252.6466, Val MSE: 19049331344.4900, Val R2: 0.0322\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2351, Val Loss: 0.2513\n",
      "Val RMSE: 133997.3980, Val MAE: 77569.1955, Val MSE: 17955302671.4835, Val R2: 0.0878\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2266, Val Loss: 0.2417\n",
      "Val RMSE: 133442.1108, Val MAE: 76337.2910, Val MSE: 17806796946.6073, Val R2: 0.0953\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2118, Val Loss: 0.2430\n",
      "Val RMSE: 134516.5683, Val MAE: 74187.3865, Val MSE: 18094707136.9711, Val R2: 0.0807\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2158, Val Loss: 0.2440\n",
      "Val RMSE: 131888.9432, Val MAE: 78524.5815, Val MSE: 17394693338.3992, Val R2: 0.1162\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2084, Val Loss: 0.2357\n",
      "Val RMSE: 133608.9918, Val MAE: 71320.5163, Val MSE: 17851362689.8906, Val R2: 0.0930\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2275\n",
      "Val RMSE: 129915.9302, Val MAE: 70936.7163, Val MSE: 16878148918.5587, Val R2: 0.1425\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2078, Val Loss: 0.2341\n",
      "Val RMSE: 130518.5709, Val MAE: 74253.8501, Val MSE: 17035097359.2355, Val R2: 0.1345\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2099, Val Loss: 0.2371\n",
      "Val RMSE: 130307.9171, Val MAE: 75950.7348, Val MSE: 16980153257.7710, Val R2: 0.1373\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.2094, Val Loss: 0.2412\n",
      "Val RMSE: 133496.0024, Val MAE: 72502.2774, Val MSE: 17821182643.9168, Val R2: 0.0946\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.2089, Val Loss: 0.2349\n",
      "Val RMSE: 129947.1955, Val MAE: 75165.6700, Val MSE: 16886273615.3245, Val R2: 0.1421\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.2066, Val Loss: 0.2310\n",
      "Val RMSE: 128398.1749, Val MAE: 73744.1468, Val MSE: 16486091316.8919, Val R2: 0.1624\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.2039, Val Loss: 0.2312\n",
      "Val RMSE: 128434.7541, Val MAE: 73215.6099, Val MSE: 16495486071.5196, Val R2: 0.1619\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.2026, Val Loss: 0.2250\n",
      "Val RMSE: 125734.0003, Val MAE: 73269.4565, Val MSE: 15809038834.2126, Val R2: 0.1968\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1942, Val Loss: 0.2116\n",
      "Val RMSE: 116893.5759, Val MAE: 69019.9818, Val MSE: 13664108077.0576, Val R2: 0.3058\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1873, Val Loss: 0.2033\n",
      "Val RMSE: 111032.5732, Val MAE: 69062.5221, Val MSE: 12328232322.4198, Val R2: 0.3736\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.1998\n",
      "Val RMSE: 109217.5019, Val MAE: 69230.1187, Val MSE: 11928462726.3533, Val R2: 0.3940\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1783, Val Loss: 0.1982\n",
      "Val RMSE: 109149.0636, Val MAE: 65868.4565, Val MSE: 11913518093.8013, Val R2: 0.3947\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1759, Val Loss: 0.1901\n",
      "Val RMSE: 106253.0577, Val MAE: 64104.2645, Val MSE: 11289712271.8755, Val R2: 0.4264\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1738, Val Loss: 0.1940\n",
      "Val RMSE: 107379.1680, Val MAE: 63697.0644, Val MSE: 11530285730.1931, Val R2: 0.4142\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1664, Val Loss: 0.1795\n",
      "Val RMSE: 103486.1913, Val MAE: 61201.3069, Val MSE: 10709391795.5609, Val R2: 0.4559\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1749\n",
      "Val RMSE: 101951.2890, Val MAE: 62251.5020, Val MSE: 10394065335.3780, Val R2: 0.4719\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1575, Val Loss: 0.1617\n",
      "Val RMSE: 97860.4021, Val MAE: 59058.8833, Val MSE: 9576658300.6862, Val R2: 0.5134\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1598\n",
      "Val RMSE: 97133.5657, Val MAE: 58813.3319, Val MSE: 9434929581.2986, Val R2: 0.5206\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1568, Val Loss: 0.1627\n",
      "Val RMSE: 98141.5639, Val MAE: 58822.9934, Val MSE: 9631766573.1090, Val R2: 0.5106\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1508, Val Loss: 0.1541\n",
      "Val RMSE: 96168.4131, Val MAE: 55327.6804, Val MSE: 9248363683.5075, Val R2: 0.5301\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1466, Val Loss: 0.1724\n",
      "Val RMSE: 102577.2818, Val MAE: 57992.8224, Val MSE: 10522098739.2279, Val R2: 0.4654\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1464, Val Loss: 0.1547\n",
      "Val RMSE: 96666.8822, Val MAE: 55523.0163, Val MSE: 9344486115.0048, Val R2: 0.5252\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1411, Val Loss: 0.1533\n",
      "Val RMSE: 96673.8673, Val MAE: 54613.1369, Val MSE: 9345836628.3904, Val R2: 0.5252\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1559\n",
      "Val RMSE: 97293.5257, Val MAE: 55381.3444, Val MSE: 9466030143.8171, Val R2: 0.5191\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1381, Val Loss: 0.1471\n",
      "Val RMSE: 94147.2685, Val MAE: 53774.0474, Val MSE: 8863708172.0688, Val R2: 0.5497\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1313, Val Loss: 0.1415\n",
      "Val RMSE: 92522.1091, Val MAE: 51183.8536, Val MSE: 8560340674.8700, Val R2: 0.5651\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1274, Val Loss: 0.1426\n",
      "Val RMSE: 93519.8729, Val MAE: 51899.6795, Val MSE: 8745966635.6496, Val R2: 0.5556\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1261, Val Loss: 0.1679\n",
      "Val RMSE: 96312.1074, Val MAE: 59343.9636, Val MSE: 9276022024.8743, Val R2: 0.5287\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1263, Val Loss: 0.1592\n",
      "Val RMSE: 99546.3155, Val MAE: 54946.5228, Val MSE: 9909468928.0908, Val R2: 0.4965\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1212, Val Loss: 0.1411\n",
      "Val RMSE: 92123.2188, Val MAE: 51552.0390, Val MSE: 8486687449.9176, Val R2: 0.5688\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1164, Val Loss: 0.1445\n",
      "Val RMSE: 93669.6000, Val MAE: 52681.3434, Val MSE: 8773993957.8275, Val R2: 0.5542\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1145, Val Loss: 0.1497\n",
      "Val RMSE: 93776.4982, Val MAE: 54475.1635, Val MSE: 8794031608.7281, Val R2: 0.5532\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1119, Val Loss: 0.1448\n",
      "Val RMSE: 93055.5790, Val MAE: 51081.4598, Val MSE: 8659340775.4899, Val R2: 0.5601\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1086, Val Loss: 0.1503\n",
      "Val RMSE: 94820.5867, Val MAE: 55639.3134, Val MSE: 8990943671.3577, Val R2: 0.5432\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1472\n",
      "Val RMSE: 94434.5321, Val MAE: 52160.3769, Val MSE: 8917880847.2223, Val R2: 0.5469\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1045, Val Loss: 0.1433\n",
      "Val RMSE: 91341.7517, Val MAE: 53104.7965, Val MSE: 8343315596.5605, Val R2: 0.5761\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1022, Val Loss: 0.1463\n",
      "Val RMSE: 93398.7690, Val MAE: 52606.0268, Val MSE: 8723330043.8710, Val R2: 0.5568\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1413\n",
      "Val RMSE: 92622.7272, Val MAE: 51165.5400, Val MSE: 8578969592.4435, Val R2: 0.5641\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1604\n",
      "Val RMSE: 97735.9128, Val MAE: 55380.1409, Val MSE: 9552308654.8223, Val R2: 0.5147\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0978, Val Loss: 0.1504\n",
      "Val RMSE: 95507.1027, Val MAE: 53120.0046, Val MSE: 9121606663.4502, Val R2: 0.5366\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1533\n",
      "Val RMSE: 95987.6000, Val MAE: 54515.3012, Val MSE: 9213619346.3015, Val R2: 0.5319\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0911, Val Loss: 0.1473\n",
      "Val RMSE: 93498.2389, Val MAE: 53829.8052, Val MSE: 8741920678.5200, Val R2: 0.5559\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1476\n",
      "Val RMSE: 94411.5008, Val MAE: 52728.0815, Val MSE: 8913531480.4192, Val R2: 0.5471\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1457\n",
      "Val RMSE: 92557.5646, Val MAE: 53960.4795, Val MSE: 8566902757.9469, Val R2: 0.5647\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1511\n",
      "Val RMSE: 93884.8929, Val MAE: 54499.2259, Val MSE: 8814373123.6158, Val R2: 0.5522\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0830, Val Loss: 0.1527\n",
      "Val RMSE: 95162.3843, Val MAE: 54112.9982, Val MSE: 9055879381.8247, Val R2: 0.5399\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1646\n",
      "Val RMSE: 97880.0759, Val MAE: 58483.3687, Val MSE: 9580509255.1172, Val R2: 0.5132\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0824, Val Loss: 0.1450\n",
      "Val RMSE: 91097.0989, Val MAE: 53626.7186, Val MSE: 8298681437.0613, Val R2: 0.5784\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1482\n",
      "Val RMSE: 92049.9541, Val MAE: 52318.9429, Val MSE: 8473194055.3166, Val R2: 0.5695\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1398\n",
      "Val RMSE: 89307.3917, Val MAE: 51218.8818, Val MSE: 7975810203.9064, Val R2: 0.5948\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0764, Val Loss: 0.1471\n",
      "Val RMSE: 88884.8279, Val MAE: 52230.2698, Val MSE: 7900512632.4549, Val R2: 0.5986\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1459\n",
      "Val RMSE: 89706.0052, Val MAE: 52010.8688, Val MSE: 8047167360.2687, Val R2: 0.5912\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0735, Val Loss: 0.1532\n",
      "Val RMSE: 93753.5196, Val MAE: 54669.8169, Val MSE: 8789722438.9364, Val R2: 0.5534\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1609\n",
      "Val RMSE: 94893.2781, Val MAE: 55669.0559, Val MSE: 9004734236.9223, Val R2: 0.5425\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.1487\n",
      "Val RMSE: 91380.3253, Val MAE: 52546.7786, Val MSE: 8350363850.9933, Val R2: 0.5757\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1487\n",
      "Val RMSE: 89813.1838, Val MAE: 52283.8623, Val MSE: 8066407986.5556, Val R2: 0.5902\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1429\n",
      "Val RMSE: 84844.2022, Val MAE: 51289.6339, Val MSE: 7198538639.7363, Val R2: 0.6343\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1400\n",
      "Val RMSE: 86551.3261, Val MAE: 50613.9724, Val MSE: 7491132049.1900, Val R2: 0.6194\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1470\n",
      "Val RMSE: 87138.1183, Val MAE: 53200.0593, Val MSE: 7593051654.7516, Val R2: 0.6142\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1635\n",
      "Val RMSE: 92085.9940, Val MAE: 55623.0934, Val MSE: 8479830290.2682, Val R2: 0.5692\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1436\n",
      "Val RMSE: 86565.1147, Val MAE: 52318.0606, Val MSE: 7493519087.8515, Val R2: 0.6193\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.1429\n",
      "Val RMSE: 85607.3919, Val MAE: 52778.6285, Val MSE: 7328625543.1492, Val R2: 0.6277\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1486\n",
      "Val RMSE: 88582.4585, Val MAE: 54786.4214, Val MSE: 7846851957.7408, Val R2: 0.6013\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1414\n",
      "Val RMSE: 85800.5931, Val MAE: 51649.9835, Val MSE: 7361741782.9420, Val R2: 0.6260\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.1464\n",
      "Val RMSE: 87147.7317, Val MAE: 52302.9679, Val MSE: 7594727133.1950, Val R2: 0.6141\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1349\n",
      "Val RMSE: 82629.8830, Val MAE: 49025.9321, Val MSE: 6827697567.7185, Val R2: 0.6531\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1441\n",
      "Val RMSE: 84903.3439, Val MAE: 52518.1910, Val MSE: 7208577802.4170, Val R2: 0.6338\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1365\n",
      "Val RMSE: 81647.8973, Val MAE: 49304.0150, Val MSE: 6666379138.8483, Val R2: 0.6613\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1478\n",
      "Val RMSE: 85383.1875, Val MAE: 55341.5725, Val MSE: 7290288699.2775, Val R2: 0.6296\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1456\n",
      "Val RMSE: 86591.3610, Val MAE: 53320.2972, Val MSE: 7498063797.1307, Val R2: 0.6191\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1334\n",
      "Val RMSE: 80748.1720, Val MAE: 48930.5217, Val MSE: 6520267288.3548, Val R2: 0.6687\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1595\n",
      "Val RMSE: 90292.9071, Val MAE: 57411.5620, Val MSE: 8152809070.8078, Val R2: 0.5858\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1355\n",
      "Val RMSE: 82191.3904, Val MAE: 48969.6300, Val MSE: 6755424662.4212, Val R2: 0.6568\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1364\n",
      "Val RMSE: 83080.8077, Val MAE: 50352.9664, Val MSE: 6902420606.2280, Val R2: 0.6493\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 85785.6004, Test MAE: 49206.8371, Test MSE: 7359169229.1803, Test R2: 0.5283\n",
      "Inference Time: 3.96881470313439e-05 seconds per sample\n",
      "\n",
      "Iteration 77 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3438, Val Loss: 0.2983\n",
      "Val RMSE: 147118.3523, Val MAE: 80828.1516, Val MSE: 21643809571.1623, Val R2: -0.0996\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2727, Val Loss: 0.2750\n",
      "Val RMSE: 140812.9268, Val MAE: 85093.3919, Val MSE: 19828280366.9403, Val R2: -0.0074\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2660, Val Loss: 0.2766\n",
      "Val RMSE: 142244.7550, Val MAE: 82658.6053, Val MSE: 20233570327.3200, Val R2: -0.0280\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2640, Val Loss: 0.2804\n",
      "Val RMSE: 143638.9815, Val MAE: 81632.5792, Val MSE: 20632157019.4049, Val R2: -0.0482\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2820\n",
      "Val RMSE: 144219.5666, Val MAE: 80498.9800, Val MSE: 20799283397.8751, Val R2: -0.0567\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2603, Val Loss: 0.2789\n",
      "Val RMSE: 141073.3650, Val MAE: 87019.2119, Val MSE: 19901694311.6018, Val R2: -0.0111\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2805\n",
      "Val RMSE: 141446.4985, Val MAE: 86627.0323, Val MSE: 20007111940.4691, Val R2: -0.0165\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2718\n",
      "Val RMSE: 141860.3684, Val MAE: 81256.5982, Val MSE: 20124364113.2373, Val R2: -0.0224\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2674\n",
      "Val RMSE: 141487.2113, Val MAE: 80065.1449, Val MSE: 20018630951.5782, Val R2: -0.0171\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2515, Val Loss: 0.2711\n",
      "Val RMSE: 140160.6903, Val MAE: 83774.2732, Val MSE: 19645019093.2289, Val R2: 0.0019\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2522, Val Loss: 0.2633\n",
      "Val RMSE: 139692.4711, Val MAE: 80613.4800, Val MSE: 19513986487.2582, Val R2: 0.0086\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2464, Val Loss: 0.2664\n",
      "Val RMSE: 142326.5638, Val MAE: 76813.0253, Val MSE: 20256850764.7657, Val R2: -0.0292\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2441, Val Loss: 0.2587\n",
      "Val RMSE: 137309.8318, Val MAE: 78524.4731, Val MSE: 18853989895.5260, Val R2: 0.0421\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2368, Val Loss: 0.2512\n",
      "Val RMSE: 132754.4393, Val MAE: 80025.6709, Val MSE: 17623741149.1555, Val R2: 0.1046\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2311, Val Loss: 0.2505\n",
      "Val RMSE: 133744.0558, Val MAE: 77867.8990, Val MSE: 17887472451.7713, Val R2: 0.0912\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2286, Val Loss: 0.2340\n",
      "Val RMSE: 130108.2738, Val MAE: 73993.4095, Val MSE: 16928162910.7973, Val R2: 0.1399\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2173, Val Loss: 0.2426\n",
      "Val RMSE: 135559.1835, Val MAE: 70512.2785, Val MSE: 18376292230.8578, Val R2: 0.0664\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2096, Val Loss: 0.2349\n",
      "Val RMSE: 132778.0174, Val MAE: 73257.5979, Val MSE: 17630001907.3298, Val R2: 0.1043\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2033, Val Loss: 0.2417\n",
      "Val RMSE: 134818.8438, Val MAE: 73941.5732, Val MSE: 18176120653.0838, Val R2: 0.0765\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.1989, Val Loss: 0.2198\n",
      "Val RMSE: 128280.0293, Val MAE: 67802.6206, Val MSE: 16455765910.1211, Val R2: 0.1639\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1986, Val Loss: 0.2230\n",
      "Val RMSE: 129323.6546, Val MAE: 70361.7860, Val MSE: 16724607643.6654, Val R2: 0.1503\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1935, Val Loss: 0.2170\n",
      "Val RMSE: 123432.8621, Val MAE: 68419.5023, Val MSE: 15235671438.8900, Val R2: 0.2259\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1928, Val Loss: 0.2113\n",
      "Val RMSE: 116212.4561, Val MAE: 69629.3269, Val MSE: 13505334952.6374, Val R2: 0.3138\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.2027\n",
      "Val RMSE: 112877.2424, Val MAE: 67141.7786, Val MSE: 12741271856.5434, Val R2: 0.3527\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1770, Val Loss: 0.1869\n",
      "Val RMSE: 105381.2501, Val MAE: 62773.6032, Val MSE: 11105207868.5689, Val R2: 0.4358\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1727, Val Loss: 0.1757\n",
      "Val RMSE: 101230.7245, Val MAE: 60553.4314, Val MSE: 10247659583.9363, Val R2: 0.4794\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1704, Val Loss: 0.1924\n",
      "Val RMSE: 105750.5184, Val MAE: 63126.3379, Val MSE: 11183172147.6639, Val R2: 0.4318\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1641, Val Loss: 0.1784\n",
      "Val RMSE: 102672.4145, Val MAE: 60904.5829, Val MSE: 10541624691.2932, Val R2: 0.4644\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1597, Val Loss: 0.1791\n",
      "Val RMSE: 102556.8426, Val MAE: 61070.2661, Val MSE: 10517905954.2241, Val R2: 0.4656\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1555, Val Loss: 0.1778\n",
      "Val RMSE: 101966.7142, Val MAE: 60433.2344, Val MSE: 10397210797.6467, Val R2: 0.4718\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1553\n",
      "Val RMSE: 96064.0671, Val MAE: 55973.3591, Val MSE: 9228304988.1956, Val R2: 0.5311\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1492, Val Loss: 0.1551\n",
      "Val RMSE: 96473.2828, Val MAE: 58211.3203, Val MSE: 9307094301.9078, Val R2: 0.5271\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1446, Val Loss: 0.1665\n",
      "Val RMSE: 99152.6370, Val MAE: 56505.5999, Val MSE: 9831245425.1278, Val R2: 0.5005\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1438, Val Loss: 0.1648\n",
      "Val RMSE: 98261.9465, Val MAE: 56835.0788, Val MSE: 9655410137.4324, Val R2: 0.5094\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1397, Val Loss: 0.1524\n",
      "Val RMSE: 94831.9537, Val MAE: 55827.0548, Val MSE: 8993099441.8922, Val R2: 0.5431\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1331, Val Loss: 0.1462\n",
      "Val RMSE: 93424.6327, Val MAE: 52405.8828, Val MSE: 8728161998.0512, Val R2: 0.5566\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1281, Val Loss: 0.1668\n",
      "Val RMSE: 95330.8710, Val MAE: 56417.6193, Val MSE: 9087974956.5278, Val R2: 0.5383\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1269, Val Loss: 0.2141\n",
      "Val RMSE: 105809.3084, Val MAE: 66296.8767, Val MSE: 11195609746.0066, Val R2: 0.4312\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1225, Val Loss: 0.1538\n",
      "Val RMSE: 97560.3390, Val MAE: 54990.9692, Val MSE: 9518019754.7617, Val R2: 0.5164\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1304, Val Loss: 0.1752\n",
      "Val RMSE: 98513.3401, Val MAE: 62173.6530, Val MSE: 9704878186.1487, Val R2: 0.5069\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1172, Val Loss: 0.1416\n",
      "Val RMSE: 90477.4961, Val MAE: 50547.1242, Val MSE: 8186177296.2000, Val R2: 0.5841\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1105, Val Loss: 0.1389\n",
      "Val RMSE: 90143.2490, Val MAE: 50195.8926, Val MSE: 8125805347.3685, Val R2: 0.5872\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1489\n",
      "Val RMSE: 92970.5268, Val MAE: 55504.2038, Val MSE: 8643518858.7155, Val R2: 0.5609\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1080, Val Loss: 0.1489\n",
      "Val RMSE: 91329.0902, Val MAE: 52384.3581, Val MSE: 8341002725.1588, Val R2: 0.5762\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1046, Val Loss: 0.1594\n",
      "Val RMSE: 92737.3639, Val MAE: 53010.0572, Val MSE: 8600218665.3321, Val R2: 0.5631\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1771\n",
      "Val RMSE: 95812.1452, Val MAE: 57465.9704, Val MSE: 9179967169.3015, Val R2: 0.5336\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0949, Val Loss: 0.1409\n",
      "Val RMSE: 89975.1327, Val MAE: 50069.0906, Val MSE: 8095524499.9315, Val R2: 0.5887\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0937, Val Loss: 0.1601\n",
      "Val RMSE: 92095.8421, Val MAE: 55194.5033, Val MSE: 8481644128.1502, Val R2: 0.5691\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0909, Val Loss: 0.1684\n",
      "Val RMSE: 94644.8427, Val MAE: 56359.7959, Val MSE: 8957646258.2800, Val R2: 0.5449\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1627\n",
      "Val RMSE: 93164.3760, Val MAE: 54443.6445, Val MSE: 8679600958.9676, Val R2: 0.5590\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1520\n",
      "Val RMSE: 90653.4603, Val MAE: 53599.7668, Val MSE: 8218049868.0388, Val R2: 0.5825\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1759\n",
      "Val RMSE: 94882.6107, Val MAE: 57382.7766, Val MSE: 9002709807.4019, Val R2: 0.5426\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1503\n",
      "Val RMSE: 90157.3694, Val MAE: 53702.1633, Val MSE: 8128351253.4993, Val R2: 0.5870\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0884, Val Loss: 0.1501\n",
      "Val RMSE: 89976.2559, Val MAE: 50676.3304, Val MSE: 8095726622.7694, Val R2: 0.5887\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0831, Val Loss: 0.1921\n",
      "Val RMSE: 96550.8148, Val MAE: 59169.8215, Val MSE: 9322059833.0856, Val R2: 0.5264\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0816, Val Loss: 0.2163\n",
      "Val RMSE: 98545.3004, Val MAE: 62118.5977, Val MSE: 9711176234.5284, Val R2: 0.5066\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.2055\n",
      "Val RMSE: 95883.0773, Val MAE: 61732.9865, Val MSE: 9193564503.8411, Val R2: 0.5329\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0764, Val Loss: 0.1379\n",
      "Val RMSE: 81855.1077, Val MAE: 46670.3249, Val MSE: 6700258660.8724, Val R2: 0.6596\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1594\n",
      "Val RMSE: 86377.9593, Val MAE: 53550.2589, Val MSE: 7461151858.5928, Val R2: 0.6209\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1362\n",
      "Val RMSE: 81685.1150, Val MAE: 46105.5196, Val MSE: 6672458010.9067, Val R2: 0.6610\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0724, Val Loss: 0.1853\n",
      "Val RMSE: 90040.1325, Val MAE: 55490.0323, Val MSE: 8107225463.9730, Val R2: 0.5881\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0708, Val Loss: 0.1561\n",
      "Val RMSE: 84903.9991, Val MAE: 50046.8871, Val MSE: 7208689068.6202, Val R2: 0.6338\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1455\n",
      "Val RMSE: 81798.9158, Val MAE: 49445.0066, Val MSE: 6691062627.9512, Val R2: 0.6601\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1293\n",
      "Val RMSE: 80916.0809, Val MAE: 44862.0249, Val MSE: 6547412148.1780, Val R2: 0.6674\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.2072\n",
      "Val RMSE: 93451.6073, Val MAE: 57127.2036, Val MSE: 8733202908.6748, Val R2: 0.5563\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1898\n",
      "Val RMSE: 88315.3116, Val MAE: 54224.9290, Val MSE: 7799594254.9526, Val R2: 0.6037\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1964\n",
      "Val RMSE: 90690.8340, Val MAE: 57022.7921, Val MSE: 8224827372.7009, Val R2: 0.5821\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0629, Val Loss: 0.2157\n",
      "Val RMSE: 92710.1955, Val MAE: 58659.1368, Val MSE: 8595180358.5517, Val R2: 0.5633\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1352\n",
      "Val RMSE: 80423.9496, Val MAE: 47781.9607, Val MSE: 6468011672.1605, Val R2: 0.6714\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1279\n",
      "Val RMSE: 80668.1937, Val MAE: 44338.1366, Val MSE: 6507357474.5914, Val R2: 0.6694\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1724\n",
      "Val RMSE: 86999.3913, Val MAE: 52303.5096, Val MSE: 7568894085.1567, Val R2: 0.6155\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1773\n",
      "Val RMSE: 86385.9808, Val MAE: 53199.8944, Val MSE: 7462537684.1136, Val R2: 0.6209\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1280\n",
      "Val RMSE: 78701.6998, Val MAE: 45097.6500, Val MSE: 6193957557.7142, Val R2: 0.6853\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1281\n",
      "Val RMSE: 75772.6196, Val MAE: 46230.7307, Val MSE: 5741489884.3037, Val R2: 0.7083\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1397\n",
      "Val RMSE: 79539.2880, Val MAE: 47166.2951, Val MSE: 6326498330.6096, Val R2: 0.6786\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.2130\n",
      "Val RMSE: 94235.3611, Val MAE: 61733.8004, Val MSE: 8880303289.3373, Val R2: 0.5488\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1457\n",
      "Val RMSE: 80756.2637, Val MAE: 48348.4364, Val MSE: 6521574132.6810, Val R2: 0.6687\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1772\n",
      "Val RMSE: 90175.8555, Val MAE: 52291.6083, Val MSE: 8131684920.0245, Val R2: 0.5869\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1985\n",
      "Val RMSE: 91077.7318, Val MAE: 56767.0752, Val MSE: 8295153232.7761, Val R2: 0.5786\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1393\n",
      "Val RMSE: 82730.4043, Val MAE: 45618.5781, Val MSE: 6844319788.5820, Val R2: 0.6523\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1258\n",
      "Val RMSE: 75081.5091, Val MAE: 43130.5335, Val MSE: 5637233004.9457, Val R2: 0.7136\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0502, Val Loss: 0.1699\n",
      "Val RMSE: 83198.9100, Val MAE: 51453.2433, Val MSE: 6922058633.1290, Val R2: 0.6483\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1583\n",
      "Val RMSE: 83392.2055, Val MAE: 49730.2208, Val MSE: 6954259933.6645, Val R2: 0.6467\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1421\n",
      "Val RMSE: 79296.3142, Val MAE: 46633.6761, Val MSE: 6287905444.8739, Val R2: 0.6805\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1221\n",
      "Val RMSE: 76487.8865, Val MAE: 43782.1123, Val MSE: 5850396776.6210, Val R2: 0.7028\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1246\n",
      "Val RMSE: 74618.5892, Val MAE: 43525.6216, Val MSE: 5567933859.0132, Val R2: 0.7171\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1514\n",
      "Val RMSE: 82218.5264, Val MAE: 47443.6211, Val MSE: 6759886082.8831, Val R2: 0.6566\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1220\n",
      "Val RMSE: 73572.0971, Val MAE: 43960.6471, Val MSE: 5412853466.3316, Val R2: 0.7250\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1288\n",
      "Val RMSE: 77177.1478, Val MAE: 46032.2021, Val MSE: 5956312144.2358, Val R2: 0.6974\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1178\n",
      "Val RMSE: 75350.8059, Val MAE: 42390.4133, Val MSE: 5677743944.6234, Val R2: 0.7115\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1827\n",
      "Val RMSE: 88551.4577, Val MAE: 54023.1995, Val MSE: 7841360653.7437, Val R2: 0.6016\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1299\n",
      "Val RMSE: 78157.8741, Val MAE: 45299.5925, Val MSE: 6108653280.4376, Val R2: 0.6896\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1204\n",
      "Val RMSE: 74353.7271, Val MAE: 42686.0041, Val MSE: 5528476735.9362, Val R2: 0.7191\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0461, Val Loss: 0.1257\n",
      "Val RMSE: 78964.1956, Val MAE: 44019.8356, Val MSE: 6235344190.6430, Val R2: 0.6832\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.2194\n",
      "Val RMSE: 94230.1442, Val MAE: 59532.4726, Val MSE: 8879320076.3706, Val R2: 0.5489\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.1397\n",
      "Val RMSE: 80453.1115, Val MAE: 45685.9936, Val MSE: 6472703156.4751, Val R2: 0.6711\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.2466\n",
      "Val RMSE: 114964.2264, Val MAE: 63743.8729, Val MSE: 13216773344.7954, Val R2: 0.3285\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.2503\n",
      "Val RMSE: 112610.9244, Val MAE: 63974.9364, Val MSE: 12681220284.9315, Val R2: 0.3557\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1244\n",
      "Val RMSE: 74875.4656, Val MAE: 42840.7128, Val MSE: 5606335352.2732, Val R2: 0.7152\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1152\n",
      "Val RMSE: 74320.3403, Val MAE: 43060.9975, Val MSE: 5523512984.6515, Val R2: 0.7194\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74198.1020, Test MAE: 41860.6650, Test MSE: 5505358342.5931, Test R2: 0.6471\n",
      "Inference Time: 2.7219222142146185e-05 seconds per sample\n",
      "\n",
      "Iteration 78 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3980, Val Loss: 0.2814\n",
      "Val RMSE: 143304.9662, Val MAE: 81734.5550, Val MSE: 20536313340.3217, Val R2: -0.0434\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2777, Val Loss: 0.2749\n",
      "Val RMSE: 140798.3665, Val MAE: 84847.7069, Val MSE: 19824180011.3233, Val R2: -0.0072\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2730, Val Loss: 0.2769\n",
      "Val RMSE: 142164.1303, Val MAE: 82567.6076, Val MSE: 20210639947.4656, Val R2: -0.0268\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2676, Val Loss: 0.2773\n",
      "Val RMSE: 142386.6473, Val MAE: 82296.5984, Val MSE: 20273957326.6856, Val R2: -0.0300\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2660, Val Loss: 0.2754\n",
      "Val RMSE: 141945.9364, Val MAE: 82910.4432, Val MSE: 20148648872.0864, Val R2: -0.0237\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2651, Val Loss: 0.2751\n",
      "Val RMSE: 142027.0481, Val MAE: 83850.4420, Val MSE: 20171682395.3910, Val R2: -0.0248\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2598, Val Loss: 0.2726\n",
      "Val RMSE: 142922.9934, Val MAE: 79706.2766, Val MSE: 20426982043.0711, Val R2: -0.0378\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2597, Val Loss: 0.2730\n",
      "Val RMSE: 140278.9086, Val MAE: 85072.9211, Val MSE: 19678172210.7178, Val R2: 0.0002\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2692\n",
      "Val RMSE: 141345.0971, Val MAE: 81144.1179, Val MSE: 19978436464.1720, Val R2: -0.0150\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2737\n",
      "Val RMSE: 139889.0821, Val MAE: 86578.5413, Val MSE: 19568955282.3631, Val R2: 0.0058\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2670\n",
      "Val RMSE: 141322.3999, Val MAE: 79841.3343, Val MSE: 19972020701.0638, Val R2: -0.0147\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2732\n",
      "Val RMSE: 140626.3485, Val MAE: 83924.1708, Val MSE: 19775769904.5310, Val R2: -0.0047\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2663\n",
      "Val RMSE: 140404.8686, Val MAE: 80962.9194, Val MSE: 19713527133.7608, Val R2: -0.0016\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2499, Val Loss: 0.2669\n",
      "Val RMSE: 139061.5107, Val MAE: 81923.9485, Val MSE: 19338103747.3480, Val R2: 0.0175\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2393, Val Loss: 0.2583\n",
      "Val RMSE: 134101.9029, Val MAE: 80038.6549, Val MSE: 17983320369.9018, Val R2: 0.0863\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2344, Val Loss: 0.2547\n",
      "Val RMSE: 132109.8626, Val MAE: 80801.5095, Val MSE: 17453015801.3755, Val R2: 0.1133\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2291, Val Loss: 0.2475\n",
      "Val RMSE: 132380.0816, Val MAE: 77833.0044, Val MSE: 17524486000.0612, Val R2: 0.1096\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2253, Val Loss: 0.2322\n",
      "Val RMSE: 130275.7474, Val MAE: 73425.5354, Val MSE: 16971770364.9715, Val R2: 0.1377\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2196, Val Loss: 0.2460\n",
      "Val RMSE: 134847.9823, Val MAE: 79292.9182, Val MSE: 18183978328.7258, Val R2: 0.0761\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2300, Val Loss: 0.2526\n",
      "Val RMSE: 138618.9602, Val MAE: 74473.1854, Val MSE: 19215216135.4238, Val R2: 0.0237\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2187, Val Loss: 0.2481\n",
      "Val RMSE: 135947.6004, Val MAE: 76912.9879, Val MSE: 18481750064.0718, Val R2: 0.0610\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2185, Val Loss: 0.2363\n",
      "Val RMSE: 130668.5004, Val MAE: 75402.8927, Val MSE: 17074256993.5286, Val R2: 0.1325\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2006, Val Loss: 0.2244\n",
      "Val RMSE: 122139.9545, Val MAE: 73960.7138, Val MSE: 14918168484.6820, Val R2: 0.2421\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1926, Val Loss: 0.2229\n",
      "Val RMSE: 120168.1369, Val MAE: 72191.4056, Val MSE: 14440381127.5297, Val R2: 0.2663\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1860, Val Loss: 0.2215\n",
      "Val RMSE: 119457.5356, Val MAE: 72119.6179, Val MSE: 14270102806.7991, Val R2: 0.2750\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1834, Val Loss: 0.1947\n",
      "Val RMSE: 111223.2459, Val MAE: 65930.1042, Val MSE: 12370610428.8526, Val R2: 0.3715\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1778, Val Loss: 0.2050\n",
      "Val RMSE: 113058.1654, Val MAE: 67267.3565, Val MSE: 12782148771.5235, Val R2: 0.3506\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1704, Val Loss: 0.1883\n",
      "Val RMSE: 109334.4288, Val MAE: 63118.2434, Val MSE: 11954017319.9977, Val R2: 0.3927\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1659, Val Loss: 0.1901\n",
      "Val RMSE: 107377.3203, Val MAE: 64615.6599, Val MSE: 11529888925.4295, Val R2: 0.4142\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1626, Val Loss: 0.1681\n",
      "Val RMSE: 101584.2904, Val MAE: 61051.9084, Val MSE: 10319368066.0909, Val R2: 0.4757\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1680\n",
      "Val RMSE: 101975.3711, Val MAE: 60962.5950, Val MSE: 10398976305.0677, Val R2: 0.4717\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1560, Val Loss: 0.1636\n",
      "Val RMSE: 99787.1859, Val MAE: 59174.1172, Val MSE: 9957482475.3053, Val R2: 0.4941\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1542, Val Loss: 0.1576\n",
      "Val RMSE: 99128.0952, Val MAE: 56411.4471, Val MSE: 9826379262.4116, Val R2: 0.5008\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1494, Val Loss: 0.1605\n",
      "Val RMSE: 98362.4728, Val MAE: 58642.0296, Val MSE: 9675176047.1871, Val R2: 0.5084\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1457, Val Loss: 0.1591\n",
      "Val RMSE: 96466.0643, Val MAE: 59503.5569, Val MSE: 9305701559.3882, Val R2: 0.5272\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1496\n",
      "Val RMSE: 95184.1116, Val MAE: 55089.6218, Val MSE: 9060015092.5759, Val R2: 0.5397\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1431, Val Loss: 0.1427\n",
      "Val RMSE: 92172.0308, Val MAE: 53860.2007, Val MSE: 8495683267.9294, Val R2: 0.5684\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1450\n",
      "Val RMSE: 91812.5544, Val MAE: 51148.0550, Val MSE: 8429545148.2232, Val R2: 0.5717\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1359\n",
      "Val RMSE: 90704.9839, Val MAE: 52265.6232, Val MSE: 8227394100.9412, Val R2: 0.5820\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1279, Val Loss: 0.1344\n",
      "Val RMSE: 89597.9223, Val MAE: 51370.2475, Val MSE: 8027787688.7380, Val R2: 0.5921\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1321\n",
      "Val RMSE: 89946.6248, Val MAE: 50119.4731, Val MSE: 8090395320.9763, Val R2: 0.5890\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1228, Val Loss: 0.1321\n",
      "Val RMSE: 89796.9641, Val MAE: 49366.1006, Val MSE: 8063494768.7646, Val R2: 0.5903\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1177, Val Loss: 0.1278\n",
      "Val RMSE: 88082.5255, Val MAE: 48899.8653, Val MSE: 7758531294.0828, Val R2: 0.6058\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1166, Val Loss: 0.1388\n",
      "Val RMSE: 90956.0929, Val MAE: 51850.8515, Val MSE: 8273010840.5340, Val R2: 0.5797\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1357\n",
      "Val RMSE: 90835.6145, Val MAE: 47916.6139, Val MSE: 8251108858.2013, Val R2: 0.5808\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1112, Val Loss: 0.1375\n",
      "Val RMSE: 91363.3972, Val MAE: 50159.8828, Val MSE: 8347270347.3034, Val R2: 0.5759\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1177, Val Loss: 0.1375\n",
      "Val RMSE: 90431.6107, Val MAE: 51181.8873, Val MSE: 8177876219.3236, Val R2: 0.5845\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1325\n",
      "Val RMSE: 88822.2470, Val MAE: 51802.3133, Val MSE: 7889391564.1988, Val R2: 0.5992\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1075, Val Loss: 0.1261\n",
      "Val RMSE: 87591.8590, Val MAE: 47742.4522, Val MSE: 7672333764.8589, Val R2: 0.6102\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1045, Val Loss: 0.1379\n",
      "Val RMSE: 90710.1067, Val MAE: 49799.0272, Val MSE: 8228323451.2941, Val R2: 0.5819\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1349\n",
      "Val RMSE: 89451.1249, Val MAE: 47630.3644, Val MSE: 8001503752.1636, Val R2: 0.5935\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1319\n",
      "Val RMSE: 89474.0300, Val MAE: 47339.5327, Val MSE: 8005602040.5359, Val R2: 0.5933\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0934, Val Loss: 0.1362\n",
      "Val RMSE: 90176.8845, Val MAE: 49747.8792, Val MSE: 8131870499.7140, Val R2: 0.5868\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0930, Val Loss: 0.1307\n",
      "Val RMSE: 90592.0174, Val MAE: 47538.1589, Val MSE: 8206913615.8155, Val R2: 0.5830\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1300\n",
      "Val RMSE: 89706.3636, Val MAE: 47715.1017, Val MSE: 8047231664.1048, Val R2: 0.5911\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0890, Val Loss: 0.1343\n",
      "Val RMSE: 90451.8527, Val MAE: 49218.8056, Val MSE: 8181537651.4660, Val R2: 0.5843\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1388\n",
      "Val RMSE: 91739.0909, Val MAE: 53291.8113, Val MSE: 8416060796.8301, Val R2: 0.5724\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0843, Val Loss: 0.1290\n",
      "Val RMSE: 89537.9631, Val MAE: 49874.0658, Val MSE: 8017046830.3687, Val R2: 0.5927\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1409\n",
      "Val RMSE: 92085.4601, Val MAE: 53745.6220, Val MSE: 8479731967.0874, Val R2: 0.5692\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0838, Val Loss: 0.1353\n",
      "Val RMSE: 91368.7097, Val MAE: 50513.3881, Val MSE: 8348241113.6217, Val R2: 0.5759\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1372\n",
      "Val RMSE: 90891.1463, Val MAE: 49559.5982, Val MSE: 8261200468.1934, Val R2: 0.5803\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1357\n",
      "Val RMSE: 91436.5237, Val MAE: 47720.3337, Val MSE: 8360637873.6249, Val R2: 0.5752\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1368\n",
      "Val RMSE: 90568.8156, Val MAE: 48856.5177, Val MSE: 8202710360.3846, Val R2: 0.5833\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0768, Val Loss: 0.1309\n",
      "Val RMSE: 89442.6359, Val MAE: 47262.3239, Val MSE: 7999985119.6823, Val R2: 0.5936\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1366\n",
      "Val RMSE: 90839.1422, Val MAE: 50195.9574, Val MSE: 8251749756.2157, Val R2: 0.5808\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1351\n",
      "Val RMSE: 90652.3645, Val MAE: 48802.2796, Val MSE: 8217851186.2546, Val R2: 0.5825\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1363\n",
      "Val RMSE: 90119.2427, Val MAE: 51098.4099, Val MSE: 8121477911.9542, Val R2: 0.5874\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1413\n",
      "Val RMSE: 92137.1387, Val MAE: 51506.3453, Val MSE: 8489252332.4064, Val R2: 0.5687\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1397\n",
      "Val RMSE: 92186.9650, Val MAE: 50756.3740, Val MSE: 8498436520.7070, Val R2: 0.5682\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1382\n",
      "Val RMSE: 90614.7363, Val MAE: 49893.1875, Val MSE: 8211030441.6945, Val R2: 0.5828\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1358\n",
      "Val RMSE: 90193.9062, Val MAE: 49327.2746, Val MSE: 8134940708.6855, Val R2: 0.5867\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1338\n",
      "Val RMSE: 89307.1039, Val MAE: 49676.8699, Val MSE: 7975758799.7115, Val R2: 0.5948\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1378\n",
      "Val RMSE: 89443.5025, Val MAE: 49793.5136, Val MSE: 8000140138.4194, Val R2: 0.5935\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1220\n",
      "Val RMSE: 84513.4197, Val MAE: 46287.7385, Val MSE: 7142518108.3978, Val R2: 0.6371\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1263\n",
      "Val RMSE: 86466.5815, Val MAE: 48439.7196, Val MSE: 7476469712.3081, Val R2: 0.6201\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1214\n",
      "Val RMSE: 83880.2454, Val MAE: 45478.9265, Val MSE: 7035895571.4100, Val R2: 0.6425\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0590, Val Loss: 0.1188\n",
      "Val RMSE: 83903.1385, Val MAE: 44856.8880, Val MSE: 7039736654.9637, Val R2: 0.6423\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1333\n",
      "Val RMSE: 87534.6730, Val MAE: 48239.2732, Val MSE: 7662318971.8226, Val R2: 0.6107\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1250\n",
      "Val RMSE: 83842.7307, Val MAE: 46975.7673, Val MSE: 7029603495.5125, Val R2: 0.6429\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0579, Val Loss: 0.1212\n",
      "Val RMSE: 82580.9276, Val MAE: 44911.6298, Val MSE: 6819609598.2637, Val R2: 0.6535\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1299\n",
      "Val RMSE: 86063.9586, Val MAE: 46320.1128, Val MSE: 7407004967.4885, Val R2: 0.6237\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1309\n",
      "Val RMSE: 85364.1015, Val MAE: 47173.9835, Val MSE: 7287029820.1127, Val R2: 0.6298\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1226\n",
      "Val RMSE: 82553.0765, Val MAE: 45050.2667, Val MSE: 6815010440.6007, Val R2: 0.6538\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1227\n",
      "Val RMSE: 82472.3493, Val MAE: 45830.4032, Val MSE: 6801688396.7061, Val R2: 0.6544\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1271\n",
      "Val RMSE: 82375.0177, Val MAE: 50039.1039, Val MSE: 6785643542.4718, Val R2: 0.6552\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1286\n",
      "Val RMSE: 83145.7965, Val MAE: 49849.8701, Val MSE: 6913223472.3147, Val R2: 0.6488\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1247\n",
      "Val RMSE: 82387.6899, Val MAE: 46851.1592, Val MSE: 6787731446.2237, Val R2: 0.6551\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1153\n",
      "Val RMSE: 79164.2598, Val MAE: 43973.9060, Val MSE: 6266980036.3291, Val R2: 0.6816\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1227\n",
      "Val RMSE: 81945.6889, Val MAE: 47638.7134, Val MSE: 6715095935.2953, Val R2: 0.6588\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1255\n",
      "Val RMSE: 82641.0774, Val MAE: 45650.3453, Val MSE: 6829547676.2031, Val R2: 0.6530\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1255\n",
      "Val RMSE: 81908.8639, Val MAE: 45979.4475, Val MSE: 6709061988.1063, Val R2: 0.6591\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.1264\n",
      "Val RMSE: 81797.8810, Val MAE: 49576.5818, Val MSE: 6690893338.5206, Val R2: 0.6601\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1186\n",
      "Val RMSE: 80061.8223, Val MAE: 47038.6582, Val MSE: 6409895382.4032, Val R2: 0.6743\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1288\n",
      "Val RMSE: 82011.4012, Val MAE: 45250.4012, Val MSE: 6725869925.2999, Val R2: 0.6583\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1159\n",
      "Val RMSE: 78783.8256, Val MAE: 46448.0046, Val MSE: 6206891174.6727, Val R2: 0.6847\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1225\n",
      "Val RMSE: 79910.8889, Val MAE: 45998.3187, Val MSE: 6385750161.4926, Val R2: 0.6756\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1247\n",
      "Val RMSE: 81960.0101, Val MAE: 45060.1617, Val MSE: 6717443256.1720, Val R2: 0.6587\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1221\n",
      "Val RMSE: 81545.7224, Val MAE: 44365.9454, Val MSE: 6649704838.6050, Val R2: 0.6622\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1245\n",
      "Val RMSE: 81729.7817, Val MAE: 45046.2895, Val MSE: 6679757210.9577, Val R2: 0.6606\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1214\n",
      "Val RMSE: 80093.2137, Val MAE: 47121.5352, Val MSE: 6414922881.1200, Val R2: 0.6741\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 87040.3294, Test MAE: 48531.5274, Test MSE: 7576018946.9517, Test R2: 0.5144\n",
      "Inference Time: 3.030061721801758e-05 seconds per sample\n",
      "\n",
      "Iteration 79 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3636, Val Loss: 0.2794\n",
      "Val RMSE: 140261.6816, Val MAE: 88292.0586, Val MSE: 19673339319.2790, Val R2: 0.0005\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2758, Val Loss: 0.2802\n",
      "Val RMSE: 143292.0307, Val MAE: 81481.5977, Val MSE: 20532606066.5845, Val R2: -0.0432\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2704, Val Loss: 0.2746\n",
      "Val RMSE: 141320.2282, Val MAE: 83945.2673, Val MSE: 19971406909.9400, Val R2: -0.0147\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2729\n",
      "Val RMSE: 141602.1529, Val MAE: 83093.7964, Val MSE: 20051169703.3340, Val R2: -0.0187\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2650, Val Loss: 0.2722\n",
      "Val RMSE: 141663.3619, Val MAE: 82585.8531, Val MSE: 20068508095.2908, Val R2: -0.0196\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2747\n",
      "Val RMSE: 142204.7545, Val MAE: 82384.7269, Val MSE: 20222192200.2987, Val R2: -0.0274\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2571, Val Loss: 0.2709\n",
      "Val RMSE: 141020.3122, Val MAE: 82900.7406, Val MSE: 19886728457.2541, Val R2: -0.0104\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2739\n",
      "Val RMSE: 142609.9185, Val MAE: 82028.3327, Val MSE: 20337588846.1990, Val R2: -0.0333\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2730\n",
      "Val RMSE: 140524.4055, Val MAE: 85022.0899, Val MSE: 19747108537.0249, Val R2: -0.0033\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2788\n",
      "Val RMSE: 141936.9790, Val MAE: 85265.6214, Val MSE: 20146106000.2401, Val R2: -0.0235\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2725\n",
      "Val RMSE: 142394.0470, Val MAE: 79684.6819, Val MSE: 20276064630.1521, Val R2: -0.0302\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2514, Val Loss: 0.2703\n",
      "Val RMSE: 141818.8526, Val MAE: 78001.0172, Val MSE: 20112586956.3992, Val R2: -0.0218\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2489, Val Loss: 0.2604\n",
      "Val RMSE: 136207.4592, Val MAE: 80678.5869, Val MSE: 18552471928.4258, Val R2: 0.0574\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2395, Val Loss: 0.2541\n",
      "Val RMSE: 132413.9145, Val MAE: 80792.8832, Val MSE: 17533444744.5472, Val R2: 0.1092\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2268, Val Loss: 0.2309\n",
      "Val RMSE: 130108.7005, Val MAE: 74141.0771, Val MSE: 16928273941.8078, Val R2: 0.1399\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2280, Val Loss: 0.2484\n",
      "Val RMSE: 131757.4650, Val MAE: 81928.5359, Val MSE: 17360029587.7007, Val R2: 0.1180\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2200, Val Loss: 0.2320\n",
      "Val RMSE: 130635.2776, Val MAE: 74918.5272, Val MSE: 17065575765.4712, Val R2: 0.1330\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2169, Val Loss: 0.2453\n",
      "Val RMSE: 134992.1112, Val MAE: 71880.0112, Val MSE: 18222870086.3267, Val R2: 0.0742\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2187, Val Loss: 0.2330\n",
      "Val RMSE: 130318.1115, Val MAE: 74434.8088, Val MSE: 16982810177.2282, Val R2: 0.1372\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2136, Val Loss: 0.2325\n",
      "Val RMSE: 131056.9571, Val MAE: 72870.8508, Val MSE: 17175925993.6984, Val R2: 0.1274\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2099, Val Loss: 0.2259\n",
      "Val RMSE: 128715.5029, Val MAE: 72880.0677, Val MSE: 16567680686.5063, Val R2: 0.1583\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2233\n",
      "Val RMSE: 128086.9859, Val MAE: 73118.0181, Val MSE: 16406275955.8520, Val R2: 0.1665\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2032, Val Loss: 0.2260\n",
      "Val RMSE: 128448.4689, Val MAE: 73703.7062, Val MSE: 16499009169.3480, Val R2: 0.1617\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2031, Val Loss: 0.2259\n",
      "Val RMSE: 129098.5989, Val MAE: 72424.8953, Val MSE: 16666448243.9792, Val R2: 0.1532\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2008, Val Loss: 0.2463\n",
      "Val RMSE: 130022.3950, Val MAE: 77892.7068, Val MSE: 16905823210.9904, Val R2: 0.1411\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2237, Val Loss: 0.2312\n",
      "Val RMSE: 130579.8648, Val MAE: 73497.3014, Val MSE: 17051101086.1566, Val R2: 0.1337\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2057, Val Loss: 0.2323\n",
      "Val RMSE: 129903.9340, Val MAE: 73282.7885, Val MSE: 16875032064.9002, Val R2: 0.1426\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2003, Val Loss: 0.2279\n",
      "Val RMSE: 128586.8796, Val MAE: 71906.9547, Val MSE: 16534585601.7456, Val R2: 0.1599\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1854, Val Loss: 0.2113\n",
      "Val RMSE: 118918.3396, Val MAE: 68892.4492, Val MSE: 14141571484.7530, Val R2: 0.2815\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1764, Val Loss: 0.1998\n",
      "Val RMSE: 111766.7355, Val MAE: 67486.3155, Val MSE: 12491803174.7334, Val R2: 0.3653\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1720, Val Loss: 0.2009\n",
      "Val RMSE: 111460.9481, Val MAE: 64193.8403, Val MSE: 12423542951.5752, Val R2: 0.3688\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1690, Val Loss: 0.2005\n",
      "Val RMSE: 110256.5369, Val MAE: 64513.4582, Val MSE: 12156503930.1745, Val R2: 0.3824\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1670, Val Loss: 0.1910\n",
      "Val RMSE: 107082.4539, Val MAE: 62509.3659, Val MSE: 11466651940.9623, Val R2: 0.4174\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1599, Val Loss: 0.1750\n",
      "Val RMSE: 101815.3649, Val MAE: 61464.3947, Val MSE: 10366368524.4166, Val R2: 0.4733\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1555, Val Loss: 0.1761\n",
      "Val RMSE: 101533.8656, Val MAE: 60486.5224, Val MSE: 10309125858.2355, Val R2: 0.4762\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1497, Val Loss: 0.1676\n",
      "Val RMSE: 101163.7844, Val MAE: 58200.2148, Val MSE: 10234111280.8162, Val R2: 0.4800\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1477, Val Loss: 0.1688\n",
      "Val RMSE: 101890.5333, Val MAE: 57238.6497, Val MSE: 10381680768.7711, Val R2: 0.4725\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1447, Val Loss: 0.1721\n",
      "Val RMSE: 101927.0940, Val MAE: 61877.4441, Val MSE: 10389132496.5868, Val R2: 0.4722\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1403, Val Loss: 0.1653\n",
      "Val RMSE: 99296.6053, Val MAE: 58883.5414, Val MSE: 9859815828.8782, Val R2: 0.4991\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1383, Val Loss: 0.1626\n",
      "Val RMSE: 97058.3798, Val MAE: 59448.1442, Val MSE: 9420329083.8980, Val R2: 0.5214\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1320, Val Loss: 0.1570\n",
      "Val RMSE: 97836.3338, Val MAE: 55029.0771, Val MSE: 9571948217.8614, Val R2: 0.5137\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1266, Val Loss: 0.1517\n",
      "Val RMSE: 95623.4836, Val MAE: 53940.8692, Val MSE: 9143850614.6643, Val R2: 0.5354\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1253, Val Loss: 0.1597\n",
      "Val RMSE: 97750.3218, Val MAE: 55670.3691, Val MSE: 9555125418.4853, Val R2: 0.5145\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1219, Val Loss: 0.1529\n",
      "Val RMSE: 96079.2717, Val MAE: 54409.6557, Val MSE: 9231226453.9182, Val R2: 0.5310\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1616\n",
      "Val RMSE: 98398.4017, Val MAE: 56980.2354, Val MSE: 9682245452.9667, Val R2: 0.5081\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1510\n",
      "Val RMSE: 95248.6138, Val MAE: 53192.9875, Val MSE: 9072298438.5921, Val R2: 0.5391\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1592\n",
      "Val RMSE: 97719.4884, Val MAE: 55730.0773, Val MSE: 9549098419.0218, Val R2: 0.5148\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1060, Val Loss: 0.1548\n",
      "Val RMSE: 96046.5925, Val MAE: 56056.5806, Val MSE: 9224947930.6377, Val R2: 0.5313\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1035, Val Loss: 0.1484\n",
      "Val RMSE: 95086.5097, Val MAE: 50531.1793, Val MSE: 9041444333.9314, Val R2: 0.5406\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0995, Val Loss: 0.1487\n",
      "Val RMSE: 93706.1803, Val MAE: 54166.6919, Val MSE: 8780848219.4449, Val R2: 0.5539\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0976, Val Loss: 0.1529\n",
      "Val RMSE: 94216.5442, Val MAE: 52677.4404, Val MSE: 8876757194.7872, Val R2: 0.5490\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1519\n",
      "Val RMSE: 92562.3568, Val MAE: 55964.5866, Val MSE: 8567789897.9499, Val R2: 0.5647\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0906, Val Loss: 0.1460\n",
      "Val RMSE: 90720.1014, Val MAE: 54338.5243, Val MSE: 8230136801.0375, Val R2: 0.5819\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1467\n",
      "Val RMSE: 89172.2877, Val MAE: 52774.4817, Val MSE: 7951696895.3138, Val R2: 0.5960\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1415\n",
      "Val RMSE: 88057.8142, Val MAE: 51363.8581, Val MSE: 7754178634.1281, Val R2: 0.6060\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1453\n",
      "Val RMSE: 89492.5930, Val MAE: 52148.4428, Val MSE: 8008924209.3785, Val R2: 0.5931\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1573\n",
      "Val RMSE: 93654.4127, Val MAE: 55692.5159, Val MSE: 8771149015.1653, Val R2: 0.5544\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0808, Val Loss: 0.1515\n",
      "Val RMSE: 91279.6205, Val MAE: 55130.5171, Val MSE: 8331969110.1248, Val R2: 0.5767\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0808, Val Loss: 0.1585\n",
      "Val RMSE: 89354.1477, Val MAE: 56520.6493, Val MSE: 7984163709.0287, Val R2: 0.5944\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1476\n",
      "Val RMSE: 89325.8384, Val MAE: 53538.4743, Val MSE: 7979105409.0981, Val R2: 0.5946\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1322\n",
      "Val RMSE: 81769.0109, Val MAE: 50332.6074, Val MSE: 6686171145.5165, Val R2: 0.6603\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1358\n",
      "Val RMSE: 83240.8267, Val MAE: 49919.5094, Val MSE: 6929035233.5842, Val R2: 0.6480\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1332\n",
      "Val RMSE: 79705.9222, Val MAE: 49970.5779, Val MSE: 6353034031.2059, Val R2: 0.6772\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1429\n",
      "Val RMSE: 84821.9947, Val MAE: 52001.1357, Val MSE: 7194770781.7898, Val R2: 0.6345\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1308\n",
      "Val RMSE: 78824.8853, Val MAE: 49476.7250, Val MSE: 6213362547.2201, Val R2: 0.6843\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0718, Val Loss: 0.1508\n",
      "Val RMSE: 84321.9592, Val MAE: 52671.9709, Val MSE: 7110192807.0181, Val R2: 0.6388\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1498\n",
      "Val RMSE: 83014.5526, Val MAE: 53602.1267, Val MSE: 6891415949.3569, Val R2: 0.6499\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1319\n",
      "Val RMSE: 80020.9507, Val MAE: 51294.2063, Val MSE: 6403352550.1295, Val R2: 0.6747\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1452\n",
      "Val RMSE: 83591.8229, Val MAE: 53705.6973, Val MSE: 6987592856.7377, Val R2: 0.6450\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1206\n",
      "Val RMSE: 75233.2364, Val MAE: 48287.1965, Val MSE: 5660039858.0151, Val R2: 0.7124\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0664, Val Loss: 0.1244\n",
      "Val RMSE: 74189.0862, Val MAE: 47758.4059, Val MSE: 5504020515.4930, Val R2: 0.7204\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1200\n",
      "Val RMSE: 75965.1932, Val MAE: 46575.9812, Val MSE: 5770710584.5635, Val R2: 0.7068\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1453\n",
      "Val RMSE: 83027.3755, Val MAE: 53777.5713, Val MSE: 6893545080.1874, Val R2: 0.6498\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1189\n",
      "Val RMSE: 74217.8531, Val MAE: 46271.9249, Val MSE: 5508289719.7085, Val R2: 0.7201\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1244\n",
      "Val RMSE: 76147.6400, Val MAE: 48330.3763, Val MSE: 5798463076.7508, Val R2: 0.7054\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0599, Val Loss: 0.1207\n",
      "Val RMSE: 75822.6128, Val MAE: 47079.1713, Val MSE: 5749068607.5076, Val R2: 0.7079\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1244\n",
      "Val RMSE: 76182.3499, Val MAE: 47030.5105, Val MSE: 5803750436.2567, Val R2: 0.7051\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1231\n",
      "Val RMSE: 75374.6343, Val MAE: 45721.1927, Val MSE: 5681335489.0264, Val R2: 0.7114\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1173\n",
      "Val RMSE: 73237.2014, Val MAE: 46573.5511, Val MSE: 5363687668.5043, Val R2: 0.7275\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.1155\n",
      "Val RMSE: 73045.1641, Val MAE: 47206.7870, Val MSE: 5335595996.8555, Val R2: 0.7289\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1183\n",
      "Val RMSE: 73888.8236, Val MAE: 46537.8048, Val MSE: 5459558249.2438, Val R2: 0.7226\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1217\n",
      "Val RMSE: 75569.2145, Val MAE: 46716.9474, Val MSE: 5710706185.6501, Val R2: 0.7099\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1263\n",
      "Val RMSE: 77090.0944, Val MAE: 48659.4751, Val MSE: 5942882648.7176, Val R2: 0.6981\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1144\n",
      "Val RMSE: 73743.7566, Val MAE: 43871.4239, Val MSE: 5438141639.7333, Val R2: 0.7237\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1049\n",
      "Val RMSE: 70581.9790, Val MAE: 42583.9745, Val MSE: 4981815753.1937, Val R2: 0.7469\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0534, Val Loss: 0.1162\n",
      "Val RMSE: 74366.7958, Val MAE: 44444.7400, Val MSE: 5530420315.0210, Val R2: 0.7190\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1232\n",
      "Val RMSE: 74734.8843, Val MAE: 47330.1191, Val MSE: 5585302934.0243, Val R2: 0.7162\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1154\n",
      "Val RMSE: 72691.5510, Val MAE: 44896.5220, Val MSE: 5284061593.3351, Val R2: 0.7315\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1241\n",
      "Val RMSE: 76107.4760, Val MAE: 47780.1555, Val MSE: 5792347907.5275, Val R2: 0.7057\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1138\n",
      "Val RMSE: 73201.8886, Val MAE: 43903.7378, Val MSE: 5358516498.1783, Val R2: 0.7278\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1158\n",
      "Val RMSE: 73824.5933, Val MAE: 47943.2266, Val MSE: 5450070572.5399, Val R2: 0.7231\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1137\n",
      "Val RMSE: 72165.0787, Val MAE: 45341.4393, Val MSE: 5207798579.9093, Val R2: 0.7354\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1201\n",
      "Val RMSE: 73460.4339, Val MAE: 47786.8030, Val MSE: 5396435349.7705, Val R2: 0.7258\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1236\n",
      "Val RMSE: 75664.4882, Val MAE: 47799.5448, Val MSE: 5725114777.8947, Val R2: 0.7091\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1279\n",
      "Val RMSE: 76225.7267, Val MAE: 49169.9495, Val MSE: 5810361408.2484, Val R2: 0.7048\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1144\n",
      "Val RMSE: 72849.0887, Val MAE: 45396.2690, Val MSE: 5306989730.7175, Val R2: 0.7304\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1102\n",
      "Val RMSE: 70471.2473, Val MAE: 46895.6812, Val MSE: 4966196690.3650, Val R2: 0.7477\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1178\n",
      "Val RMSE: 72869.6669, Val MAE: 46715.5139, Val MSE: 5309988350.6688, Val R2: 0.7302\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1185\n",
      "Val RMSE: 73025.8686, Val MAE: 46847.2666, Val MSE: 5332777483.8062, Val R2: 0.7291\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1078\n",
      "Val RMSE: 71084.1101, Val MAE: 42683.9291, Val MSE: 5052950708.2897, Val R2: 0.7433\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 76237.7778, Test MAE: 43779.8751, Test MSE: 5812198759.6103, Test R2: 0.6274\n",
      "Inference Time: 2.1905825688288762e-05 seconds per sample\n",
      "\n",
      "Iteration 80 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3405, Val Loss: 0.2802\n",
      "Val RMSE: 143314.9090, Val MAE: 81629.5615, Val MSE: 20539163150.2902, Val R2: -0.0435\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2754\n",
      "Val RMSE: 141246.5880, Val MAE: 84091.8811, Val MSE: 19950598619.7426, Val R2: -0.0136\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2752\n",
      "Val RMSE: 141078.0492, Val MAE: 84247.6581, Val MSE: 19903015965.5025, Val R2: -0.0112\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2663, Val Loss: 0.2755\n",
      "Val RMSE: 141531.1154, Val MAE: 83617.3315, Val MSE: 20031056629.9733, Val R2: -0.0177\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2658, Val Loss: 0.2747\n",
      "Val RMSE: 141719.3030, Val MAE: 83372.7157, Val MSE: 20084360832.4281, Val R2: -0.0204\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2758\n",
      "Val RMSE: 141630.3167, Val MAE: 83700.3950, Val MSE: 20059146599.5124, Val R2: -0.0191\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2736\n",
      "Val RMSE: 141024.2581, Val MAE: 84507.0499, Val MSE: 19887841363.3258, Val R2: -0.0104\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2755\n",
      "Val RMSE: 143718.0505, Val MAE: 79070.7392, Val MSE: 20654878039.5015, Val R2: -0.0494\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2727\n",
      "Val RMSE: 140107.0908, Val MAE: 85658.3701, Val MSE: 19629996901.7983, Val R2: 0.0027\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2555, Val Loss: 0.2658\n",
      "Val RMSE: 140071.7128, Val MAE: 81975.5832, Val MSE: 19620084717.1760, Val R2: 0.0032\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2646\n",
      "Val RMSE: 139707.8260, Val MAE: 77226.5069, Val MSE: 19518276638.0457, Val R2: 0.0083\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2610\n",
      "Val RMSE: 138794.8964, Val MAE: 76662.8005, Val MSE: 19264023273.2214, Val R2: 0.0213\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2475, Val Loss: 0.2530\n",
      "Val RMSE: 135750.3899, Val MAE: 76763.6962, Val MSE: 18428168354.9998, Val R2: 0.0637\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2413, Val Loss: 0.2524\n",
      "Val RMSE: 134916.7533, Val MAE: 78657.1733, Val MSE: 18202530331.4000, Val R2: 0.0752\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2337, Val Loss: 0.2311\n",
      "Val RMSE: 130660.6741, Val MAE: 73691.4444, Val MSE: 17072211763.4542, Val R2: 0.1326\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2247, Val Loss: 0.2303\n",
      "Val RMSE: 130842.3610, Val MAE: 72961.3211, Val MSE: 17119723422.6650, Val R2: 0.1302\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2216, Val Loss: 0.2369\n",
      "Val RMSE: 129582.7470, Val MAE: 77332.9057, Val MSE: 16791688321.1271, Val R2: 0.1469\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2957\n",
      "Val RMSE: 141584.4636, Val MAE: 78353.3544, Val MSE: 20046160344.5012, Val R2: -0.0185\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2364, Val Loss: 0.2332\n",
      "Val RMSE: 131151.2237, Val MAE: 74030.8424, Val MSE: 17200643485.7799, Val R2: 0.1261\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2338\n",
      "Val RMSE: 132267.6226, Val MAE: 72047.1440, Val MSE: 17494723979.8280, Val R2: 0.1112\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2185, Val Loss: 0.2325\n",
      "Val RMSE: 131661.5961, Val MAE: 72132.4760, Val MSE: 17334775882.8656, Val R2: 0.1193\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2187, Val Loss: 0.2356\n",
      "Val RMSE: 131987.8747, Val MAE: 73862.3184, Val MSE: 17420799064.6601, Val R2: 0.1149\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2161, Val Loss: 0.2384\n",
      "Val RMSE: 133128.2220, Val MAE: 74577.7685, Val MSE: 17723123494.1944, Val R2: 0.0996\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2109, Val Loss: 0.2350\n",
      "Val RMSE: 132790.3281, Val MAE: 72564.8964, Val MSE: 17633271228.0608, Val R2: 0.1041\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2121, Val Loss: 0.2410\n",
      "Val RMSE: 132197.0537, Val MAE: 76414.9397, Val MSE: 17476060996.0710, Val R2: 0.1121\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2273\n",
      "Val RMSE: 130217.9656, Val MAE: 71070.3732, Val MSE: 16956718567.4102, Val R2: 0.1385\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2001, Val Loss: 0.2159\n",
      "Val RMSE: 122196.7973, Val MAE: 70285.4720, Val MSE: 14932057282.4736, Val R2: 0.2414\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2105\n",
      "Val RMSE: 116848.9353, Val MAE: 66679.1196, Val MSE: 13653673683.5179, Val R2: 0.3063\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1870, Val Loss: 0.2041\n",
      "Val RMSE: 111305.1883, Val MAE: 68667.6057, Val MSE: 12388844935.6675, Val R2: 0.3706\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1809, Val Loss: 0.2052\n",
      "Val RMSE: 109059.2032, Val MAE: 72333.8167, Val MSE: 11893909804.4178, Val R2: 0.3957\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1816, Val Loss: 0.1963\n",
      "Val RMSE: 106559.8388, Val MAE: 66737.6742, Val MSE: 11354999245.3999, Val R2: 0.4231\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1732, Val Loss: 0.1890\n",
      "Val RMSE: 104838.1344, Val MAE: 66303.7338, Val MSE: 10991034416.3566, Val R2: 0.4416\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1663, Val Loss: 0.1734\n",
      "Val RMSE: 100871.1572, Val MAE: 62593.6050, Val MSE: 10174990355.5813, Val R2: 0.4830\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1632, Val Loss: 0.1840\n",
      "Val RMSE: 103380.8189, Val MAE: 65649.3806, Val MSE: 10687593723.0083, Val R2: 0.4570\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1578, Val Loss: 0.1699\n",
      "Val RMSE: 100038.3546, Val MAE: 61143.8062, Val MSE: 10007672395.7407, Val R2: 0.4915\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1533, Val Loss: 0.1693\n",
      "Val RMSE: 102377.7243, Val MAE: 58868.9526, Val MSE: 10481198431.2938, Val R2: 0.4675\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1453, Val Loss: 0.1697\n",
      "Val RMSE: 102091.5864, Val MAE: 57217.9123, Val MSE: 10422692016.6631, Val R2: 0.4705\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1439, Val Loss: 0.1595\n",
      "Val RMSE: 97878.1494, Val MAE: 57179.6744, Val MSE: 9580132139.1032, Val R2: 0.5133\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1369, Val Loss: 0.1738\n",
      "Val RMSE: 104317.0894, Val MAE: 59380.1151, Val MSE: 10882055131.8494, Val R2: 0.4471\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1325, Val Loss: 0.1635\n",
      "Val RMSE: 101633.7956, Val MAE: 57882.5945, Val MSE: 10329428409.5437, Val R2: 0.4752\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1311, Val Loss: 0.1692\n",
      "Val RMSE: 103156.3336, Val MAE: 58813.8281, Val MSE: 10641229160.0249, Val R2: 0.4594\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1236, Val Loss: 0.1502\n",
      "Val RMSE: 94740.1662, Val MAE: 51756.4487, Val MSE: 8975699094.7181, Val R2: 0.5440\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1199, Val Loss: 0.1651\n",
      "Val RMSE: 101956.1543, Val MAE: 56695.3358, Val MSE: 10395057406.7239, Val R2: 0.4719\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1155, Val Loss: 0.1683\n",
      "Val RMSE: 100088.3901, Val MAE: 54087.4796, Val MSE: 10017685824.6093, Val R2: 0.4910\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1572\n",
      "Val RMSE: 97426.3995, Val MAE: 52117.0121, Val MSE: 9491903313.7335, Val R2: 0.5178\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1673\n",
      "Val RMSE: 99480.7512, Val MAE: 54434.8190, Val MSE: 9896419858.3817, Val R2: 0.4972\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1022, Val Loss: 0.1676\n",
      "Val RMSE: 97933.5286, Val MAE: 54802.7975, Val MSE: 9590976022.2828, Val R2: 0.5127\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0971, Val Loss: 0.1487\n",
      "Val RMSE: 95010.6441, Val MAE: 51413.2366, Val MSE: 9027022485.2521, Val R2: 0.5414\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1533\n",
      "Val RMSE: 95956.6427, Val MAE: 52130.3944, Val MSE: 9207677272.2581, Val R2: 0.5322\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0910, Val Loss: 0.1494\n",
      "Val RMSE: 93886.0001, Val MAE: 51994.6299, Val MSE: 8814581012.0476, Val R2: 0.5522\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1447\n",
      "Val RMSE: 91786.8198, Val MAE: 50981.0050, Val MSE: 8424820297.1966, Val R2: 0.5720\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1368\n",
      "Val RMSE: 88774.4935, Val MAE: 49791.8531, Val MSE: 7880910704.2281, Val R2: 0.5996\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0827, Val Loss: 0.1511\n",
      "Val RMSE: 95391.6654, Val MAE: 50896.7530, Val MSE: 9099569831.7513, Val R2: 0.5377\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0808, Val Loss: 0.1403\n",
      "Val RMSE: 87660.3344, Val MAE: 51913.2662, Val MSE: 7684334226.9031, Val R2: 0.6096\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0787, Val Loss: 0.1443\n",
      "Val RMSE: 89697.7113, Val MAE: 49664.8388, Val MSE: 8045679411.1577, Val R2: 0.5912\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1356\n",
      "Val RMSE: 86085.7285, Val MAE: 48789.3814, Val MSE: 7410752659.8223, Val R2: 0.6235\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1443\n",
      "Val RMSE: 89209.4285, Val MAE: 49417.8152, Val MSE: 7958322141.5709, Val R2: 0.5957\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1449\n",
      "Val RMSE: 88094.1608, Val MAE: 49601.0174, Val MSE: 7760581170.5174, Val R2: 0.6057\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1346\n",
      "Val RMSE: 83615.6966, Val MAE: 49174.5649, Val MSE: 6991584714.9604, Val R2: 0.6448\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0716, Val Loss: 0.1451\n",
      "Val RMSE: 89637.4569, Val MAE: 50750.3161, Val MSE: 8034873676.6630, Val R2: 0.5918\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0690, Val Loss: 0.1384\n",
      "Val RMSE: 84914.4425, Val MAE: 49280.4155, Val MSE: 7210462551.4724, Val R2: 0.6337\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1457\n",
      "Val RMSE: 89403.9608, Val MAE: 50152.8986, Val MSE: 7993068203.2121, Val R2: 0.5939\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0665, Val Loss: 0.1430\n",
      "Val RMSE: 88660.9998, Val MAE: 49052.4151, Val MSE: 7860772891.3516, Val R2: 0.6006\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1332\n",
      "Val RMSE: 84368.7033, Val MAE: 46932.9497, Val MSE: 7118078089.3358, Val R2: 0.6384\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0639, Val Loss: 0.1292\n",
      "Val RMSE: 83275.6205, Val MAE: 45759.7322, Val MSE: 6934828961.8301, Val R2: 0.6477\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0638, Val Loss: 0.1372\n",
      "Val RMSE: 85677.7159, Val MAE: 48957.9996, Val MSE: 7340671010.2691, Val R2: 0.6270\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1373\n",
      "Val RMSE: 86852.3731, Val MAE: 47498.2681, Val MSE: 7543334706.0832, Val R2: 0.6168\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1365\n",
      "Val RMSE: 83867.1709, Val MAE: 48145.4274, Val MSE: 7033702358.2950, Val R2: 0.6426\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1300\n",
      "Val RMSE: 82379.3395, Val MAE: 46636.6591, Val MSE: 6786355576.6805, Val R2: 0.6552\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0590, Val Loss: 0.1428\n",
      "Val RMSE: 87791.7880, Val MAE: 50547.3090, Val MSE: 7707398041.6390, Val R2: 0.6084\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1334\n",
      "Val RMSE: 85321.7233, Val MAE: 46932.0886, Val MSE: 7279796465.6027, Val R2: 0.6301\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1324\n",
      "Val RMSE: 85175.0341, Val MAE: 46719.1941, Val MSE: 7254786436.1356, Val R2: 0.6314\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1338\n",
      "Val RMSE: 82549.6560, Val MAE: 48591.3161, Val MSE: 6814445709.6040, Val R2: 0.6538\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1352\n",
      "Val RMSE: 84679.9308, Val MAE: 49878.9903, Val MSE: 7170690681.9500, Val R2: 0.6357\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1367\n",
      "Val RMSE: 86380.0227, Val MAE: 47388.1483, Val MSE: 7461508317.1447, Val R2: 0.6209\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1356\n",
      "Val RMSE: 83215.9279, Val MAE: 48438.1657, Val MSE: 6924890657.1983, Val R2: 0.6482\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1207\n",
      "Val RMSE: 78167.4684, Val MAE: 44486.8267, Val MSE: 6110153118.0138, Val R2: 0.6896\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1243\n",
      "Val RMSE: 80680.7163, Val MAE: 45485.9329, Val MSE: 6509377981.1923, Val R2: 0.6693\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1293\n",
      "Val RMSE: 81040.3939, Val MAE: 46460.4133, Val MSE: 6567545448.9229, Val R2: 0.6663\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1317\n",
      "Val RMSE: 82883.4128, Val MAE: 46981.4809, Val MSE: 6869660111.9513, Val R2: 0.6510\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1419\n",
      "Val RMSE: 86202.0697, Val MAE: 49427.8621, Val MSE: 7430796817.9759, Val R2: 0.6225\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1287\n",
      "Val RMSE: 82146.1214, Val MAE: 45441.9160, Val MSE: 6747985254.8682, Val R2: 0.6572\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1341\n",
      "Val RMSE: 82593.4752, Val MAE: 47399.7779, Val MSE: 6821682144.0252, Val R2: 0.6534\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1286\n",
      "Val RMSE: 82903.4391, Val MAE: 45539.7009, Val MSE: 6872980211.2056, Val R2: 0.6508\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1293\n",
      "Val RMSE: 81015.3570, Val MAE: 46921.2655, Val MSE: 6563488065.0677, Val R2: 0.6665\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1321\n",
      "Val RMSE: 82185.8297, Val MAE: 45924.2824, Val MSE: 6754510609.5936, Val R2: 0.6568\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1285\n",
      "Val RMSE: 80538.8258, Val MAE: 45778.2176, Val MSE: 6486502456.6471, Val R2: 0.6704\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1391\n",
      "Val RMSE: 84931.1648, Val MAE: 47246.4929, Val MSE: 7213302750.5707, Val R2: 0.6335\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1267\n",
      "Val RMSE: 80881.0509, Val MAE: 44888.7973, Val MSE: 6541744388.6930, Val R2: 0.6676\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1248\n",
      "Val RMSE: 79307.3052, Val MAE: 45255.2628, Val MSE: 6289648661.5750, Val R2: 0.6804\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1224\n",
      "Val RMSE: 78415.3818, Val MAE: 44231.2365, Val MSE: 6148972100.6198, Val R2: 0.6876\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1228\n",
      "Val RMSE: 77273.3954, Val MAE: 44945.4817, Val MSE: 5971177630.7003, Val R2: 0.6966\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1311\n",
      "Val RMSE: 83129.4771, Val MAE: 46158.5807, Val MSE: 6910509960.7283, Val R2: 0.6489\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1289\n",
      "Val RMSE: 80214.9585, Val MAE: 45911.2805, Val MSE: 6434439574.8508, Val R2: 0.6731\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0445, Val Loss: 0.1328\n",
      "Val RMSE: 81657.0317, Val MAE: 47962.4051, Val MSE: 6667870822.6784, Val R2: 0.6612\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1319\n",
      "Val RMSE: 82032.1856, Val MAE: 45752.6614, Val MSE: 6729279469.2431, Val R2: 0.6581\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1363\n",
      "Val RMSE: 81846.8990, Val MAE: 49009.4444, Val MSE: 6698914882.4569, Val R2: 0.6597\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0425, Val Loss: 0.1342\n",
      "Val RMSE: 83530.1943, Val MAE: 46031.4198, Val MSE: 6977293358.6663, Val R2: 0.6455\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.1257\n",
      "Val RMSE: 81581.3796, Val MAE: 45025.1479, Val MSE: 6655521503.0480, Val R2: 0.6619\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0418, Val Loss: 0.1252\n",
      "Val RMSE: 80206.8282, Val MAE: 44854.3447, Val MSE: 6433135289.0537, Val R2: 0.6732\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 85248.0086, Test MAE: 47421.9367, Test MSE: 7267222964.4727, Test R2: 0.5342\n",
      "Inference Time: 2.794064008272611e-05 seconds per sample\n",
      "\n",
      "Iteration 81 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3370, Val Loss: 0.2975\n",
      "Val RMSE: 146620.9752, Val MAE: 81512.1412, Val MSE: 21497710375.1974, Val R2: -0.0922\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2746, Val Loss: 0.2765\n",
      "Val RMSE: 141749.9113, Val MAE: 84081.4895, Val MSE: 20093037345.9815, Val R2: -0.0209\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2688, Val Loss: 0.2756\n",
      "Val RMSE: 141888.8977, Val MAE: 82925.5212, Val MSE: 20132459299.0390, Val R2: -0.0229\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2650, Val Loss: 0.2749\n",
      "Val RMSE: 142286.9634, Val MAE: 82214.6087, Val MSE: 20245579952.8898, Val R2: -0.0286\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2860\n",
      "Val RMSE: 145426.7335, Val MAE: 79713.8278, Val MSE: 21148934819.3457, Val R2: -0.0745\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2633, Val Loss: 0.2716\n",
      "Val RMSE: 141396.7062, Val MAE: 82237.3026, Val MSE: 19993028533.9486, Val R2: -0.0158\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2701\n",
      "Val RMSE: 140867.8113, Val MAE: 82715.5019, Val MSE: 19843740250.7951, Val R2: -0.0082\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2696\n",
      "Val RMSE: 140558.1936, Val MAE: 83064.3574, Val MSE: 19756605776.9203, Val R2: -0.0038\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2755\n",
      "Val RMSE: 140745.7037, Val MAE: 85515.5559, Val MSE: 19809353115.4339, Val R2: -0.0064\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2676\n",
      "Val RMSE: 140442.5043, Val MAE: 82490.7184, Val MSE: 19724097011.6775, Val R2: -0.0021\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2520, Val Loss: 0.2665\n",
      "Val RMSE: 140416.4020, Val MAE: 81227.1080, Val MSE: 19716765942.4297, Val R2: -0.0017\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2492, Val Loss: 0.2625\n",
      "Val RMSE: 137797.7895, Val MAE: 81196.1759, Val MSE: 18988230785.8616, Val R2: 0.0353\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2406, Val Loss: 0.2733\n",
      "Val RMSE: 136688.0548, Val MAE: 83809.5660, Val MSE: 18683624325.2847, Val R2: 0.0508\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2383, Val Loss: 0.2517\n",
      "Val RMSE: 135639.8898, Val MAE: 76232.4181, Val MSE: 18398179706.8659, Val R2: 0.0653\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2372, Val Loss: 0.2608\n",
      "Val RMSE: 135904.6169, Val MAE: 80115.0489, Val MSE: 18470064907.0995, Val R2: 0.0616\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2346, Val Loss: 0.2538\n",
      "Val RMSE: 136189.3196, Val MAE: 76495.5805, Val MSE: 18547530775.7350, Val R2: 0.0577\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2525\n",
      "Val RMSE: 136092.7390, Val MAE: 73658.2682, Val MSE: 18521233604.4689, Val R2: 0.0590\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2210, Val Loss: 0.2417\n",
      "Val RMSE: 132618.3954, Val MAE: 75899.7479, Val MSE: 17587638792.2910, Val R2: 0.1064\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2154, Val Loss: 0.2406\n",
      "Val RMSE: 133538.0829, Val MAE: 73020.8176, Val MSE: 17832419595.6995, Val R2: 0.0940\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2143, Val Loss: 0.2419\n",
      "Val RMSE: 133362.4777, Val MAE: 72630.1212, Val MSE: 17785550468.6534, Val R2: 0.0964\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2140, Val Loss: 0.2422\n",
      "Val RMSE: 134321.6547, Val MAE: 75133.6641, Val MSE: 18042306925.6971, Val R2: 0.0833\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2125, Val Loss: 0.2274\n",
      "Val RMSE: 128183.0891, Val MAE: 73375.8669, Val MSE: 16430904333.8932, Val R2: 0.1652\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2083, Val Loss: 0.2216\n",
      "Val RMSE: 127864.4865, Val MAE: 71677.0359, Val MSE: 16349326906.0231, Val R2: 0.1694\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2046, Val Loss: 0.2222\n",
      "Val RMSE: 128065.6241, Val MAE: 71560.9568, Val MSE: 16400804084.0845, Val R2: 0.1667\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2051, Val Loss: 0.2222\n",
      "Val RMSE: 128661.3621, Val MAE: 70412.5262, Val MSE: 16553746094.8543, Val R2: 0.1590\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2034, Val Loss: 0.2223\n",
      "Val RMSE: 127725.5454, Val MAE: 71683.5729, Val MSE: 16313814940.8389, Val R2: 0.1712\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1981, Val Loss: 0.2340\n",
      "Val RMSE: 131922.5659, Val MAE: 70962.2523, Val MSE: 17403563404.3959, Val R2: 0.1158\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1994, Val Loss: 0.2304\n",
      "Val RMSE: 127783.6704, Val MAE: 77182.0231, Val MSE: 16328666409.1676, Val R2: 0.1704\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2072, Val Loss: 0.2213\n",
      "Val RMSE: 123997.5345, Val MAE: 69511.4115, Val MSE: 15375388569.6174, Val R2: 0.2188\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1931, Val Loss: 0.2119\n",
      "Val RMSE: 118140.0867, Val MAE: 68399.4329, Val MSE: 13957080079.7538, Val R2: 0.2909\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1825, Val Loss: 0.2068\n",
      "Val RMSE: 115252.4194, Val MAE: 64900.2882, Val MSE: 13283120184.1657, Val R2: 0.3251\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1753, Val Loss: 0.1905\n",
      "Val RMSE: 105932.4418, Val MAE: 63656.0419, Val MSE: 11221682230.5225, Val R2: 0.4299\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1676, Val Loss: 0.1926\n",
      "Val RMSE: 108455.5013, Val MAE: 63120.8843, Val MSE: 11762595759.9082, Val R2: 0.4024\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1619, Val Loss: 0.2004\n",
      "Val RMSE: 107907.9451, Val MAE: 63371.2139, Val MSE: 11644124616.9055, Val R2: 0.4084\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1597, Val Loss: 0.1758\n",
      "Val RMSE: 101504.9128, Val MAE: 61962.5172, Val MSE: 10303247323.8977, Val R2: 0.4765\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1504, Val Loss: 0.1764\n",
      "Val RMSE: 102092.8666, Val MAE: 61255.5392, Val MSE: 10422953401.5714, Val R2: 0.4704\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1447, Val Loss: 0.1778\n",
      "Val RMSE: 101132.7539, Val MAE: 63469.1505, Val MSE: 10227833917.3811, Val R2: 0.4804\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1669\n",
      "Val RMSE: 99401.8650, Val MAE: 58386.8128, Val MSE: 9880730759.3589, Val R2: 0.4980\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1361, Val Loss: 0.1775\n",
      "Val RMSE: 99595.8608, Val MAE: 61440.6319, Val MSE: 9919335491.9919, Val R2: 0.4960\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1337, Val Loss: 0.1648\n",
      "Val RMSE: 98826.0339, Val MAE: 58177.0174, Val MSE: 9766584985.8035, Val R2: 0.5038\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1293, Val Loss: 0.2003\n",
      "Val RMSE: 111773.6419, Val MAE: 63600.9605, Val MSE: 12493347026.8315, Val R2: 0.3653\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1264, Val Loss: 0.1617\n",
      "Val RMSE: 97788.5729, Val MAE: 57256.5553, Val MSE: 9562604991.1089, Val R2: 0.5142\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1198, Val Loss: 0.1819\n",
      "Val RMSE: 107969.9877, Val MAE: 58537.2370, Val MSE: 11657518235.4403, Val R2: 0.4077\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1174, Val Loss: 0.1535\n",
      "Val RMSE: 97330.8181, Val MAE: 54036.2989, Val MSE: 9473288160.5342, Val R2: 0.5187\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1147, Val Loss: 0.1494\n",
      "Val RMSE: 93695.2353, Val MAE: 53152.7927, Val MSE: 8778797110.9515, Val R2: 0.5540\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1114, Val Loss: 0.1608\n",
      "Val RMSE: 96309.8129, Val MAE: 54474.5618, Val MSE: 9275580066.3143, Val R2: 0.5287\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1101, Val Loss: 0.1535\n",
      "Val RMSE: 93792.0381, Val MAE: 52145.4938, Val MSE: 8796946418.9574, Val R2: 0.5531\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1090, Val Loss: 0.1637\n",
      "Val RMSE: 95737.6337, Val MAE: 54247.7690, Val MSE: 9165694504.7200, Val R2: 0.5343\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1084, Val Loss: 0.1554\n",
      "Val RMSE: 93611.2911, Val MAE: 54344.5794, Val MSE: 8763073812.3929, Val R2: 0.5548\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1081, Val Loss: 0.1480\n",
      "Val RMSE: 92555.3439, Val MAE: 52712.1210, Val MSE: 8566491683.3083, Val R2: 0.5648\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1053, Val Loss: 0.1610\n",
      "Val RMSE: 96352.7790, Val MAE: 57348.5660, Val MSE: 9283858018.1230, Val R2: 0.5283\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1015, Val Loss: 0.1522\n",
      "Val RMSE: 93577.7561, Val MAE: 54709.7898, Val MSE: 8756796436.6278, Val R2: 0.5551\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0998, Val Loss: 0.1557\n",
      "Val RMSE: 94644.1323, Val MAE: 53005.7388, Val MSE: 8957511778.1269, Val R2: 0.5449\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0972, Val Loss: 0.1591\n",
      "Val RMSE: 96446.5153, Val MAE: 55828.0108, Val MSE: 9301930307.6650, Val R2: 0.5274\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1639\n",
      "Val RMSE: 96217.0591, Val MAE: 54812.5355, Val MSE: 9257722471.2368, Val R2: 0.5296\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1470\n",
      "Val RMSE: 91504.7228, Val MAE: 53409.1395, Val MSE: 8373114302.4359, Val R2: 0.5746\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0872, Val Loss: 0.1664\n",
      "Val RMSE: 99382.4505, Val MAE: 55456.1223, Val MSE: 9876871463.6923, Val R2: 0.4982\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0861, Val Loss: 0.1578\n",
      "Val RMSE: 94853.3560, Val MAE: 52103.6224, Val MSE: 8997159152.1198, Val R2: 0.5429\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1470\n",
      "Val RMSE: 91717.7137, Val MAE: 52079.5094, Val MSE: 8412139015.4819, Val R2: 0.5726\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1482\n",
      "Val RMSE: 92969.0471, Val MAE: 51265.3512, Val MSE: 8643243723.0279, Val R2: 0.5609\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1522\n",
      "Val RMSE: 91894.7716, Val MAE: 53498.0701, Val MSE: 8444649044.5353, Val R2: 0.5710\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1487\n",
      "Val RMSE: 92414.1403, Val MAE: 51072.0501, Val MSE: 8540373320.1445, Val R2: 0.5661\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0739, Val Loss: 0.1481\n",
      "Val RMSE: 92354.7688, Val MAE: 51482.1134, Val MSE: 8529403314.5724, Val R2: 0.5667\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1503\n",
      "Val RMSE: 93448.0087, Val MAE: 51942.9802, Val MSE: 8732530322.6994, Val R2: 0.5563\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0713, Val Loss: 0.1538\n",
      "Val RMSE: 93712.5891, Val MAE: 52102.4472, Val MSE: 8782049360.9473, Val R2: 0.5538\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1598\n",
      "Val RMSE: 96121.8240, Val MAE: 53976.0067, Val MSE: 9239405042.4977, Val R2: 0.5306\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1515\n",
      "Val RMSE: 92872.0489, Val MAE: 52725.2524, Val MSE: 8625217463.9932, Val R2: 0.5618\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1491\n",
      "Val RMSE: 92512.6858, Val MAE: 50914.7657, Val MSE: 8558597027.4113, Val R2: 0.5652\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1487\n",
      "Val RMSE: 91724.8045, Val MAE: 50950.1491, Val MSE: 8413439767.0076, Val R2: 0.5725\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1518\n",
      "Val RMSE: 92703.2157, Val MAE: 51045.4334, Val MSE: 8593886196.5340, Val R2: 0.5634\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1463\n",
      "Val RMSE: 90347.8148, Val MAE: 49967.7452, Val MSE: 8162727645.8212, Val R2: 0.5853\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0600, Val Loss: 0.1600\n",
      "Val RMSE: 94026.7876, Val MAE: 52439.2303, Val MSE: 8841036790.0087, Val R2: 0.5508\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1532\n",
      "Val RMSE: 91797.7455, Val MAE: 51866.0412, Val MSE: 8426826079.9418, Val R2: 0.5719\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1549\n",
      "Val RMSE: 89174.3672, Val MAE: 50926.0671, Val MSE: 7952067770.8391, Val R2: 0.5960\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1494\n",
      "Val RMSE: 90312.9309, Val MAE: 50897.6233, Val MSE: 8156425488.1177, Val R2: 0.5856\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1634\n",
      "Val RMSE: 90346.1222, Val MAE: 51777.0144, Val MSE: 8162421791.8845, Val R2: 0.5853\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.1501\n",
      "Val RMSE: 87627.6096, Val MAE: 50201.5091, Val MSE: 7678597959.2337, Val R2: 0.6099\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0555, Val Loss: 0.1492\n",
      "Val RMSE: 89324.5802, Val MAE: 50611.8299, Val MSE: 7978880629.6421, Val R2: 0.5946\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1497\n",
      "Val RMSE: 89607.8178, Val MAE: 50187.5516, Val MSE: 8029561014.6162, Val R2: 0.5920\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1523\n",
      "Val RMSE: 91760.3503, Val MAE: 51207.3297, Val MSE: 8419961895.3253, Val R2: 0.5722\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1520\n",
      "Val RMSE: 90686.3955, Val MAE: 50410.4512, Val MSE: 8224022334.5818, Val R2: 0.5822\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1436\n",
      "Val RMSE: 87794.6298, Val MAE: 49054.8822, Val MSE: 7707897021.1733, Val R2: 0.6084\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1490\n",
      "Val RMSE: 90858.6626, Val MAE: 49865.9585, Val MSE: 8255296565.2345, Val R2: 0.5806\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1515\n",
      "Val RMSE: 91501.3738, Val MAE: 49812.8089, Val MSE: 8372501403.1540, Val R2: 0.5746\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1472\n",
      "Val RMSE: 88131.3324, Val MAE: 49671.8268, Val MSE: 7767131749.4802, Val R2: 0.6054\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1448\n",
      "Val RMSE: 87988.0433, Val MAE: 48649.8768, Val MSE: 7741895761.6270, Val R2: 0.6067\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1468\n",
      "Val RMSE: 88930.7434, Val MAE: 48224.4601, Val MSE: 7908677121.7136, Val R2: 0.5982\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1459\n",
      "Val RMSE: 89083.3574, Val MAE: 48704.1105, Val MSE: 7935844558.3573, Val R2: 0.5968\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1502\n",
      "Val RMSE: 90776.0810, Val MAE: 50635.2746, Val MSE: 8240296879.1971, Val R2: 0.5813\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1478\n",
      "Val RMSE: 89979.9173, Val MAE: 49747.4088, Val MSE: 8096385516.0750, Val R2: 0.5887\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1438\n",
      "Val RMSE: 89063.0917, Val MAE: 48556.6960, Val MSE: 7932234306.7630, Val R2: 0.5970\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1463\n",
      "Val RMSE: 87803.0109, Val MAE: 49680.9803, Val MSE: 7709368727.7456, Val R2: 0.6083\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.1492\n",
      "Val RMSE: 89271.6011, Val MAE: 48720.2863, Val MSE: 7969418768.2178, Val R2: 0.5951\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1441\n",
      "Val RMSE: 86842.4094, Val MAE: 47796.4126, Val MSE: 7541604075.6002, Val R2: 0.6168\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0433, Val Loss: 0.1496\n",
      "Val RMSE: 87249.0278, Val MAE: 48334.2444, Val MSE: 7612392851.4512, Val R2: 0.6132\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0422, Val Loss: 0.1396\n",
      "Val RMSE: 84807.1845, Val MAE: 48130.0988, Val MSE: 7192258547.1746, Val R2: 0.6346\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.1432\n",
      "Val RMSE: 85238.3162, Val MAE: 48596.7585, Val MSE: 7265570545.8162, Val R2: 0.6309\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0438, Val Loss: 0.1504\n",
      "Val RMSE: 90036.4311, Val MAE: 50622.6959, Val MSE: 8106558920.6717, Val R2: 0.5881\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0423, Val Loss: 0.1423\n",
      "Val RMSE: 85299.9028, Val MAE: 48215.6739, Val MSE: 7276073418.5751, Val R2: 0.6303\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.1433\n",
      "Val RMSE: 85998.2710, Val MAE: 48952.2529, Val MSE: 7395702616.5942, Val R2: 0.6243\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 90865.6818, Test MAE: 55756.4609, Test MSE: 8256572123.4341, Test R2: 0.4707\n",
      "Inference Time: 3.173985848060021e-05 seconds per sample\n",
      "\n",
      "Iteration 82 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3637, Val Loss: 0.2907\n",
      "Val RMSE: 144845.8665, Val MAE: 82171.1802, Val MSE: 20980325051.9901, Val R2: -0.0659\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2740, Val Loss: 0.2755\n",
      "Val RMSE: 140657.9063, Val MAE: 85724.8246, Val MSE: 19784646604.9770, Val R2: -0.0052\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2769\n",
      "Val RMSE: 142557.0327, Val MAE: 82187.9090, Val MSE: 20322507574.2376, Val R2: -0.0325\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2619, Val Loss: 0.2735\n",
      "Val RMSE: 142533.8617, Val MAE: 82583.9480, Val MSE: 20315901724.5405, Val R2: -0.0322\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2632, Val Loss: 0.2728\n",
      "Val RMSE: 140954.9148, Val MAE: 84240.0699, Val MSE: 19868288001.7056, Val R2: -0.0094\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2737\n",
      "Val RMSE: 142157.4120, Val MAE: 82841.2284, Val MSE: 20208729790.5865, Val R2: -0.0267\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2567, Val Loss: 0.2729\n",
      "Val RMSE: 142012.5708, Val MAE: 81815.3658, Val MSE: 20167570269.6326, Val R2: -0.0246\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2549, Val Loss: 0.2743\n",
      "Val RMSE: 141472.2856, Val MAE: 84095.6916, Val MSE: 20014407587.3677, Val R2: -0.0169\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2700\n",
      "Val RMSE: 142093.4902, Val MAE: 81071.0396, Val MSE: 20190559971.0447, Val R2: -0.0258\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2527, Val Loss: 0.2687\n",
      "Val RMSE: 142175.1174, Val MAE: 78905.3790, Val MSE: 20213763999.4951, Val R2: -0.0270\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2539, Val Loss: 0.2671\n",
      "Val RMSE: 142409.0707, Val MAE: 78442.9203, Val MSE: 20280343418.5710, Val R2: -0.0304\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2534, Val Loss: 0.2679\n",
      "Val RMSE: 140636.7732, Val MAE: 81316.3158, Val MSE: 19778701979.3785, Val R2: -0.0049\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2664\n",
      "Val RMSE: 142180.9945, Val MAE: 78427.7793, Val MSE: 20215435188.6334, Val R2: -0.0271\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2742\n",
      "Val RMSE: 142664.1028, Val MAE: 77154.3046, Val MSE: 20353046228.2083, Val R2: -0.0341\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2574\n",
      "Val RMSE: 138405.0163, Val MAE: 75686.7859, Val MSE: 19155948523.1680, Val R2: 0.0268\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2386, Val Loss: 0.2475\n",
      "Val RMSE: 133562.7766, Val MAE: 76103.5327, Val MSE: 17839015304.6235, Val R2: 0.0937\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2338, Val Loss: 0.2513\n",
      "Val RMSE: 130368.4520, Val MAE: 80522.6862, Val MSE: 16995933278.5700, Val R2: 0.1365\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2289, Val Loss: 0.2323\n",
      "Val RMSE: 132057.2577, Val MAE: 72403.2609, Val MSE: 17439119301.9338, Val R2: 0.1140\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2383\n",
      "Val RMSE: 133799.9157, Val MAE: 71474.2269, Val MSE: 17902417430.0816, Val R2: 0.0904\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2160, Val Loss: 0.2290\n",
      "Val RMSE: 130352.3384, Val MAE: 72318.0648, Val MSE: 16991732116.3334, Val R2: 0.1367\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2112, Val Loss: 0.2254\n",
      "Val RMSE: 129601.4675, Val MAE: 71137.7180, Val MSE: 16796540380.4868, Val R2: 0.1466\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2078, Val Loss: 0.2317\n",
      "Val RMSE: 128894.2201, Val MAE: 75490.0949, Val MSE: 16613719971.8068, Val R2: 0.1559\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2120, Val Loss: 0.2560\n",
      "Val RMSE: 133347.6306, Val MAE: 77936.2167, Val MSE: 17781590581.7005, Val R2: 0.0966\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2091, Val Loss: 0.2227\n",
      "Val RMSE: 128402.0190, Val MAE: 69685.4336, Val MSE: 16487078482.9326, Val R2: 0.1624\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2046, Val Loss: 0.2244\n",
      "Val RMSE: 128685.6251, Val MAE: 70550.8605, Val MSE: 16559990104.1886, Val R2: 0.1586\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2012, Val Loss: 0.2329\n",
      "Val RMSE: 131053.8992, Val MAE: 71609.6090, Val MSE: 17175124496.9493, Val R2: 0.1274\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1929, Val Loss: 0.2071\n",
      "Val RMSE: 117854.4276, Val MAE: 68211.0203, Val MSE: 13889666098.4630, Val R2: 0.2943\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1870, Val Loss: 0.2292\n",
      "Val RMSE: 124309.8380, Val MAE: 69246.9161, Val MSE: 15452935820.2220, Val R2: 0.2149\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1773, Val Loss: 0.1850\n",
      "Val RMSE: 104530.1211, Val MAE: 61134.1853, Val MSE: 10926546213.9585, Val R2: 0.4449\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1692, Val Loss: 0.1896\n",
      "Val RMSE: 106699.6879, Val MAE: 63475.4571, Val MSE: 11384823399.4474, Val R2: 0.4216\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1738\n",
      "Val RMSE: 102145.7480, Val MAE: 60088.7782, Val MSE: 10433753831.6658, Val R2: 0.4699\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1648, Val Loss: 0.1719\n",
      "Val RMSE: 98871.2994, Val MAE: 62645.0346, Val MSE: 9775533840.6806, Val R2: 0.5033\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1636, Val Loss: 0.1682\n",
      "Val RMSE: 99902.3383, Val MAE: 57740.1544, Val MSE: 9980477202.0564, Val R2: 0.4929\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1581, Val Loss: 0.1665\n",
      "Val RMSE: 98946.3836, Val MAE: 59087.9152, Val MSE: 9790386825.1497, Val R2: 0.5026\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1508, Val Loss: 0.1637\n",
      "Val RMSE: 99609.3270, Val MAE: 56356.2255, Val MSE: 9922018023.3575, Val R2: 0.4959\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1465, Val Loss: 0.1843\n",
      "Val RMSE: 100080.0983, Val MAE: 61223.6211, Val MSE: 10016026071.0177, Val R2: 0.4911\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1431, Val Loss: 0.1545\n",
      "Val RMSE: 96667.2872, Val MAE: 55337.5768, Val MSE: 9344564406.7547, Val R2: 0.5252\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1595\n",
      "Val RMSE: 96006.4270, Val MAE: 55974.7997, Val MSE: 9217234021.5914, Val R2: 0.5317\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1323, Val Loss: 0.1407\n",
      "Val RMSE: 91791.8838, Val MAE: 52376.9320, Val MSE: 8425749935.2200, Val R2: 0.5719\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1252, Val Loss: 0.1354\n",
      "Val RMSE: 90322.0958, Val MAE: 49683.3839, Val MSE: 8158080993.6413, Val R2: 0.5855\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1362\n",
      "Val RMSE: 89765.5097, Val MAE: 50048.6602, Val MSE: 8057846730.7709, Val R2: 0.5906\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1386\n",
      "Val RMSE: 90614.3895, Val MAE: 49588.7895, Val MSE: 8210967576.8509, Val R2: 0.5828\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1165, Val Loss: 0.1355\n",
      "Val RMSE: 88435.4312, Val MAE: 52969.8667, Val MSE: 7820825492.3589, Val R2: 0.6027\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1114, Val Loss: 0.1460\n",
      "Val RMSE: 92421.5777, Val MAE: 50597.2929, Val MSE: 8541748021.9278, Val R2: 0.5660\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1449\n",
      "Val RMSE: 90776.2764, Val MAE: 52820.6644, Val MSE: 8240332353.4611, Val R2: 0.5813\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1344\n",
      "Val RMSE: 88516.6556, Val MAE: 48567.5199, Val MSE: 7835198320.3524, Val R2: 0.6019\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1012, Val Loss: 0.1425\n",
      "Val RMSE: 90284.9991, Val MAE: 51388.7056, Val MSE: 8151381062.7352, Val R2: 0.5859\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0965, Val Loss: 0.1427\n",
      "Val RMSE: 91362.1009, Val MAE: 49643.7500, Val MSE: 8347033483.5272, Val R2: 0.5759\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1362\n",
      "Val RMSE: 89291.2514, Val MAE: 48170.6387, Val MSE: 7972927573.7889, Val R2: 0.5949\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0903, Val Loss: 0.1359\n",
      "Val RMSE: 88627.0240, Val MAE: 50710.7665, Val MSE: 7854749387.8618, Val R2: 0.6009\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0884, Val Loss: 0.1379\n",
      "Val RMSE: 89085.7246, Val MAE: 48203.6123, Val MSE: 7936266331.9823, Val R2: 0.5968\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0874, Val Loss: 0.1384\n",
      "Val RMSE: 88973.0526, Val MAE: 49019.6389, Val MSE: 7916204082.2451, Val R2: 0.5978\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.1398\n",
      "Val RMSE: 90606.6074, Val MAE: 49042.2484, Val MSE: 8209557301.1282, Val R2: 0.5829\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0845, Val Loss: 0.1514\n",
      "Val RMSE: 92521.5766, Val MAE: 50746.3879, Val MSE: 8560242131.1325, Val R2: 0.5651\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1361\n",
      "Val RMSE: 86800.0122, Val MAE: 50159.1559, Val MSE: 7534242111.9896, Val R2: 0.6172\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1492\n",
      "Val RMSE: 89677.2115, Val MAE: 52760.7943, Val MSE: 8042002265.7254, Val R2: 0.5914\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1263\n",
      "Val RMSE: 79366.0055, Val MAE: 46995.7602, Val MSE: 6298962828.0000, Val R2: 0.6800\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0796, Val Loss: 0.1399\n",
      "Val RMSE: 83469.4037, Val MAE: 51078.7942, Val MSE: 6967141361.2692, Val R2: 0.6460\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1312\n",
      "Val RMSE: 83865.5557, Val MAE: 48024.1739, Val MSE: 7033431433.2993, Val R2: 0.6427\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0741, Val Loss: 0.1367\n",
      "Val RMSE: 84702.2732, Val MAE: 49220.7156, Val MSE: 7174475077.9147, Val R2: 0.6355\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1338\n",
      "Val RMSE: 82973.2462, Val MAE: 48258.9755, Val MSE: 6884559588.5200, Val R2: 0.6502\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1181\n",
      "Val RMSE: 76132.9556, Val MAE: 44460.6288, Val MSE: 5796226929.3618, Val R2: 0.7055\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1270\n",
      "Val RMSE: 78821.5432, Val MAE: 46519.6219, Val MSE: 6212835678.2893, Val R2: 0.6843\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1176\n",
      "Val RMSE: 75418.2702, Val MAE: 44159.4939, Val MSE: 5687915477.4920, Val R2: 0.7110\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1301\n",
      "Val RMSE: 78985.5196, Val MAE: 48140.1933, Val MSE: 6238712306.1904, Val R2: 0.6830\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1281\n",
      "Val RMSE: 78535.0177, Val MAE: 46499.4167, Val MSE: 6167749011.6063, Val R2: 0.6866\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1243\n",
      "Val RMSE: 77340.8648, Val MAE: 45409.4342, Val MSE: 5981609368.2465, Val R2: 0.6961\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0628, Val Loss: 0.1261\n",
      "Val RMSE: 77363.8943, Val MAE: 46908.2250, Val MSE: 5985172144.1165, Val R2: 0.6959\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1226\n",
      "Val RMSE: 77053.0660, Val MAE: 44211.3009, Val MSE: 5937174973.0133, Val R2: 0.6984\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1281\n",
      "Val RMSE: 76906.6263, Val MAE: 49697.0875, Val MSE: 5914629161.3300, Val R2: 0.6995\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1211\n",
      "Val RMSE: 76089.8845, Val MAE: 44619.0309, Val MSE: 5789670523.7320, Val R2: 0.7058\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0596, Val Loss: 0.1111\n",
      "Val RMSE: 71579.0162, Val MAE: 42333.3897, Val MSE: 5123555566.8165, Val R2: 0.7397\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1118\n",
      "Val RMSE: 71669.2345, Val MAE: 43307.5378, Val MSE: 5136479170.0186, Val R2: 0.7390\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1213\n",
      "Val RMSE: 72478.1159, Val MAE: 44682.3263, Val MSE: 5253077289.2387, Val R2: 0.7331\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1107\n",
      "Val RMSE: 71651.1693, Val MAE: 43130.6472, Val MSE: 5133890056.8859, Val R2: 0.7392\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1201\n",
      "Val RMSE: 75488.8063, Val MAE: 44359.4171, Val MSE: 5698559881.7359, Val R2: 0.7105\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1029\n",
      "Val RMSE: 69390.6366, Val MAE: 39822.2281, Val MSE: 4815060454.1542, Val R2: 0.7554\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.1147\n",
      "Val RMSE: 72564.3943, Val MAE: 44160.2412, Val MSE: 5265591315.4658, Val R2: 0.7325\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1058\n",
      "Val RMSE: 69812.3131, Val MAE: 40438.0322, Val MSE: 4873759055.4239, Val R2: 0.7524\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1046\n",
      "Val RMSE: 68928.3906, Val MAE: 40863.1735, Val MSE: 4751123027.6146, Val R2: 0.7586\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1176\n",
      "Val RMSE: 74143.6638, Val MAE: 43784.8922, Val MSE: 5497282888.1127, Val R2: 0.7207\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1214\n",
      "Val RMSE: 75293.6727, Val MAE: 43889.9384, Val MSE: 5669137142.9144, Val R2: 0.7120\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1020\n",
      "Val RMSE: 68160.4007, Val MAE: 39424.5885, Val MSE: 4645840219.5187, Val R2: 0.7640\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1122\n",
      "Val RMSE: 71115.3419, Val MAE: 43274.7504, Val MSE: 5057391856.9262, Val R2: 0.7431\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1155\n",
      "Val RMSE: 72076.6618, Val MAE: 42695.3941, Val MSE: 5195045180.4921, Val R2: 0.7361\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1106\n",
      "Val RMSE: 70963.1280, Val MAE: 41945.2184, Val MSE: 5035765537.4826, Val R2: 0.7442\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1340\n",
      "Val RMSE: 76487.8690, Val MAE: 50498.5281, Val MSE: 5850394107.2808, Val R2: 0.7028\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0517, Val Loss: 0.1037\n",
      "Val RMSE: 68161.6430, Val MAE: 41703.6127, Val MSE: 4646009574.4970, Val R2: 0.7640\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1057\n",
      "Val RMSE: 69169.1593, Val MAE: 40876.6722, Val MSE: 4784372595.7760, Val R2: 0.7569\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1061\n",
      "Val RMSE: 70098.6472, Val MAE: 40987.7366, Val MSE: 4913820337.0917, Val R2: 0.7503\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1123\n",
      "Val RMSE: 72778.2332, Val MAE: 42021.3366, Val MSE: 5296671223.0557, Val R2: 0.7309\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.1093\n",
      "Val RMSE: 69615.1976, Val MAE: 43046.0894, Val MSE: 4846275743.2011, Val R2: 0.7538\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1012\n",
      "Val RMSE: 67677.7147, Val MAE: 38895.3751, Val MSE: 4580273062.0138, Val R2: 0.7673\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1086\n",
      "Val RMSE: 70788.3959, Val MAE: 41987.1898, Val MSE: 5010996994.0958, Val R2: 0.7454\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1054\n",
      "Val RMSE: 70441.6935, Val MAE: 39812.2864, Val MSE: 4962032183.2034, Val R2: 0.7479\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1062\n",
      "Val RMSE: 70553.9693, Val MAE: 40193.4070, Val MSE: 4977862582.3785, Val R2: 0.7471\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1152\n",
      "Val RMSE: 72737.7774, Val MAE: 43838.6612, Val MSE: 5290784258.3071, Val R2: 0.7312\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.1102\n",
      "Val RMSE: 70784.2458, Val MAE: 42799.2876, Val MSE: 5010409446.6778, Val R2: 0.7454\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.1099\n",
      "Val RMSE: 70714.6583, Val MAE: 42987.5920, Val MSE: 5000562895.4358, Val R2: 0.7459\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.1128\n",
      "Val RMSE: 72891.2478, Val MAE: 40413.0731, Val MSE: 5313133999.9750, Val R2: 0.7301\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 71093.3193, Test MAE: 40351.6954, Test MSE: 5054260044.4495, Test R2: 0.6760\n",
      "Inference Time: 3.4119312579815204e-05 seconds per sample\n",
      "\n",
      "Iteration 83 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3687, Val Loss: 0.2802\n",
      "Val RMSE: 141596.8096, Val MAE: 85196.9999, Val MSE: 20049656493.7533, Val R2: -0.0186\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2761, Val Loss: 0.2759\n",
      "Val RMSE: 142259.3044, Val MAE: 82886.8412, Val MSE: 20237709674.9168, Val R2: -0.0282\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2713, Val Loss: 0.2779\n",
      "Val RMSE: 143838.4859, Val MAE: 80320.1300, Val MSE: 20689510037.4456, Val R2: -0.0512\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2691, Val Loss: 0.2796\n",
      "Val RMSE: 144523.1757, Val MAE: 79380.5596, Val MSE: 20886948316.2944, Val R2: -0.0612\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2610, Val Loss: 0.2766\n",
      "Val RMSE: 143146.2840, Val MAE: 80341.4058, Val MSE: 20490858623.6547, Val R2: -0.0411\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2734\n",
      "Val RMSE: 142634.5984, Val MAE: 79806.8090, Val MSE: 20344628658.9335, Val R2: -0.0336\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2574, Val Loss: 0.2712\n",
      "Val RMSE: 141198.6128, Val MAE: 81633.2447, Val MSE: 19937048268.7737, Val R2: -0.0129\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2747\n",
      "Val RMSE: 140445.5441, Val MAE: 85909.1216, Val MSE: 19724950844.3436, Val R2: -0.0022\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2694\n",
      "Val RMSE: 142038.8983, Val MAE: 80170.1871, Val MSE: 20175048623.7338, Val R2: -0.0250\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2691\n",
      "Val RMSE: 139888.9986, Val MAE: 81613.5957, Val MSE: 19568931937.1023, Val R2: 0.0058\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2443, Val Loss: 0.2674\n",
      "Val RMSE: 138437.1670, Val MAE: 80179.3710, Val MSE: 19164849199.1944, Val R2: 0.0263\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2388, Val Loss: 0.2556\n",
      "Val RMSE: 136192.5388, Val MAE: 77811.0791, Val MSE: 18548407628.1306, Val R2: 0.0576\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2365, Val Loss: 0.2664\n",
      "Val RMSE: 139687.7565, Val MAE: 75579.9663, Val MSE: 19512669323.4159, Val R2: 0.0086\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2358, Val Loss: 0.2499\n",
      "Val RMSE: 136093.8153, Val MAE: 74841.9600, Val MSE: 18521526551.5328, Val R2: 0.0590\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2322, Val Loss: 0.2577\n",
      "Val RMSE: 133275.1628, Val MAE: 82193.0753, Val MSE: 17762269028.5843, Val R2: 0.0976\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2312, Val Loss: 0.2501\n",
      "Val RMSE: 136403.7850, Val MAE: 74432.3553, Val MSE: 18605992567.2688, Val R2: 0.0547\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2276, Val Loss: 0.2505\n",
      "Val RMSE: 135701.4200, Val MAE: 73974.3827, Val MSE: 18414875381.7904, Val R2: 0.0644\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2176, Val Loss: 0.2355\n",
      "Val RMSE: 133023.6715, Val MAE: 70918.7793, Val MSE: 17695297179.8524, Val R2: 0.1010\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2138, Val Loss: 0.2315\n",
      "Val RMSE: 131316.2300, Val MAE: 72959.5833, Val MSE: 17243952253.4821, Val R2: 0.1239\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2097, Val Loss: 0.2449\n",
      "Val RMSE: 135783.9091, Val MAE: 71185.9851, Val MSE: 18437269982.3001, Val R2: 0.0633\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2088, Val Loss: 0.2193\n",
      "Val RMSE: 126587.4987, Val MAE: 71854.6465, Val MSE: 16024394834.0511, Val R2: 0.1859\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2023, Val Loss: 0.2331\n",
      "Val RMSE: 130977.1653, Val MAE: 69256.4096, Val MSE: 17155017827.3402, Val R2: 0.1284\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1950, Val Loss: 0.2250\n",
      "Val RMSE: 127996.9870, Val MAE: 69590.5185, Val MSE: 16383228681.4245, Val R2: 0.1676\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1893, Val Loss: 0.2097\n",
      "Val RMSE: 120676.5372, Val MAE: 68187.0980, Val MSE: 14562826625.2544, Val R2: 0.2601\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1835, Val Loss: 0.1995\n",
      "Val RMSE: 113426.5385, Val MAE: 67532.0140, Val MSE: 12865579630.9258, Val R2: 0.3463\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1796, Val Loss: 0.2010\n",
      "Val RMSE: 113880.3275, Val MAE: 65464.3865, Val MSE: 12968728998.2703, Val R2: 0.3411\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1722, Val Loss: 0.1845\n",
      "Val RMSE: 105847.5557, Val MAE: 61854.1739, Val MSE: 11203705037.1960, Val R2: 0.4308\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1873\n",
      "Val RMSE: 107326.1617, Val MAE: 62554.5281, Val MSE: 11518904995.8624, Val R2: 0.4148\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1691, Val Loss: 0.1624\n",
      "Val RMSE: 97791.2298, Val MAE: 60426.4251, Val MSE: 9563124625.4929, Val R2: 0.5141\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1674, Val Loss: 0.1777\n",
      "Val RMSE: 101803.1512, Val MAE: 60030.3415, Val MSE: 10363881596.3465, Val R2: 0.4734\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1630, Val Loss: 0.1665\n",
      "Val RMSE: 98991.9802, Val MAE: 60848.5572, Val MSE: 9799412144.5017, Val R2: 0.5021\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1612\n",
      "Val RMSE: 98107.3865, Val MAE: 59739.6383, Val MSE: 9625059286.3088, Val R2: 0.5110\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1557, Val Loss: 0.1647\n",
      "Val RMSE: 98251.4735, Val MAE: 58024.7736, Val MSE: 9653352050.3345, Val R2: 0.5095\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1556, Val Loss: 0.1637\n",
      "Val RMSE: 98786.3456, Val MAE: 59414.8062, Val MSE: 9758742079.3289, Val R2: 0.5042\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1542, Val Loss: 0.1569\n",
      "Val RMSE: 96753.6355, Val MAE: 56436.0988, Val MSE: 9361265984.7872, Val R2: 0.5244\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1499, Val Loss: 0.1480\n",
      "Val RMSE: 94364.5924, Val MAE: 54410.7010, Val MSE: 8904676294.5311, Val R2: 0.5476\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1443, Val Loss: 0.1582\n",
      "Val RMSE: 97891.1787, Val MAE: 55110.1518, Val MSE: 9582682867.1881, Val R2: 0.5131\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1499\n",
      "Val RMSE: 92688.7250, Val MAE: 53767.8324, Val MSE: 8591199733.2072, Val R2: 0.5635\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1415, Val Loss: 0.1455\n",
      "Val RMSE: 92825.4329, Val MAE: 53018.8986, Val MSE: 8616560988.2602, Val R2: 0.5622\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1371, Val Loss: 0.1452\n",
      "Val RMSE: 92891.4974, Val MAE: 53250.0297, Val MSE: 8628830282.4788, Val R2: 0.5616\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1340, Val Loss: 0.1605\n",
      "Val RMSE: 96562.1181, Val MAE: 56091.7024, Val MSE: 9324242661.1368, Val R2: 0.5263\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1293, Val Loss: 0.1327\n",
      "Val RMSE: 90311.0611, Val MAE: 50145.1394, Val MSE: 8156087758.4697, Val R2: 0.5856\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1265, Val Loss: 0.1462\n",
      "Val RMSE: 90929.7782, Val MAE: 51050.1491, Val MSE: 8268224560.5887, Val R2: 0.5799\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1353\n",
      "Val RMSE: 89557.7524, Val MAE: 51846.1204, Val MSE: 8020591019.5790, Val R2: 0.5925\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1202, Val Loss: 0.1280\n",
      "Val RMSE: 89602.8221, Val MAE: 47804.5541, Val MSE: 8028665735.5436, Val R2: 0.5921\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1229\n",
      "Val RMSE: 85880.6343, Val MAE: 46277.7426, Val MSE: 7375483346.0692, Val R2: 0.6253\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1242\n",
      "Val RMSE: 87451.6365, Val MAE: 47881.2363, Val MSE: 7647788720.6371, Val R2: 0.6114\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1277\n",
      "Val RMSE: 89307.3895, Val MAE: 46373.1643, Val MSE: 7975809812.5408, Val R2: 0.5948\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1012, Val Loss: 0.1182\n",
      "Val RMSE: 85289.6081, Val MAE: 46472.7387, Val MSE: 7274317253.3041, Val R2: 0.6304\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1330\n",
      "Val RMSE: 91557.8813, Val MAE: 46519.1705, Val MSE: 8382845627.3742, Val R2: 0.5741\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0972, Val Loss: 0.1310\n",
      "Val RMSE: 89967.7870, Val MAE: 45422.0313, Val MSE: 8094202702.3622, Val R2: 0.5888\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0966, Val Loss: 0.1390\n",
      "Val RMSE: 93119.4344, Val MAE: 49069.5459, Val MSE: 8671229055.8544, Val R2: 0.5594\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0943, Val Loss: 0.1288\n",
      "Val RMSE: 89034.4616, Val MAE: 47666.0880, Val MSE: 7927135356.9042, Val R2: 0.5973\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0916, Val Loss: 0.1401\n",
      "Val RMSE: 92883.1213, Val MAE: 48842.0802, Val MSE: 8627274217.8489, Val R2: 0.5617\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1256\n",
      "Val RMSE: 85390.5897, Val MAE: 47914.6676, Val MSE: 7291552817.5835, Val R2: 0.6295\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1425\n",
      "Val RMSE: 94443.8211, Val MAE: 48440.0764, Val MSE: 8919635336.5416, Val R2: 0.5468\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0867, Val Loss: 0.1381\n",
      "Val RMSE: 92788.8794, Val MAE: 48680.9010, Val MSE: 8609776140.2680, Val R2: 0.5626\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0836, Val Loss: 0.1391\n",
      "Val RMSE: 92407.8794, Val MAE: 48235.8447, Val MSE: 8539216180.5487, Val R2: 0.5662\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0816, Val Loss: 0.1330\n",
      "Val RMSE: 90699.0938, Val MAE: 46781.5838, Val MSE: 8226325609.4789, Val R2: 0.5821\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0815, Val Loss: 0.1238\n",
      "Val RMSE: 82922.7561, Val MAE: 43869.6576, Val MSE: 6876183487.1158, Val R2: 0.6506\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1402\n",
      "Val RMSE: 92241.2671, Val MAE: 49532.7170, Val MSE: 8508451360.2238, Val R2: 0.5677\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1357\n",
      "Val RMSE: 87504.0617, Val MAE: 47801.9435, Val MSE: 7656960819.4262, Val R2: 0.6110\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0771, Val Loss: 0.1283\n",
      "Val RMSE: 85755.0222, Val MAE: 44886.9849, Val MSE: 7353923824.5251, Val R2: 0.6264\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1359\n",
      "Val RMSE: 87264.3530, Val MAE: 48962.3778, Val MSE: 7615067304.4674, Val R2: 0.6131\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0755, Val Loss: 0.1369\n",
      "Val RMSE: 90671.1206, Val MAE: 46059.1796, Val MSE: 8221252112.9563, Val R2: 0.5823\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0726, Val Loss: 0.1350\n",
      "Val RMSE: 87730.5017, Val MAE: 47377.0338, Val MSE: 7696640931.2745, Val R2: 0.6090\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1354\n",
      "Val RMSE: 86057.4056, Val MAE: 49105.0148, Val MSE: 7405877060.9054, Val R2: 0.6237\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1333\n",
      "Val RMSE: 86521.3805, Val MAE: 47182.2293, Val MSE: 7485949288.2055, Val R2: 0.6197\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0677, Val Loss: 0.1239\n",
      "Val RMSE: 81269.9776, Val MAE: 44073.8278, Val MSE: 6604809263.4241, Val R2: 0.6644\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1321\n",
      "Val RMSE: 86487.2511, Val MAE: 45534.4477, Val MSE: 7480044600.5204, Val R2: 0.6200\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1341\n",
      "Val RMSE: 87882.5706, Val MAE: 46120.8487, Val MSE: 7723346211.9377, Val R2: 0.6076\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1296\n",
      "Val RMSE: 85829.4716, Val MAE: 45733.1814, Val MSE: 7366698192.8900, Val R2: 0.6257\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1476\n",
      "Val RMSE: 92903.0549, Val MAE: 51378.6861, Val MSE: 8630977612.5680, Val R2: 0.5615\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1412\n",
      "Val RMSE: 89578.2102, Val MAE: 47592.6616, Val MSE: 8024255745.5622, Val R2: 0.5923\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1348\n",
      "Val RMSE: 87386.7695, Val MAE: 47180.7432, Val MSE: 7636447484.2691, Val R2: 0.6120\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1256\n",
      "Val RMSE: 84234.8891, Val MAE: 45329.4335, Val MSE: 7095516537.1387, Val R2: 0.6395\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1338\n",
      "Val RMSE: 84246.5523, Val MAE: 48123.5068, Val MSE: 7097481580.9614, Val R2: 0.6394\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1313\n",
      "Val RMSE: 84982.3655, Val MAE: 47437.6089, Val MSE: 7222002447.4426, Val R2: 0.6331\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0583, Val Loss: 0.1184\n",
      "Val RMSE: 79169.4710, Val MAE: 43295.9061, Val MSE: 6267805132.5173, Val R2: 0.6816\n",
      "Early stopping triggered after epoch 79\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 98036.7313, Test MAE: 52582.9404, Test MSE: 9611200687.1691, Test R2: 0.3839\n",
      "Inference Time: 2.4005376375638522e-05 seconds per sample\n",
      "\n",
      "Iteration 84 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3127, Val Loss: 0.2791\n",
      "Val RMSE: 139694.5511, Val MAE: 89956.1206, Val MSE: 19514567607.1321, Val R2: 0.0085\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2695, Val Loss: 0.2776\n",
      "Val RMSE: 142515.9365, Val MAE: 82402.5170, Val MSE: 20310792157.0298, Val R2: -0.0319\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2659, Val Loss: 0.2798\n",
      "Val RMSE: 143740.3339, Val MAE: 81203.4374, Val MSE: 20661283600.1747, Val R2: -0.0497\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2637, Val Loss: 0.2750\n",
      "Val RMSE: 141937.6269, Val MAE: 84108.6368, Val MSE: 20146289934.8859, Val R2: -0.0236\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2592, Val Loss: 0.2691\n",
      "Val RMSE: 141451.6917, Val MAE: 81432.7260, Val MSE: 20008581083.0403, Val R2: -0.0166\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2560, Val Loss: 0.2748\n",
      "Val RMSE: 140754.4842, Val MAE: 84852.7951, Val MSE: 19811824833.7136, Val R2: -0.0066\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2693\n",
      "Val RMSE: 140624.0312, Val MAE: 81817.2218, Val MSE: 19775118155.4421, Val R2: -0.0047\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2559, Val Loss: 0.2667\n",
      "Val RMSE: 141447.5130, Val MAE: 79709.9566, Val MSE: 20007398933.5456, Val R2: -0.0165\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2722\n",
      "Val RMSE: 140523.1871, Val MAE: 83445.1156, Val MSE: 19746766106.9238, Val R2: -0.0033\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2476, Val Loss: 0.2668\n",
      "Val RMSE: 141246.5933, Val MAE: 78852.2182, Val MSE: 19950600118.4675, Val R2: -0.0136\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2621\n",
      "Val RMSE: 140245.4592, Val MAE: 79450.3830, Val MSE: 19668788817.5239, Val R2: 0.0007\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2471, Val Loss: 0.2650\n",
      "Val RMSE: 138733.5591, Val MAE: 82046.9610, Val MSE: 19247000432.9724, Val R2: 0.0221\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2445, Val Loss: 0.2653\n",
      "Val RMSE: 139545.5234, Val MAE: 81074.1531, Val MSE: 19472953092.8129, Val R2: 0.0107\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2447, Val Loss: 0.2731\n",
      "Val RMSE: 139570.9150, Val MAE: 84328.8219, Val MSE: 19480040317.7956, Val R2: 0.0103\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2426, Val Loss: 0.2696\n",
      "Val RMSE: 139624.1201, Val MAE: 82358.6612, Val MSE: 19494894904.8883, Val R2: 0.0095\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2382, Val Loss: 0.2779\n",
      "Val RMSE: 140705.7251, Val MAE: 83182.6574, Val MSE: 19798101088.4400, Val R2: -0.0059\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2384, Val Loss: 0.2645\n",
      "Val RMSE: 137207.4772, Val MAE: 80999.6990, Val MSE: 18825891801.5285, Val R2: 0.0435\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2271, Val Loss: 0.2420\n",
      "Val RMSE: 134047.8759, Val MAE: 72298.9884, Val MSE: 17968833031.5238, Val R2: 0.0871\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2244, Val Loss: 0.2369\n",
      "Val RMSE: 128782.8217, Val MAE: 78377.9976, Val MSE: 16585015161.3342, Val R2: 0.1574\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2142, Val Loss: 0.2334\n",
      "Val RMSE: 131250.7457, Val MAE: 74322.3043, Val MSE: 17226758251.3756, Val R2: 0.1248\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2099, Val Loss: 0.2240\n",
      "Val RMSE: 128569.5289, Val MAE: 73747.7309, Val MSE: 16530123762.8695, Val R2: 0.1602\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2052, Val Loss: 0.2335\n",
      "Val RMSE: 133507.7735, Val MAE: 69599.5768, Val MSE: 17824325574.1778, Val R2: 0.0944\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1954, Val Loss: 0.2086\n",
      "Val RMSE: 119368.7762, Val MAE: 68206.9170, Val MSE: 14248904723.5892, Val R2: 0.2761\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1877, Val Loss: 0.2026\n",
      "Val RMSE: 115765.1535, Val MAE: 66671.5620, Val MSE: 13401570770.6752, Val R2: 0.3191\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1820, Val Loss: 0.1950\n",
      "Val RMSE: 110470.8096, Val MAE: 64350.6101, Val MSE: 12203799781.4782, Val R2: 0.3800\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1719, Val Loss: 0.1830\n",
      "Val RMSE: 104333.5062, Val MAE: 64227.4083, Val MSE: 10885480520.4294, Val R2: 0.4469\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1669, Val Loss: 0.1788\n",
      "Val RMSE: 103192.0079, Val MAE: 62563.9750, Val MSE: 10648590493.5818, Val R2: 0.4590\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1643, Val Loss: 0.1701\n",
      "Val RMSE: 99607.9703, Val MAE: 63720.8406, Val MSE: 9921747756.6425, Val R2: 0.4959\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1570, Val Loss: 0.1818\n",
      "Val RMSE: 102186.8782, Val MAE: 60551.5859, Val MSE: 10442158072.1542, Val R2: 0.4695\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1669\n",
      "Val RMSE: 100958.4789, Val MAE: 59770.8952, Val MSE: 10192614456.4342, Val R2: 0.4822\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1516, Val Loss: 0.1828\n",
      "Val RMSE: 102592.8627, Val MAE: 60057.5606, Val MSE: 10525295485.1962, Val R2: 0.4652\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1489, Val Loss: 0.1599\n",
      "Val RMSE: 98246.3856, Val MAE: 56473.1628, Val MSE: 9652352280.6793, Val R2: 0.5096\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1441, Val Loss: 0.1539\n",
      "Val RMSE: 95244.1300, Val MAE: 57003.5990, Val MSE: 9071444292.4964, Val R2: 0.5391\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1519\n",
      "Val RMSE: 96145.2810, Val MAE: 54175.2107, Val MSE: 9243915065.7886, Val R2: 0.5304\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1418, Val Loss: 0.1572\n",
      "Val RMSE: 97396.8508, Val MAE: 54915.8197, Val MSE: 9486146541.2914, Val R2: 0.5180\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1372, Val Loss: 0.1434\n",
      "Val RMSE: 93361.1331, Val MAE: 52306.5409, Val MSE: 8716301180.5010, Val R2: 0.5572\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1359, Val Loss: 0.1476\n",
      "Val RMSE: 95533.8559, Val MAE: 51941.7839, Val MSE: 9126717627.1265, Val R2: 0.5363\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1339, Val Loss: 0.1368\n",
      "Val RMSE: 91094.1840, Val MAE: 50932.1263, Val MSE: 8298150355.2358, Val R2: 0.5784\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1309, Val Loss: 0.1420\n",
      "Val RMSE: 91577.4729, Val MAE: 51590.0998, Val MSE: 8386433538.5388, Val R2: 0.5739\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1288, Val Loss: 0.1358\n",
      "Val RMSE: 91372.1288, Val MAE: 50114.7901, Val MSE: 8348865922.7866, Val R2: 0.5758\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1285, Val Loss: 0.1469\n",
      "Val RMSE: 94812.0328, Val MAE: 51885.1591, Val MSE: 8989321559.0640, Val R2: 0.5433\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1198, Val Loss: 0.1323\n",
      "Val RMSE: 88930.4574, Val MAE: 50844.6970, Val MSE: 7908626257.7372, Val R2: 0.5982\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1149, Val Loss: 0.1330\n",
      "Val RMSE: 91428.5490, Val MAE: 47479.0423, Val MSE: 8359179574.0869, Val R2: 0.5753\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1093, Val Loss: 0.1215\n",
      "Val RMSE: 86285.0953, Val MAE: 47993.9753, Val MSE: 7445117666.8024, Val R2: 0.6217\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1087, Val Loss: 0.1266\n",
      "Val RMSE: 89480.3355, Val MAE: 48540.3466, Val MSE: 8006730435.8995, Val R2: 0.5932\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1058, Val Loss: 0.1226\n",
      "Val RMSE: 87342.6164, Val MAE: 48024.5503, Val MSE: 7628732642.2586, Val R2: 0.6124\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1018, Val Loss: 0.1115\n",
      "Val RMSE: 82433.6302, Val MAE: 43361.7027, Val MSE: 6795303395.2398, Val R2: 0.6548\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1002, Val Loss: 0.1234\n",
      "Val RMSE: 85622.1804, Val MAE: 45465.0834, Val MSE: 7331157771.9810, Val R2: 0.6275\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0954, Val Loss: 0.1139\n",
      "Val RMSE: 81822.2013, Val MAE: 43637.1299, Val MSE: 6694872619.3768, Val R2: 0.6599\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1202\n",
      "Val RMSE: 84599.5210, Val MAE: 44613.0133, Val MSE: 7157078946.6011, Val R2: 0.6364\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0928, Val Loss: 0.1159\n",
      "Val RMSE: 82851.2658, Val MAE: 45847.9149, Val MSE: 6864332247.2343, Val R2: 0.6512\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1244\n",
      "Val RMSE: 85007.2044, Val MAE: 48832.1547, Val MSE: 7226224796.4854, Val R2: 0.6329\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1238\n",
      "Val RMSE: 83303.3114, Val MAE: 47625.9418, Val MSE: 6939441688.9721, Val R2: 0.6474\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0827, Val Loss: 0.1220\n",
      "Val RMSE: 83055.6443, Val MAE: 47641.5106, Val MSE: 6898240046.4868, Val R2: 0.6495\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0814, Val Loss: 0.1134\n",
      "Val RMSE: 82285.1366, Val MAE: 43781.1877, Val MSE: 6770843701.7815, Val R2: 0.6560\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1294\n",
      "Val RMSE: 85398.9146, Val MAE: 47950.9989, Val MSE: 7292974607.5531, Val R2: 0.6295\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.1167\n",
      "Val RMSE: 81694.5891, Val MAE: 45347.5651, Val MSE: 6674005888.1839, Val R2: 0.6609\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0777, Val Loss: 0.1156\n",
      "Val RMSE: 79211.7985, Val MAE: 46411.2135, Val MSE: 6274509024.6688, Val R2: 0.6812\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1223\n",
      "Val RMSE: 81544.1041, Val MAE: 48003.6326, Val MSE: 6649440920.4249, Val R2: 0.6622\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0733, Val Loss: 0.1140\n",
      "Val RMSE: 78046.0168, Val MAE: 43811.0907, Val MSE: 6091180733.9015, Val R2: 0.6905\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1036\n",
      "Val RMSE: 73144.9294, Val MAE: 42257.8126, Val MSE: 5350180690.1417, Val R2: 0.7282\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1073\n",
      "Val RMSE: 74149.2641, Val MAE: 44987.0318, Val MSE: 5498113372.5219, Val R2: 0.7207\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1059\n",
      "Val RMSE: 74783.9278, Val MAE: 41376.0824, Val MSE: 5592635855.9863, Val R2: 0.7159\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0851, Val Loss: 0.1370\n",
      "Val RMSE: 93610.6509, Val MAE: 53115.9042, Val MSE: 8762953965.5403, Val R2: 0.5548\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1073, Val Loss: 0.1289\n",
      "Val RMSE: 85941.3986, Val MAE: 50154.0660, Val MSE: 7385924001.1002, Val R2: 0.6247\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0925, Val Loss: 0.1219\n",
      "Val RMSE: 79487.0497, Val MAE: 46144.1355, Val MSE: 6318191064.0708, Val R2: 0.6790\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1130\n",
      "Val RMSE: 76287.3154, Val MAE: 47114.2585, Val MSE: 5819754491.3638, Val R2: 0.7043\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1198\n",
      "Val RMSE: 78491.5645, Val MAE: 48019.7876, Val MSE: 6160925702.2746, Val R2: 0.6870\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.1192\n",
      "Val RMSE: 77138.3917, Val MAE: 48351.5233, Val MSE: 5950331474.0658, Val R2: 0.6977\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0698, Val Loss: 0.1078\n",
      "Val RMSE: 72994.3995, Val MAE: 44007.4613, Val MSE: 5328182364.9921, Val R2: 0.7293\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.0968\n",
      "Val RMSE: 69019.6106, Val MAE: 40741.3442, Val MSE: 4763706644.6787, Val R2: 0.7580\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1076\n",
      "Val RMSE: 72783.1232, Val MAE: 44658.2399, Val MSE: 5297383019.5220, Val R2: 0.7309\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.0985\n",
      "Val RMSE: 70280.6113, Val MAE: 41045.3133, Val MSE: 4939364328.4827, Val R2: 0.7490\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1046\n",
      "Val RMSE: 72099.8761, Val MAE: 43819.4971, Val MSE: 5198392138.7265, Val R2: 0.7359\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1018\n",
      "Val RMSE: 71409.7120, Val MAE: 43080.7523, Val MSE: 5099346965.4271, Val R2: 0.7409\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1062\n",
      "Val RMSE: 73741.5640, Val MAE: 44542.0593, Val MSE: 5437818256.7117, Val R2: 0.7237\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.0926\n",
      "Val RMSE: 68513.9806, Val MAE: 38899.7621, Val MSE: 4694165542.0506, Val R2: 0.7615\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.0936\n",
      "Val RMSE: 68838.4633, Val MAE: 38681.0420, Val MSE: 4738734032.4311, Val R2: 0.7592\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1008\n",
      "Val RMSE: 73424.4351, Val MAE: 41571.9829, Val MSE: 5391147676.4415, Val R2: 0.7261\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.0970\n",
      "Val RMSE: 70539.4293, Val MAE: 41254.7479, Val MSE: 4975811080.1753, Val R2: 0.7472\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.0970\n",
      "Val RMSE: 69255.2912, Val MAE: 39523.9574, Val MSE: 4796295360.7355, Val R2: 0.7563\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.0990\n",
      "Val RMSE: 69769.6701, Val MAE: 41290.7679, Val MSE: 4867806862.0132, Val R2: 0.7527\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.0940\n",
      "Val RMSE: 67751.5348, Val MAE: 41982.6355, Val MSE: 4590270462.4920, Val R2: 0.7668\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.0943\n",
      "Val RMSE: 69685.1670, Val MAE: 38790.3083, Val MSE: 4856022493.7579, Val R2: 0.7533\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.0874\n",
      "Val RMSE: 67677.8397, Val MAE: 38064.0051, Val MSE: 4580289988.2990, Val R2: 0.7673\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.0870\n",
      "Val RMSE: 66798.1989, Val MAE: 38777.3464, Val MSE: 4461999374.2406, Val R2: 0.7733\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.0959\n",
      "Val RMSE: 70000.4800, Val MAE: 38685.4234, Val MSE: 4900067203.4413, Val R2: 0.7510\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.0930\n",
      "Val RMSE: 68289.0235, Val MAE: 38201.1789, Val MSE: 4663390723.8539, Val R2: 0.7631\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.0915\n",
      "Val RMSE: 66372.6637, Val MAE: 38337.8240, Val MSE: 4405330488.4447, Val R2: 0.7762\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1045\n",
      "Val RMSE: 71460.5558, Val MAE: 45387.1701, Val MSE: 5106611037.5961, Val R2: 0.7406\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1016\n",
      "Val RMSE: 70425.4748, Val MAE: 41986.4292, Val MSE: 4959747505.5695, Val R2: 0.7480\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.0820\n",
      "Val RMSE: 63608.1320, Val MAE: 36665.8590, Val MSE: 4045994452.2738, Val R2: 0.7944\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1063\n",
      "Val RMSE: 73261.8664, Val MAE: 42069.5391, Val MSE: 5367301075.5356, Val R2: 0.7273\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1189\n",
      "Val RMSE: 75713.5793, Val MAE: 50695.6877, Val MSE: 5732546093.8973, Val R2: 0.7088\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1085\n",
      "Val RMSE: 73134.3455, Val MAE: 45268.7670, Val MSE: 5348632492.1453, Val R2: 0.7283\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.0975\n",
      "Val RMSE: 68867.9647, Val MAE: 41643.4990, Val MSE: 4742796555.9032, Val R2: 0.7590\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.0963\n",
      "Val RMSE: 69339.0076, Val MAE: 39951.5348, Val MSE: 4807897974.8250, Val R2: 0.7557\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.0988\n",
      "Val RMSE: 71588.8434, Val MAE: 42743.3867, Val MSE: 5124962498.0782, Val R2: 0.7396\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.0852\n",
      "Val RMSE: 63833.6552, Val MAE: 38502.2605, Val MSE: 4074735530.2691, Val R2: 0.7930\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.0835\n",
      "Val RMSE: 65148.9952, Val MAE: 36363.5916, Val MSE: 4244391579.9104, Val R2: 0.7844\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69347.1230, Test MAE: 37424.7946, Test MSE: 4809023465.4883, Test R2: 0.6917\n",
      "Inference Time: 2.9364695915809044e-05 seconds per sample\n",
      "\n",
      "Iteration 85 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4131, Val Loss: 0.2952\n",
      "Val RMSE: 145726.8770, Val MAE: 82157.4082, Val MSE: 21236322690.1872, Val R2: -0.0789\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2885, Val Loss: 0.2762\n",
      "Val RMSE: 140942.6009, Val MAE: 85390.8390, Val MSE: 19864816760.6463, Val R2: -0.0093\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2759, Val Loss: 0.2781\n",
      "Val RMSE: 143042.7261, Val MAE: 81848.2220, Val MSE: 20461221490.3619, Val R2: -0.0396\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2688, Val Loss: 0.2741\n",
      "Val RMSE: 140805.0167, Val MAE: 85510.7321, Val MSE: 19826052726.5304, Val R2: -0.0073\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2635, Val Loss: 0.2783\n",
      "Val RMSE: 141790.0117, Val MAE: 85570.1118, Val MSE: 20104407420.1866, Val R2: -0.0214\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2595, Val Loss: 0.2753\n",
      "Val RMSE: 141243.0364, Val MAE: 85126.7016, Val MSE: 19949595332.2643, Val R2: -0.0136\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2566, Val Loss: 0.2761\n",
      "Val RMSE: 140820.2275, Val MAE: 86607.8259, Val MSE: 19830336472.3086, Val R2: -0.0075\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2598, Val Loss: 0.2744\n",
      "Val RMSE: 142052.2847, Val MAE: 81098.9863, Val MSE: 20178851590.9551, Val R2: -0.0252\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2676\n",
      "Val RMSE: 141733.3663, Val MAE: 79714.4645, Val MSE: 20088347122.5580, Val R2: -0.0206\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2550, Val Loss: 0.2679\n",
      "Val RMSE: 140375.6108, Val MAE: 82481.6652, Val MSE: 19705312114.0785, Val R2: -0.0012\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2640\n",
      "Val RMSE: 140602.9011, Val MAE: 79632.9096, Val MSE: 19769175807.4476, Val R2: -0.0044\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2538, Val Loss: 0.2657\n",
      "Val RMSE: 139462.6680, Val MAE: 82536.2343, Val MSE: 19449835760.3871, Val R2: 0.0118\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2474, Val Loss: 0.2688\n",
      "Val RMSE: 139455.9405, Val MAE: 83878.0069, Val MSE: 19447959339.9605, Val R2: 0.0119\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2502, Val Loss: 0.2629\n",
      "Val RMSE: 139035.4973, Val MAE: 81290.5729, Val MSE: 19330869520.2717, Val R2: 0.0179\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2436, Val Loss: 0.2543\n",
      "Val RMSE: 137157.3215, Val MAE: 76356.8231, Val MSE: 18812130846.8606, Val R2: 0.0442\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2358, Val Loss: 0.2513\n",
      "Val RMSE: 136548.6335, Val MAE: 75189.4673, Val MSE: 18645529300.0040, Val R2: 0.0527\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2317, Val Loss: 0.2465\n",
      "Val RMSE: 132039.7887, Val MAE: 75986.3280, Val MSE: 17434505792.6290, Val R2: 0.1142\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2196, Val Loss: 0.2342\n",
      "Val RMSE: 133628.9584, Val MAE: 71057.2546, Val MSE: 17856698514.9159, Val R2: 0.0928\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2181, Val Loss: 0.2380\n",
      "Val RMSE: 133547.4398, Val MAE: 72917.2350, Val MSE: 17834918671.7263, Val R2: 0.0939\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2077, Val Loss: 0.2254\n",
      "Val RMSE: 130692.1015, Val MAE: 69837.1943, Val MSE: 17080425404.3878, Val R2: 0.1322\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2078, Val Loss: 0.2232\n",
      "Val RMSE: 128363.2990, Val MAE: 71143.0832, Val MSE: 16477136527.9887, Val R2: 0.1629\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2027, Val Loss: 0.2246\n",
      "Val RMSE: 129609.1427, Val MAE: 69615.3490, Val MSE: 16798529882.4602, Val R2: 0.1465\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1975, Val Loss: 0.2249\n",
      "Val RMSE: 128252.8929, Val MAE: 71617.8468, Val MSE: 16448804540.8130, Val R2: 0.1643\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1976, Val Loss: 0.2261\n",
      "Val RMSE: 128108.6788, Val MAE: 72048.2109, Val MSE: 16411833585.5451, Val R2: 0.1662\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2118\n",
      "Val RMSE: 120454.9229, Val MAE: 69385.2389, Val MSE: 14509388457.6861, Val R2: 0.2628\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1774, Val Loss: 0.1943\n",
      "Val RMSE: 111246.0475, Val MAE: 64839.6532, Val MSE: 12375683078.9300, Val R2: 0.3712\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1705, Val Loss: 0.1956\n",
      "Val RMSE: 109463.5772, Val MAE: 65829.9480, Val MSE: 11982274729.8321, Val R2: 0.3912\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1646, Val Loss: 0.1715\n",
      "Val RMSE: 100950.8778, Val MAE: 62160.3220, Val MSE: 10191079731.4814, Val R2: 0.4822\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1603, Val Loss: 0.1729\n",
      "Val RMSE: 99789.4319, Val MAE: 61151.3227, Val MSE: 9957930719.9695, Val R2: 0.4941\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1541, Val Loss: 0.1659\n",
      "Val RMSE: 100285.1700, Val MAE: 57819.2478, Val MSE: 10057115331.8301, Val R2: 0.4890\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1491, Val Loss: 0.1649\n",
      "Val RMSE: 99807.4909, Val MAE: 57669.4057, Val MSE: 9961535241.6627, Val R2: 0.4939\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1463, Val Loss: 0.1638\n",
      "Val RMSE: 99029.1258, Val MAE: 57804.9839, Val MSE: 9806767752.1519, Val R2: 0.5018\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1660\n",
      "Val RMSE: 98863.9480, Val MAE: 60537.1425, Val MSE: 9774080219.3436, Val R2: 0.5034\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1328, Val Loss: 0.1649\n",
      "Val RMSE: 98898.9858, Val MAE: 59612.3593, Val MSE: 9781009399.4040, Val R2: 0.5031\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1266, Val Loss: 0.1591\n",
      "Val RMSE: 97303.3298, Val MAE: 57592.7958, Val MSE: 9467937983.8368, Val R2: 0.5190\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1189, Val Loss: 0.1499\n",
      "Val RMSE: 94525.2738, Val MAE: 54999.0022, Val MSE: 8935027386.8404, Val R2: 0.5460\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1274, Val Loss: 0.1681\n",
      "Val RMSE: 99609.7821, Val MAE: 60725.8042, Val MSE: 9922108695.4948, Val R2: 0.4959\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1232, Val Loss: 0.1770\n",
      "Val RMSE: 99967.7689, Val MAE: 65098.3625, Val MSE: 9993554823.2618, Val R2: 0.4923\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1174, Val Loss: 0.1556\n",
      "Val RMSE: 96119.8395, Val MAE: 57381.3325, Val MSE: 9239023540.1161, Val R2: 0.5306\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1121, Val Loss: 0.1490\n",
      "Val RMSE: 94182.9192, Val MAE: 55705.9875, Val MSE: 8870422276.3247, Val R2: 0.5493\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1516\n",
      "Val RMSE: 95207.7398, Val MAE: 52950.5806, Val MSE: 9064513708.8363, Val R2: 0.5395\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1045, Val Loss: 0.1530\n",
      "Val RMSE: 94602.0717, Val MAE: 56438.7774, Val MSE: 8949551967.5948, Val R2: 0.5453\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1524\n",
      "Val RMSE: 97281.6550, Val MAE: 53123.0381, Val MSE: 9463720405.4945, Val R2: 0.5192\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1490\n",
      "Val RMSE: 94579.8495, Val MAE: 54462.2301, Val MSE: 8945347930.7397, Val R2: 0.5455\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1528\n",
      "Val RMSE: 94996.0325, Val MAE: 56853.6858, Val MSE: 9024246182.4222, Val R2: 0.5415\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1612\n",
      "Val RMSE: 96666.9747, Val MAE: 58482.7403, Val MSE: 9344504006.6518, Val R2: 0.5252\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1559\n",
      "Val RMSE: 95833.2807, Val MAE: 56178.5342, Val MSE: 9184017681.4148, Val R2: 0.5334\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0899, Val Loss: 0.1537\n",
      "Val RMSE: 95114.7928, Val MAE: 54211.0854, Val MSE: 9046823812.6717, Val R2: 0.5404\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1579\n",
      "Val RMSE: 97906.1548, Val MAE: 55373.3579, Val MSE: 9585615144.6930, Val R2: 0.5130\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0847, Val Loss: 0.1541\n",
      "Val RMSE: 95592.9374, Val MAE: 53864.9990, Val MSE: 9138009689.6801, Val R2: 0.5357\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0829, Val Loss: 0.1551\n",
      "Val RMSE: 94492.9094, Val MAE: 55299.2762, Val MSE: 8928909923.7362, Val R2: 0.5464\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1523\n",
      "Val RMSE: 93938.9137, Val MAE: 54836.2725, Val MSE: 8824519502.4265, Val R2: 0.5517\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1520\n",
      "Val RMSE: 92636.4900, Val MAE: 54337.1964, Val MSE: 8581519278.1206, Val R2: 0.5640\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1546\n",
      "Val RMSE: 91666.5422, Val MAE: 55063.3599, Val MSE: 8402754961.7882, Val R2: 0.5731\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1511\n",
      "Val RMSE: 90640.2015, Val MAE: 54598.0220, Val MSE: 8215646133.3890, Val R2: 0.5826\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1386\n",
      "Val RMSE: 84527.7879, Val MAE: 53247.2621, Val MSE: 7144946929.6058, Val R2: 0.6370\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1449\n",
      "Val RMSE: 87561.0867, Val MAE: 53156.5392, Val MSE: 7666943895.9304, Val R2: 0.6105\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1383\n",
      "Val RMSE: 84471.4329, Val MAE: 53530.2204, Val MSE: 7135422974.9780, Val R2: 0.6375\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1365\n",
      "Val RMSE: 85916.6416, Val MAE: 51385.7615, Val MSE: 7381669306.1116, Val R2: 0.6250\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0715, Val Loss: 0.1323\n",
      "Val RMSE: 81689.5386, Val MAE: 50558.2972, Val MSE: 6673180721.3669, Val R2: 0.6610\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0675, Val Loss: 0.1321\n",
      "Val RMSE: 81470.3923, Val MAE: 49856.9741, Val MSE: 6637424816.9925, Val R2: 0.6628\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1344\n",
      "Val RMSE: 81341.8167, Val MAE: 49505.7565, Val MSE: 6616491136.3233, Val R2: 0.6638\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1312\n",
      "Val RMSE: 82618.4412, Val MAE: 49133.6100, Val MSE: 6825806829.6551, Val R2: 0.6532\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1366\n",
      "Val RMSE: 84212.6730, Val MAE: 50605.7099, Val MSE: 7091774296.3064, Val R2: 0.6397\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1277\n",
      "Val RMSE: 77301.3152, Val MAE: 48881.9131, Val MSE: 5975493332.4264, Val R2: 0.6964\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1349\n",
      "Val RMSE: 81026.8923, Val MAE: 50520.2305, Val MSE: 6565357268.8007, Val R2: 0.6664\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1305\n",
      "Val RMSE: 79102.1278, Val MAE: 49266.0134, Val MSE: 6257146625.6552, Val R2: 0.6821\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1277\n",
      "Val RMSE: 80874.3447, Val MAE: 47710.4085, Val MSE: 6540659627.3420, Val R2: 0.6677\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1303\n",
      "Val RMSE: 79786.0984, Val MAE: 49577.3119, Val MSE: 6365821497.9063, Val R2: 0.6766\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0569, Val Loss: 0.1286\n",
      "Val RMSE: 77080.1180, Val MAE: 48887.3100, Val MSE: 5941344587.7240, Val R2: 0.6981\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1325\n",
      "Val RMSE: 76940.5548, Val MAE: 51342.3686, Val MSE: 5919848973.0086, Val R2: 0.6992\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1212\n",
      "Val RMSE: 77508.6890, Val MAE: 46189.3839, Val MSE: 6007596876.0655, Val R2: 0.6948\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1798\n",
      "Val RMSE: 90687.1435, Val MAE: 60738.4710, Val MSE: 8224158004.0386, Val R2: 0.5822\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1150\n",
      "Val RMSE: 75782.7185, Val MAE: 45508.0964, Val MSE: 5743020427.4971, Val R2: 0.7082\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1338\n",
      "Val RMSE: 78947.7761, Val MAE: 49652.4987, Val MSE: 6232751355.3345, Val R2: 0.6833\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1229\n",
      "Val RMSE: 75561.4721, Val MAE: 49056.5706, Val MSE: 5709536067.2774, Val R2: 0.7099\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1295\n",
      "Val RMSE: 78508.2115, Val MAE: 48125.3129, Val MSE: 6163539268.9109, Val R2: 0.6869\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1156\n",
      "Val RMSE: 75286.8969, Val MAE: 45902.7477, Val MSE: 5668116839.7319, Val R2: 0.7120\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0512, Val Loss: 0.1241\n",
      "Val RMSE: 76712.9577, Val MAE: 48532.3277, Val MSE: 5884877885.8019, Val R2: 0.7010\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1178\n",
      "Val RMSE: 74639.1552, Val MAE: 45266.1999, Val MSE: 5571003485.7625, Val R2: 0.7170\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1148\n",
      "Val RMSE: 73954.4601, Val MAE: 46117.0530, Val MSE: 5469262175.4223, Val R2: 0.7221\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1133\n",
      "Val RMSE: 75122.1025, Val MAE: 43322.7054, Val MSE: 5643330288.1716, Val R2: 0.7133\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1208\n",
      "Val RMSE: 75672.0875, Val MAE: 47336.2263, Val MSE: 5726264833.3567, Val R2: 0.7091\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1177\n",
      "Val RMSE: 78147.1744, Val MAE: 44197.4563, Val MSE: 6106980860.0020, Val R2: 0.6897\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0470, Val Loss: 0.1123\n",
      "Val RMSE: 74472.3314, Val MAE: 44866.7523, Val MSE: 5546128146.5568, Val R2: 0.7182\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1159\n",
      "Val RMSE: 76148.7650, Val MAE: 44808.4345, Val MSE: 5798634412.5252, Val R2: 0.7054\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1130\n",
      "Val RMSE: 76725.6061, Val MAE: 45122.7602, Val MSE: 5886818624.5987, Val R2: 0.7009\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0454, Val Loss: 0.1091\n",
      "Val RMSE: 73163.6233, Val MAE: 43394.6330, Val MSE: 5352915776.0094, Val R2: 0.7280\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1109\n",
      "Val RMSE: 73298.2000, Val MAE: 43661.5065, Val MSE: 5372626124.9315, Val R2: 0.7270\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0436, Val Loss: 0.1194\n",
      "Val RMSE: 78039.1333, Val MAE: 45759.7740, Val MSE: 6090106319.8989, Val R2: 0.6906\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0453, Val Loss: 0.1303\n",
      "Val RMSE: 83411.6567, Val MAE: 46572.9244, Val MSE: 6957504478.3443, Val R2: 0.6465\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.1322\n",
      "Val RMSE: 86769.3441, Val MAE: 47892.3593, Val MSE: 7528919078.4530, Val R2: 0.6175\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1340\n",
      "Val RMSE: 85501.9021, Val MAE: 48201.9408, Val MSE: 7310575262.1398, Val R2: 0.6286\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1196\n",
      "Val RMSE: 80347.4700, Val MAE: 45876.4476, Val MSE: 6455715942.3442, Val R2: 0.6720\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1062\n",
      "Val RMSE: 71495.9090, Val MAE: 43349.0548, Val MSE: 5111664998.2524, Val R2: 0.7403\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1173\n",
      "Val RMSE: 76767.1199, Val MAE: 45546.2856, Val MSE: 5893190702.5910, Val R2: 0.7006\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1255\n",
      "Val RMSE: 79233.8502, Val MAE: 45367.8956, Val MSE: 6278003011.2418, Val R2: 0.6810\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1266\n",
      "Val RMSE: 76950.9660, Val MAE: 49808.1075, Val MSE: 5921451166.0531, Val R2: 0.6992\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1120\n",
      "Val RMSE: 75351.9283, Val MAE: 44251.3636, Val MSE: 5677913099.2875, Val R2: 0.7115\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0416, Val Loss: 0.1294\n",
      "Val RMSE: 81029.7871, Val MAE: 45155.2698, Val MSE: 6565826394.6750, Val R2: 0.6664\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75645.3366, Test MAE: 46054.0549, Test MSE: 5722216946.8286, Test R2: 0.6332\n",
      "Inference Time: 2.3395905127892127e-05 seconds per sample\n",
      "\n",
      "Iteration 86 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3725, Val Loss: 0.2845\n",
      "Val RMSE: 142935.3314, Val MAE: 83753.6475, Val MSE: 20430508957.2453, Val R2: -0.0380\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2788, Val Loss: 0.2782\n",
      "Val RMSE: 142161.8577, Val MAE: 83172.6224, Val MSE: 20209993787.7203, Val R2: -0.0268\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2706, Val Loss: 0.2749\n",
      "Val RMSE: 141522.3562, Val MAE: 83731.7641, Val MSE: 20028577303.3784, Val R2: -0.0176\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2662, Val Loss: 0.2764\n",
      "Val RMSE: 141698.6731, Val MAE: 84840.5498, Val MSE: 20078513964.2554, Val R2: -0.0201\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2620, Val Loss: 0.2800\n",
      "Val RMSE: 143649.6224, Val MAE: 81255.2837, Val MSE: 20635214015.1823, Val R2: -0.0484\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2594, Val Loss: 0.2707\n",
      "Val RMSE: 141993.3711, Val MAE: 81383.7452, Val MSE: 20162117448.9674, Val R2: -0.0244\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2768\n",
      "Val RMSE: 143956.7165, Val MAE: 78779.9280, Val MSE: 20723536226.4255, Val R2: -0.0529\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2558, Val Loss: 0.2694\n",
      "Val RMSE: 142068.6500, Val MAE: 79323.0213, Val MSE: 20183501319.4710, Val R2: -0.0254\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2566, Val Loss: 0.2690\n",
      "Val RMSE: 142054.2087, Val MAE: 79214.1012, Val MSE: 20179398215.7617, Val R2: -0.0252\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2519, Val Loss: 0.2702\n",
      "Val RMSE: 140885.5732, Val MAE: 81304.0502, Val MSE: 19848744726.5648, Val R2: -0.0084\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2701\n",
      "Val RMSE: 141289.5482, Val MAE: 79721.1651, Val MSE: 19962736421.8824, Val R2: -0.0142\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2711\n",
      "Val RMSE: 139786.7833, Val MAE: 83171.6978, Val MSE: 19540344772.0265, Val R2: 0.0072\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2486, Val Loss: 0.2687\n",
      "Val RMSE: 139778.0226, Val MAE: 80968.3844, Val MSE: 19537895612.4080, Val R2: 0.0074\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2410, Val Loss: 0.2492\n",
      "Val RMSE: 133879.0013, Val MAE: 76886.8663, Val MSE: 17923586990.5445, Val R2: 0.0894\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2322, Val Loss: 0.2541\n",
      "Val RMSE: 134775.1304, Val MAE: 75960.7051, Val MSE: 18164335777.8969, Val R2: 0.0771\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2298, Val Loss: 0.2527\n",
      "Val RMSE: 135165.4082, Val MAE: 77191.3357, Val MSE: 18269687564.1650, Val R2: 0.0718\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2159, Val Loss: 0.2388\n",
      "Val RMSE: 131036.7627, Val MAE: 74073.8977, Val MSE: 17170633177.7989, Val R2: 0.1276\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2277\n",
      "Val RMSE: 130119.5125, Val MAE: 72411.3428, Val MSE: 16931087535.8677, Val R2: 0.1398\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2146, Val Loss: 0.2298\n",
      "Val RMSE: 130010.0547, Val MAE: 74200.1942, Val MSE: 16902614324.9137, Val R2: 0.1412\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2492\n",
      "Val RMSE: 137722.3228, Val MAE: 77916.9606, Val MSE: 18967438207.0016, Val R2: 0.0363\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2117, Val Loss: 0.2313\n",
      "Val RMSE: 132642.1373, Val MAE: 71027.4338, Val MSE: 17593936594.2054, Val R2: 0.1061\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2137, Val Loss: 0.2258\n",
      "Val RMSE: 130684.7798, Val MAE: 70960.4728, Val MSE: 17078511668.5530, Val R2: 0.1323\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2062, Val Loss: 0.2200\n",
      "Val RMSE: 126466.4520, Val MAE: 73076.0777, Val MSE: 15993763487.9968, Val R2: 0.1874\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2023, Val Loss: 0.2491\n",
      "Val RMSE: 133237.2230, Val MAE: 72526.8446, Val MSE: 17752157600.5479, Val R2: 0.0981\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1977, Val Loss: 0.2020\n",
      "Val RMSE: 115662.2514, Val MAE: 68089.5690, Val MSE: 13377756404.5023, Val R2: 0.3203\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2217, Val Loss: 0.2422\n",
      "Val RMSE: 133724.7322, Val MAE: 72172.3662, Val MSE: 17882303998.9203, Val R2: 0.0915\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2011, Val Loss: 0.2194\n",
      "Val RMSE: 125183.2446, Val MAE: 67419.2494, Val MSE: 15670844735.0271, Val R2: 0.2038\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1907, Val Loss: 0.2115\n",
      "Val RMSE: 122128.0389, Val MAE: 67405.4539, Val MSE: 14915257879.5543, Val R2: 0.2422\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1901, Val Loss: 0.2100\n",
      "Val RMSE: 117938.6946, Val MAE: 66680.2131, Val MSE: 13909535687.4550, Val R2: 0.2933\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1825, Val Loss: 0.2199\n",
      "Val RMSE: 124123.0629, Val MAE: 67309.1925, Val MSE: 15406534748.3170, Val R2: 0.2173\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1834, Val Loss: 0.1994\n",
      "Val RMSE: 113423.4117, Val MAE: 64654.7608, Val MSE: 12864870325.8706, Val R2: 0.3464\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1798, Val Loss: 0.2027\n",
      "Val RMSE: 112823.4460, Val MAE: 64523.2029, Val MSE: 12729129967.4576, Val R2: 0.3533\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1725, Val Loss: 0.2199\n",
      "Val RMSE: 123444.2642, Val MAE: 67932.3998, Val MSE: 15238486358.2894, Val R2: 0.2258\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1713, Val Loss: 0.1860\n",
      "Val RMSE: 105583.2236, Val MAE: 61073.1218, Val MSE: 11147817098.9688, Val R2: 0.4336\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1644, Val Loss: 0.1888\n",
      "Val RMSE: 105983.7245, Val MAE: 62240.8166, Val MSE: 11232549849.8356, Val R2: 0.4293\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1605, Val Loss: 0.1988\n",
      "Val RMSE: 109042.7975, Val MAE: 63315.4866, Val MSE: 11890331695.8311, Val R2: 0.3959\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1853\n",
      "Val RMSE: 106041.8643, Val MAE: 64487.0567, Val MSE: 11244876990.2738, Val R2: 0.4287\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1586, Val Loss: 0.1751\n",
      "Val RMSE: 104026.4242, Val MAE: 59259.8387, Val MSE: 10821496937.9090, Val R2: 0.4502\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1538, Val Loss: 0.1913\n",
      "Val RMSE: 107219.8037, Val MAE: 65194.0623, Val MSE: 11496086314.7223, Val R2: 0.4159\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1496, Val Loss: 0.1718\n",
      "Val RMSE: 102928.7886, Val MAE: 58623.4504, Val MSE: 10594335522.7756, Val R2: 0.4617\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1760\n",
      "Val RMSE: 102692.3702, Val MAE: 61559.3027, Val MSE: 10545722891.1010, Val R2: 0.4642\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1487, Val Loss: 0.1827\n",
      "Val RMSE: 103497.0143, Val MAE: 61470.5881, Val MSE: 10711631965.2876, Val R2: 0.4558\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1469, Val Loss: 0.1675\n",
      "Val RMSE: 100545.6432, Val MAE: 58193.9231, Val MSE: 10109426367.8821, Val R2: 0.4864\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1731\n",
      "Val RMSE: 102667.8726, Val MAE: 57828.0807, Val MSE: 10540692056.7804, Val R2: 0.4645\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1415, Val Loss: 0.1749\n",
      "Val RMSE: 101265.2028, Val MAE: 60519.7396, Val MSE: 10254641306.3005, Val R2: 0.4790\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1367, Val Loss: 0.1668\n",
      "Val RMSE: 102240.9783, Val MAE: 56643.6898, Val MSE: 10453217652.6451, Val R2: 0.4689\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1598\n",
      "Val RMSE: 99723.7232, Val MAE: 56141.0210, Val MSE: 9944820977.7904, Val R2: 0.4947\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1291, Val Loss: 0.1582\n",
      "Val RMSE: 97319.7812, Val MAE: 54916.2528, Val MSE: 9471139813.7740, Val R2: 0.5188\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1253, Val Loss: 0.1579\n",
      "Val RMSE: 97889.4763, Val MAE: 55616.8337, Val MSE: 9582349579.7697, Val R2: 0.5132\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1203, Val Loss: 0.1516\n",
      "Val RMSE: 95658.3830, Val MAE: 52912.9913, Val MSE: 9150526244.9148, Val R2: 0.5351\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1484\n",
      "Val RMSE: 94969.7083, Val MAE: 53847.4555, Val MSE: 9019245497.5225, Val R2: 0.5418\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1123, Val Loss: 0.1539\n",
      "Val RMSE: 96734.0547, Val MAE: 54479.4175, Val MSE: 9357477339.5686, Val R2: 0.5246\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1583\n",
      "Val RMSE: 97157.9635, Val MAE: 53663.8143, Val MSE: 9439669878.8969, Val R2: 0.5204\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1115, Val Loss: 0.1635\n",
      "Val RMSE: 98581.7415, Val MAE: 54717.6560, Val MSE: 9718359756.6106, Val R2: 0.5062\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1113, Val Loss: 0.1502\n",
      "Val RMSE: 94673.3583, Val MAE: 51339.4981, Val MSE: 8963044781.0482, Val R2: 0.5446\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1016, Val Loss: 0.1450\n",
      "Val RMSE: 93862.4330, Val MAE: 51228.5998, Val MSE: 8810156324.2261, Val R2: 0.5524\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1490\n",
      "Val RMSE: 94032.3063, Val MAE: 52132.7510, Val MSE: 8842074623.3118, Val R2: 0.5508\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0963, Val Loss: 0.1396\n",
      "Val RMSE: 90626.2471, Val MAE: 51586.0273, Val MSE: 8213116655.0968, Val R2: 0.5827\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1450\n",
      "Val RMSE: 92198.1517, Val MAE: 51451.9361, Val MSE: 8500499184.4329, Val R2: 0.5681\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1457\n",
      "Val RMSE: 92917.4636, Val MAE: 50927.5735, Val MSE: 8633655034.0913, Val R2: 0.5614\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1455\n",
      "Val RMSE: 92892.1397, Val MAE: 50961.9134, Val MSE: 8628949617.1202, Val R2: 0.5616\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0885, Val Loss: 0.1423\n",
      "Val RMSE: 90716.2601, Val MAE: 51594.0770, Val MSE: 8229439854.6455, Val R2: 0.5819\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1444\n",
      "Val RMSE: 90931.1749, Val MAE: 52835.8889, Val MSE: 8268478572.9597, Val R2: 0.5799\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1448\n",
      "Val RMSE: 91781.1773, Val MAE: 53000.2245, Val MSE: 8423784501.1967, Val R2: 0.5720\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1401\n",
      "Val RMSE: 91491.2751, Val MAE: 51599.0164, Val MSE: 8370653428.0934, Val R2: 0.5747\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0812, Val Loss: 0.1429\n",
      "Val RMSE: 90902.1411, Val MAE: 50829.1480, Val MSE: 8263199257.7802, Val R2: 0.5802\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0793, Val Loss: 0.1406\n",
      "Val RMSE: 88883.2211, Val MAE: 51399.5193, Val MSE: 7900227000.4411, Val R2: 0.5986\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1392\n",
      "Val RMSE: 90213.1761, Val MAE: 51310.7461, Val MSE: 8138417141.2886, Val R2: 0.5865\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1512\n",
      "Val RMSE: 89576.5306, Val MAE: 52784.0864, Val MSE: 8023954827.7707, Val R2: 0.5923\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1362\n",
      "Val RMSE: 88883.1743, Val MAE: 51056.7976, Val MSE: 7900218668.3119, Val R2: 0.5986\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0766, Val Loss: 0.1358\n",
      "Val RMSE: 87243.0397, Val MAE: 49910.4007, Val MSE: 7611347967.5805, Val R2: 0.6133\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0727, Val Loss: 0.1396\n",
      "Val RMSE: 89916.5678, Val MAE: 51059.5425, Val MSE: 8084989173.2229, Val R2: 0.5892\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0721, Val Loss: 0.1360\n",
      "Val RMSE: 85299.9605, Val MAE: 48897.7981, Val MSE: 7276083259.0736, Val R2: 0.6303\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1307\n",
      "Val RMSE: 86392.8353, Val MAE: 48070.8961, Val MSE: 7463721999.4056, Val R2: 0.6208\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0695, Val Loss: 0.1323\n",
      "Val RMSE: 84252.3567, Val MAE: 48313.6951, Val MSE: 7098459614.3309, Val R2: 0.6394\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1411\n",
      "Val RMSE: 89662.8593, Val MAE: 52197.6120, Val MSE: 8039428337.1656, Val R2: 0.5915\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1470\n",
      "Val RMSE: 90654.1015, Val MAE: 50111.5493, Val MSE: 8218166122.8532, Val R2: 0.5825\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1332\n",
      "Val RMSE: 85945.5427, Val MAE: 47896.1307, Val MSE: 7386636308.6506, Val R2: 0.6247\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0645, Val Loss: 0.1305\n",
      "Val RMSE: 84465.8816, Val MAE: 48312.9000, Val MSE: 7134485147.4362, Val R2: 0.6375\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0646, Val Loss: 0.1330\n",
      "Val RMSE: 86747.5166, Val MAE: 48826.2319, Val MSE: 7525131634.9746, Val R2: 0.6177\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1334\n",
      "Val RMSE: 83115.0316, Val MAE: 47808.4690, Val MSE: 6908108481.1847, Val R2: 0.6490\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.1426\n",
      "Val RMSE: 86570.6162, Val MAE: 49097.5678, Val MSE: 7494471591.7045, Val R2: 0.6192\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1401\n",
      "Val RMSE: 85172.9903, Val MAE: 47765.8359, Val MSE: 7254438278.5029, Val R2: 0.6314\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1480\n",
      "Val RMSE: 88142.5552, Val MAE: 48716.9484, Val MSE: 7769110041.8488, Val R2: 0.6053\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0576, Val Loss: 0.1432\n",
      "Val RMSE: 87592.4558, Val MAE: 50932.4543, Val MSE: 7672438317.2119, Val R2: 0.6102\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1492\n",
      "Val RMSE: 89223.1330, Val MAE: 48833.9452, Val MSE: 7960767470.1960, Val R2: 0.5955\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1487\n",
      "Val RMSE: 88795.5844, Val MAE: 49598.9214, Val MSE: 7884655800.6868, Val R2: 0.5994\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1448\n",
      "Val RMSE: 89512.0970, Val MAE: 48727.9222, Val MSE: 8012415510.6259, Val R2: 0.5929\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0557, Val Loss: 0.1484\n",
      "Val RMSE: 89033.8262, Val MAE: 49856.3513, Val MSE: 7927022214.1881, Val R2: 0.5973\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1684\n",
      "Val RMSE: 94969.4596, Val MAE: 56573.7094, Val MSE: 9019198254.1722, Val R2: 0.5418\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0566, Val Loss: 0.1320\n",
      "Val RMSE: 84539.7144, Val MAE: 49909.9193, Val MSE: 7146963309.5484, Val R2: 0.6369\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1410\n",
      "Val RMSE: 85237.7024, Val MAE: 48872.4526, Val MSE: 7265465909.2566, Val R2: 0.6309\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1223\n",
      "Val RMSE: 81881.1210, Val MAE: 47714.0429, Val MSE: 6704517974.8667, Val R2: 0.6594\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0527, Val Loss: 0.1258\n",
      "Val RMSE: 83687.7038, Val MAE: 45665.7450, Val MSE: 7003631769.0788, Val R2: 0.6442\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1454\n",
      "Val RMSE: 90528.4336, Val MAE: 49951.2273, Val MSE: 8195397288.0436, Val R2: 0.5836\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1426\n",
      "Val RMSE: 87941.2250, Val MAE: 48549.9522, Val MSE: 7733659056.7225, Val R2: 0.6071\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1414\n",
      "Val RMSE: 87604.5059, Val MAE: 49035.7301, Val MSE: 7674549447.0266, Val R2: 0.6101\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1297\n",
      "Val RMSE: 84070.1959, Val MAE: 47149.0682, Val MSE: 7067797833.4164, Val R2: 0.6409\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1342\n",
      "Val RMSE: 84382.8557, Val MAE: 48370.5497, Val MSE: 7120466328.9830, Val R2: 0.6382\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.2134\n",
      "Val RMSE: 105679.7093, Val MAE: 64346.9633, Val MSE: 11168200964.6715, Val R2: 0.4326\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 93759.2268, Test MAE: 56867.5151, Test MSE: 8790792605.7295, Test R2: 0.4365\n",
      "Inference Time: 2.2298299349271336e-05 seconds per sample\n",
      "\n",
      "Iteration 87 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3418, Val Loss: 0.2762\n",
      "Val RMSE: 140401.9776, Val MAE: 86625.2599, Val MSE: 19712715303.2627, Val R2: -0.0015\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2756, Val Loss: 0.2851\n",
      "Val RMSE: 144587.9368, Val MAE: 80618.6676, Val MSE: 20905671477.4809, Val R2: -0.0621\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2716, Val Loss: 0.2753\n",
      "Val RMSE: 140560.2749, Val MAE: 85508.9456, Val MSE: 19757190887.8844, Val R2: -0.0038\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2663, Val Loss: 0.2753\n",
      "Val RMSE: 141357.6848, Val MAE: 83499.5633, Val MSE: 19981995057.4354, Val R2: -0.0152\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2653, Val Loss: 0.2764\n",
      "Val RMSE: 142148.3907, Val MAE: 81957.0587, Val MSE: 20206164991.7452, Val R2: -0.0266\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2626, Val Loss: 0.2692\n",
      "Val RMSE: 141850.5382, Val MAE: 81249.1928, Val MSE: 20121575199.8205, Val R2: -0.0223\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2558, Val Loss: 0.2724\n",
      "Val RMSE: 141531.6442, Val MAE: 81577.2114, Val MSE: 20031206312.5962, Val R2: -0.0177\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2689\n",
      "Val RMSE: 140766.5381, Val MAE: 81617.5728, Val MSE: 19815218259.2731, Val R2: -0.0067\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2549, Val Loss: 0.2648\n",
      "Val RMSE: 140715.0923, Val MAE: 79344.9815, Val MSE: 19800737205.0179, Val R2: -0.0060\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2618\n",
      "Val RMSE: 138018.3180, Val MAE: 77299.2673, Val MSE: 19049056111.6684, Val R2: 0.0322\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2471, Val Loss: 0.2546\n",
      "Val RMSE: 135896.8534, Val MAE: 77200.8913, Val MSE: 18467954768.5929, Val R2: 0.0617\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2462, Val Loss: 0.2535\n",
      "Val RMSE: 135784.7782, Val MAE: 78595.2111, Val MSE: 18437505990.9990, Val R2: 0.0633\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2419, Val Loss: 0.2504\n",
      "Val RMSE: 134710.6552, Val MAE: 78086.4442, Val MSE: 18146960632.9256, Val R2: 0.0780\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2415, Val Loss: 0.2506\n",
      "Val RMSE: 134566.4400, Val MAE: 77444.6389, Val MSE: 18108126761.2472, Val R2: 0.0800\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2408, Val Loss: 0.2606\n",
      "Val RMSE: 136316.0639, Val MAE: 80442.8879, Val MSE: 18582069276.8966, Val R2: 0.0559\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2383, Val Loss: 0.2556\n",
      "Val RMSE: 135598.5150, Val MAE: 78220.4869, Val MSE: 18386957281.3129, Val R2: 0.0658\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2404\n",
      "Val RMSE: 132565.9636, Val MAE: 75124.4332, Val MSE: 17573734705.4479, Val R2: 0.1071\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2210, Val Loss: 0.2278\n",
      "Val RMSE: 127259.1843, Val MAE: 72080.8828, Val MSE: 16194899976.9397, Val R2: 0.1772\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2167, Val Loss: 0.2473\n",
      "Val RMSE: 132507.7687, Val MAE: 77432.8424, Val MSE: 17558308761.7315, Val R2: 0.1079\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2101, Val Loss: 0.2462\n",
      "Val RMSE: 131715.5267, Val MAE: 76941.3966, Val MSE: 17348979977.5281, Val R2: 0.1186\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2291\n",
      "Val RMSE: 125680.0021, Val MAE: 72470.6480, Val MSE: 15795462917.3378, Val R2: 0.1975\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2013, Val Loss: 0.2569\n",
      "Val RMSE: 127903.5080, Val MAE: 84272.2464, Val MSE: 16359307370.8017, Val R2: 0.1688\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2019, Val Loss: 0.2118\n",
      "Val RMSE: 115737.1256, Val MAE: 70611.6784, Val MSE: 13395082240.9112, Val R2: 0.3194\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1903, Val Loss: 0.2043\n",
      "Val RMSE: 112908.5317, Val MAE: 65888.9261, Val MSE: 12748336525.9291, Val R2: 0.3523\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1877, Val Loss: 0.1884\n",
      "Val RMSE: 106146.0117, Val MAE: 65381.3035, Val MSE: 11266975806.1278, Val R2: 0.4276\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1813, Val Loss: 0.1893\n",
      "Val RMSE: 106666.6827, Val MAE: 63598.9622, Val MSE: 11377781205.0626, Val R2: 0.4219\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1784, Val Loss: 0.1721\n",
      "Val RMSE: 100374.8835, Val MAE: 61896.2804, Val MSE: 10075117235.2341, Val R2: 0.4881\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1760, Val Loss: 0.1792\n",
      "Val RMSE: 101064.7736, Val MAE: 62489.2537, Val MSE: 10214088461.9015, Val R2: 0.4811\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1701, Val Loss: 0.1726\n",
      "Val RMSE: 100671.0685, Val MAE: 60038.1445, Val MSE: 10134664024.0609, Val R2: 0.4851\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1669, Val Loss: 0.2026\n",
      "Val RMSE: 106326.8117, Val MAE: 72461.6106, Val MSE: 11305390881.1156, Val R2: 0.4256\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1712, Val Loss: 0.1846\n",
      "Val RMSE: 105127.7817, Val MAE: 62901.2254, Val MSE: 11051850479.6570, Val R2: 0.4385\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1626, Val Loss: 0.1801\n",
      "Val RMSE: 103630.1296, Val MAE: 62810.8073, Val MSE: 10739203766.1492, Val R2: 0.4544\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1640, Val Loss: 0.1733\n",
      "Val RMSE: 100646.0220, Val MAE: 62041.1309, Val MSE: 10129621749.7795, Val R2: 0.4854\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1531, Val Loss: 0.1737\n",
      "Val RMSE: 100216.6952, Val MAE: 59892.1838, Val MSE: 10043385990.2217, Val R2: 0.4897\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1505, Val Loss: 0.1691\n",
      "Val RMSE: 99088.0772, Val MAE: 60900.7633, Val MSE: 9818447044.4664, Val R2: 0.5012\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1453, Val Loss: 0.1625\n",
      "Val RMSE: 96296.9157, Val MAE: 57803.0274, Val MSE: 9273095964.2653, Val R2: 0.5289\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1435, Val Loss: 0.1581\n",
      "Val RMSE: 95155.4695, Val MAE: 57602.5613, Val MSE: 9054563377.3898, Val R2: 0.5400\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1389, Val Loss: 0.1779\n",
      "Val RMSE: 100965.6927, Val MAE: 57853.8106, Val MSE: 10194071108.1696, Val R2: 0.4821\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1363, Val Loss: 0.1567\n",
      "Val RMSE: 97279.0482, Val MAE: 56202.2301, Val MSE: 9463213210.8105, Val R2: 0.5192\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1308, Val Loss: 0.1828\n",
      "Val RMSE: 100498.7448, Val MAE: 57801.7562, Val MSE: 10099997701.6315, Val R2: 0.4869\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1251, Val Loss: 0.1494\n",
      "Val RMSE: 95223.2358, Val MAE: 54159.6378, Val MSE: 9067464627.4552, Val R2: 0.5393\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1212, Val Loss: 0.1455\n",
      "Val RMSE: 93833.4466, Val MAE: 52269.5045, Val MSE: 8804715698.1908, Val R2: 0.5527\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1192, Val Loss: 0.1550\n",
      "Val RMSE: 96020.7869, Val MAE: 58605.9119, Val MSE: 9219991513.8733, Val R2: 0.5316\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1154, Val Loss: 0.1554\n",
      "Val RMSE: 94841.7158, Val MAE: 54514.7900, Val MSE: 8994951055.1826, Val R2: 0.5430\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1114, Val Loss: 0.1515\n",
      "Val RMSE: 93930.7305, Val MAE: 57541.9881, Val MSE: 8822982132.7758, Val R2: 0.5517\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1521\n",
      "Val RMSE: 94016.4375, Val MAE: 53843.4695, Val MSE: 8839090516.4922, Val R2: 0.5509\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1063, Val Loss: 0.1629\n",
      "Val RMSE: 96926.2020, Val MAE: 55754.9114, Val MSE: 9394688626.5067, Val R2: 0.5227\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1031, Val Loss: 0.1583\n",
      "Val RMSE: 96776.9465, Val MAE: 59199.3269, Val MSE: 9365777378.5675, Val R2: 0.5242\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1009, Val Loss: 0.1508\n",
      "Val RMSE: 94307.0200, Val MAE: 57179.5461, Val MSE: 8893814023.5943, Val R2: 0.5481\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1016, Val Loss: 0.1553\n",
      "Val RMSE: 93970.6493, Val MAE: 53814.5640, Val MSE: 8830482922.7542, Val R2: 0.5514\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0969, Val Loss: 0.1916\n",
      "Val RMSE: 102364.3683, Val MAE: 56091.2202, Val MSE: 10478463892.2823, Val R2: 0.4676\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1528\n",
      "Val RMSE: 92378.0629, Val MAE: 53078.9959, Val MSE: 8533706509.2491, Val R2: 0.5664\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0923, Val Loss: 0.1343\n",
      "Val RMSE: 86720.2277, Val MAE: 52796.2486, Val MSE: 7520397890.7275, Val R2: 0.6179\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0924, Val Loss: 0.1454\n",
      "Val RMSE: 89867.5438, Val MAE: 48262.7738, Val MSE: 8076175426.4612, Val R2: 0.5897\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1591\n",
      "Val RMSE: 91409.4106, Val MAE: 50631.8839, Val MSE: 8355680349.6107, Val R2: 0.5755\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0914, Val Loss: 0.1505\n",
      "Val RMSE: 89828.7395, Val MAE: 51830.5160, Val MSE: 8069202436.4715, Val R2: 0.5900\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1401\n",
      "Val RMSE: 88373.3228, Val MAE: 48780.7600, Val MSE: 7809844183.0366, Val R2: 0.6032\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1358\n",
      "Val RMSE: 90624.0743, Val MAE: 49898.1517, Val MSE: 8212722840.6219, Val R2: 0.5827\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0833, Val Loss: 0.1380\n",
      "Val RMSE: 88963.7970, Val MAE: 49221.1606, Val MSE: 7914557168.2051, Val R2: 0.5979\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0806, Val Loss: 0.1213\n",
      "Val RMSE: 77842.1417, Val MAE: 46961.1532, Val MSE: 6059399022.5399, Val R2: 0.6921\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0804, Val Loss: 0.1280\n",
      "Val RMSE: 82026.3806, Val MAE: 46879.4286, Val MSE: 6728327110.4171, Val R2: 0.6582\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0807, Val Loss: 0.1271\n",
      "Val RMSE: 82602.0023, Val MAE: 47697.9469, Val MSE: 6823090784.3033, Val R2: 0.6533\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1288\n",
      "Val RMSE: 84758.6951, Val MAE: 51276.2170, Val MSE: 7184036392.7302, Val R2: 0.6350\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1302\n",
      "Val RMSE: 82147.3439, Val MAE: 46817.2242, Val MSE: 6748186111.1579, Val R2: 0.6571\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1276\n",
      "Val RMSE: 83115.3233, Val MAE: 46330.6949, Val MSE: 6908156965.9363, Val R2: 0.6490\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1158\n",
      "Val RMSE: 76336.3945, Val MAE: 46934.5043, Val MSE: 5827245128.8312, Val R2: 0.7039\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0741, Val Loss: 0.1213\n",
      "Val RMSE: 78696.0880, Val MAE: 49502.4038, Val MSE: 6193074259.4626, Val R2: 0.6854\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1099\n",
      "Val RMSE: 73037.8242, Val MAE: 44646.3097, Val MSE: 5334523758.5010, Val R2: 0.7290\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0690, Val Loss: 0.1172\n",
      "Val RMSE: 77282.6544, Val MAE: 46097.1242, Val MSE: 5972608677.7868, Val R2: 0.6966\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1062\n",
      "Val RMSE: 73136.7804, Val MAE: 42189.8186, Val MSE: 5348988642.0487, Val R2: 0.7282\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1201\n",
      "Val RMSE: 77470.0175, Val MAE: 46792.8008, Val MSE: 6001603610.5435, Val R2: 0.6951\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0666, Val Loss: 0.1097\n",
      "Val RMSE: 77872.3343, Val MAE: 41253.9380, Val MSE: 6064100442.0384, Val R2: 0.6919\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1084\n",
      "Val RMSE: 72694.2071, Val MAE: 40411.3317, Val MSE: 5284447745.3702, Val R2: 0.7315\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0738, Val Loss: 0.1304\n",
      "Val RMSE: 83402.9788, Val MAE: 45881.1357, Val MSE: 6956056870.5560, Val R2: 0.6466\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0672, Val Loss: 0.1269\n",
      "Val RMSE: 79225.9181, Val MAE: 50382.5852, Val MSE: 6276746106.5309, Val R2: 0.6811\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1196\n",
      "Val RMSE: 77737.5584, Val MAE: 48168.0953, Val MSE: 6043127985.6457, Val R2: 0.6930\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1096\n",
      "Val RMSE: 77116.5159, Val MAE: 42883.4985, Val MSE: 5946957028.1875, Val R2: 0.6979\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1114\n",
      "Val RMSE: 77382.7499, Val MAE: 41683.5527, Val MSE: 5988089987.7047, Val R2: 0.6958\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1083\n",
      "Val RMSE: 72726.0001, Val MAE: 42651.9041, Val MSE: 5289071097.1390, Val R2: 0.7313\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1286\n",
      "Val RMSE: 77393.7313, Val MAE: 44805.0900, Val MSE: 5989789649.9778, Val R2: 0.6957\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1083\n",
      "Val RMSE: 70661.1406, Val MAE: 40532.0625, Val MSE: 4992996785.7062, Val R2: 0.7463\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1126\n",
      "Val RMSE: 75941.4541, Val MAE: 42896.3861, Val MSE: 5767104449.4382, Val R2: 0.7070\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1272\n",
      "Val RMSE: 80496.8191, Val MAE: 46063.4579, Val MSE: 6479737886.3994, Val R2: 0.6708\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1276\n",
      "Val RMSE: 78688.8386, Val MAE: 43649.3894, Val MSE: 6191933327.8986, Val R2: 0.6854\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1198\n",
      "Val RMSE: 77918.5881, Val MAE: 44534.6337, Val MSE: 6071306379.2036, Val R2: 0.6915\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0531, Val Loss: 0.1144\n",
      "Val RMSE: 75497.8809, Val MAE: 44600.0665, Val MSE: 5699930022.8756, Val R2: 0.7104\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1184\n",
      "Val RMSE: 74851.2575, Val MAE: 43153.6205, Val MSE: 5602710744.2826, Val R2: 0.7153\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1108\n",
      "Val RMSE: 70418.5639, Val MAE: 41432.1940, Val MSE: 4958774139.2301, Val R2: 0.7481\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0533, Val Loss: 0.1172\n",
      "Val RMSE: 77367.9206, Val MAE: 43608.9032, Val MSE: 5985795139.4976, Val R2: 0.6959\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1304\n",
      "Val RMSE: 78179.4062, Val MAE: 45290.3856, Val MSE: 6112019556.7375, Val R2: 0.6895\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1173\n",
      "Val RMSE: 76912.9724, Val MAE: 44026.2794, Val MSE: 5915605321.3869, Val R2: 0.6994\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1180\n",
      "Val RMSE: 77144.8925, Val MAE: 44604.4337, Val MSE: 5951334439.7178, Val R2: 0.6976\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1139\n",
      "Val RMSE: 72931.5113, Val MAE: 42573.6000, Val MSE: 5319005334.3903, Val R2: 0.7298\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1148\n",
      "Val RMSE: 74455.3046, Val MAE: 42160.2658, Val MSE: 5543592376.9633, Val R2: 0.7184\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1134\n",
      "Val RMSE: 72394.8287, Val MAE: 40802.5989, Val MSE: 5241011228.7595, Val R2: 0.7337\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1213\n",
      "Val RMSE: 77504.4179, Val MAE: 44347.0759, Val MSE: 6006934796.2364, Val R2: 0.6948\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0476, Val Loss: 0.1065\n",
      "Val RMSE: 71514.7758, Val MAE: 40024.5478, Val MSE: 5114363156.7489, Val R2: 0.7402\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1191\n",
      "Val RMSE: 75268.5803, Val MAE: 42889.9631, Val MSE: 5665359174.0779, Val R2: 0.7122\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1262\n",
      "Val RMSE: 78589.0995, Val MAE: 42813.4882, Val MSE: 6176246559.1269, Val R2: 0.6862\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.1063\n",
      "Val RMSE: 72400.9203, Val MAE: 40274.8295, Val MSE: 5241893261.3049, Val R2: 0.7337\n",
      "Early stopping triggered after epoch 100\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 89092.3866, Test MAE: 48910.6479, Test MSE: 7937453344.6191, Test R2: 0.4912\n",
      "Inference Time: 2.1526116591233474e-05 seconds per sample\n",
      "\n",
      "Iteration 88 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.4043, Val Loss: 0.2919\n",
      "Val RMSE: 144479.2610, Val MAE: 83407.9480, Val MSE: 20874256862.6633, Val R2: -0.0605\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2872, Val Loss: 0.2807\n",
      "Val RMSE: 141389.2066, Val MAE: 85930.1805, Val MSE: 19990907732.2423, Val R2: -0.0157\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2782, Val Loss: 0.2769\n",
      "Val RMSE: 142632.4124, Val MAE: 82515.7604, Val MSE: 20344005077.9830, Val R2: -0.0336\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2705, Val Loss: 0.2736\n",
      "Val RMSE: 141882.6612, Val MAE: 82761.1110, Val MSE: 20130689562.2975, Val R2: -0.0228\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2712\n",
      "Val RMSE: 141859.1766, Val MAE: 81651.5822, Val MSE: 20124025989.1875, Val R2: -0.0224\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2591, Val Loss: 0.2828\n",
      "Val RMSE: 146088.3744, Val MAE: 78069.8836, Val MSE: 21341813147.1810, Val R2: -0.0843\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2723\n",
      "Val RMSE: 141637.2887, Val MAE: 82480.8922, Val MSE: 20061121536.6656, Val R2: -0.0192\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2759\n",
      "Val RMSE: 141563.6759, Val MAE: 84608.2219, Val MSE: 20040274348.0288, Val R2: -0.0182\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2732\n",
      "Val RMSE: 142904.8670, Val MAE: 79120.2381, Val MSE: 20421801019.8819, Val R2: -0.0376\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2548, Val Loss: 0.2713\n",
      "Val RMSE: 142670.3514, Val MAE: 78980.3013, Val MSE: 20354829155.3393, Val R2: -0.0342\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2738\n",
      "Val RMSE: 141504.6307, Val MAE: 83174.8167, Val MSE: 20023560518.2840, Val R2: -0.0173\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2498, Val Loss: 0.2689\n",
      "Val RMSE: 141546.8528, Val MAE: 80834.5643, Val MSE: 20035511536.5552, Val R2: -0.0179\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2513, Val Loss: 0.2739\n",
      "Val RMSE: 141063.3776, Val MAE: 83872.1884, Val MSE: 19898876489.0127, Val R2: -0.0110\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2510, Val Loss: 0.2676\n",
      "Val RMSE: 141310.0585, Val MAE: 80043.3407, Val MSE: 19968532641.0904, Val R2: -0.0145\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2478, Val Loss: 0.2675\n",
      "Val RMSE: 141155.5222, Val MAE: 80161.7081, Val MSE: 19924881449.4643, Val R2: -0.0123\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2447, Val Loss: 0.2702\n",
      "Val RMSE: 141484.5204, Val MAE: 80725.5964, Val MSE: 20017869500.6834, Val R2: -0.0170\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2431, Val Loss: 0.2652\n",
      "Val RMSE: 139384.0898, Val MAE: 81817.6274, Val MSE: 19427924501.3086, Val R2: 0.0129\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2765\n",
      "Val RMSE: 140902.9887, Val MAE: 83290.6154, Val MSE: 19853652228.4662, Val R2: -0.0087\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2405, Val Loss: 0.2622\n",
      "Val RMSE: 140259.0131, Val MAE: 79124.2565, Val MSE: 19672590753.1967, Val R2: 0.0005\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2404, Val Loss: 0.2624\n",
      "Val RMSE: 139876.3493, Val MAE: 79850.2685, Val MSE: 19565393094.3061, Val R2: 0.0060\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2527\n",
      "Val RMSE: 136069.9426, Val MAE: 77504.5884, Val MSE: 18515029268.4397, Val R2: 0.0593\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2250, Val Loss: 0.2394\n",
      "Val RMSE: 131060.4416, Val MAE: 74776.9015, Val MSE: 17176839346.6557, Val R2: 0.1273\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2206, Val Loss: 0.2298\n",
      "Val RMSE: 130297.4608, Val MAE: 72787.7285, Val MSE: 16977428278.9431, Val R2: 0.1374\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2111, Val Loss: 0.2276\n",
      "Val RMSE: 130015.6547, Val MAE: 72125.0441, Val MSE: 16904070468.2870, Val R2: 0.1412\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2042, Val Loss: 0.2104\n",
      "Val RMSE: 119759.8837, Val MAE: 66248.2882, Val MSE: 14342429736.1680, Val R2: 0.2713\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2146, Val Loss: 0.2140\n",
      "Val RMSE: 120341.9494, Val MAE: 68004.7370, Val MSE: 14482184796.1499, Val R2: 0.2642\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1995, Val Loss: 0.2163\n",
      "Val RMSE: 120678.3569, Val MAE: 68715.8450, Val MSE: 14563265825.5372, Val R2: 0.2601\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1839, Val Loss: 0.2102\n",
      "Val RMSE: 116312.7014, Val MAE: 69349.2576, Val MSE: 13528644495.6696, Val R2: 0.3127\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1766, Val Loss: 0.2023\n",
      "Val RMSE: 109754.4553, Val MAE: 63599.7201, Val MSE: 12046040461.3731, Val R2: 0.3880\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1718, Val Loss: 0.1769\n",
      "Val RMSE: 102654.4607, Val MAE: 61898.3407, Val MSE: 10537938302.2844, Val R2: 0.4646\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1669, Val Loss: 0.1738\n",
      "Val RMSE: 101151.6213, Val MAE: 61708.5520, Val MSE: 10231650481.9170, Val R2: 0.4802\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1642, Val Loss: 0.1777\n",
      "Val RMSE: 102523.9912, Val MAE: 61132.9121, Val MSE: 10511168775.7991, Val R2: 0.4660\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1654, Val Loss: 0.1695\n",
      "Val RMSE: 99583.2018, Val MAE: 59182.9960, Val MSE: 9916814086.4121, Val R2: 0.4962\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1632, Val Loss: 0.1668\n",
      "Val RMSE: 98600.9237, Val MAE: 60105.2883, Val MSE: 9722142144.6740, Val R2: 0.5061\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1564, Val Loss: 0.1605\n",
      "Val RMSE: 98018.7136, Val MAE: 59472.2709, Val MSE: 9607668216.1027, Val R2: 0.5119\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1553, Val Loss: 0.1531\n",
      "Val RMSE: 95765.3398, Val MAE: 57249.7311, Val MSE: 9171000311.7836, Val R2: 0.5341\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1512, Val Loss: 0.1546\n",
      "Val RMSE: 96159.2370, Val MAE: 56358.6488, Val MSE: 9246598867.5830, Val R2: 0.5302\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1510, Val Loss: 0.1560\n",
      "Val RMSE: 96750.3046, Val MAE: 56014.6110, Val MSE: 9360621449.2204, Val R2: 0.5244\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1470, Val Loss: 0.1498\n",
      "Val RMSE: 95450.3882, Val MAE: 53679.6919, Val MSE: 9110776611.7113, Val R2: 0.5371\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1535\n",
      "Val RMSE: 96497.5358, Val MAE: 53776.8083, Val MSE: 9311774409.8735, Val R2: 0.5269\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1455, Val Loss: 0.1580\n",
      "Val RMSE: 96453.0161, Val MAE: 55882.4376, Val MSE: 9303184319.7416, Val R2: 0.5273\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1410, Val Loss: 0.1501\n",
      "Val RMSE: 94507.1643, Val MAE: 54978.0775, Val MSE: 8931604098.1298, Val R2: 0.5462\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1346, Val Loss: 0.1500\n",
      "Val RMSE: 94579.7486, Val MAE: 54254.1168, Val MSE: 8945328842.8509, Val R2: 0.5455\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1297, Val Loss: 0.1411\n",
      "Val RMSE: 91523.5091, Val MAE: 53709.1841, Val MSE: 8376552711.1362, Val R2: 0.5744\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1245, Val Loss: 0.1457\n",
      "Val RMSE: 91829.6809, Val MAE: 55943.2952, Val MSE: 8432690302.8635, Val R2: 0.5716\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1185, Val Loss: 0.1343\n",
      "Val RMSE: 89893.5898, Val MAE: 48981.0582, Val MSE: 8080857489.6586, Val R2: 0.5894\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1134, Val Loss: 0.1413\n",
      "Val RMSE: 91172.8609, Val MAE: 53635.9894, Val MSE: 8312490570.6621, Val R2: 0.5777\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1137, Val Loss: 0.1379\n",
      "Val RMSE: 90890.2654, Val MAE: 52425.7066, Val MSE: 8261040345.2220, Val R2: 0.5803\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1071, Val Loss: 0.1250\n",
      "Val RMSE: 88333.2386, Val MAE: 47250.9760, Val MSE: 7802761048.9393, Val R2: 0.6036\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1320\n",
      "Val RMSE: 89189.9250, Val MAE: 47013.5526, Val MSE: 7954842728.5730, Val R2: 0.5958\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1025, Val Loss: 0.1322\n",
      "Val RMSE: 88434.4637, Val MAE: 52465.0471, Val MSE: 7820654362.2892, Val R2: 0.6027\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1016, Val Loss: 0.1299\n",
      "Val RMSE: 87764.1929, Val MAE: 49693.0813, Val MSE: 7702553551.1215, Val R2: 0.6087\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0970, Val Loss: 0.1441\n",
      "Val RMSE: 92932.0609, Val MAE: 48574.9616, Val MSE: 8636367937.6886, Val R2: 0.5612\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0935, Val Loss: 0.1358\n",
      "Val RMSE: 90713.5602, Val MAE: 48089.0560, Val MSE: 8228949998.8907, Val R2: 0.5819\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0921, Val Loss: 0.1309\n",
      "Val RMSE: 89325.5758, Val MAE: 46822.8567, Val MSE: 7979058491.1597, Val R2: 0.5946\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0902, Val Loss: 0.1467\n",
      "Val RMSE: 95268.8685, Val MAE: 53170.8007, Val MSE: 9076157296.9214, Val R2: 0.5389\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1345\n",
      "Val RMSE: 90340.2559, Val MAE: 48745.8295, Val MSE: 8161361840.2690, Val R2: 0.5854\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1405\n",
      "Val RMSE: 90388.1980, Val MAE: 51147.3561, Val MSE: 8170026338.7068, Val R2: 0.5849\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0869, Val Loss: 0.1542\n",
      "Val RMSE: 93947.8415, Val MAE: 55670.7994, Val MSE: 8826196928.0512, Val R2: 0.5516\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0851, Val Loss: 0.1356\n",
      "Val RMSE: 89035.3068, Val MAE: 50205.8353, Val MSE: 7927285862.9357, Val R2: 0.5972\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0839, Val Loss: 0.1413\n",
      "Val RMSE: 91729.2013, Val MAE: 50166.4592, Val MSE: 8414246366.5801, Val R2: 0.5725\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.1447\n",
      "Val RMSE: 94276.1653, Val MAE: 49533.6872, Val MSE: 8887995340.2732, Val R2: 0.5484\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1374\n",
      "Val RMSE: 91865.6516, Val MAE: 49561.5582, Val MSE: 8439297948.9901, Val R2: 0.5712\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0786, Val Loss: 0.1411\n",
      "Val RMSE: 93899.9217, Val MAE: 50056.1317, Val MSE: 8817195299.0997, Val R2: 0.5520\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0761, Val Loss: 0.1469\n",
      "Val RMSE: 92539.0158, Val MAE: 53791.5448, Val MSE: 8563469447.9827, Val R2: 0.5649\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0754, Val Loss: 0.1446\n",
      "Val RMSE: 92526.2133, Val MAE: 48712.2817, Val MSE: 8561100147.0526, Val R2: 0.5650\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0722, Val Loss: 0.1447\n",
      "Val RMSE: 92261.7363, Val MAE: 48927.2033, Val MSE: 8512227991.9901, Val R2: 0.5675\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1384\n",
      "Val RMSE: 90680.1813, Val MAE: 48372.2043, Val MSE: 8222895279.3631, Val R2: 0.5822\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1394\n",
      "Val RMSE: 90096.4401, Val MAE: 50300.7314, Val MSE: 8117368525.5498, Val R2: 0.5876\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1408\n",
      "Val RMSE: 90130.7005, Val MAE: 48098.4867, Val MSE: 8123543173.7879, Val R2: 0.5873\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1440\n",
      "Val RMSE: 88305.8302, Val MAE: 51071.4299, Val MSE: 7797919649.1498, Val R2: 0.6038\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0659, Val Loss: 0.1482\n",
      "Val RMSE: 94271.9430, Val MAE: 50316.3163, Val MSE: 8887199235.1885, Val R2: 0.5485\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0656, Val Loss: 0.1424\n",
      "Val RMSE: 89836.7294, Val MAE: 48668.0208, Val MSE: 8070637945.3749, Val R2: 0.5900\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.1474\n",
      "Val RMSE: 93125.7285, Val MAE: 49917.2954, Val MSE: 8672401303.6212, Val R2: 0.5594\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1454\n",
      "Val RMSE: 91683.8502, Val MAE: 50959.5858, Val MSE: 8405928386.6957, Val R2: 0.5729\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1395\n",
      "Val RMSE: 88733.1026, Val MAE: 47902.6892, Val MSE: 7873563494.9986, Val R2: 0.6000\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1483\n",
      "Val RMSE: 89491.1297, Val MAE: 49003.1036, Val MSE: 8008662291.8793, Val R2: 0.5931\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1357\n",
      "Val RMSE: 85251.4958, Val MAE: 51198.7574, Val MSE: 7267817535.4646, Val R2: 0.6307\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1348\n",
      "Val RMSE: 87432.7548, Val MAE: 47040.5245, Val MSE: 7644486616.1579, Val R2: 0.6116\n",
      "Early stopping triggered after epoch 79\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 100459.6146, Test MAE: 54346.1545, Test MSE: 10092134156.7162, Test R2: 0.3531\n",
      "Inference Time: 2.827035463773287e-05 seconds per sample\n",
      "\n",
      "Iteration 89 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3560, Val Loss: 0.2834\n",
      "Val RMSE: 142667.8718, Val MAE: 83691.5832, Val MSE: 20354121643.1352, Val R2: -0.0341\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2830, Val Loss: 0.2749\n",
      "Val RMSE: 141276.0208, Val MAE: 84059.0118, Val MSE: 19958914063.5436, Val R2: -0.0140\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2761, Val Loss: 0.2768\n",
      "Val RMSE: 139876.8155, Val MAE: 88428.3795, Val MSE: 19565523502.1849, Val R2: 0.0059\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2696, Val Loss: 0.2750\n",
      "Val RMSE: 141181.5203, Val MAE: 84695.0221, Val MSE: 19932221669.1870, Val R2: -0.0127\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2773\n",
      "Val RMSE: 141387.2289, Val MAE: 85553.8558, Val MSE: 19990348487.7023, Val R2: -0.0156\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2696\n",
      "Val RMSE: 141472.4083, Val MAE: 82332.1849, Val MSE: 20014442322.9156, Val R2: -0.0169\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2755\n",
      "Val RMSE: 141498.3497, Val MAE: 82981.2024, Val MSE: 20021782975.0518, Val R2: -0.0172\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2796\n",
      "Val RMSE: 141397.2306, Val MAE: 86434.5829, Val MSE: 19993176824.2727, Val R2: -0.0158\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2541, Val Loss: 0.2967\n",
      "Val RMSE: 142573.9149, Val MAE: 90966.5152, Val MSE: 20327321198.8491, Val R2: -0.0328\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2670\n",
      "Val RMSE: 141551.9162, Val MAE: 80518.7102, Val MSE: 20036944967.8992, Val R2: -0.0180\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2665\n",
      "Val RMSE: 141458.3140, Val MAE: 80101.5816, Val MSE: 20010454590.6397, Val R2: -0.0167\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2499, Val Loss: 0.2794\n",
      "Val RMSE: 142002.6476, Val MAE: 84404.1885, Val MSE: 20164751917.0020, Val R2: -0.0245\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2503, Val Loss: 0.2696\n",
      "Val RMSE: 140441.8910, Val MAE: 83341.7723, Val MSE: 19723924756.9810, Val R2: -0.0021\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2820\n",
      "Val RMSE: 142065.5254, Val MAE: 85482.5068, Val MSE: 20182613499.4706, Val R2: -0.0254\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2444, Val Loss: 0.2731\n",
      "Val RMSE: 142980.9601, Val MAE: 79243.1497, Val MSE: 20443554963.7544, Val R2: -0.0387\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2452, Val Loss: 0.2655\n",
      "Val RMSE: 141845.1624, Val MAE: 79247.8647, Val MSE: 20120050104.1662, Val R2: -0.0222\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2690\n",
      "Val RMSE: 140430.0913, Val MAE: 81979.8538, Val MSE: 19720610549.4642, Val R2: -0.0019\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2400, Val Loss: 0.2541\n",
      "Val RMSE: 137455.0818, Val MAE: 77018.2241, Val MSE: 18893899506.4208, Val R2: 0.0401\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2245, Val Loss: 0.2307\n",
      "Val RMSE: 131454.2524, Val MAE: 73196.3559, Val MSE: 17280220483.8932, Val R2: 0.1221\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2195, Val Loss: 0.2408\n",
      "Val RMSE: 133774.0754, Val MAE: 72562.5655, Val MSE: 17895503243.1374, Val R2: 0.0908\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2128, Val Loss: 0.2290\n",
      "Val RMSE: 130143.1126, Val MAE: 72835.7249, Val MSE: 16937229763.6508, Val R2: 0.1395\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2144, Val Loss: 0.2554\n",
      "Val RMSE: 136401.9695, Val MAE: 72989.5703, Val MSE: 18605497289.1248, Val R2: 0.0547\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2175, Val Loss: 0.2341\n",
      "Val RMSE: 130251.6721, Val MAE: 74813.3021, Val MSE: 16965498087.8646, Val R2: 0.1380\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2070, Val Loss: 0.2279\n",
      "Val RMSE: 129785.1961, Val MAE: 73046.1513, Val MSE: 16844197123.0726, Val R2: 0.1442\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2039, Val Loss: 0.2288\n",
      "Val RMSE: 129322.3214, Val MAE: 72592.2953, Val MSE: 16724262819.1867, Val R2: 0.1503\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2000, Val Loss: 0.2291\n",
      "Val RMSE: 129510.0882, Val MAE: 70997.0358, Val MSE: 16772862941.5539, Val R2: 0.1478\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1924, Val Loss: 0.2306\n",
      "Val RMSE: 127157.1195, Val MAE: 72354.4340, Val MSE: 16168933045.6844, Val R2: 0.1785\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1884, Val Loss: 0.2063\n",
      "Val RMSE: 117073.4479, Val MAE: 70576.0595, Val MSE: 13706192214.1428, Val R2: 0.3036\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1869, Val Loss: 0.2210\n",
      "Val RMSE: 126222.2827, Val MAE: 69025.5137, Val MSE: 15932064656.1101, Val R2: 0.1906\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1833, Val Loss: 0.1892\n",
      "Val RMSE: 106671.4237, Val MAE: 64410.2570, Val MSE: 11378792639.2027, Val R2: 0.4219\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1760, Val Loss: 0.1987\n",
      "Val RMSE: 110319.9259, Val MAE: 65499.5962, Val MSE: 12170486055.2659, Val R2: 0.3817\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1672, Val Loss: 0.1815\n",
      "Val RMSE: 104162.6639, Val MAE: 61510.8735, Val MSE: 10849860544.9276, Val R2: 0.4488\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1647, Val Loss: 0.1781\n",
      "Val RMSE: 102821.2027, Val MAE: 61697.1428, Val MSE: 10572199724.9631, Val R2: 0.4629\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1593, Val Loss: 0.1670\n",
      "Val RMSE: 99897.3594, Val MAE: 58111.5735, Val MSE: 9979482424.6010, Val R2: 0.4930\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1576, Val Loss: 0.1643\n",
      "Val RMSE: 99974.4279, Val MAE: 57358.2498, Val MSE: 9994886243.4472, Val R2: 0.4922\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1547, Val Loss: 0.1588\n",
      "Val RMSE: 98531.8325, Val MAE: 56526.2795, Val MSE: 9708522014.3855, Val R2: 0.5067\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1534, Val Loss: 0.1555\n",
      "Val RMSE: 96635.4821, Val MAE: 56232.2953, Val MSE: 9338416406.3213, Val R2: 0.5255\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1521, Val Loss: 0.1605\n",
      "Val RMSE: 98753.7557, Val MAE: 56745.9610, Val MSE: 9752304268.6602, Val R2: 0.5045\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1500, Val Loss: 0.1517\n",
      "Val RMSE: 95918.0605, Val MAE: 53746.8399, Val MSE: 9200274333.6362, Val R2: 0.5326\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1462, Val Loss: 0.1573\n",
      "Val RMSE: 96934.0981, Val MAE: 56608.7690, Val MSE: 9396219382.4556, Val R2: 0.5226\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1437, Val Loss: 0.1491\n",
      "Val RMSE: 95074.5857, Val MAE: 53837.9839, Val MSE: 9039176841.4591, Val R2: 0.5408\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1411, Val Loss: 0.1445\n",
      "Val RMSE: 93147.7214, Val MAE: 51898.3971, Val MSE: 8676498002.0297, Val R2: 0.5592\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1375, Val Loss: 0.1429\n",
      "Val RMSE: 93057.9170, Val MAE: 51139.1819, Val MSE: 8659775918.4391, Val R2: 0.5600\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1368, Val Loss: 0.1417\n",
      "Val RMSE: 92776.8775, Val MAE: 51558.2453, Val MSE: 8607548990.2041, Val R2: 0.5627\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1340, Val Loss: 0.1328\n",
      "Val RMSE: 89707.9354, Val MAE: 50156.9323, Val MSE: 8047513667.7030, Val R2: 0.5911\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1305, Val Loss: 0.1358\n",
      "Val RMSE: 91399.5012, Val MAE: 47907.1725, Val MSE: 8353868825.4050, Val R2: 0.5756\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1316, Val Loss: 0.1391\n",
      "Val RMSE: 91339.1313, Val MAE: 52290.3176, Val MSE: 8342836903.9742, Val R2: 0.5761\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1191, Val Loss: 0.1398\n",
      "Val RMSE: 90505.8709, Val MAE: 50214.0727, Val MSE: 8191312667.7265, Val R2: 0.5838\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1293\n",
      "Val RMSE: 90608.1046, Val MAE: 45771.1592, Val MSE: 8209828620.9293, Val R2: 0.5829\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1228\n",
      "Val RMSE: 87909.2506, Val MAE: 45676.4215, Val MSE: 7728036332.3275, Val R2: 0.6074\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1098, Val Loss: 0.1256\n",
      "Val RMSE: 88348.9391, Val MAE: 45849.8486, Val MSE: 7805535033.2307, Val R2: 0.6034\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1050, Val Loss: 0.1289\n",
      "Val RMSE: 89154.0338, Val MAE: 47439.6218, Val MSE: 7948441738.2842, Val R2: 0.5962\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1064, Val Loss: 0.1284\n",
      "Val RMSE: 88877.5841, Val MAE: 45171.3437, Val MSE: 7899224954.9227, Val R2: 0.5987\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1386\n",
      "Val RMSE: 92327.5468, Val MAE: 48042.4570, Val MSE: 8524375898.6590, Val R2: 0.5669\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1006, Val Loss: 0.1302\n",
      "Val RMSE: 90325.2768, Val MAE: 46540.1666, Val MSE: 8158655625.6260, Val R2: 0.5855\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1300\n",
      "Val RMSE: 88222.4456, Val MAE: 49217.8491, Val MSE: 7783199909.0842, Val R2: 0.6046\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0950, Val Loss: 0.1308\n",
      "Val RMSE: 89823.3392, Val MAE: 45413.1846, Val MSE: 8068232267.7068, Val R2: 0.5901\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0913, Val Loss: 0.1308\n",
      "Val RMSE: 89248.0584, Val MAE: 47753.8639, Val MSE: 7965215923.5085, Val R2: 0.5953\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1324\n",
      "Val RMSE: 89361.9330, Val MAE: 50303.2693, Val MSE: 7985555070.2385, Val R2: 0.5943\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0893, Val Loss: 0.1227\n",
      "Val RMSE: 87651.9123, Val MAE: 45276.9548, Val MSE: 7682857726.0723, Val R2: 0.6097\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0850, Val Loss: 0.1234\n",
      "Val RMSE: 86429.0781, Val MAE: 45846.9852, Val MSE: 7469985549.5114, Val R2: 0.6205\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1267\n",
      "Val RMSE: 86384.8510, Val MAE: 47001.2991, Val MSE: 7462342489.6584, Val R2: 0.6209\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.1235\n",
      "Val RMSE: 83895.9922, Val MAE: 47745.3202, Val MSE: 7038537503.5129, Val R2: 0.6424\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0770, Val Loss: 0.1250\n",
      "Val RMSE: 83818.9582, Val MAE: 47285.3171, Val MSE: 7025617761.1204, Val R2: 0.6431\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0751, Val Loss: 0.1284\n",
      "Val RMSE: 82398.3334, Val MAE: 45914.6276, Val MSE: 6789485351.9199, Val R2: 0.6551\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1333\n",
      "Val RMSE: 85364.4992, Val MAE: 47366.0228, Val MSE: 7287097724.8904, Val R2: 0.6298\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1237\n",
      "Val RMSE: 80805.8381, Val MAE: 44614.8713, Val MSE: 6529583477.4606, Val R2: 0.6683\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0704, Val Loss: 0.1137\n",
      "Val RMSE: 77600.5564, Val MAE: 44223.6597, Val MSE: 6021846345.8380, Val R2: 0.6941\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1176\n",
      "Val RMSE: 78223.7609, Val MAE: 44998.3287, Val MSE: 6118956763.7479, Val R2: 0.6891\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1478\n",
      "Val RMSE: 85302.6697, Val MAE: 52533.9931, Val MSE: 7276545457.2108, Val R2: 0.6303\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1136\n",
      "Val RMSE: 75562.1816, Val MAE: 43430.1715, Val MSE: 5709643289.7350, Val R2: 0.7099\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1218\n",
      "Val RMSE: 76752.6571, Val MAE: 44647.4845, Val MSE: 5890970368.3135, Val R2: 0.7007\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0639, Val Loss: 0.1234\n",
      "Val RMSE: 78124.7320, Val MAE: 45226.9451, Val MSE: 6103473752.9334, Val R2: 0.6899\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1195\n",
      "Val RMSE: 74095.2122, Val MAE: 43785.0298, Val MSE: 5490100472.1673, Val R2: 0.7211\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0623, Val Loss: 0.1082\n",
      "Val RMSE: 71951.1748, Val MAE: 42629.1553, Val MSE: 5176971548.5791, Val R2: 0.7370\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1154\n",
      "Val RMSE: 75454.8688, Val MAE: 43729.4244, Val MSE: 5693437220.6682, Val R2: 0.7107\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1295\n",
      "Val RMSE: 77843.3277, Val MAE: 43760.1818, Val MSE: 6059583669.1953, Val R2: 0.6921\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1308\n",
      "Val RMSE: 80586.5054, Val MAE: 46925.5665, Val MSE: 6494184860.2222, Val R2: 0.6701\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1152\n",
      "Val RMSE: 74630.0854, Val MAE: 41619.2814, Val MSE: 5569649643.7474, Val R2: 0.7170\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0575, Val Loss: 0.1207\n",
      "Val RMSE: 75808.1855, Val MAE: 45587.9208, Val MSE: 5746880994.4135, Val R2: 0.7080\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1275\n",
      "Val RMSE: 78102.8555, Val MAE: 47297.6109, Val MSE: 6100056032.5876, Val R2: 0.6901\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0551, Val Loss: 0.1180\n",
      "Val RMSE: 76201.4442, Val MAE: 45895.0652, Val MSE: 5806660096.2101, Val R2: 0.7050\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1206\n",
      "Val RMSE: 74999.3569, Val MAE: 44586.5160, Val MSE: 5624903528.2628, Val R2: 0.7142\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1291\n",
      "Val RMSE: 80545.1523, Val MAE: 46056.7103, Val MSE: 6487521561.6667, Val R2: 0.6704\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1326\n",
      "Val RMSE: 80232.3790, Val MAE: 46712.4102, Val MSE: 6437234639.2046, Val R2: 0.6729\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0542, Val Loss: 0.1241\n",
      "Val RMSE: 78302.1063, Val MAE: 47240.0818, Val MSE: 6131219844.5351, Val R2: 0.6885\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1217\n",
      "Val RMSE: 76301.5405, Val MAE: 45341.9242, Val MSE: 5821925089.1340, Val R2: 0.7042\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1195\n",
      "Val RMSE: 77437.1438, Val MAE: 44136.9205, Val MSE: 5996511240.6492, Val R2: 0.6953\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1209\n",
      "Val RMSE: 77457.8180, Val MAE: 45374.0625, Val MSE: 5999713575.2180, Val R2: 0.6952\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1354\n",
      "Val RMSE: 83170.9929, Val MAE: 48225.7150, Val MSE: 6917414066.2309, Val R2: 0.6486\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1247\n",
      "Val RMSE: 79995.2555, Val MAE: 46202.7584, Val MSE: 6399240895.0206, Val R2: 0.6749\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.1200\n",
      "Val RMSE: 76909.3966, Val MAE: 44601.8234, Val MSE: 5915055288.5211, Val R2: 0.6995\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1108\n",
      "Val RMSE: 73846.1136, Val MAE: 41454.7216, Val MSE: 5453248488.5069, Val R2: 0.7229\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1066\n",
      "Val RMSE: 73458.4239, Val MAE: 41104.1755, Val MSE: 5396140042.8030, Val R2: 0.7258\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1214\n",
      "Val RMSE: 75198.5128, Val MAE: 43503.9859, Val MSE: 5654816327.7689, Val R2: 0.7127\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1278\n",
      "Val RMSE: 77782.8630, Val MAE: 47665.7279, Val MSE: 6050173769.5105, Val R2: 0.6926\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.1327\n",
      "Val RMSE: 81008.9989, Val MAE: 47534.7948, Val MSE: 6562457894.8810, Val R2: 0.6666\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0483, Val Loss: 0.1359\n",
      "Val RMSE: 81024.6857, Val MAE: 48850.9717, Val MSE: 6564999693.1712, Val R2: 0.6665\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0464, Val Loss: 0.1171\n",
      "Val RMSE: 76584.2284, Val MAE: 45405.0668, Val MSE: 5865144041.4802, Val R2: 0.7020\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0457, Val Loss: 0.1206\n",
      "Val RMSE: 78183.6040, Val MAE: 45240.6346, Val MSE: 6112675930.4328, Val R2: 0.6894\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 75032.7034, Test MAE: 41981.3131, Test MSE: 5629906572.1455, Test R2: 0.6391\n",
      "Inference Time: 3.3886249248798074e-05 seconds per sample\n",
      "\n",
      "Iteration 90 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3743, Val Loss: 0.2797\n",
      "Val RMSE: 143141.8603, Val MAE: 81765.7345, Val MSE: 20489592169.7613, Val R2: -0.0410\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2741, Val Loss: 0.2755\n",
      "Val RMSE: 141235.9093, Val MAE: 83978.8934, Val MSE: 19947582063.1551, Val R2: -0.0135\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2697, Val Loss: 0.2800\n",
      "Val RMSE: 143295.1016, Val MAE: 81529.5983, Val MSE: 20533486133.1570, Val R2: -0.0432\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2673, Val Loss: 0.2796\n",
      "Val RMSE: 143131.4983, Val MAE: 81649.0988, Val MSE: 20486625813.6283, Val R2: -0.0408\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2668, Val Loss: 0.2789\n",
      "Val RMSE: 143025.8216, Val MAE: 81879.1891, Val MSE: 20456385654.7110, Val R2: -0.0393\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2753\n",
      "Val RMSE: 141936.2293, Val MAE: 83219.3929, Val MSE: 20145893173.7757, Val R2: -0.0235\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2606, Val Loss: 0.2747\n",
      "Val RMSE: 142373.6572, Val MAE: 82325.2882, Val MSE: 20270258276.1003, Val R2: -0.0299\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2807\n",
      "Val RMSE: 143907.3491, Val MAE: 80728.5564, Val MSE: 20709325125.9899, Val R2: -0.0522\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2703\n",
      "Val RMSE: 140919.3744, Val MAE: 82140.8985, Val MSE: 19858270089.9421, Val R2: -0.0089\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2576, Val Loss: 0.2717\n",
      "Val RMSE: 143121.3414, Val MAE: 79002.6629, Val MSE: 20483718373.4585, Val R2: -0.0407\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2526, Val Loss: 0.2754\n",
      "Val RMSE: 141761.8634, Val MAE: 84156.1154, Val MSE: 20096425911.1148, Val R2: -0.0210\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2693\n",
      "Val RMSE: 141105.8860, Val MAE: 81198.6311, Val MSE: 19910871073.8218, Val R2: -0.0116\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2693\n",
      "Val RMSE: 142177.4048, Val MAE: 78633.9212, Val MSE: 20214414440.9921, Val R2: -0.0270\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2452, Val Loss: 0.2643\n",
      "Val RMSE: 141791.0108, Val MAE: 78562.8961, Val MSE: 20104690755.5920, Val R2: -0.0214\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2446, Val Loss: 0.2574\n",
      "Val RMSE: 136599.2976, Val MAE: 79574.3442, Val MSE: 18659368096.6700, Val R2: 0.0520\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2307, Val Loss: 0.2387\n",
      "Val RMSE: 134355.9165, Val MAE: 71722.2184, Val MSE: 18051512296.5854, Val R2: 0.0829\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2254, Val Loss: 0.2380\n",
      "Val RMSE: 132721.8483, Val MAE: 74853.8585, Val MSE: 17615089004.3057, Val R2: 0.1050\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2174, Val Loss: 0.2466\n",
      "Val RMSE: 135463.7510, Val MAE: 76320.5104, Val MSE: 18350427823.3560, Val R2: 0.0677\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2211, Val Loss: 0.2474\n",
      "Val RMSE: 133148.3998, Val MAE: 80660.4573, Val MSE: 17728496364.1667, Val R2: 0.0993\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2162, Val Loss: 0.2314\n",
      "Val RMSE: 131893.1661, Val MAE: 70036.5696, Val MSE: 17395807258.3156, Val R2: 0.1162\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2163, Val Loss: 0.2314\n",
      "Val RMSE: 131666.4415, Val MAE: 71251.0348, Val MSE: 17336051813.5527, Val R2: 0.1192\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2109, Val Loss: 0.2306\n",
      "Val RMSE: 128056.2219, Val MAE: 76470.6112, Val MSE: 16398395970.8041, Val R2: 0.1669\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2063, Val Loss: 0.2223\n",
      "Val RMSE: 127207.2929, Val MAE: 71047.4018, Val MSE: 16181695356.1773, Val R2: 0.1779\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1992, Val Loss: 0.2226\n",
      "Val RMSE: 127115.8844, Val MAE: 71028.0808, Val MSE: 16158448072.6618, Val R2: 0.1790\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1978, Val Loss: 0.2269\n",
      "Val RMSE: 128066.3352, Val MAE: 71335.7816, Val MSE: 16400986211.5024, Val R2: 0.1667\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1925, Val Loss: 0.2264\n",
      "Val RMSE: 127844.8523, Val MAE: 70580.2681, Val MSE: 16344306249.8552, Val R2: 0.1696\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1902, Val Loss: 0.2228\n",
      "Val RMSE: 126834.5819, Val MAE: 69299.2642, Val MSE: 16087011175.7429, Val R2: 0.1827\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1855, Val Loss: 0.2061\n",
      "Val RMSE: 116546.1722, Val MAE: 67358.2350, Val MSE: 13583010261.8940, Val R2: 0.3099\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1812, Val Loss: 0.2073\n",
      "Val RMSE: 113545.9197, Val MAE: 66258.3896, Val MSE: 12892675873.8492, Val R2: 0.3450\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1746, Val Loss: 0.1872\n",
      "Val RMSE: 106712.5179, Val MAE: 65097.1889, Val MSE: 11387561467.3021, Val R2: 0.4214\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1740, Val Loss: 0.2010\n",
      "Val RMSE: 112163.9732, Val MAE: 65041.6509, Val MSE: 12580756879.3598, Val R2: 0.3608\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1752, Val Loss: 0.1984\n",
      "Val RMSE: 109768.9085, Val MAE: 64841.4686, Val MSE: 12049213274.1468, Val R2: 0.3878\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1669, Val Loss: 0.1806\n",
      "Val RMSE: 101822.4594, Val MAE: 61881.7614, Val MSE: 10367813247.8368, Val R2: 0.4732\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1632, Val Loss: 0.1863\n",
      "Val RMSE: 104423.7254, Val MAE: 63240.8459, Val MSE: 10904314428.9905, Val R2: 0.4460\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1573, Val Loss: 0.1769\n",
      "Val RMSE: 101647.7695, Val MAE: 60253.4860, Val MSE: 10332269038.9523, Val R2: 0.4751\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1555, Val Loss: 0.1900\n",
      "Val RMSE: 104820.9029, Val MAE: 60771.3858, Val MSE: 10987421682.9881, Val R2: 0.4418\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1569, Val Loss: 0.1640\n",
      "Val RMSE: 97607.4508, Val MAE: 59267.3908, Val MSE: 9527214450.0365, Val R2: 0.5160\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1516, Val Loss: 0.1654\n",
      "Val RMSE: 99697.7389, Val MAE: 58483.7894, Val MSE: 9939639144.4435, Val R2: 0.4950\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1469, Val Loss: 0.1617\n",
      "Val RMSE: 97530.5600, Val MAE: 57915.0194, Val MSE: 9512210132.0176, Val R2: 0.5167\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1495, Val Loss: 0.1554\n",
      "Val RMSE: 96507.4205, Val MAE: 55327.7834, Val MSE: 9313682213.8709, Val R2: 0.5268\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1474, Val Loss: 0.1604\n",
      "Val RMSE: 98193.6321, Val MAE: 56535.1751, Val MSE: 9641989388.3605, Val R2: 0.5101\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1416, Val Loss: 0.1523\n",
      "Val RMSE: 96272.1063, Val MAE: 55197.2898, Val MSE: 9268318445.4244, Val R2: 0.5291\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1407, Val Loss: 0.1579\n",
      "Val RMSE: 96536.8814, Val MAE: 56052.9836, Val MSE: 9319369476.4036, Val R2: 0.5265\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1474\n",
      "Val RMSE: 93649.9151, Val MAE: 53834.8024, Val MSE: 8770306590.5130, Val R2: 0.5544\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1426, Val Loss: 0.1397\n",
      "Val RMSE: 93110.5973, Val MAE: 50497.4380, Val MSE: 8669583320.3147, Val R2: 0.5595\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1370, Val Loss: 0.1363\n",
      "Val RMSE: 93208.9243, Val MAE: 50166.1773, Val MSE: 8687903573.0411, Val R2: 0.5586\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1330, Val Loss: 0.1313\n",
      "Val RMSE: 93474.6097, Val MAE: 47645.8200, Val MSE: 8737502663.8980, Val R2: 0.5561\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1298, Val Loss: 0.1362\n",
      "Val RMSE: 92966.9530, Val MAE: 50394.1484, Val MSE: 8642854357.6368, Val R2: 0.5609\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1259, Val Loss: 0.1277\n",
      "Val RMSE: 91897.1961, Val MAE: 48088.5998, Val MSE: 8445094650.6842, Val R2: 0.5709\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1231, Val Loss: 0.1223\n",
      "Val RMSE: 90169.5957, Val MAE: 45936.6028, Val MSE: 8130555988.2089, Val R2: 0.5869\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1189, Val Loss: 0.1120\n",
      "Val RMSE: 87049.0491, Val MAE: 44417.8375, Val MSE: 7577536949.0798, Val R2: 0.6150\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1165, Val Loss: 0.1183\n",
      "Val RMSE: 88300.2752, Val MAE: 47105.1825, Val MSE: 7796938592.3102, Val R2: 0.6039\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1096\n",
      "Val RMSE: 85592.2244, Val MAE: 44303.5174, Val MSE: 7326028872.0334, Val R2: 0.6278\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1042, Val Loss: 0.1107\n",
      "Val RMSE: 87544.7330, Val MAE: 42490.3476, Val MSE: 7664080279.7766, Val R2: 0.6106\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1187\n",
      "Val RMSE: 89332.5228, Val MAE: 44725.1324, Val MSE: 7980299625.8087, Val R2: 0.5946\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1108\n",
      "Val RMSE: 87527.7203, Val MAE: 41973.3823, Val MSE: 7661101819.9375, Val R2: 0.6108\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1097\n",
      "Val RMSE: 86739.7760, Val MAE: 41127.1758, Val MSE: 7523788745.0009, Val R2: 0.6177\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1125\n",
      "Val RMSE: 89141.5623, Val MAE: 41461.4062, Val MSE: 7946218122.3707, Val R2: 0.5963\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0904, Val Loss: 0.1156\n",
      "Val RMSE: 87575.7722, Val MAE: 44859.0688, Val MSE: 7669515877.9113, Val R2: 0.6103\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0887, Val Loss: 0.1309\n",
      "Val RMSE: 91525.2375, Val MAE: 47272.3740, Val MSE: 8376869095.0564, Val R2: 0.5744\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0875, Val Loss: 0.1125\n",
      "Val RMSE: 86414.3998, Val MAE: 40875.8419, Val MSE: 7467448499.9513, Val R2: 0.6206\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0865, Val Loss: 0.1222\n",
      "Val RMSE: 88955.1857, Val MAE: 48007.7132, Val MSE: 7913025057.3371, Val R2: 0.5980\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1087\n",
      "Val RMSE: 82929.0197, Val MAE: 38643.4864, Val MSE: 6877222315.9014, Val R2: 0.6506\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1080\n",
      "Val RMSE: 78281.6216, Val MAE: 40524.6212, Val MSE: 6128012276.7944, Val R2: 0.6887\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1143\n",
      "Val RMSE: 84861.7853, Val MAE: 43997.1009, Val MSE: 7201522604.1413, Val R2: 0.6341\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.0969\n",
      "Val RMSE: 75235.1645, Val MAE: 38495.8466, Val MSE: 5660329978.4683, Val R2: 0.7124\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1093\n",
      "Val RMSE: 78978.9175, Val MAE: 41293.5511, Val MSE: 6237669403.7757, Val R2: 0.6831\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1013\n",
      "Val RMSE: 74310.9634, Val MAE: 39910.2949, Val MSE: 5522119285.4621, Val R2: 0.7194\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1317\n",
      "Val RMSE: 86453.2944, Val MAE: 46299.5419, Val MSE: 7474172114.0242, Val R2: 0.6203\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0717, Val Loss: 0.0963\n",
      "Val RMSE: 72935.3442, Val MAE: 37915.8610, Val MSE: 5319564440.8170, Val R2: 0.7297\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.0940\n",
      "Val RMSE: 71440.2665, Val MAE: 37190.4548, Val MSE: 5103711678.5715, Val R2: 0.7407\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0679, Val Loss: 0.1128\n",
      "Val RMSE: 76210.1682, Val MAE: 42192.7194, Val MSE: 5807989734.9576, Val R2: 0.7049\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0703, Val Loss: 0.1143\n",
      "Val RMSE: 78942.1852, Val MAE: 40827.9131, Val MSE: 6231868605.7264, Val R2: 0.6834\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0663, Val Loss: 0.1038\n",
      "Val RMSE: 75679.7274, Val MAE: 40266.8035, Val MSE: 5727421137.1022, Val R2: 0.7090\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0640, Val Loss: 0.0970\n",
      "Val RMSE: 72124.7359, Val MAE: 36492.0731, Val MSE: 5201977531.9353, Val R2: 0.7357\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0625, Val Loss: 0.0974\n",
      "Val RMSE: 71444.7199, Val MAE: 38025.2995, Val MSE: 5104348002.8262, Val R2: 0.7407\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.0935\n",
      "Val RMSE: 70220.6043, Val MAE: 35531.4771, Val MSE: 4930933266.3201, Val R2: 0.7495\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1229\n",
      "Val RMSE: 80176.7834, Val MAE: 42407.1717, Val MSE: 6428316590.2880, Val R2: 0.6734\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1061\n",
      "Val RMSE: 74437.4532, Val MAE: 39497.2886, Val MSE: 5540934433.8756, Val R2: 0.7185\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0593, Val Loss: 0.0992\n",
      "Val RMSE: 72541.0170, Val MAE: 38006.0136, Val MSE: 5262199140.3874, Val R2: 0.7326\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0584, Val Loss: 0.1214\n",
      "Val RMSE: 78267.1931, Val MAE: 45202.4357, Val MSE: 6125753514.1229, Val R2: 0.6888\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1119\n",
      "Val RMSE: 76709.1650, Val MAE: 39515.1125, Val MSE: 5884295996.8683, Val R2: 0.7010\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1029\n",
      "Val RMSE: 73331.8420, Val MAE: 38774.1185, Val MSE: 5377559057.5402, Val R2: 0.7268\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.0888\n",
      "Val RMSE: 67599.8226, Val MAE: 35021.5114, Val MSE: 4569736013.8816, Val R2: 0.7678\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1088\n",
      "Val RMSE: 75327.7911, Val MAE: 39476.4116, Val MSE: 5674276110.4106, Val R2: 0.7117\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.0923\n",
      "Val RMSE: 69695.1646, Val MAE: 35475.1055, Val MSE: 4857415968.1385, Val R2: 0.7532\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1112\n",
      "Val RMSE: 75956.2831, Val MAE: 39502.6227, Val MSE: 5769356941.7763, Val R2: 0.7069\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.0930\n",
      "Val RMSE: 69648.8821, Val MAE: 36008.1475, Val MSE: 4850966779.7103, Val R2: 0.7535\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0496, Val Loss: 0.0922\n",
      "Val RMSE: 69563.6791, Val MAE: 36004.4804, Val MSE: 4839105455.1588, Val R2: 0.7541\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0488, Val Loss: 0.0897\n",
      "Val RMSE: 67303.9013, Val MAE: 35565.7234, Val MSE: 4529815129.6149, Val R2: 0.7699\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1240\n",
      "Val RMSE: 83628.3390, Val MAE: 42331.7124, Val MSE: 6993699086.3841, Val R2: 0.6447\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.0901\n",
      "Val RMSE: 68178.0460, Val MAE: 35095.6036, Val MSE: 4648245957.6555, Val R2: 0.7638\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.0965\n",
      "Val RMSE: 69831.2697, Val MAE: 37562.5310, Val MSE: 4876406232.8371, Val R2: 0.7522\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.0993\n",
      "Val RMSE: 72014.8488, Val MAE: 37588.6621, Val MSE: 5186138451.8656, Val R2: 0.7365\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0446, Val Loss: 0.1003\n",
      "Val RMSE: 71701.7853, Val MAE: 39065.8542, Val MSE: 5141146016.1997, Val R2: 0.7388\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.0971\n",
      "Val RMSE: 71618.7466, Val MAE: 36919.1789, Val MSE: 5129244865.7214, Val R2: 0.7394\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0437, Val Loss: 0.0874\n",
      "Val RMSE: 66977.5021, Val MAE: 33871.7300, Val MSE: 4485985793.3547, Val R2: 0.7721\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.0864\n",
      "Val RMSE: 67871.2103, Val MAE: 32838.1078, Val MSE: 4606501190.3877, Val R2: 0.7660\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0428, Val Loss: 0.0930\n",
      "Val RMSE: 69369.7661, Val MAE: 37151.5086, Val MSE: 4812164443.9734, Val R2: 0.7555\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0439, Val Loss: 0.0888\n",
      "Val RMSE: 67468.9030, Val MAE: 34877.4822, Val MSE: 4552052871.0681, Val R2: 0.7687\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74404.9582, Test MAE: 34609.8849, Test MSE: 5536097797.3495, Test R2: 0.6451\n",
      "Inference Time: 4.0793712322528545e-05 seconds per sample\n",
      "\n",
      "Iteration 91 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3550, Val Loss: 0.2882\n",
      "Val RMSE: 144795.9865, Val MAE: 81226.5141, Val MSE: 20965877694.9110, Val R2: -0.0652\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2768, Val Loss: 0.2778\n",
      "Val RMSE: 142649.3860, Val MAE: 82101.2500, Val MSE: 20348847334.0182, Val R2: -0.0338\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2715, Val Loss: 0.2768\n",
      "Val RMSE: 142478.1210, Val MAE: 82023.0849, Val MSE: 20300014958.1832, Val R2: -0.0314\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2653, Val Loss: 0.2757\n",
      "Val RMSE: 142520.7132, Val MAE: 81700.7052, Val MSE: 20312153677.4538, Val R2: -0.0320\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2732\n",
      "Val RMSE: 142151.8534, Val MAE: 81778.1493, Val MSE: 20207149421.1954, Val R2: -0.0267\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2584, Val Loss: 0.2865\n",
      "Val RMSE: 145640.1893, Val MAE: 79841.9204, Val MSE: 21211064726.3674, Val R2: -0.0777\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2748\n",
      "Val RMSE: 142431.1517, Val MAE: 80446.9691, Val MSE: 20286632976.5727, Val R2: -0.0307\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2582, Val Loss: 0.2682\n",
      "Val RMSE: 142060.2306, Val MAE: 79575.6492, Val MSE: 20181109122.8967, Val R2: -0.0253\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2815\n",
      "Val RMSE: 146293.4967, Val MAE: 77520.1652, Val MSE: 21401787168.1165, Val R2: -0.0873\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2657\n",
      "Val RMSE: 141990.2226, Val MAE: 78510.4938, Val MSE: 20161223325.3683, Val R2: -0.0243\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2503, Val Loss: 0.2754\n",
      "Val RMSE: 143056.4610, Val MAE: 79067.9514, Val MSE: 20465151024.4886, Val R2: -0.0398\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2511, Val Loss: 0.2649\n",
      "Val RMSE: 141532.9882, Val MAE: 78786.1287, Val MSE: 20031586753.1406, Val R2: -0.0177\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2473, Val Loss: 0.2746\n",
      "Val RMSE: 139758.1318, Val MAE: 85238.4555, Val MSE: 19532335414.3796, Val R2: 0.0076\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2465, Val Loss: 0.2686\n",
      "Val RMSE: 139807.9254, Val MAE: 82321.6006, Val MSE: 19546256017.5471, Val R2: 0.0069\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2440, Val Loss: 0.2645\n",
      "Val RMSE: 140529.8959, Val MAE: 80207.3380, Val MSE: 19748651654.7285, Val R2: -0.0034\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2436, Val Loss: 0.2589\n",
      "Val RMSE: 139127.2268, Val MAE: 78634.4761, Val MSE: 19356385235.4587, Val R2: 0.0166\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2335, Val Loss: 0.2510\n",
      "Val RMSE: 136652.3989, Val MAE: 75290.9411, Val MSE: 18673878114.9243, Val R2: 0.0512\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2331, Val Loss: 0.2469\n",
      "Val RMSE: 133061.6732, Val MAE: 77090.8501, Val MSE: 17705408867.1453, Val R2: 0.1005\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2278, Val Loss: 0.2415\n",
      "Val RMSE: 133976.9812, Val MAE: 73088.8677, Val MSE: 17949831482.8806, Val R2: 0.0880\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2213, Val Loss: 0.2330\n",
      "Val RMSE: 131105.5317, Val MAE: 72970.4716, Val MSE: 17188660438.8076, Val R2: 0.1267\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2133, Val Loss: 0.2303\n",
      "Val RMSE: 128996.7271, Val MAE: 74949.7221, Val MSE: 16640155601.5483, Val R2: 0.1546\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2055, Val Loss: 0.2295\n",
      "Val RMSE: 131067.9091, Val MAE: 68882.3452, Val MSE: 17178796795.2086, Val R2: 0.1272\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2219\n",
      "Val RMSE: 129430.5188, Val MAE: 68672.5366, Val MSE: 16752259199.0208, Val R2: 0.1489\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1944, Val Loss: 0.2248\n",
      "Val RMSE: 129433.5770, Val MAE: 69758.7170, Val MSE: 16753050842.9935, Val R2: 0.1488\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1961, Val Loss: 0.2281\n",
      "Val RMSE: 128965.1302, Val MAE: 72519.6258, Val MSE: 16632004812.5418, Val R2: 0.1550\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1912, Val Loss: 0.2323\n",
      "Val RMSE: 131325.6289, Val MAE: 69083.4779, Val MSE: 17246420795.6760, Val R2: 0.1238\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1896, Val Loss: 0.2215\n",
      "Val RMSE: 125527.4121, Val MAE: 70880.1707, Val MSE: 15757131179.4910, Val R2: 0.1994\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2188\n",
      "Val RMSE: 123053.8461, Val MAE: 70774.6391, Val MSE: 15142249042.3413, Val R2: 0.2307\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1780, Val Loss: 0.2016\n",
      "Val RMSE: 112312.5656, Val MAE: 66441.4148, Val MSE: 12614112393.7891, Val R2: 0.3591\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1699, Val Loss: 0.1906\n",
      "Val RMSE: 106714.6810, Val MAE: 65160.2185, Val MSE: 11388023148.5734, Val R2: 0.4214\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1653, Val Loss: 0.1970\n",
      "Val RMSE: 107048.3462, Val MAE: 61623.5455, Val MSE: 11459348419.3523, Val R2: 0.4178\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1640, Val Loss: 0.1654\n",
      "Val RMSE: 98294.1725, Val MAE: 59261.4675, Val MSE: 9661744342.3261, Val R2: 0.5091\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1529, Val Loss: 0.1715\n",
      "Val RMSE: 100336.2872, Val MAE: 59046.8360, Val MSE: 10067370528.7077, Val R2: 0.4885\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1545, Val Loss: 0.1790\n",
      "Val RMSE: 102204.3899, Val MAE: 59025.3742, Val MSE: 10445737312.3514, Val R2: 0.4693\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1507, Val Loss: 0.1651\n",
      "Val RMSE: 99470.4548, Val MAE: 58356.9860, Val MSE: 9894371377.2325, Val R2: 0.4973\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1478, Val Loss: 0.1531\n",
      "Val RMSE: 95403.5092, Val MAE: 56167.9146, Val MSE: 9101829569.9400, Val R2: 0.5376\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1446, Val Loss: 0.1473\n",
      "Val RMSE: 94601.7448, Val MAE: 54930.1629, Val MSE: 8949490110.6758, Val R2: 0.5453\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1422, Val Loss: 0.1482\n",
      "Val RMSE: 93848.7773, Val MAE: 55325.1742, Val MSE: 8807592992.2396, Val R2: 0.5525\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1402, Val Loss: 0.1392\n",
      "Val RMSE: 92298.1915, Val MAE: 52170.0944, Val MSE: 8518956162.7291, Val R2: 0.5672\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1356, Val Loss: 0.1376\n",
      "Val RMSE: 92003.8013, Val MAE: 52356.1494, Val MSE: 8464699457.8048, Val R2: 0.5699\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1375, Val Loss: 0.1586\n",
      "Val RMSE: 94083.7631, Val MAE: 57245.5426, Val MSE: 8851754474.8216, Val R2: 0.5503\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1368, Val Loss: 0.1333\n",
      "Val RMSE: 91693.2296, Val MAE: 50237.2875, Val MSE: 8407648352.1577, Val R2: 0.5728\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1347, Val Loss: 0.1337\n",
      "Val RMSE: 89395.9529, Val MAE: 52989.1153, Val MSE: 7991636391.0425, Val R2: 0.5940\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1267, Val Loss: 0.1517\n",
      "Val RMSE: 93269.9639, Val MAE: 55425.7658, Val MSE: 8699286160.1885, Val R2: 0.5580\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1224, Val Loss: 0.1293\n",
      "Val RMSE: 88643.1957, Val MAE: 51492.3686, Val MSE: 7857616138.4122, Val R2: 0.6008\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1206, Val Loss: 0.1359\n",
      "Val RMSE: 90124.8915, Val MAE: 54562.9261, Val MSE: 8122496059.1673, Val R2: 0.5873\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1159, Val Loss: 0.1439\n",
      "Val RMSE: 92869.6605, Val MAE: 53589.0565, Val MSE: 8624773849.1419, Val R2: 0.5618\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1138, Val Loss: 0.1876\n",
      "Val RMSE: 101047.5593, Val MAE: 62552.1645, Val MSE: 10210609231.8663, Val R2: 0.4812\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1121, Val Loss: 0.1239\n",
      "Val RMSE: 88474.2013, Val MAE: 50660.2556, Val MSE: 7827684289.4404, Val R2: 0.6023\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1087, Val Loss: 0.1288\n",
      "Val RMSE: 90350.8969, Val MAE: 52087.1482, Val MSE: 8163284577.4087, Val R2: 0.5853\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1056, Val Loss: 0.1443\n",
      "Val RMSE: 92563.7894, Val MAE: 55380.1767, Val MSE: 8568055116.8880, Val R2: 0.5647\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1050, Val Loss: 0.2064\n",
      "Val RMSE: 105126.4516, Val MAE: 63221.2988, Val MSE: 11051570824.6062, Val R2: 0.4385\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1046, Val Loss: 0.1432\n",
      "Val RMSE: 92273.7911, Val MAE: 53306.8111, Val MSE: 8514452522.2965, Val R2: 0.5674\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1023, Val Loss: 0.1463\n",
      "Val RMSE: 94132.3549, Val MAE: 54390.1086, Val MSE: 8860900240.3078, Val R2: 0.5498\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1020, Val Loss: 0.1306\n",
      "Val RMSE: 90269.2531, Val MAE: 51528.7106, Val MSE: 8148538052.1608, Val R2: 0.5860\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0999, Val Loss: 0.1328\n",
      "Val RMSE: 92036.0260, Val MAE: 50155.9518, Val MSE: 8470630081.3217, Val R2: 0.5696\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0969, Val Loss: 0.1255\n",
      "Val RMSE: 89373.4397, Val MAE: 49189.4802, Val MSE: 7987611732.3248, Val R2: 0.5942\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0991, Val Loss: 0.1360\n",
      "Val RMSE: 91200.7383, Val MAE: 54392.5452, Val MSE: 8317574664.9921, Val R2: 0.5774\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0951, Val Loss: 0.1303\n",
      "Val RMSE: 90594.2819, Val MAE: 50452.3792, Val MSE: 8207323916.8602, Val R2: 0.5830\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0929, Val Loss: 0.1699\n",
      "Val RMSE: 98105.7775, Val MAE: 60195.5917, Val MSE: 9624743576.2674, Val R2: 0.5110\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0933, Val Loss: 0.1326\n",
      "Val RMSE: 91421.1224, Val MAE: 49330.7808, Val MSE: 8357821622.9204, Val R2: 0.5754\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1828\n",
      "Val RMSE: 100866.1426, Val MAE: 59636.6547, Val MSE: 10173978726.4518, Val R2: 0.4831\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0878, Val Loss: 0.1470\n",
      "Val RMSE: 91869.8857, Val MAE: 53876.1102, Val MSE: 8440075890.6536, Val R2: 0.5712\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1395\n",
      "Val RMSE: 91066.6755, Val MAE: 53294.4016, Val MSE: 8293139393.6441, Val R2: 0.5787\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0856, Val Loss: 0.1452\n",
      "Val RMSE: 91884.2251, Val MAE: 54838.2235, Val MSE: 8442710828.7711, Val R2: 0.5711\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1235\n",
      "Val RMSE: 85129.1584, Val MAE: 47619.0349, Val MSE: 7246973616.4597, Val R2: 0.6318\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0811, Val Loss: 0.1238\n",
      "Val RMSE: 85389.2307, Val MAE: 47327.7436, Val MSE: 7291320713.6719, Val R2: 0.6296\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0808, Val Loss: 0.1207\n",
      "Val RMSE: 81387.2938, Val MAE: 48426.2866, Val MSE: 6623891586.4557, Val R2: 0.6635\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1344\n",
      "Val RMSE: 87788.2282, Val MAE: 51842.9176, Val MSE: 7706773009.0757, Val R2: 0.6084\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0782, Val Loss: 0.1248\n",
      "Val RMSE: 84128.1366, Val MAE: 47764.9674, Val MSE: 7077543372.9924, Val R2: 0.6404\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1356\n",
      "Val RMSE: 82758.2453, Val MAE: 50234.0712, Val MSE: 6848927163.5329, Val R2: 0.6520\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0733, Val Loss: 0.1500\n",
      "Val RMSE: 87829.3514, Val MAE: 54757.2559, Val MSE: 7713994963.6780, Val R2: 0.6081\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.2028\n",
      "Val RMSE: 99851.3613, Val MAE: 61904.5996, Val MSE: 9970294347.6747, Val R2: 0.4934\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1222\n",
      "Val RMSE: 77874.9268, Val MAE: 47920.9943, Val MSE: 6064504224.2045, Val R2: 0.6919\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1663\n",
      "Val RMSE: 87392.8543, Val MAE: 55977.2909, Val MSE: 7637510986.1106, Val R2: 0.6120\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1930\n",
      "Val RMSE: 91649.5362, Val MAE: 60292.7626, Val MSE: 8399637484.2326, Val R2: 0.5732\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0669, Val Loss: 0.1149\n",
      "Val RMSE: 75360.1099, Val MAE: 45017.0458, Val MSE: 5679146166.8103, Val R2: 0.7115\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0650, Val Loss: 0.1136\n",
      "Val RMSE: 74986.1048, Val MAE: 43671.7910, Val MSE: 5622915908.1375, Val R2: 0.7143\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0671, Val Loss: 0.1680\n",
      "Val RMSE: 86020.1011, Val MAE: 54794.9420, Val MSE: 7399457797.9009, Val R2: 0.6241\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1483\n",
      "Val RMSE: 80661.7653, Val MAE: 51159.2467, Val MSE: 6506320386.8627, Val R2: 0.6694\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0618, Val Loss: 0.1059\n",
      "Val RMSE: 72884.2324, Val MAE: 41088.4199, Val MSE: 5312111328.3928, Val R2: 0.7301\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0609, Val Loss: 0.1225\n",
      "Val RMSE: 77037.6382, Val MAE: 48040.3908, Val MSE: 5934797699.0682, Val R2: 0.6985\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0573, Val Loss: 0.1577\n",
      "Val RMSE: 84196.7969, Val MAE: 54484.6393, Val MSE: 7089100616.0280, Val R2: 0.6398\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1422\n",
      "Val RMSE: 80151.9853, Val MAE: 48812.0492, Val MSE: 6424340752.0413, Val R2: 0.6736\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1119\n",
      "Val RMSE: 72573.7212, Val MAE: 45144.0249, Val MSE: 5266945004.1652, Val R2: 0.7324\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1305\n",
      "Val RMSE: 76732.3386, Val MAE: 46638.5827, Val MSE: 5887851783.8086, Val R2: 0.7009\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1134\n",
      "Val RMSE: 73972.2774, Val MAE: 43327.3588, Val MSE: 5471897828.1182, Val R2: 0.7220\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0541, Val Loss: 0.1599\n",
      "Val RMSE: 86696.0443, Val MAE: 51627.3509, Val MSE: 7516204099.4647, Val R2: 0.6181\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1261\n",
      "Val RMSE: 78594.8482, Val MAE: 48839.3869, Val MSE: 6177150169.2406, Val R2: 0.6862\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0604, Val Loss: 0.1252\n",
      "Val RMSE: 83421.7410, Val MAE: 44987.9293, Val MSE: 6959186879.4880, Val R2: 0.6464\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1131\n",
      "Val RMSE: 72128.9149, Val MAE: 46349.9053, Val MSE: 5202580358.4478, Val R2: 0.7357\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1275\n",
      "Val RMSE: 77601.9379, Val MAE: 48568.4426, Val MSE: 6022060762.1317, Val R2: 0.6940\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1227\n",
      "Val RMSE: 72208.8398, Val MAE: 44609.6972, Val MSE: 5214116547.3262, Val R2: 0.7351\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1285\n",
      "Val RMSE: 76565.0407, Val MAE: 45847.7434, Val MSE: 5862205461.9497, Val R2: 0.7022\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1377\n",
      "Val RMSE: 77549.9654, Val MAE: 47659.6971, Val MSE: 6013997140.7727, Val R2: 0.6945\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1151\n",
      "Val RMSE: 71732.4711, Val MAE: 44419.5053, Val MSE: 5145547404.1205, Val R2: 0.7386\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1247\n",
      "Val RMSE: 73900.0241, Val MAE: 44189.2554, Val MSE: 5461213568.2397, Val R2: 0.7225\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0477, Val Loss: 0.1417\n",
      "Val RMSE: 81180.7810, Val MAE: 49901.0464, Val MSE: 6590319197.4699, Val R2: 0.6652\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1051\n",
      "Val RMSE: 69567.1453, Val MAE: 41060.4075, Val MSE: 4839587711.1698, Val R2: 0.7541\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.1204\n",
      "Val RMSE: 74230.9352, Val MAE: 46018.7870, Val MSE: 5510231743.0851, Val R2: 0.7200\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69618.8917, Test MAE: 41453.5803, Test MSE: 4846790081.4898, Test R2: 0.6893\n",
      "Inference Time: 2.7890902299147385e-05 seconds per sample\n",
      "\n",
      "Iteration 92 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3506, Val Loss: 0.2829\n",
      "Val RMSE: 142161.4972, Val MAE: 84736.7633, Val MSE: 20209891274.8486, Val R2: -0.0268\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2736, Val Loss: 0.2752\n",
      "Val RMSE: 140598.0676, Val MAE: 85421.6059, Val MSE: 19767816619.6410, Val R2: -0.0043\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2689, Val Loss: 0.2766\n",
      "Val RMSE: 141963.6521, Val MAE: 82950.8703, Val MSE: 20153678530.1443, Val R2: -0.0239\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2652, Val Loss: 0.2791\n",
      "Val RMSE: 143374.7690, Val MAE: 81298.9183, Val MSE: 20556324393.9882, Val R2: -0.0444\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2648, Val Loss: 0.2872\n",
      "Val RMSE: 144160.0689, Val MAE: 81771.2269, Val MSE: 20782125462.3255, Val R2: -0.0559\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2637, Val Loss: 0.2726\n",
      "Val RMSE: 141387.0889, Val MAE: 82538.9640, Val MSE: 19990308920.9549, Val R2: -0.0156\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2816\n",
      "Val RMSE: 140918.8411, Val MAE: 88330.2404, Val MSE: 19858119770.6300, Val R2: -0.0089\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2563, Val Loss: 0.2683\n",
      "Val RMSE: 141601.9514, Val MAE: 80876.7640, Val MSE: 20051112627.7955, Val R2: -0.0187\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2911\n",
      "Val RMSE: 142627.3467, Val MAE: 88873.2245, Val MSE: 20342560014.4330, Val R2: -0.0335\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2739\n",
      "Val RMSE: 141710.2060, Val MAE: 82855.9731, Val MSE: 20081782473.5381, Val R2: -0.0203\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2802\n",
      "Val RMSE: 142751.4141, Val MAE: 83890.8452, Val MSE: 20377966218.5746, Val R2: -0.0353\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2503, Val Loss: 0.2682\n",
      "Val RMSE: 141392.6854, Val MAE: 80741.3187, Val MSE: 19991891471.2281, Val R2: -0.0157\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2484, Val Loss: 0.2754\n",
      "Val RMSE: 141142.1109, Val MAE: 83357.2963, Val MSE: 19921095463.4553, Val R2: -0.0121\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2472, Val Loss: 0.2657\n",
      "Val RMSE: 141088.3031, Val MAE: 79671.2874, Val MSE: 19905909269.6543, Val R2: -0.0113\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2467, Val Loss: 0.2678\n",
      "Val RMSE: 142961.9464, Val MAE: 78166.6184, Val MSE: 20438118129.8657, Val R2: -0.0384\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2431, Val Loss: 0.2860\n",
      "Val RMSE: 142591.5231, Val MAE: 84302.8989, Val MSE: 20332342467.6513, Val R2: -0.0330\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2438, Val Loss: 0.2633\n",
      "Val RMSE: 141885.1386, Val MAE: 77777.3492, Val MSE: 20131392556.7179, Val R2: -0.0228\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2603\n",
      "Val RMSE: 135664.2615, Val MAE: 80424.5006, Val MSE: 18404791839.2775, Val R2: 0.0649\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2318, Val Loss: 0.2547\n",
      "Val RMSE: 132951.0341, Val MAE: 78768.9744, Val MSE: 17675977462.3287, Val R2: 0.1019\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2221, Val Loss: 0.2283\n",
      "Val RMSE: 129436.9977, Val MAE: 72369.1338, Val MSE: 16753936384.4948, Val R2: 0.1488\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2106, Val Loss: 0.2271\n",
      "Val RMSE: 130110.4913, Val MAE: 70799.3691, Val MSE: 16928739957.0554, Val R2: 0.1399\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2097, Val Loss: 0.2289\n",
      "Val RMSE: 128211.4939, Val MAE: 74799.8429, Val MSE: 16438187179.6002, Val R2: 0.1648\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2057, Val Loss: 0.2316\n",
      "Val RMSE: 131032.0393, Val MAE: 72094.8934, Val MSE: 17169395328.5572, Val R2: 0.1277\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2052, Val Loss: 0.2332\n",
      "Val RMSE: 128752.3634, Val MAE: 74429.6079, Val MSE: 16577171087.7191, Val R2: 0.1578\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2015, Val Loss: 0.2314\n",
      "Val RMSE: 128362.4879, Val MAE: 73331.7316, Val MSE: 16476928288.0663, Val R2: 0.1629\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2073, Val Loss: 0.2277\n",
      "Val RMSE: 126605.8613, Val MAE: 69780.4692, Val MSE: 16029044122.3166, Val R2: 0.1856\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1961, Val Loss: 0.1988\n",
      "Val RMSE: 112540.3704, Val MAE: 67482.4653, Val MSE: 12665334959.4063, Val R2: 0.3565\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1877, Val Loss: 0.2031\n",
      "Val RMSE: 110536.0814, Val MAE: 68385.5650, Val MSE: 12218225297.2821, Val R2: 0.3792\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1821, Val Loss: 0.1907\n",
      "Val RMSE: 107758.2256, Val MAE: 65100.4264, Val MSE: 11611835188.3182, Val R2: 0.4100\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1775, Val Loss: 0.1896\n",
      "Val RMSE: 104478.5304, Val MAE: 65818.6209, Val MSE: 10915763324.9627, Val R2: 0.4454\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1749, Val Loss: 0.2184\n",
      "Val RMSE: 112142.2072, Val MAE: 69892.7018, Val MSE: 12575874630.4060, Val R2: 0.3611\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1693, Val Loss: 0.1822\n",
      "Val RMSE: 104889.1384, Val MAE: 61249.0792, Val MSE: 11001731356.0397, Val R2: 0.4410\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1621, Val Loss: 0.1966\n",
      "Val RMSE: 106130.4734, Val MAE: 64988.5900, Val MSE: 11263677377.9690, Val R2: 0.4277\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1611, Val Loss: 0.1696\n",
      "Val RMSE: 100272.5777, Val MAE: 59973.9583, Val MSE: 10054589833.5610, Val R2: 0.4892\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1590, Val Loss: 0.1685\n",
      "Val RMSE: 100909.3495, Val MAE: 59211.9323, Val MSE: 10182696808.4120, Val R2: 0.4827\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1558, Val Loss: 0.1606\n",
      "Val RMSE: 97844.1437, Val MAE: 57729.2394, Val MSE: 9573476448.0501, Val R2: 0.5136\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1507, Val Loss: 0.1610\n",
      "Val RMSE: 96212.8842, Val MAE: 59325.0936, Val MSE: 9256919082.0765, Val R2: 0.5297\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1484, Val Loss: 0.1554\n",
      "Val RMSE: 96768.2128, Val MAE: 56361.7926, Val MSE: 9364087004.2256, Val R2: 0.5242\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1526, Val Loss: 0.1619\n",
      "Val RMSE: 98608.3767, Val MAE: 56614.1035, Val MSE: 9723611960.5849, Val R2: 0.5060\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1549, Val Loss: 0.1544\n",
      "Val RMSE: 97941.2399, Val MAE: 55172.5938, Val MSE: 9592486477.4785, Val R2: 0.5126\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1435, Val Loss: 0.1429\n",
      "Val RMSE: 93441.8563, Val MAE: 54051.9898, Val MSE: 8731380500.5060, Val R2: 0.5564\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1388, Val Loss: 0.1393\n",
      "Val RMSE: 92309.2474, Val MAE: 55898.1794, Val MSE: 8520997163.6914, Val R2: 0.5671\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1343, Val Loss: 0.1360\n",
      "Val RMSE: 92757.1151, Val MAE: 50186.7041, Val MSE: 8603882398.2029, Val R2: 0.5629\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1362\n",
      "Val RMSE: 92748.7944, Val MAE: 53745.0719, Val MSE: 8602338856.4445, Val R2: 0.5629\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1261, Val Loss: 0.1220\n",
      "Val RMSE: 88957.0994, Val MAE: 47522.5139, Val MSE: 7913365525.0638, Val R2: 0.5980\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1238, Val Loss: 0.1203\n",
      "Val RMSE: 88225.2582, Val MAE: 49712.9906, Val MSE: 7783696192.2794, Val R2: 0.6045\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1193, Val Loss: 0.1240\n",
      "Val RMSE: 89672.4337, Val MAE: 51395.1868, Val MSE: 8041145374.5453, Val R2: 0.5915\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1157, Val Loss: 0.1200\n",
      "Val RMSE: 89370.7790, Val MAE: 45864.5969, Val MSE: 7987136138.1938, Val R2: 0.5942\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1135, Val Loss: 0.1205\n",
      "Val RMSE: 89225.3003, Val MAE: 47373.0593, Val MSE: 7961154219.0399, Val R2: 0.5955\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1108, Val Loss: 0.1272\n",
      "Val RMSE: 90109.5171, Val MAE: 50667.0152, Val MSE: 8119725075.2364, Val R2: 0.5875\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1072, Val Loss: 0.1098\n",
      "Val RMSE: 85056.6649, Val MAE: 43464.1770, Val MSE: 7234636242.4654, Val R2: 0.6324\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1051, Val Loss: 0.1118\n",
      "Val RMSE: 85458.7498, Val MAE: 45731.1947, Val MSE: 7303197916.9399, Val R2: 0.6290\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1038, Val Loss: 0.1120\n",
      "Val RMSE: 87497.5171, Val MAE: 43576.9010, Val MSE: 7655815496.0847, Val R2: 0.6110\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1017, Val Loss: 0.1158\n",
      "Val RMSE: 85295.9334, Val MAE: 47434.8390, Val MSE: 7275396255.7330, Val R2: 0.6304\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1154\n",
      "Val RMSE: 85773.1493, Val MAE: 48158.6960, Val MSE: 7357033136.7426, Val R2: 0.6262\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0964, Val Loss: 0.1324\n",
      "Val RMSE: 89299.6379, Val MAE: 51274.1560, Val MSE: 7974425335.0199, Val R2: 0.5948\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1097\n",
      "Val RMSE: 84532.5178, Val MAE: 43598.9560, Val MSE: 7145746568.5065, Val R2: 0.6370\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0905, Val Loss: 0.1231\n",
      "Val RMSE: 85610.3644, Val MAE: 49285.2885, Val MSE: 7329134500.7235, Val R2: 0.6276\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1091\n",
      "Val RMSE: 83787.0996, Val MAE: 42157.0236, Val MSE: 7020278064.4400, Val R2: 0.6433\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0872, Val Loss: 0.1148\n",
      "Val RMSE: 82722.5944, Val MAE: 45456.2086, Val MSE: 6843027626.0487, Val R2: 0.6523\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1118\n",
      "Val RMSE: 82421.3069, Val MAE: 44715.5916, Val MSE: 6793271826.2404, Val R2: 0.6549\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0823, Val Loss: 0.1104\n",
      "Val RMSE: 82027.5468, Val MAE: 41172.1171, Val MSE: 6728518436.7182, Val R2: 0.6581\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0827, Val Loss: 0.1053\n",
      "Val RMSE: 77234.7244, Val MAE: 38996.4426, Val MSE: 5965202655.0126, Val R2: 0.6969\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0848, Val Loss: 0.1050\n",
      "Val RMSE: 75322.7596, Val MAE: 41773.3752, Val MSE: 5673518119.8697, Val R2: 0.7117\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0794, Val Loss: 0.1074\n",
      "Val RMSE: 74419.2166, Val MAE: 43387.5198, Val MSE: 5538219800.1375, Val R2: 0.7186\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0760, Val Loss: 0.1012\n",
      "Val RMSE: 73088.6415, Val MAE: 42229.8412, Val MSE: 5341949513.8968, Val R2: 0.7286\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1063\n",
      "Val RMSE: 74514.0591, Val MAE: 43722.3545, Val MSE: 5552344998.4008, Val R2: 0.7179\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1018\n",
      "Val RMSE: 74505.3592, Val MAE: 39244.8245, Val MSE: 5551048556.3004, Val R2: 0.7180\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1184\n",
      "Val RMSE: 78345.2420, Val MAE: 47651.9655, Val MSE: 6137976941.9739, Val R2: 0.6882\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0692, Val Loss: 0.1000\n",
      "Val RMSE: 72737.5289, Val MAE: 39306.7099, Val MSE: 5290748106.8579, Val R2: 0.7312\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0683, Val Loss: 0.1022\n",
      "Val RMSE: 72847.8139, Val MAE: 41039.2078, Val MSE: 5306803994.6152, Val R2: 0.7304\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1029\n",
      "Val RMSE: 73254.0756, Val MAE: 40237.7576, Val MSE: 5366159593.0608, Val R2: 0.7274\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0655, Val Loss: 0.1008\n",
      "Val RMSE: 71939.4464, Val MAE: 42156.8110, Val MSE: 5175283941.4977, Val R2: 0.7371\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.0921\n",
      "Val RMSE: 69033.8195, Val MAE: 37532.3864, Val MSE: 4765668232.3173, Val R2: 0.7579\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0634, Val Loss: 0.1011\n",
      "Val RMSE: 71168.6795, Val MAE: 39991.8469, Val MSE: 5064980947.7061, Val R2: 0.7427\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0616, Val Loss: 0.1107\n",
      "Val RMSE: 72494.9712, Val MAE: 44905.4824, Val MSE: 5255520842.3624, Val R2: 0.7330\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1018\n",
      "Val RMSE: 71316.4591, Val MAE: 42886.3492, Val MSE: 5086037336.5678, Val R2: 0.7416\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.0954\n",
      "Val RMSE: 68293.8113, Val MAE: 39536.9931, Val MSE: 4664044662.4637, Val R2: 0.7630\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.0997\n",
      "Val RMSE: 70752.0835, Val MAE: 40548.7508, Val MSE: 5005857318.1427, Val R2: 0.7457\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.0989\n",
      "Val RMSE: 68767.7144, Val MAE: 40777.6375, Val MSE: 4728998545.2181, Val R2: 0.7597\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0562, Val Loss: 0.1009\n",
      "Val RMSE: 70507.6041, Val MAE: 40853.3088, Val MSE: 4971322240.1371, Val R2: 0.7474\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.0956\n",
      "Val RMSE: 69613.1177, Val MAE: 37105.5799, Val MSE: 4845986151.8982, Val R2: 0.7538\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.0936\n",
      "Val RMSE: 68603.3026, Val MAE: 37108.3440, Val MSE: 4706413123.6589, Val R2: 0.7609\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.0974\n",
      "Val RMSE: 69516.8577, Val MAE: 38905.9560, Val MSE: 4832593507.3730, Val R2: 0.7545\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.0958\n",
      "Val RMSE: 69065.6096, Val MAE: 36559.3180, Val MSE: 4770058425.4507, Val R2: 0.7577\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.0940\n",
      "Val RMSE: 67528.9119, Val MAE: 38909.3088, Val MSE: 4560153937.9053, Val R2: 0.7683\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.0985\n",
      "Val RMSE: 69669.0501, Val MAE: 40196.1856, Val MSE: 4853776546.4415, Val R2: 0.7534\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0507, Val Loss: 0.0893\n",
      "Val RMSE: 67232.1632, Val MAE: 36527.3975, Val MSE: 4520163763.6382, Val R2: 0.7703\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.0898\n",
      "Val RMSE: 66812.3103, Val MAE: 35676.4231, Val MSE: 4463884810.0578, Val R2: 0.7732\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0490, Val Loss: 0.0947\n",
      "Val RMSE: 66662.8169, Val MAE: 38692.0845, Val MSE: 4443931151.0373, Val R2: 0.7742\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1015\n",
      "Val RMSE: 70419.7107, Val MAE: 41673.2647, Val MSE: 4958935661.3076, Val R2: 0.7481\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0473, Val Loss: 0.0947\n",
      "Val RMSE: 66845.3857, Val MAE: 38933.0745, Val MSE: 4468305595.8670, Val R2: 0.7730\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0466, Val Loss: 0.0867\n",
      "Val RMSE: 66483.9469, Val MAE: 34945.6204, Val MSE: 4420115200.5359, Val R2: 0.7754\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.0881\n",
      "Val RMSE: 65104.9338, Val MAE: 36616.6398, Val MSE: 4238652402.6486, Val R2: 0.7846\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0465, Val Loss: 0.0849\n",
      "Val RMSE: 64221.7355, Val MAE: 34921.8185, Val MSE: 4124431312.1316, Val R2: 0.7905\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0459, Val Loss: 0.0911\n",
      "Val RMSE: 68224.0582, Val MAE: 36549.5803, Val MSE: 4654522119.4427, Val R2: 0.7635\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.0906\n",
      "Val RMSE: 68102.8653, Val MAE: 36580.7096, Val MSE: 4638000268.6987, Val R2: 0.7644\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.0900\n",
      "Val RMSE: 63943.0246, Val MAE: 36118.9301, Val MSE: 4088710391.4409, Val R2: 0.7923\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.0844\n",
      "Val RMSE: 65927.8983, Val MAE: 34385.0729, Val MSE: 4346487775.4340, Val R2: 0.7792\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0444, Val Loss: 0.0838\n",
      "Val RMSE: 63381.3524, Val MAE: 35385.1028, Val MSE: 4017195837.7322, Val R2: 0.7959\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 64962.8848, Test MAE: 34903.0658, Test MSE: 4220176399.1959, Test R2: 0.7295\n",
      "Inference Time: 2.3523917564978965e-05 seconds per sample\n",
      "\n",
      "Iteration 93 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3245, Val Loss: 0.2814\n",
      "Val RMSE: 141076.2362, Val MAE: 87002.3338, Val MSE: 19902504430.5018, Val R2: -0.0112\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2760, Val Loss: 0.2792\n",
      "Val RMSE: 142514.6920, Val MAE: 82574.6209, Val MSE: 20310437435.0359, Val R2: -0.0319\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2707, Val Loss: 0.2780\n",
      "Val RMSE: 142504.8875, Val MAE: 82233.9990, Val MSE: 20307642975.6164, Val R2: -0.0318\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2679, Val Loss: 0.2749\n",
      "Val RMSE: 141658.3490, Val MAE: 83073.0750, Val MSE: 20067087840.6465, Val R2: -0.0195\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2621, Val Loss: 0.2814\n",
      "Val RMSE: 144283.8855, Val MAE: 80243.4903, Val MSE: 20817839601.3765, Val R2: -0.0577\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2627, Val Loss: 0.2750\n",
      "Val RMSE: 141330.7228, Val MAE: 84510.8899, Val MSE: 19974373196.2951, Val R2: -0.0148\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2580, Val Loss: 0.2813\n",
      "Val RMSE: 141382.1535, Val MAE: 86558.6777, Val MSE: 19988913328.7068, Val R2: -0.0156\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2741\n",
      "Val RMSE: 140943.3094, Val MAE: 83125.1784, Val MSE: 19865016454.4244, Val R2: -0.0093\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2565, Val Loss: 0.2682\n",
      "Val RMSE: 140921.1208, Val MAE: 80467.5312, Val MSE: 19858762292.9794, Val R2: -0.0090\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2676\n",
      "Val RMSE: 139954.2016, Val MAE: 82915.4292, Val MSE: 19587178538.0154, Val R2: 0.0048\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2789\n",
      "Val RMSE: 140750.3596, Val MAE: 85520.3157, Val MSE: 19810663727.5631, Val R2: -0.0065\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2478, Val Loss: 0.2659\n",
      "Val RMSE: 140757.2367, Val MAE: 78323.1071, Val MSE: 19812599690.3303, Val R2: -0.0066\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2573\n",
      "Val RMSE: 135692.2055, Val MAE: 78032.5922, Val MSE: 18412374627.4655, Val R2: 0.0645\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2437, Val Loss: 0.2507\n",
      "Val RMSE: 135384.4137, Val MAE: 76736.0330, Val MSE: 18328939477.4736, Val R2: 0.0688\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2310, Val Loss: 0.2333\n",
      "Val RMSE: 129912.2539, Val MAE: 74618.8432, Val MSE: 16877193704.2266, Val R2: 0.1425\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2223, Val Loss: 0.2372\n",
      "Val RMSE: 131169.1753, Val MAE: 73298.3797, Val MSE: 17205352543.9032, Val R2: 0.1259\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2141, Val Loss: 0.2277\n",
      "Val RMSE: 127591.0996, Val MAE: 76551.2848, Val MSE: 16279488686.6197, Val R2: 0.1729\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2136, Val Loss: 0.2243\n",
      "Val RMSE: 129141.6973, Val MAE: 71066.9275, Val MSE: 16677577987.1234, Val R2: 0.1527\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2079, Val Loss: 0.2210\n",
      "Val RMSE: 127288.8478, Val MAE: 69933.0902, Val MSE: 16202450778.8784, Val R2: 0.1768\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2183\n",
      "Val RMSE: 125727.3348, Val MAE: 70269.1312, Val MSE: 15807362725.5031, Val R2: 0.1969\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.1973, Val Loss: 0.2143\n",
      "Val RMSE: 124445.4110, Val MAE: 69378.6800, Val MSE: 15486660312.3758, Val R2: 0.2132\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1882, Val Loss: 0.1999\n",
      "Val RMSE: 113286.7770, Val MAE: 67507.6618, Val MSE: 12833893843.0462, Val R2: 0.3480\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1793, Val Loss: 0.1967\n",
      "Val RMSE: 109285.9827, Val MAE: 65518.8927, Val MSE: 11943426020.3964, Val R2: 0.3932\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1762, Val Loss: 0.2066\n",
      "Val RMSE: 111505.2562, Val MAE: 65294.8372, Val MSE: 12433422169.7058, Val R2: 0.3683\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1688, Val Loss: 0.1863\n",
      "Val RMSE: 104226.1935, Val MAE: 62425.9777, Val MSE: 10863099408.5091, Val R2: 0.4481\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1655, Val Loss: 0.1780\n",
      "Val RMSE: 100249.1342, Val MAE: 63795.6771, Val MSE: 10049888916.2750, Val R2: 0.4894\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1633, Val Loss: 0.1804\n",
      "Val RMSE: 102980.1466, Val MAE: 61478.7320, Val MSE: 10604910590.0132, Val R2: 0.4612\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1587, Val Loss: 0.1729\n",
      "Val RMSE: 99703.4768, Val MAE: 60689.9747, Val MSE: 9940783285.4297, Val R2: 0.4949\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1510, Val Loss: 0.1725\n",
      "Val RMSE: 99830.6838, Val MAE: 58664.7431, Val MSE: 9966165435.8438, Val R2: 0.4937\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1449, Val Loss: 0.1654\n",
      "Val RMSE: 99389.0088, Val MAE: 56937.8864, Val MSE: 9878175069.9317, Val R2: 0.4981\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1388, Val Loss: 0.1798\n",
      "Val RMSE: 100451.2165, Val MAE: 62576.1216, Val MSE: 10090446897.3844, Val R2: 0.4873\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1336, Val Loss: 0.1597\n",
      "Val RMSE: 96110.7543, Val MAE: 56838.8233, Val MSE: 9237277089.0157, Val R2: 0.5307\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1309, Val Loss: 0.1575\n",
      "Val RMSE: 96217.8670, Val MAE: 55674.6241, Val MSE: 9257877927.3126, Val R2: 0.5296\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1276, Val Loss: 0.1617\n",
      "Val RMSE: 94898.5141, Val MAE: 58666.0354, Val MSE: 9005727980.1042, Val R2: 0.5425\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1240, Val Loss: 0.1549\n",
      "Val RMSE: 94621.2482, Val MAE: 57010.3642, Val MSE: 8953180618.0162, Val R2: 0.5451\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1183, Val Loss: 0.1579\n",
      "Val RMSE: 95495.4618, Val MAE: 56712.6403, Val MSE: 9119383216.1575, Val R2: 0.5367\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1158, Val Loss: 0.1596\n",
      "Val RMSE: 94974.9936, Val MAE: 60262.8747, Val MSE: 9020249417.5979, Val R2: 0.5417\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1145, Val Loss: 0.1570\n",
      "Val RMSE: 96268.0794, Val MAE: 56304.1681, Val MSE: 9267543102.8444, Val R2: 0.5292\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1116, Val Loss: 0.1584\n",
      "Val RMSE: 95611.0755, Val MAE: 54017.1750, Val MSE: 9141477752.1125, Val R2: 0.5356\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1079, Val Loss: 0.1664\n",
      "Val RMSE: 96868.7931, Val MAE: 61066.6775, Val MSE: 9383563067.2463, Val R2: 0.5233\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1048, Val Loss: 0.1624\n",
      "Val RMSE: 95656.6437, Val MAE: 60182.8784, Val MSE: 9150193482.6695, Val R2: 0.5351\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1466\n",
      "Val RMSE: 91445.8991, Val MAE: 55326.5786, Val MSE: 8362352455.5487, Val R2: 0.5751\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0981, Val Loss: 0.1499\n",
      "Val RMSE: 92986.7029, Val MAE: 54056.5672, Val MSE: 8646526912.6024, Val R2: 0.5607\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0922, Val Loss: 0.1648\n",
      "Val RMSE: 96043.5749, Val MAE: 59686.1637, Val MSE: 9224368281.7819, Val R2: 0.5313\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0917, Val Loss: 0.1574\n",
      "Val RMSE: 93299.2748, Val MAE: 56001.5884, Val MSE: 8704754673.2561, Val R2: 0.5577\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0902, Val Loss: 0.1557\n",
      "Val RMSE: 91401.1348, Val MAE: 52082.7324, Val MSE: 8354167445.9865, Val R2: 0.5756\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0872, Val Loss: 0.1496\n",
      "Val RMSE: 90096.3909, Val MAE: 55100.0721, Val MSE: 8117359646.5807, Val R2: 0.5876\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0849, Val Loss: 0.1535\n",
      "Val RMSE: 92565.3756, Val MAE: 53411.9910, Val MSE: 8568348766.3161, Val R2: 0.5647\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0860, Val Loss: 0.1480\n",
      "Val RMSE: 89630.2041, Val MAE: 53305.0743, Val MSE: 8033573479.9757, Val R2: 0.5918\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0847, Val Loss: 0.1489\n",
      "Val RMSE: 91124.9104, Val MAE: 52418.4317, Val MSE: 8303749301.4461, Val R2: 0.5781\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0820, Val Loss: 0.1504\n",
      "Val RMSE: 89954.1591, Val MAE: 53514.0229, Val MSE: 8091750732.1394, Val R2: 0.5889\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1533\n",
      "Val RMSE: 91552.5012, Val MAE: 53690.4547, Val MSE: 8381860484.3871, Val R2: 0.5741\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1497\n",
      "Val RMSE: 90269.0484, Val MAE: 52223.3372, Val MSE: 8148501107.4315, Val R2: 0.5860\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1424\n",
      "Val RMSE: 85623.9461, Val MAE: 52856.4968, Val MSE: 7331460152.5749, Val R2: 0.6275\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0742, Val Loss: 0.1502\n",
      "Val RMSE: 88782.3851, Val MAE: 55189.7233, Val MSE: 7882311909.2315, Val R2: 0.5995\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0736, Val Loss: 0.1431\n",
      "Val RMSE: 84979.3869, Val MAE: 50692.4448, Val MSE: 7221496192.2721, Val R2: 0.6331\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1489\n",
      "Val RMSE: 89106.4307, Val MAE: 52424.4843, Val MSE: 7939955990.6202, Val R2: 0.5966\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1459\n",
      "Val RMSE: 85465.2709, Val MAE: 51892.8387, Val MSE: 7304312527.9421, Val R2: 0.6289\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0697, Val Loss: 0.1371\n",
      "Val RMSE: 82686.1450, Val MAE: 48807.0809, Val MSE: 6836998581.1229, Val R2: 0.6526\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0685, Val Loss: 0.1567\n",
      "Val RMSE: 88772.3076, Val MAE: 56934.9796, Val MSE: 7880522596.5589, Val R2: 0.5996\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0668, Val Loss: 0.1347\n",
      "Val RMSE: 82056.6592, Val MAE: 49578.1351, Val MSE: 6733295315.7135, Val R2: 0.6579\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0676, Val Loss: 0.1395\n",
      "Val RMSE: 83867.4868, Val MAE: 50520.2800, Val MSE: 7033755340.5133, Val R2: 0.6426\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0660, Val Loss: 0.1507\n",
      "Val RMSE: 88664.1144, Val MAE: 54630.4895, Val MSE: 7861325189.6299, Val R2: 0.6006\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0620, Val Loss: 0.1418\n",
      "Val RMSE: 84932.4188, Val MAE: 50825.2064, Val MSE: 7213515763.7821, Val R2: 0.6335\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1456\n",
      "Val RMSE: 86881.1175, Val MAE: 51416.3718, Val MSE: 7548328579.7828, Val R2: 0.6165\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1430\n",
      "Val RMSE: 86643.8649, Val MAE: 50876.8543, Val MSE: 7507159329.1700, Val R2: 0.6186\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1606\n",
      "Val RMSE: 90533.4159, Val MAE: 55902.1234, Val MSE: 8196299395.6253, Val R2: 0.5836\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1591\n",
      "Val RMSE: 87385.3267, Val MAE: 55379.5966, Val MSE: 7636195319.8956, Val R2: 0.6120\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1599\n",
      "Val RMSE: 91444.9394, Val MAE: 55353.8846, Val MSE: 8362176947.8688, Val R2: 0.5751\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1402\n",
      "Val RMSE: 86376.8274, Val MAE: 49820.8484, Val MSE: 7460956315.4674, Val R2: 0.6209\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1524\n",
      "Val RMSE: 88855.3345, Val MAE: 52660.9471, Val MSE: 7895270471.3617, Val R2: 0.5989\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1543\n",
      "Val RMSE: 88399.4936, Val MAE: 53949.2715, Val MSE: 7814470470.3677, Val R2: 0.6030\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0547, Val Loss: 0.1473\n",
      "Val RMSE: 89872.0346, Val MAE: 49590.1288, Val MSE: 8076982594.7612, Val R2: 0.5896\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0545, Val Loss: 0.1460\n",
      "Val RMSE: 87440.9210, Val MAE: 49196.1904, Val MSE: 7645914657.3076, Val R2: 0.6115\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1544\n",
      "Val RMSE: 89963.9908, Val MAE: 53900.1941, Val MSE: 8093519641.0093, Val R2: 0.5888\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1374\n",
      "Val RMSE: 84713.4246, Val MAE: 48067.5320, Val MSE: 7176364315.1205, Val R2: 0.6354\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1350\n",
      "Val RMSE: 84180.1514, Val MAE: 48913.1861, Val MSE: 7086297891.8816, Val R2: 0.6400\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1365\n",
      "Val RMSE: 84379.3283, Val MAE: 50306.9920, Val MSE: 7119871041.1093, Val R2: 0.6383\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0503, Val Loss: 0.1377\n",
      "Val RMSE: 85598.9337, Val MAE: 48398.8653, Val MSE: 7327177445.0412, Val R2: 0.6277\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1423\n",
      "Val RMSE: 86787.4427, Val MAE: 49025.4486, Val MSE: 7532060211.9500, Val R2: 0.6173\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0491, Val Loss: 0.1620\n",
      "Val RMSE: 89674.2745, Val MAE: 57135.5532, Val MSE: 8041475514.2930, Val R2: 0.5914\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.1523\n",
      "Val RMSE: 89383.7184, Val MAE: 53817.4699, Val MSE: 7989449114.7353, Val R2: 0.5941\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1447\n",
      "Val RMSE: 88184.6661, Val MAE: 50833.2886, Val MSE: 7776535329.0452, Val R2: 0.6049\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1516\n",
      "Val RMSE: 87981.7547, Val MAE: 53887.6294, Val MSE: 7740789168.3371, Val R2: 0.6067\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0471, Val Loss: 0.1429\n",
      "Val RMSE: 87103.9186, Val MAE: 50054.7668, Val MSE: 7587092640.9145, Val R2: 0.6145\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0462, Val Loss: 0.1466\n",
      "Val RMSE: 89189.1834, Val MAE: 49662.0773, Val MSE: 7954710429.1716, Val R2: 0.5959\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0475, Val Loss: 0.1439\n",
      "Val RMSE: 88342.9032, Val MAE: 49597.7985, Val MSE: 7804468544.7833, Val R2: 0.6035\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0449, Val Loss: 0.1315\n",
      "Val RMSE: 81929.0886, Val MAE: 46613.0850, Val MSE: 6712375557.1419, Val R2: 0.6590\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1440\n",
      "Val RMSE: 88344.4230, Val MAE: 50314.7847, Val MSE: 7804737083.6723, Val R2: 0.6035\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1428\n",
      "Val RMSE: 88201.9792, Val MAE: 50279.0050, Val MSE: 7779589131.2545, Val R2: 0.6047\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1453\n",
      "Val RMSE: 87451.0317, Val MAE: 51778.6023, Val MSE: 7647682943.8843, Val R2: 0.6114\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1376\n",
      "Val RMSE: 85476.5812, Val MAE: 47807.6064, Val MSE: 7306245931.3195, Val R2: 0.6288\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1438\n",
      "Val RMSE: 86386.8029, Val MAE: 48232.1713, Val MSE: 7462679723.3516, Val R2: 0.6208\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1435\n",
      "Val RMSE: 86520.1885, Val MAE: 49491.4075, Val MSE: 7485743015.7078, Val R2: 0.6197\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0442, Val Loss: 0.1492\n",
      "Val RMSE: 89905.0406, Val MAE: 50709.5780, Val MSE: 8082916332.4615, Val R2: 0.5893\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1505\n",
      "Val RMSE: 90776.9359, Val MAE: 50535.4178, Val MSE: 8240452093.9538, Val R2: 0.5813\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0434, Val Loss: 0.1477\n",
      "Val RMSE: 89176.5985, Val MAE: 49974.7093, Val MSE: 7952465716.0297, Val R2: 0.5960\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0415, Val Loss: 0.1504\n",
      "Val RMSE: 88844.7268, Val MAE: 51995.0571, Val MSE: 7893385483.6065, Val R2: 0.5990\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0408, Val Loss: 0.1475\n",
      "Val RMSE: 86751.8760, Val MAE: 51788.2274, Val MSE: 7525887990.8141, Val R2: 0.6176\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0422, Val Loss: 0.1360\n",
      "Val RMSE: 83477.7371, Val MAE: 47744.1002, Val MSE: 6968532586.2804, Val R2: 0.6460\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 88997.0987, Test MAE: 50617.2512, Test MSE: 7920483581.4998, Test R2: 0.4923\n",
      "Inference Time: 2.1685526921198917e-05 seconds per sample\n",
      "\n",
      "Iteration 94 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3574, Val Loss: 0.2784\n",
      "Val RMSE: 142680.9500, Val MAE: 82411.3639, Val MSE: 20357853505.0632, Val R2: -0.0343\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2735, Val Loss: 0.2748\n",
      "Val RMSE: 140605.7410, Val MAE: 85417.0100, Val MSE: 19769974408.4834, Val R2: -0.0044\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2703, Val Loss: 0.2751\n",
      "Val RMSE: 141264.2410, Val MAE: 83956.5188, Val MSE: 19955585797.1717, Val R2: -0.0139\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2664, Val Loss: 0.2748\n",
      "Val RMSE: 140500.1944, Val MAE: 86546.0627, Val MSE: 19740304630.1098, Val R2: -0.0029\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2624, Val Loss: 0.2818\n",
      "Val RMSE: 141695.8364, Val MAE: 87964.1346, Val MSE: 20077710043.3834, Val R2: -0.0201\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2631, Val Loss: 0.2758\n",
      "Val RMSE: 141262.1515, Val MAE: 84752.8965, Val MSE: 19954995446.0156, Val R2: -0.0138\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2572, Val Loss: 0.2803\n",
      "Val RMSE: 143681.8187, Val MAE: 80233.8396, Val MSE: 20644465022.2950, Val R2: -0.0489\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2589, Val Loss: 0.2767\n",
      "Val RMSE: 141586.1316, Val MAE: 84032.4711, Val MSE: 20046632675.1571, Val R2: -0.0185\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2545, Val Loss: 0.2784\n",
      "Val RMSE: 141173.8097, Val MAE: 85652.0144, Val MSE: 19930044533.7471, Val R2: -0.0126\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2506, Val Loss: 0.2709\n",
      "Val RMSE: 139670.4253, Val MAE: 85122.0256, Val MSE: 19507827689.7554, Val R2: 0.0089\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2517, Val Loss: 0.2667\n",
      "Val RMSE: 141121.0500, Val MAE: 80082.6782, Val MSE: 19915150742.8795, Val R2: -0.0118\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2472, Val Loss: 0.2684\n",
      "Val RMSE: 140573.4414, Val MAE: 81267.5711, Val MSE: 19760892422.4106, Val R2: -0.0040\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2444, Val Loss: 0.2597\n",
      "Val RMSE: 139108.1801, Val MAE: 79336.4483, Val MSE: 19351085772.1836, Val R2: 0.0168\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2378, Val Loss: 0.2536\n",
      "Val RMSE: 135015.0243, Val MAE: 74979.4541, Val MSE: 18229056786.0245, Val R2: 0.0738\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2280, Val Loss: 0.2343\n",
      "Val RMSE: 130523.8380, Val MAE: 77413.8615, Val MSE: 17036472283.9701, Val R2: 0.1344\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2200, Val Loss: 0.2513\n",
      "Val RMSE: 131297.6907, Val MAE: 79513.4543, Val MSE: 17239083578.9767, Val R2: 0.1241\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2166, Val Loss: 0.2513\n",
      "Val RMSE: 130087.6502, Val MAE: 82501.6789, Val MSE: 16922796742.0467, Val R2: 0.1402\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2197, Val Loss: 0.2314\n",
      "Val RMSE: 128388.2787, Val MAE: 77703.0745, Val MSE: 16483550118.1529, Val R2: 0.1625\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2170, Val Loss: 0.2374\n",
      "Val RMSE: 132702.9655, Val MAE: 73513.7148, Val MSE: 17610077039.3318, Val R2: 0.1053\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2216, Val Loss: 0.2548\n",
      "Val RMSE: 136731.4050, Val MAE: 80288.8905, Val MSE: 18695477114.2152, Val R2: 0.0502\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2454, Val Loss: 0.2539\n",
      "Val RMSE: 136838.4731, Val MAE: 78127.1802, Val MSE: 18724767713.2508, Val R2: 0.0487\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2342, Val Loss: 0.2397\n",
      "Val RMSE: 134707.6165, Val MAE: 75410.4516, Val MSE: 18146141935.7629, Val R2: 0.0781\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2234, Val Loss: 0.2374\n",
      "Val RMSE: 134528.6187, Val MAE: 74558.1443, Val MSE: 18097949244.3242, Val R2: 0.0805\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2174, Val Loss: 0.2370\n",
      "Val RMSE: 132821.1547, Val MAE: 76616.3989, Val MSE: 17641459143.8557, Val R2: 0.1037\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2086, Val Loss: 0.2358\n",
      "Val RMSE: 131998.4891, Val MAE: 75352.8547, Val MSE: 17423601124.2151, Val R2: 0.1148\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2120, Val Loss: 0.2360\n",
      "Val RMSE: 132975.4487, Val MAE: 74957.4646, Val MSE: 17682469955.9976, Val R2: 0.1016\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2074, Val Loss: 0.2347\n",
      "Val RMSE: 132074.1622, Val MAE: 74436.4671, Val MSE: 17443584322.6718, Val R2: 0.1138\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2030, Val Loss: 0.2452\n",
      "Val RMSE: 131182.2276, Val MAE: 79600.1615, Val MSE: 17208776843.2835, Val R2: 0.1257\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2335\n",
      "Val RMSE: 128913.5433, Val MAE: 76754.6270, Val MSE: 16618701643.4744, Val R2: 0.1557\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1980, Val Loss: 0.2345\n",
      "Val RMSE: 129986.5061, Val MAE: 74675.7123, Val MSE: 16896491771.3203, Val R2: 0.1416\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1920, Val Loss: 0.2307\n",
      "Val RMSE: 128112.0976, Val MAE: 74859.8476, Val MSE: 16412709555.2630, Val R2: 0.1661\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1870, Val Loss: 0.2373\n",
      "Val RMSE: 124942.7973, Val MAE: 77873.5489, Val MSE: 15610702594.9123, Val R2: 0.2069\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1871, Val Loss: 0.2250\n",
      "Val RMSE: 125390.5892, Val MAE: 72948.8401, Val MSE: 15722799851.5394, Val R2: 0.2012\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1810, Val Loss: 0.2096\n",
      "Val RMSE: 119771.3728, Val MAE: 70467.0218, Val MSE: 14345181746.6838, Val R2: 0.2712\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1787, Val Loss: 0.2081\n",
      "Val RMSE: 116117.3374, Val MAE: 70579.3970, Val MSE: 13483236052.5751, Val R2: 0.3150\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1776, Val Loss: 0.2198\n",
      "Val RMSE: 125207.2388, Val MAE: 70007.1000, Val MSE: 15676852640.0030, Val R2: 0.2035\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1799, Val Loss: 0.2026\n",
      "Val RMSE: 114698.0610, Val MAE: 70794.0409, Val MSE: 13155645187.9018, Val R2: 0.3316\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1760, Val Loss: 0.2022\n",
      "Val RMSE: 112792.0366, Val MAE: 69339.3298, Val MSE: 12722043513.3041, Val R2: 0.3536\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1700, Val Loss: 0.1882\n",
      "Val RMSE: 109020.6551, Val MAE: 65012.6890, Val MSE: 11885503227.6519, Val R2: 0.3961\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1700, Val Loss: 0.1855\n",
      "Val RMSE: 106087.0092, Val MAE: 65043.3130, Val MSE: 11254453512.0665, Val R2: 0.4282\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1702, Val Loss: 0.1941\n",
      "Val RMSE: 108485.0877, Val MAE: 65627.7388, Val MSE: 11769014247.8926, Val R2: 0.4021\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1656, Val Loss: 0.1899\n",
      "Val RMSE: 107018.2798, Val MAE: 65526.5055, Val MSE: 11452912214.3425, Val R2: 0.4181\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1635, Val Loss: 0.1782\n",
      "Val RMSE: 102755.6344, Val MAE: 63204.0586, Val MSE: 10558720397.3630, Val R2: 0.4636\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1590, Val Loss: 0.1755\n",
      "Val RMSE: 100980.3499, Val MAE: 62567.0459, Val MSE: 10197031075.5537, Val R2: 0.4819\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1587, Val Loss: 0.1648\n",
      "Val RMSE: 98351.6294, Val MAE: 60245.8107, Val MSE: 9673043010.4468, Val R2: 0.5085\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1577, Val Loss: 0.1639\n",
      "Val RMSE: 97559.8352, Val MAE: 58987.4597, Val MSE: 9517921451.1290, Val R2: 0.5164\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1554, Val Loss: 0.1720\n",
      "Val RMSE: 98196.3726, Val MAE: 62596.3705, Val MSE: 9642527590.6488, Val R2: 0.5101\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1535, Val Loss: 0.1639\n",
      "Val RMSE: 95659.6161, Val MAE: 62108.1769, Val MSE: 9150762158.9234, Val R2: 0.5351\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1523, Val Loss: 0.1645\n",
      "Val RMSE: 97833.4350, Val MAE: 60300.7021, Val MSE: 9571381010.3426, Val R2: 0.5137\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1523, Val Loss: 0.1567\n",
      "Val RMSE: 97166.0234, Val MAE: 56066.9636, Val MSE: 9441236094.8633, Val R2: 0.5203\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1489, Val Loss: 0.1573\n",
      "Val RMSE: 96148.1852, Val MAE: 57033.5271, Val MSE: 9244473512.0728, Val R2: 0.5303\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1527\n",
      "Val RMSE: 94207.5776, Val MAE: 58761.2220, Val MSE: 8875067685.0783, Val R2: 0.5491\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1445, Val Loss: 0.1563\n",
      "Val RMSE: 95101.1973, Val MAE: 56932.3905, Val MSE: 9044237734.1707, Val R2: 0.5405\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1432, Val Loss: 0.1598\n",
      "Val RMSE: 95992.0257, Val MAE: 58156.2867, Val MSE: 9214468995.8094, Val R2: 0.5318\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.1401, Val Loss: 0.1516\n",
      "Val RMSE: 94851.8371, Val MAE: 55467.4925, Val MSE: 8996870999.7414, Val R2: 0.5429\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.1369, Val Loss: 0.1579\n",
      "Val RMSE: 95834.9333, Val MAE: 56902.7721, Val MSE: 9184334447.8677, Val R2: 0.5334\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.1329, Val Loss: 0.1552\n",
      "Val RMSE: 94262.0838, Val MAE: 58514.1107, Val MSE: 8885340443.0438, Val R2: 0.5486\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1309, Val Loss: 0.1446\n",
      "Val RMSE: 92634.0365, Val MAE: 54230.3694, Val MSE: 8581064715.0400, Val R2: 0.5640\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1315, Val Loss: 0.1626\n",
      "Val RMSE: 96212.7504, Val MAE: 59665.3938, Val MSE: 9256893348.7808, Val R2: 0.5297\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1298, Val Loss: 0.1648\n",
      "Val RMSE: 96364.3024, Val MAE: 59879.1569, Val MSE: 9286078774.7678, Val R2: 0.5282\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1231, Val Loss: 0.1481\n",
      "Val RMSE: 93733.3965, Val MAE: 55631.0265, Val MSE: 8785949624.2280, Val R2: 0.5536\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1229, Val Loss: 0.1628\n",
      "Val RMSE: 96400.7231, Val MAE: 57294.2550, Val MSE: 9293099410.4135, Val R2: 0.5279\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1226, Val Loss: 0.1461\n",
      "Val RMSE: 93427.9689, Val MAE: 54623.1468, Val MSE: 8728785374.0851, Val R2: 0.5565\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.1180, Val Loss: 0.1561\n",
      "Val RMSE: 95316.8567, Val MAE: 55245.4023, Val MSE: 9085303172.2820, Val R2: 0.5384\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.1159, Val Loss: 0.1548\n",
      "Val RMSE: 94534.8376, Val MAE: 58276.5580, Val MSE: 8936835521.7641, Val R2: 0.5460\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.1146, Val Loss: 0.1394\n",
      "Val RMSE: 92407.1740, Val MAE: 51413.1712, Val MSE: 8539085803.1730, Val R2: 0.5662\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.1121, Val Loss: 0.1372\n",
      "Val RMSE: 91189.8570, Val MAE: 51639.5190, Val MSE: 8315590024.8192, Val R2: 0.5775\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1381\n",
      "Val RMSE: 89870.3862, Val MAE: 53849.1903, Val MSE: 8076686310.1040, Val R2: 0.5897\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.1079, Val Loss: 0.1338\n",
      "Val RMSE: 90889.4281, Val MAE: 50486.7437, Val MSE: 8260888133.0514, Val R2: 0.5803\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.1083, Val Loss: 0.1343\n",
      "Val RMSE: 90127.9505, Val MAE: 50787.1538, Val MSE: 8123047464.3521, Val R2: 0.5873\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.1053, Val Loss: 0.1376\n",
      "Val RMSE: 92024.0986, Val MAE: 51242.4831, Val MSE: 8468434722.4901, Val R2: 0.5698\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.1047, Val Loss: 0.1428\n",
      "Val RMSE: 92116.4752, Val MAE: 53233.6609, Val MSE: 8485445009.7820, Val R2: 0.5689\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.1036, Val Loss: 0.1426\n",
      "Val RMSE: 93587.9080, Val MAE: 52304.5152, Val MSE: 8758696514.6091, Val R2: 0.5550\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.1021, Val Loss: 0.1519\n",
      "Val RMSE: 93264.9589, Val MAE: 55813.5211, Val MSE: 8698352554.7844, Val R2: 0.5581\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.1012, Val Loss: 0.1320\n",
      "Val RMSE: 89710.5954, Val MAE: 52674.9238, Val MSE: 8047990923.3018, Val R2: 0.5911\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0989, Val Loss: 0.1366\n",
      "Val RMSE: 91763.0004, Val MAE: 50415.8167, Val MSE: 8420448236.8743, Val R2: 0.5722\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1318\n",
      "Val RMSE: 90768.1703, Val MAE: 48147.3015, Val MSE: 8238860736.3843, Val R2: 0.5814\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0958, Val Loss: 0.1394\n",
      "Val RMSE: 92193.8150, Val MAE: 53325.0923, Val MSE: 8499699525.1643, Val R2: 0.5682\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0997, Val Loss: 0.1319\n",
      "Val RMSE: 90328.9893, Val MAE: 50184.5195, Val MSE: 8159326302.5522, Val R2: 0.5855\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0970, Val Loss: 0.1331\n",
      "Val RMSE: 91462.4128, Val MAE: 49902.2780, Val MSE: 8365372952.5152, Val R2: 0.5750\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0941, Val Loss: 0.1331\n",
      "Val RMSE: 90686.1494, Val MAE: 49422.5087, Val MSE: 8223977695.9271, Val R2: 0.5822\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0902, Val Loss: 0.1367\n",
      "Val RMSE: 90718.2686, Val MAE: 50704.9790, Val MSE: 8229804256.1798, Val R2: 0.5819\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1352\n",
      "Val RMSE: 89886.0205, Val MAE: 48886.9981, Val MSE: 8079496689.2362, Val R2: 0.5895\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0894, Val Loss: 0.1300\n",
      "Val RMSE: 87599.0496, Val MAE: 50702.9439, Val MSE: 7673593496.3882, Val R2: 0.6101\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1306\n",
      "Val RMSE: 87769.5675, Val MAE: 49273.8152, Val MSE: 7703496987.6223, Val R2: 0.6086\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0883, Val Loss: 0.1281\n",
      "Val RMSE: 88668.5282, Val MAE: 48054.1906, Val MSE: 7862107890.0134, Val R2: 0.6006\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1342\n",
      "Val RMSE: 90154.2551, Val MAE: 49409.3299, Val MSE: 8127789714.3325, Val R2: 0.5871\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0868, Val Loss: 0.1226\n",
      "Val RMSE: 88172.6037, Val MAE: 45767.1743, Val MSE: 7774408048.0859, Val R2: 0.6050\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0852, Val Loss: 0.1371\n",
      "Val RMSE: 91723.7681, Val MAE: 50379.3251, Val MSE: 8413249641.6656, Val R2: 0.5726\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1295\n",
      "Val RMSE: 89392.8933, Val MAE: 47929.7410, Val MSE: 7991089380.3393, Val R2: 0.5940\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1270\n",
      "Val RMSE: 87776.0734, Val MAE: 48783.3337, Val MSE: 7704639058.4185, Val R2: 0.6086\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1262\n",
      "Val RMSE: 87464.2512, Val MAE: 47873.7157, Val MSE: 7649995238.0971, Val R2: 0.6113\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0818, Val Loss: 0.1436\n",
      "Val RMSE: 93846.7314, Val MAE: 51264.1835, Val MSE: 8807208987.5532, Val R2: 0.5525\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0820, Val Loss: 0.1295\n",
      "Val RMSE: 91455.2862, Val MAE: 48185.1113, Val MSE: 8364069374.0972, Val R2: 0.5751\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0790, Val Loss: 0.1316\n",
      "Val RMSE: 89803.0380, Val MAE: 49560.1279, Val MSE: 8064585642.9685, Val R2: 0.5903\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1292\n",
      "Val RMSE: 88218.4599, Val MAE: 47840.9599, Val MSE: 7782496663.6973, Val R2: 0.6046\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1315\n",
      "Val RMSE: 90408.2158, Val MAE: 48477.6770, Val MSE: 8173645491.4297, Val R2: 0.5847\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1281\n",
      "Val RMSE: 87625.7407, Val MAE: 46938.3805, Val MSE: 7678270436.9488, Val R2: 0.6099\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0778, Val Loss: 0.1254\n",
      "Val RMSE: 89059.4981, Val MAE: 46751.1938, Val MSE: 7931594196.2870, Val R2: 0.5970\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1310\n",
      "Val RMSE: 85708.2347, Val MAE: 49346.5737, Val MSE: 7345901489.0686, Val R2: 0.6268\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 90969.8802, Test MAE: 48191.6973, Test MSE: 8275519106.5006, Test R2: 0.4695\n",
      "Inference Time: 4.764894338754507e-05 seconds per sample\n",
      "\n",
      "Iteration 95 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3507, Val Loss: 0.3024\n",
      "Val RMSE: 147504.0615, Val MAE: 81788.6693, Val MSE: 21757448173.3740, Val R2: -0.1054\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2780, Val Loss: 0.2760\n",
      "Val RMSE: 141021.3163, Val MAE: 85189.7080, Val MSE: 19887011659.4855, Val R2: -0.0104\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2705, Val Loss: 0.2753\n",
      "Val RMSE: 140948.4970, Val MAE: 84922.5235, Val MSE: 19866478812.3814, Val R2: -0.0093\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2669, Val Loss: 0.2782\n",
      "Val RMSE: 141983.7644, Val MAE: 84647.1689, Val MSE: 20159389346.3753, Val R2: -0.0242\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2678, Val Loss: 0.2764\n",
      "Val RMSE: 142753.1679, Val MAE: 81371.8977, Val MSE: 20378466950.4864, Val R2: -0.0354\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2639, Val Loss: 0.2760\n",
      "Val RMSE: 140722.3858, Val MAE: 86160.9853, Val MSE: 19802789873.2394, Val R2: -0.0061\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2612, Val Loss: 0.2730\n",
      "Val RMSE: 141181.0131, Val MAE: 84136.8507, Val MSE: 19932078468.8734, Val R2: -0.0127\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2611, Val Loss: 0.2810\n",
      "Val RMSE: 143935.6466, Val MAE: 80355.7781, Val MSE: 20717470375.1471, Val R2: -0.0526\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2770\n",
      "Val RMSE: 144098.4025, Val MAE: 79534.1704, Val MSE: 20764349611.3390, Val R2: -0.0550\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2577, Val Loss: 0.2718\n",
      "Val RMSE: 140896.5077, Val MAE: 83625.9080, Val MSE: 19851825881.6020, Val R2: -0.0086\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2540, Val Loss: 0.2692\n",
      "Val RMSE: 141875.3156, Val MAE: 80487.0307, Val MSE: 20128605169.0159, Val R2: -0.0227\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2535, Val Loss: 0.2724\n",
      "Val RMSE: 142827.5433, Val MAE: 80292.8307, Val MSE: 20399707120.0710, Val R2: -0.0364\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2518, Val Loss: 0.2633\n",
      "Val RMSE: 140071.4459, Val MAE: 77409.9022, Val MSE: 19620009955.4575, Val R2: 0.0032\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2422, Val Loss: 0.2573\n",
      "Val RMSE: 136440.8467, Val MAE: 79668.4209, Val MSE: 18616104649.3792, Val R2: 0.0542\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2387, Val Loss: 0.2583\n",
      "Val RMSE: 135838.4970, Val MAE: 78407.6041, Val MSE: 18452097271.2832, Val R2: 0.0625\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2347, Val Loss: 0.2425\n",
      "Val RMSE: 131985.5110, Val MAE: 78669.7765, Val MSE: 17420175111.8046, Val R2: 0.1149\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2262, Val Loss: 0.2336\n",
      "Val RMSE: 130822.2266, Val MAE: 74572.7148, Val MSE: 17114454980.2752, Val R2: 0.1305\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2202, Val Loss: 0.2392\n",
      "Val RMSE: 130757.3698, Val MAE: 77579.1095, Val MSE: 17097489746.0300, Val R2: 0.1313\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2195, Val Loss: 0.2357\n",
      "Val RMSE: 132138.2404, Val MAE: 73553.7779, Val MSE: 17460514575.7104, Val R2: 0.1129\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2159, Val Loss: 0.2439\n",
      "Val RMSE: 130746.9408, Val MAE: 79265.6267, Val MSE: 17094762537.5120, Val R2: 0.1315\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2134, Val Loss: 0.2281\n",
      "Val RMSE: 129346.3488, Val MAE: 71715.1331, Val MSE: 16730477951.8716, Val R2: 0.1500\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2080, Val Loss: 0.2235\n",
      "Val RMSE: 128887.2752, Val MAE: 71641.0368, Val MSE: 16611929706.4718, Val R2: 0.1560\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2058, Val Loss: 0.2257\n",
      "Val RMSE: 128488.1146, Val MAE: 71120.4291, Val MSE: 16509195601.9231, Val R2: 0.1612\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2059, Val Loss: 0.2303\n",
      "Val RMSE: 129645.0055, Val MAE: 72565.3004, Val MSE: 16807827456.8820, Val R2: 0.1461\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1966, Val Loss: 0.2307\n",
      "Val RMSE: 128074.8251, Val MAE: 69644.0992, Val MSE: 16403160814.9548, Val R2: 0.1666\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1967, Val Loss: 0.2157\n",
      "Val RMSE: 119543.9946, Val MAE: 71257.0114, Val MSE: 14290766639.8015, Val R2: 0.2739\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1914, Val Loss: 0.2284\n",
      "Val RMSE: 126123.5634, Val MAE: 72306.8266, Val MSE: 15907153248.8057, Val R2: 0.1918\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1832, Val Loss: 0.2051\n",
      "Val RMSE: 114760.0645, Val MAE: 66567.3311, Val MSE: 13169872401.1532, Val R2: 0.3309\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1776, Val Loss: 0.1914\n",
      "Val RMSE: 108463.0731, Val MAE: 63332.2098, Val MSE: 11764238219.0552, Val R2: 0.4023\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1727, Val Loss: 0.1942\n",
      "Val RMSE: 107336.7525, Val MAE: 62983.8372, Val MSE: 11521178437.6736, Val R2: 0.4147\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1629, Val Loss: 0.1743\n",
      "Val RMSE: 101104.7099, Val MAE: 60331.2831, Val MSE: 10222162368.2243, Val R2: 0.4806\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1546, Val Loss: 0.1528\n",
      "Val RMSE: 96213.7730, Val MAE: 55646.4078, Val MSE: 9257090109.1130, Val R2: 0.5297\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1473, Val Loss: 0.1522\n",
      "Val RMSE: 95365.0909, Val MAE: 56679.6403, Val MSE: 9094500567.3044, Val R2: 0.5379\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1450, Val Loss: 0.1603\n",
      "Val RMSE: 99026.2674, Val MAE: 56838.6599, Val MSE: 9806201642.5296, Val R2: 0.5018\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1417, Val Loss: 0.1547\n",
      "Val RMSE: 97241.7558, Val MAE: 56094.4999, Val MSE: 9455959068.3533, Val R2: 0.5196\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1357, Val Loss: 0.1488\n",
      "Val RMSE: 99694.3977, Val MAE: 54475.1575, Val MSE: 9938972923.4715, Val R2: 0.4950\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1421, Val Loss: 0.1391\n",
      "Val RMSE: 91816.5413, Val MAE: 52711.7654, Val MSE: 8430277258.1839, Val R2: 0.5717\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1318, Val Loss: 0.1461\n",
      "Val RMSE: 94923.5123, Val MAE: 54661.7878, Val MSE: 9010473193.0436, Val R2: 0.5422\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1212, Val Loss: 0.1511\n",
      "Val RMSE: 97176.5925, Val MAE: 55933.6651, Val MSE: 9443290134.0756, Val R2: 0.5202\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1106, Val Loss: 0.1348\n",
      "Val RMSE: 92063.7820, Val MAE: 49767.3330, Val MSE: 8475739956.1840, Val R2: 0.5694\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1034, Val Loss: 0.1314\n",
      "Val RMSE: 90827.0811, Val MAE: 50061.3915, Val MSE: 8249558654.2410, Val R2: 0.5809\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0987, Val Loss: 0.1333\n",
      "Val RMSE: 90692.7735, Val MAE: 50816.6035, Val MSE: 8225179159.9847, Val R2: 0.5821\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1331\n",
      "Val RMSE: 89995.5718, Val MAE: 51120.2419, Val MSE: 8099202946.3419, Val R2: 0.5885\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0952, Val Loss: 0.1332\n",
      "Val RMSE: 88555.0545, Val MAE: 49716.6301, Val MSE: 7841997670.8275, Val R2: 0.6016\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0929, Val Loss: 0.1190\n",
      "Val RMSE: 83104.7981, Val MAE: 46638.1931, Val MSE: 6906407466.1749, Val R2: 0.6491\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1358\n",
      "Val RMSE: 87003.5672, Val MAE: 51679.8607, Val MSE: 7569620703.8806, Val R2: 0.6154\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0853, Val Loss: 0.1225\n",
      "Val RMSE: 81711.7983, Val MAE: 46983.2871, Val MSE: 6676817988.3948, Val R2: 0.6608\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1222\n",
      "Val RMSE: 80994.7416, Val MAE: 47207.3135, Val MSE: 6560148161.2180, Val R2: 0.6667\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0791, Val Loss: 0.1246\n",
      "Val RMSE: 79185.8377, Val MAE: 48164.5061, Val MSE: 6270396892.7007, Val R2: 0.6814\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0784, Val Loss: 0.1261\n",
      "Val RMSE: 82377.7787, Val MAE: 46619.6265, Val MSE: 6786098428.8244, Val R2: 0.6552\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0762, Val Loss: 0.1310\n",
      "Val RMSE: 81154.9470, Val MAE: 46791.7648, Val MSE: 6586125422.1787, Val R2: 0.6654\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1161\n",
      "Val RMSE: 76802.4343, Val MAE: 46475.4593, Val MSE: 5898613909.4947, Val R2: 0.7003\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0719, Val Loss: 0.1320\n",
      "Val RMSE: 81315.4295, Val MAE: 48576.2447, Val MSE: 6612199081.6577, Val R2: 0.6641\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0706, Val Loss: 0.1383\n",
      "Val RMSE: 84183.3589, Val MAE: 51940.2070, Val MSE: 7086837910.8246, Val R2: 0.6399\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0688, Val Loss: 0.1259\n",
      "Val RMSE: 81698.0167, Val MAE: 46845.7927, Val MSE: 6674565938.6590, Val R2: 0.6609\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0702, Val Loss: 0.1168\n",
      "Val RMSE: 77515.8392, Val MAE: 47265.4987, Val MSE: 6008705332.0279, Val R2: 0.6947\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0654, Val Loss: 0.1172\n",
      "Val RMSE: 75947.8430, Val MAE: 45627.3467, Val MSE: 5768074854.7978, Val R2: 0.7069\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1224\n",
      "Val RMSE: 77099.6373, Val MAE: 46731.0988, Val MSE: 5944354066.7110, Val R2: 0.6980\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1200\n",
      "Val RMSE: 78617.2864, Val MAE: 46483.1542, Val MSE: 6180677721.1956, Val R2: 0.6860\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1233\n",
      "Val RMSE: 77610.3479, Val MAE: 45749.2549, Val MSE: 6023366099.8988, Val R2: 0.6940\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1155\n",
      "Val RMSE: 74529.1266, Val MAE: 45637.9235, Val MSE: 5554590707.8251, Val R2: 0.7178\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0602, Val Loss: 0.1272\n",
      "Val RMSE: 78417.6477, Val MAE: 49465.4218, Val MSE: 6149327465.7964, Val R2: 0.6876\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1167\n",
      "Val RMSE: 74583.3857, Val MAE: 47115.7532, Val MSE: 5562681415.2316, Val R2: 0.7174\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1153\n",
      "Val RMSE: 75257.9199, Val MAE: 45946.6083, Val MSE: 5663754509.7905, Val R2: 0.7122\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1146\n",
      "Val RMSE: 73479.8328, Val MAE: 45197.7522, Val MSE: 5399285820.9835, Val R2: 0.7257\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0558, Val Loss: 0.1311\n",
      "Val RMSE: 78606.6045, Val MAE: 49753.2080, Val MSE: 6178998276.2857, Val R2: 0.6861\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1247\n",
      "Val RMSE: 75931.7681, Val MAE: 51076.2511, Val MSE: 5765633408.8247, Val R2: 0.7071\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1200\n",
      "Val RMSE: 74847.0402, Val MAE: 46649.7586, Val MSE: 5602079427.7548, Val R2: 0.7154\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0532, Val Loss: 0.1161\n",
      "Val RMSE: 73417.6948, Val MAE: 46777.9895, Val MSE: 5390157903.4621, Val R2: 0.7261\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1163\n",
      "Val RMSE: 71815.8374, Val MAE: 45921.2300, Val MSE: 5157514501.3229, Val R2: 0.7380\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1128\n",
      "Val RMSE: 71512.7566, Val MAE: 44596.7956, Val MSE: 5114074358.0259, Val R2: 0.7402\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1162\n",
      "Val RMSE: 72832.9030, Val MAE: 46529.0386, Val MSE: 5304631766.1476, Val R2: 0.7305\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1198\n",
      "Val RMSE: 75395.2898, Val MAE: 45412.1141, Val MSE: 5684449726.3605, Val R2: 0.7112\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0508, Val Loss: 0.1182\n",
      "Val RMSE: 72814.2432, Val MAE: 44742.6332, Val MSE: 5301914006.4666, Val R2: 0.7306\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1236\n",
      "Val RMSE: 75228.4345, Val MAE: 46180.4255, Val MSE: 5659317354.0934, Val R2: 0.7125\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0492, Val Loss: 0.1162\n",
      "Val RMSE: 72659.9690, Val MAE: 45722.2749, Val MSE: 5279471094.9550, Val R2: 0.7318\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1159\n",
      "Val RMSE: 72165.0321, Val MAE: 45417.4072, Val MSE: 5207791863.7978, Val R2: 0.7354\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1156\n",
      "Val RMSE: 71654.7535, Val MAE: 44879.6668, Val MSE: 5134403702.0270, Val R2: 0.7391\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1164\n",
      "Val RMSE: 72380.7349, Val MAE: 45120.0298, Val MSE: 5238970789.6429, Val R2: 0.7338\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1117\n",
      "Val RMSE: 71216.0899, Val MAE: 45905.4523, Val MSE: 5071731453.9100, Val R2: 0.7423\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1154\n",
      "Val RMSE: 72940.9185, Val MAE: 46901.7415, Val MSE: 5320377592.1167, Val R2: 0.7297\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0455, Val Loss: 0.1133\n",
      "Val RMSE: 72088.3214, Val MAE: 45806.8203, Val MSE: 5196726088.8708, Val R2: 0.7360\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0472, Val Loss: 0.1218\n",
      "Val RMSE: 74992.7399, Val MAE: 48274.6341, Val MSE: 5623911030.9917, Val R2: 0.7143\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.1225\n",
      "Val RMSE: 74263.3964, Val MAE: 47357.6612, Val MSE: 5515052038.7369, Val R2: 0.7198\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0456, Val Loss: 0.1222\n",
      "Val RMSE: 75625.2324, Val MAE: 48303.7507, Val MSE: 5719175781.3034, Val R2: 0.7094\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1295\n",
      "Val RMSE: 77811.2741, Val MAE: 51031.7960, Val MSE: 6054594380.2467, Val R2: 0.6924\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0441, Val Loss: 0.1428\n",
      "Val RMSE: 82300.8810, Val MAE: 54223.5648, Val MSE: 6773435020.9625, Val R2: 0.6559\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0448, Val Loss: 0.1179\n",
      "Val RMSE: 73336.5220, Val MAE: 46442.7941, Val MSE: 5378245460.2983, Val R2: 0.7268\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0440, Val Loss: 0.1274\n",
      "Val RMSE: 75112.1260, Val MAE: 46557.4442, Val MSE: 5641831474.3656, Val R2: 0.7134\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0443, Val Loss: 0.1154\n",
      "Val RMSE: 72471.6190, Val MAE: 46349.0424, Val MSE: 5252135554.4684, Val R2: 0.7332\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0425, Val Loss: 0.1223\n",
      "Val RMSE: 74701.5465, Val MAE: 46535.0223, Val MSE: 5580321048.5518, Val R2: 0.7165\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0430, Val Loss: 0.1171\n",
      "Val RMSE: 73319.1012, Val MAE: 46144.9952, Val MSE: 5375690599.2903, Val R2: 0.7269\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0417, Val Loss: 0.1145\n",
      "Val RMSE: 72458.0135, Val MAE: 46596.2655, Val MSE: 5250163723.5656, Val R2: 0.7333\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0432, Val Loss: 0.1280\n",
      "Val RMSE: 77528.1074, Val MAE: 48329.4909, Val MSE: 6010607434.0006, Val R2: 0.6946\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0414, Val Loss: 0.1214\n",
      "Val RMSE: 74975.0095, Val MAE: 46291.7364, Val MSE: 5621252047.3925, Val R2: 0.7144\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0404, Val Loss: 0.1230\n",
      "Val RMSE: 75039.9848, Val MAE: 46963.0355, Val MSE: 5630999325.4868, Val R2: 0.7139\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0421, Val Loss: 0.1251\n",
      "Val RMSE: 75594.8683, Val MAE: 50584.7111, Val MSE: 5714584117.4809, Val R2: 0.7097\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0420, Val Loss: 0.1284\n",
      "Val RMSE: 77936.8453, Val MAE: 49762.5878, Val MSE: 6074151850.3892, Val R2: 0.6914\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0413, Val Loss: 0.1154\n",
      "Val RMSE: 73298.3844, Val MAE: 47617.0413, Val MSE: 5372653153.4355, Val R2: 0.7270\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0407, Val Loss: 0.1214\n",
      "Val RMSE: 74439.6526, Val MAE: 48812.7874, Val MSE: 5541261875.8190, Val R2: 0.7185\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 80277.7704, Test MAE: 47240.7012, Test MSE: 6444520414.9180, Test R2: 0.5869\n",
      "Inference Time: 6.18283198429988e-05 seconds per sample\n",
      "\n",
      "Iteration 96 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3591, Val Loss: 0.3007\n",
      "Val RMSE: 146688.7665, Val MAE: 82667.1327, Val MSE: 21517594218.8391, Val R2: -0.0932\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2792, Val Loss: 0.2936\n",
      "Val RMSE: 145030.9038, Val MAE: 82998.0247, Val MSE: 21033963052.3769, Val R2: -0.0687\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2750, Val Loss: 0.2831\n",
      "Val RMSE: 142477.7481, Val MAE: 84283.3662, Val MSE: 20299908690.4503, Val R2: -0.0314\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2689, Val Loss: 0.2776\n",
      "Val RMSE: 142576.7714, Val MAE: 82236.2530, Val MSE: 20328135730.9333, Val R2: -0.0328\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2666, Val Loss: 0.2746\n",
      "Val RMSE: 141119.8806, Val MAE: 84161.8807, Val MSE: 19914820699.3617, Val R2: -0.0118\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2654, Val Loss: 0.2755\n",
      "Val RMSE: 140066.1857, Val MAE: 87054.2283, Val MSE: 19618536382.1927, Val R2: 0.0033\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2626, Val Loss: 0.2737\n",
      "Val RMSE: 141779.9054, Val MAE: 81737.1868, Val MSE: 20101541578.3750, Val R2: -0.0213\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2743\n",
      "Val RMSE: 141982.4399, Val MAE: 82660.8903, Val MSE: 20159013252.9322, Val R2: -0.0242\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2563, Val Loss: 0.2723\n",
      "Val RMSE: 142512.2619, Val MAE: 80201.1669, Val MSE: 20309744778.7552, Val R2: -0.0319\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2575, Val Loss: 0.2696\n",
      "Val RMSE: 142085.0046, Val MAE: 80236.6047, Val MSE: 20188148525.0556, Val R2: -0.0257\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2581, Val Loss: 0.2690\n",
      "Val RMSE: 140896.4355, Val MAE: 82097.7389, Val MSE: 19851805524.0676, Val R2: -0.0086\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2544, Val Loss: 0.2735\n",
      "Val RMSE: 141786.5567, Val MAE: 82720.4048, Val MSE: 20103427670.7537, Val R2: -0.0214\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2524, Val Loss: 0.2679\n",
      "Val RMSE: 142484.9668, Val MAE: 78717.7818, Val MSE: 20301965753.7057, Val R2: -0.0315\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2516, Val Loss: 0.2715\n",
      "Val RMSE: 143268.7501, Val MAE: 78047.4711, Val MSE: 20525934758.5954, Val R2: -0.0428\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2489, Val Loss: 0.2704\n",
      "Val RMSE: 142615.8404, Val MAE: 79343.8385, Val MSE: 20339277924.6208, Val R2: -0.0334\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2495, Val Loss: 0.2702\n",
      "Val RMSE: 143301.8896, Val MAE: 78721.9723, Val MSE: 20535431573.7562, Val R2: -0.0433\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2462, Val Loss: 0.2685\n",
      "Val RMSE: 142742.3531, Val MAE: 77986.7447, Val MSE: 20375379376.1494, Val R2: -0.0352\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2432, Val Loss: 0.2950\n",
      "Val RMSE: 142862.0054, Val MAE: 88126.6444, Val MSE: 20409552577.2376, Val R2: -0.0369\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2478, Val Loss: 0.2669\n",
      "Val RMSE: 139691.8000, Val MAE: 82176.4176, Val MSE: 19513798984.4922, Val R2: 0.0086\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2432, Val Loss: 0.2674\n",
      "Val RMSE: 140583.5038, Val MAE: 81052.3496, Val MSE: 19763721537.0610, Val R2: -0.0041\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2397, Val Loss: 0.2726\n",
      "Val RMSE: 142369.6517, Val MAE: 80459.3559, Val MSE: 20269117717.9165, Val R2: -0.0298\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2402, Val Loss: 0.2598\n",
      "Val RMSE: 138777.5849, Val MAE: 78249.6316, Val MSE: 19259218070.2441, Val R2: 0.0215\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2292, Val Loss: 0.2532\n",
      "Val RMSE: 133527.6966, Val MAE: 76777.6783, Val MSE: 17829645769.3398, Val R2: 0.0941\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2224, Val Loss: 0.2336\n",
      "Val RMSE: 131267.7124, Val MAE: 75040.4707, Val MSE: 17231212312.4110, Val R2: 0.1245\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.2122, Val Loss: 0.2530\n",
      "Val RMSE: 131942.4155, Val MAE: 80405.7206, Val MSE: 17408800995.9084, Val R2: 0.1155\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.2071, Val Loss: 0.2260\n",
      "Val RMSE: 127566.3339, Val MAE: 75095.1738, Val MSE: 16273169548.5075, Val R2: 0.1732\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.2068, Val Loss: 0.2294\n",
      "Val RMSE: 130595.0163, Val MAE: 73713.7347, Val MSE: 17055058275.1351, Val R2: 0.1335\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.2008, Val Loss: 0.2258\n",
      "Val RMSE: 129578.9224, Val MAE: 70334.1540, Val MSE: 16790697128.9351, Val R2: 0.1469\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1984, Val Loss: 0.2284\n",
      "Val RMSE: 128981.7996, Val MAE: 73261.6001, Val MSE: 16636304632.1228, Val R2: 0.1548\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1962, Val Loss: 0.2414\n",
      "Val RMSE: 130894.4614, Val MAE: 75361.2928, Val MSE: 17133360024.6972, Val R2: 0.1295\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1924, Val Loss: 0.2252\n",
      "Val RMSE: 127850.9423, Val MAE: 70771.7931, Val MSE: 16345863436.7041, Val R2: 0.1695\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1817, Val Loss: 0.2153\n",
      "Val RMSE: 121715.7767, Val MAE: 69391.7368, Val MSE: 14814730307.7912, Val R2: 0.2473\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1779, Val Loss: 0.2014\n",
      "Val RMSE: 112392.7643, Val MAE: 67254.3213, Val MSE: 12632133467.9182, Val R2: 0.3582\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1766, Val Loss: 0.2036\n",
      "Val RMSE: 110421.8308, Val MAE: 67438.1365, Val MSE: 12192980709.5415, Val R2: 0.3805\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1693, Val Loss: 0.1863\n",
      "Val RMSE: 106702.9669, Val MAE: 61261.3225, Val MSE: 11385523136.2460, Val R2: 0.4215\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1630, Val Loss: 0.1763\n",
      "Val RMSE: 102184.2949, Val MAE: 60856.7082, Val MSE: 10441630114.9569, Val R2: 0.4695\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1608, Val Loss: 0.1775\n",
      "Val RMSE: 102231.4934, Val MAE: 60333.9819, Val MSE: 10451278235.5544, Val R2: 0.4690\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1561, Val Loss: 0.1638\n",
      "Val RMSE: 97913.1420, Val MAE: 58558.4037, Val MSE: 9586983384.6540, Val R2: 0.5129\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1527, Val Loss: 0.1701\n",
      "Val RMSE: 98722.0688, Val MAE: 57495.5665, Val MSE: 9746046859.0919, Val R2: 0.5048\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1618\n",
      "Val RMSE: 96711.1245, Val MAE: 56414.4062, Val MSE: 9353041593.3186, Val R2: 0.5248\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1399, Val Loss: 0.1526\n",
      "Val RMSE: 96088.0707, Val MAE: 53448.1150, Val MSE: 9232917331.8045, Val R2: 0.5309\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1354, Val Loss: 0.1462\n",
      "Val RMSE: 93856.0957, Val MAE: 52844.2404, Val MSE: 8808966695.6526, Val R2: 0.5524\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1242, Val Loss: 0.1623\n",
      "Val RMSE: 96015.3570, Val MAE: 56527.4657, Val MSE: 9218948781.4677, Val R2: 0.5316\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1217, Val Loss: 0.1556\n",
      "Val RMSE: 95913.3855, Val MAE: 52088.0145, Val MSE: 9199377513.0058, Val R2: 0.5326\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1173, Val Loss: 0.1589\n",
      "Val RMSE: 95331.3966, Val MAE: 53659.3908, Val MSE: 9088075173.7745, Val R2: 0.5383\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1097, Val Loss: 0.1667\n",
      "Val RMSE: 96067.5729, Val MAE: 59101.4570, Val MSE: 9228978571.2155, Val R2: 0.5311\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1478\n",
      "Val RMSE: 92150.5631, Val MAE: 54134.7844, Val MSE: 8491726271.4953, Val R2: 0.5686\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1013, Val Loss: 0.1558\n",
      "Val RMSE: 92856.3394, Val MAE: 55216.8648, Val MSE: 8622299758.3453, Val R2: 0.5619\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1001, Val Loss: 0.1511\n",
      "Val RMSE: 91286.3300, Val MAE: 55823.4885, Val MSE: 8333194039.9538, Val R2: 0.5766\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0980, Val Loss: 0.1503\n",
      "Val RMSE: 91342.4019, Val MAE: 53959.2095, Val MSE: 8343434384.0533, Val R2: 0.5761\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0952, Val Loss: 0.1447\n",
      "Val RMSE: 89032.8754, Val MAE: 50606.8570, Val MSE: 7926852899.1526, Val R2: 0.5973\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0947, Val Loss: 0.1415\n",
      "Val RMSE: 88288.4375, Val MAE: 50653.0674, Val MSE: 7794848204.0947, Val R2: 0.6040\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0900, Val Loss: 0.1448\n",
      "Val RMSE: 90732.4748, Val MAE: 51393.7595, Val MSE: 8232381984.6125, Val R2: 0.5817\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0907, Val Loss: 0.1409\n",
      "Val RMSE: 86746.8725, Val MAE: 50341.6416, Val MSE: 7525019896.9075, Val R2: 0.6177\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0884, Val Loss: 0.1481\n",
      "Val RMSE: 89577.8474, Val MAE: 50521.7050, Val MSE: 8024190749.8903, Val R2: 0.5923\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0879, Val Loss: 0.1424\n",
      "Val RMSE: 84634.7091, Val MAE: 51744.8310, Val MSE: 7163033990.3564, Val R2: 0.6361\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0854, Val Loss: 0.1440\n",
      "Val RMSE: 85239.5126, Val MAE: 48054.2846, Val MSE: 7265774512.4199, Val R2: 0.6309\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0846, Val Loss: 0.1387\n",
      "Val RMSE: 86686.8452, Val MAE: 48534.0588, Val MSE: 7514609130.8398, Val R2: 0.6182\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0834, Val Loss: 0.1382\n",
      "Val RMSE: 84215.7996, Val MAE: 49352.6821, Val MSE: 7092300902.9448, Val R2: 0.6397\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0801, Val Loss: 0.1343\n",
      "Val RMSE: 80742.3212, Val MAE: 49511.4218, Val MSE: 6519322440.0043, Val R2: 0.6688\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0797, Val Loss: 0.1422\n",
      "Val RMSE: 84677.9950, Val MAE: 51489.1763, Val MSE: 7170362844.9127, Val R2: 0.6357\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0789, Val Loss: 0.1396\n",
      "Val RMSE: 82664.8216, Val MAE: 51200.3884, Val MSE: 6833472735.7572, Val R2: 0.6528\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0776, Val Loss: 0.1377\n",
      "Val RMSE: 81212.5263, Val MAE: 49509.9574, Val MSE: 6595474421.6716, Val R2: 0.6649\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0759, Val Loss: 0.1334\n",
      "Val RMSE: 79152.2004, Val MAE: 50021.5556, Val MSE: 6265070833.9141, Val R2: 0.6817\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0743, Val Loss: 0.1378\n",
      "Val RMSE: 79881.6097, Val MAE: 52648.7243, Val MSE: 6381071565.3736, Val R2: 0.6758\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0745, Val Loss: 0.1568\n",
      "Val RMSE: 84616.5582, Val MAE: 55466.6120, Val MSE: 7159961925.1695, Val R2: 0.6362\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1364\n",
      "Val RMSE: 81977.7739, Val MAE: 46862.7300, Val MSE: 6720355410.3404, Val R2: 0.6586\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0709, Val Loss: 0.1383\n",
      "Val RMSE: 79087.0343, Val MAE: 50886.9814, Val MSE: 6254758994.5075, Val R2: 0.6822\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0713, Val Loss: 0.1405\n",
      "Val RMSE: 83035.5329, Val MAE: 50980.7359, Val MSE: 6894899730.3189, Val R2: 0.6497\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1289\n",
      "Val RMSE: 76640.6779, Val MAE: 46830.1345, Val MSE: 5873793515.8094, Val R2: 0.7016\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0680, Val Loss: 0.1320\n",
      "Val RMSE: 77565.8950, Val MAE: 48230.1480, Val MSE: 6016468073.6655, Val R2: 0.6943\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1322\n",
      "Val RMSE: 78944.6278, Val MAE: 48218.8115, Val MSE: 6232254251.1615, Val R2: 0.6834\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0647, Val Loss: 0.1330\n",
      "Val RMSE: 75097.8829, Val MAE: 45940.5014, Val MSE: 5639692008.9771, Val R2: 0.7135\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0664, Val Loss: 0.1346\n",
      "Val RMSE: 80492.4492, Val MAE: 49861.9687, Val MSE: 6479034381.1832, Val R2: 0.6708\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0653, Val Loss: 0.1252\n",
      "Val RMSE: 75175.3905, Val MAE: 44695.3386, Val MSE: 5651339336.4473, Val R2: 0.7129\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1282\n",
      "Val RMSE: 77826.6531, Val MAE: 46246.1975, Val MSE: 6056987938.3546, Val R2: 0.6923\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1550\n",
      "Val RMSE: 87304.4533, Val MAE: 51852.3334, Val MSE: 7622067564.5650, Val R2: 0.6128\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1284\n",
      "Val RMSE: 76265.6377, Val MAE: 46570.4939, Val MSE: 5816447498.4211, Val R2: 0.7045\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1330\n",
      "Val RMSE: 79737.0685, Val MAE: 46753.6631, Val MSE: 6358000099.2910, Val R2: 0.6770\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1397\n",
      "Val RMSE: 82226.0913, Val MAE: 48353.1396, Val MSE: 6761130087.8786, Val R2: 0.6565\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1311\n",
      "Val RMSE: 78262.7368, Val MAE: 48665.6697, Val MSE: 6125055964.0285, Val R2: 0.6888\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0578, Val Loss: 0.1297\n",
      "Val RMSE: 77665.2030, Val MAE: 45626.7563, Val MSE: 6031883758.3660, Val R2: 0.6935\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1241\n",
      "Val RMSE: 75855.7674, Val MAE: 45596.7567, Val MSE: 5754097448.0528, Val R2: 0.7077\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1284\n",
      "Val RMSE: 76408.2608, Val MAE: 47684.4819, Val MSE: 5838222324.6533, Val R2: 0.7034\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0540, Val Loss: 0.1253\n",
      "Val RMSE: 76249.2098, Val MAE: 45648.8865, Val MSE: 5813941987.9342, Val R2: 0.7046\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0519, Val Loss: 0.1277\n",
      "Val RMSE: 76979.6827, Val MAE: 45294.2998, Val MSE: 5925871550.9996, Val R2: 0.6989\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1355\n",
      "Val RMSE: 78403.2202, Val MAE: 46410.0163, Val MSE: 6147064942.9660, Val R2: 0.6877\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0539, Val Loss: 0.1283\n",
      "Val RMSE: 77995.2100, Val MAE: 46070.1404, Val MSE: 6083252787.1556, Val R2: 0.6909\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0538, Val Loss: 0.1264\n",
      "Val RMSE: 76490.7636, Val MAE: 45668.5625, Val MSE: 5850836915.2816, Val R2: 0.7027\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1271\n",
      "Val RMSE: 78558.2769, Val MAE: 46309.1258, Val MSE: 6171402867.6013, Val R2: 0.6865\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1433\n",
      "Val RMSE: 81112.2782, Val MAE: 51393.5119, Val MSE: 6579201679.9994, Val R2: 0.6657\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1259\n",
      "Val RMSE: 75867.5911, Val MAE: 46330.4327, Val MSE: 5755891382.9038, Val R2: 0.7076\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0499, Val Loss: 0.1297\n",
      "Val RMSE: 77426.3531, Val MAE: 45736.5541, Val MSE: 5994840148.4760, Val R2: 0.6954\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0498, Val Loss: 0.1284\n",
      "Val RMSE: 76907.8990, Val MAE: 46442.3436, Val MSE: 5914824933.7380, Val R2: 0.6995\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1214\n",
      "Val RMSE: 74767.3510, Val MAE: 45200.4935, Val MSE: 5590156780.0966, Val R2: 0.7160\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1284\n",
      "Val RMSE: 78083.3231, Val MAE: 47986.8972, Val MSE: 6097005350.4897, Val R2: 0.6902\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1136\n",
      "Val RMSE: 71695.6175, Val MAE: 43911.0521, Val MSE: 5140261568.5322, Val R2: 0.7388\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1169\n",
      "Val RMSE: 73555.5417, Val MAE: 44108.8483, Val MSE: 5410417714.3728, Val R2: 0.7251\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1348\n",
      "Val RMSE: 77392.8373, Val MAE: 45105.8466, Val MSE: 5989651266.0440, Val R2: 0.6957\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0482, Val Loss: 0.1217\n",
      "Val RMSE: 75585.3789, Val MAE: 43616.9678, Val MSE: 5713149505.1946, Val R2: 0.7097\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83311.9817, Test MAE: 48127.1700, Test MSE: 6940886302.5023, Test R2: 0.5551\n",
      "Inference Time: 5.0410123971792366e-05 seconds per sample\n",
      "\n",
      "Iteration 97 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3837, Val Loss: 0.2962\n",
      "Val RMSE: 145424.9128, Val MAE: 83192.9357, Val MSE: 21148405274.5650, Val R2: -0.0745\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2824, Val Loss: 0.2983\n",
      "Val RMSE: 146016.5125, Val MAE: 82946.0917, Val MSE: 21320821936.4147, Val R2: -0.0832\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2761, Val Loss: 0.2868\n",
      "Val RMSE: 142892.9146, Val MAE: 84713.8611, Val MSE: 20418385056.3500, Val R2: -0.0374\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2719, Val Loss: 0.2816\n",
      "Val RMSE: 141974.0375, Val MAE: 84832.8674, Val MSE: 20156627331.9785, Val R2: -0.0241\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2677, Val Loss: 0.2754\n",
      "Val RMSE: 141228.8799, Val MAE: 85316.9038, Val MSE: 19945596524.1592, Val R2: -0.0134\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2639, Val Loss: 0.2817\n",
      "Val RMSE: 144164.7463, Val MAE: 80650.7134, Val MSE: 20783474063.9231, Val R2: -0.0559\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2749\n",
      "Val RMSE: 142559.5666, Val MAE: 81207.2847, Val MSE: 20323230025.1930, Val R2: -0.0325\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2594, Val Loss: 0.2758\n",
      "Val RMSE: 141394.5321, Val MAE: 85208.7709, Val MSE: 19992413721.9103, Val R2: -0.0157\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2590, Val Loss: 0.2738\n",
      "Val RMSE: 140766.6328, Val MAE: 85011.1371, Val MSE: 19815244909.1945, Val R2: -0.0067\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2561, Val Loss: 0.2760\n",
      "Val RMSE: 142029.1582, Val MAE: 83780.7379, Val MSE: 20172281770.7818, Val R2: -0.0249\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2536, Val Loss: 0.2684\n",
      "Val RMSE: 140900.7914, Val MAE: 82213.2092, Val MSE: 19853033022.1756, Val R2: -0.0087\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2525, Val Loss: 0.2673\n",
      "Val RMSE: 141128.9550, Val MAE: 80802.4004, Val MSE: 19917381933.6208, Val R2: -0.0119\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2644\n",
      "Val RMSE: 141458.4454, Val MAE: 78746.1358, Val MSE: 20010491781.0501, Val R2: -0.0167\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2485, Val Loss: 0.2634\n",
      "Val RMSE: 140458.6231, Val MAE: 79867.2186, Val MSE: 19728624789.4287, Val R2: -0.0023\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2479, Val Loss: 0.2610\n",
      "Val RMSE: 138520.5440, Val MAE: 75931.1460, Val MSE: 19187941115.1058, Val R2: 0.0251\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2346, Val Loss: 0.2363\n",
      "Val RMSE: 132452.2389, Val MAE: 73265.6820, Val MSE: 17543595591.9608, Val R2: 0.1087\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2232, Val Loss: 0.2306\n",
      "Val RMSE: 131203.0501, Val MAE: 71287.7452, Val MSE: 17214240351.1298, Val R2: 0.1254\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2199, Val Loss: 0.2372\n",
      "Val RMSE: 131721.5916, Val MAE: 73344.9220, Val MSE: 17350577682.9067, Val R2: 0.1185\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2157, Val Loss: 0.2376\n",
      "Val RMSE: 130551.7993, Val MAE: 74025.8415, Val MSE: 17043772304.0414, Val R2: 0.1341\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2107, Val Loss: 0.2393\n",
      "Val RMSE: 129602.7550, Val MAE: 73774.4687, Val MSE: 16796874108.2419, Val R2: 0.1466\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2042, Val Loss: 0.2190\n",
      "Val RMSE: 123752.1952, Val MAE: 73601.8686, Val MSE: 15314605810.0251, Val R2: 0.2219\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2021, Val Loss: 0.2349\n",
      "Val RMSE: 127032.7221, Val MAE: 74290.4528, Val MSE: 16137312476.3964, Val R2: 0.1801\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1983, Val Loss: 0.2190\n",
      "Val RMSE: 126015.6470, Val MAE: 69794.3053, Val MSE: 15879943295.8752, Val R2: 0.1932\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1929, Val Loss: 0.2250\n",
      "Val RMSE: 124630.1597, Val MAE: 71175.7882, Val MSE: 15532676703.8804, Val R2: 0.2108\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2275\n",
      "Val RMSE: 125318.9995, Val MAE: 72326.2209, Val MSE: 15704851628.0519, Val R2: 0.2021\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1783, Val Loss: 0.2191\n",
      "Val RMSE: 123874.8666, Val MAE: 67349.2215, Val MSE: 15344982564.8996, Val R2: 0.2204\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1716, Val Loss: 0.1822\n",
      "Val RMSE: 105062.6247, Val MAE: 63740.7556, Val MSE: 11038155109.5112, Val R2: 0.4392\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1652, Val Loss: 0.1861\n",
      "Val RMSE: 104188.5184, Val MAE: 62007.2151, Val MSE: 10855247374.7828, Val R2: 0.4485\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1602, Val Loss: 0.1690\n",
      "Val RMSE: 100155.3944, Val MAE: 61487.5600, Val MSE: 10031103035.8682, Val R2: 0.4904\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1495, Val Loss: 0.1723\n",
      "Val RMSE: 102162.9216, Val MAE: 58552.8424, Val MSE: 10437262554.4406, Val R2: 0.4697\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1495, Val Loss: 0.1647\n",
      "Val RMSE: 100589.8595, Val MAE: 56445.6423, Val MSE: 10118319835.1772, Val R2: 0.4859\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1461, Val Loss: 0.1600\n",
      "Val RMSE: 98376.8939, Val MAE: 55826.6614, Val MSE: 9678013250.0415, Val R2: 0.5083\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1396, Val Loss: 0.1484\n",
      "Val RMSE: 94704.5149, Val MAE: 53762.6688, Val MSE: 8968945143.1545, Val R2: 0.5443\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1367, Val Loss: 0.1430\n",
      "Val RMSE: 92432.9214, Val MAE: 53696.4545, Val MSE: 8543844951.5967, Val R2: 0.5659\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1317, Val Loss: 0.1401\n",
      "Val RMSE: 92333.3085, Val MAE: 51365.5068, Val MSE: 8525439858.0617, Val R2: 0.5669\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1264, Val Loss: 0.1345\n",
      "Val RMSE: 90399.7490, Val MAE: 50728.3611, Val MSE: 8172114620.9575, Val R2: 0.5848\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1191, Val Loss: 0.1236\n",
      "Val RMSE: 86055.6742, Val MAE: 47879.3426, Val MSE: 7405579061.0471, Val R2: 0.6237\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1134, Val Loss: 0.1150\n",
      "Val RMSE: 82976.2727, Val MAE: 44397.1973, Val MSE: 6885061825.0874, Val R2: 0.6502\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1079, Val Loss: 0.1119\n",
      "Val RMSE: 82730.2727, Val MAE: 43316.1530, Val MSE: 6844298015.7430, Val R2: 0.6523\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1199\n",
      "Val RMSE: 85679.1741, Val MAE: 45578.7619, Val MSE: 7340920867.2938, Val R2: 0.6270\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1010, Val Loss: 0.1118\n",
      "Val RMSE: 79911.3060, Val MAE: 42592.9971, Val MSE: 6385816831.8465, Val R2: 0.6756\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0963, Val Loss: 0.1107\n",
      "Val RMSE: 78747.1938, Val MAE: 45996.8414, Val MSE: 6201120537.8341, Val R2: 0.6849\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0945, Val Loss: 0.1119\n",
      "Val RMSE: 79168.1959, Val MAE: 44634.2517, Val MSE: 6267603248.8523, Val R2: 0.6816\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0990, Val Loss: 0.1244\n",
      "Val RMSE: 82132.4312, Val MAE: 46148.5615, Val MSE: 6745736251.8080, Val R2: 0.6573\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0918, Val Loss: 0.1125\n",
      "Val RMSE: 77761.6275, Val MAE: 45855.3787, Val MSE: 6046870707.7691, Val R2: 0.6928\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0833, Val Loss: 0.1085\n",
      "Val RMSE: 75203.8800, Val MAE: 43542.8322, Val MSE: 5655623566.9178, Val R2: 0.7127\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0840, Val Loss: 0.1172\n",
      "Val RMSE: 78502.4285, Val MAE: 42992.0364, Val MSE: 6162631275.2393, Val R2: 0.6869\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0802, Val Loss: 0.1150\n",
      "Val RMSE: 78877.1674, Val MAE: 45035.9998, Val MSE: 6221607531.2844, Val R2: 0.6839\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0758, Val Loss: 0.1060\n",
      "Val RMSE: 75783.2917, Val MAE: 41840.3565, Val MSE: 5743107297.5381, Val R2: 0.7082\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0750, Val Loss: 0.1095\n",
      "Val RMSE: 74899.7614, Val MAE: 43774.7434, Val MSE: 5609974255.9030, Val R2: 0.7150\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0763, Val Loss: 0.1035\n",
      "Val RMSE: 72279.2969, Val MAE: 43714.4039, Val MSE: 5224296760.9559, Val R2: 0.7346\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0732, Val Loss: 0.1038\n",
      "Val RMSE: 71910.4244, Val MAE: 43011.1952, Val MSE: 5171109140.7899, Val R2: 0.7373\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1222\n",
      "Val RMSE: 78124.6275, Val MAE: 44577.1813, Val MSE: 6103457416.3885, Val R2: 0.6899\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0696, Val Loss: 0.1045\n",
      "Val RMSE: 71601.8539, Val MAE: 43352.7736, Val MSE: 5126825488.0390, Val R2: 0.7395\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0669, Val Loss: 0.1065\n",
      "Val RMSE: 71373.4928, Val MAE: 43206.8239, Val MSE: 5094175468.3352, Val R2: 0.7412\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0651, Val Loss: 0.1055\n",
      "Val RMSE: 71837.2275, Val MAE: 43200.5934, Val MSE: 5160587252.4425, Val R2: 0.7378\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1042\n",
      "Val RMSE: 72453.9464, Val MAE: 42601.2794, Val MSE: 5249574352.9707, Val R2: 0.7333\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1136\n",
      "Val RMSE: 74858.8639, Val MAE: 44513.3365, Val MSE: 5603849501.0660, Val R2: 0.7153\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0619, Val Loss: 0.1018\n",
      "Val RMSE: 71023.3109, Val MAE: 41256.8733, Val MSE: 5044310684.2972, Val R2: 0.7437\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1044\n",
      "Val RMSE: 70864.4860, Val MAE: 42694.6927, Val MSE: 5021775378.9216, Val R2: 0.7449\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0607, Val Loss: 0.1147\n",
      "Val RMSE: 75470.6755, Val MAE: 43566.9762, Val MSE: 5695822863.7701, Val R2: 0.7106\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0595, Val Loss: 0.1128\n",
      "Val RMSE: 74859.5371, Val MAE: 43611.1895, Val MSE: 5603950288.6858, Val R2: 0.7153\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1054\n",
      "Val RMSE: 71262.4348, Val MAE: 42219.5777, Val MSE: 5078334612.6923, Val R2: 0.7420\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0592, Val Loss: 0.1052\n",
      "Val RMSE: 71088.8469, Val MAE: 42550.6742, Val MSE: 5053624159.0029, Val R2: 0.7432\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0564, Val Loss: 0.1063\n",
      "Val RMSE: 71224.5640, Val MAE: 41843.1525, Val MSE: 5072938521.3542, Val R2: 0.7423\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0554, Val Loss: 0.1136\n",
      "Val RMSE: 74815.8957, Val MAE: 43930.3387, Val MSE: 5597418253.2301, Val R2: 0.7156\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1122\n",
      "Val RMSE: 74508.2276, Val MAE: 42477.3823, Val MSE: 5551475987.0687, Val R2: 0.7179\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0537, Val Loss: 0.1236\n",
      "Val RMSE: 77349.6304, Val MAE: 44979.9904, Val MSE: 5982965328.6500, Val R2: 0.6960\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1205\n",
      "Val RMSE: 78844.4632, Val MAE: 45324.3864, Val MSE: 6216449371.5933, Val R2: 0.6842\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1235\n",
      "Val RMSE: 77610.9364, Val MAE: 43847.4821, Val MSE: 6023457442.8458, Val R2: 0.6940\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0520, Val Loss: 0.1196\n",
      "Val RMSE: 77478.7993, Val MAE: 43777.7444, Val MSE: 6002964341.1723, Val R2: 0.6950\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1220\n",
      "Val RMSE: 77502.6918, Val MAE: 43387.3962, Val MSE: 6006667241.9072, Val R2: 0.6948\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1199\n",
      "Val RMSE: 78043.7445, Val MAE: 43898.9063, Val MSE: 6090826057.3163, Val R2: 0.6905\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1184\n",
      "Val RMSE: 75577.0809, Val MAE: 43468.1217, Val MSE: 5711895156.4631, Val R2: 0.7098\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0529, Val Loss: 0.1161\n",
      "Val RMSE: 75412.1230, Val MAE: 42457.6045, Val MSE: 5686988296.2628, Val R2: 0.7111\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0521, Val Loss: 0.1129\n",
      "Val RMSE: 73911.0882, Val MAE: 43343.1072, Val MSE: 5462848960.3733, Val R2: 0.7225\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0513, Val Loss: 0.1191\n",
      "Val RMSE: 74382.5687, Val MAE: 45529.6252, Val MSE: 5532766521.8914, Val R2: 0.7189\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1270\n",
      "Val RMSE: 77835.1582, Val MAE: 45625.3770, Val MSE: 6058311846.0437, Val R2: 0.6922\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0514, Val Loss: 0.1343\n",
      "Val RMSE: 79921.9512, Val MAE: 47796.5140, Val MSE: 6387518282.8558, Val R2: 0.6755\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0516, Val Loss: 0.1198\n",
      "Val RMSE: 78734.7327, Val MAE: 44294.9724, Val MSE: 6199158140.3239, Val R2: 0.6850\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1444\n",
      "Val RMSE: 85905.7988, Val MAE: 48239.7066, Val MSE: 7379806263.8464, Val R2: 0.6251\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0501, Val Loss: 0.1316\n",
      "Val RMSE: 80298.1087, Val MAE: 46345.5189, Val MSE: 6447786256.9041, Val R2: 0.6724\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0511, Val Loss: 0.1250\n",
      "Val RMSE: 77407.0022, Val MAE: 44018.3152, Val MSE: 5991843990.3567, Val R2: 0.6956\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.1294\n",
      "Val RMSE: 78201.1582, Val MAE: 45516.5730, Val MSE: 6115421148.9603, Val R2: 0.6893\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0486, Val Loss: 0.7578\n",
      "Val RMSE: 250421.0840, Val MAE: 134345.3410, Val MSE: 62710719329.2746, Val R2: -2.1861\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1293\n",
      "Val RMSE: 79202.3704, Val MAE: 43561.7824, Val MSE: 6273015478.5260, Val R2: 0.6813\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0487, Val Loss: 0.1219\n",
      "Val RMSE: 78583.6588, Val MAE: 44344.6642, Val MSE: 6175391427.0029, Val R2: 0.6863\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0480, Val Loss: 0.1217\n",
      "Val RMSE: 76538.3479, Val MAE: 45344.6825, Val MSE: 5858118696.7355, Val R2: 0.7024\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1264\n",
      "Val RMSE: 77935.6427, Val MAE: 44979.5169, Val MSE: 6073964409.1366, Val R2: 0.6914\n",
      "Early stopping triggered after epoch 89\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 74665.5458, Test MAE: 42215.1640, Test MSE: 5574943736.6091, Test R2: 0.6426\n",
      "Inference Time: 5.676984786987305e-05 seconds per sample\n",
      "\n",
      "Iteration 98 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3512, Val Loss: 0.2962\n",
      "Val RMSE: 146431.9469, Val MAE: 81199.8571, Val MSE: 21442315071.4235, Val R2: -0.0894\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2759, Val Loss: 0.2752\n",
      "Val RMSE: 141423.4971, Val MAE: 84089.3351, Val MSE: 20000605518.4507, Val R2: -0.0162\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2693, Val Loss: 0.2742\n",
      "Val RMSE: 141361.3004, Val MAE: 83562.0511, Val MSE: 19983017245.8032, Val R2: -0.0153\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2636, Val Loss: 0.2793\n",
      "Val RMSE: 142419.0149, Val MAE: 82741.7065, Val MSE: 20283175792.1052, Val R2: -0.0305\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2618, Val Loss: 0.2730\n",
      "Val RMSE: 141260.2271, Val MAE: 83892.0107, Val MSE: 19954451769.4388, Val R2: -0.0138\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2596, Val Loss: 0.2723\n",
      "Val RMSE: 141565.0917, Val MAE: 82196.4540, Val MSE: 20040675182.0705, Val R2: -0.0182\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2557, Val Loss: 0.2727\n",
      "Val RMSE: 140802.4570, Val MAE: 83604.3274, Val MSE: 19825331894.1935, Val R2: -0.0073\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2532, Val Loss: 0.2753\n",
      "Val RMSE: 141493.0410, Val MAE: 82015.2560, Val MSE: 20020280659.7514, Val R2: -0.0172\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2558, Val Loss: 0.2724\n",
      "Val RMSE: 141585.4894, Val MAE: 80906.6162, Val MSE: 20046450804.5651, Val R2: -0.0185\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2587, Val Loss: 0.2674\n",
      "Val RMSE: 140614.8171, Val MAE: 81381.8708, Val MSE: 19772526775.5052, Val R2: -0.0046\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2537, Val Loss: 0.2712\n",
      "Val RMSE: 142554.1213, Val MAE: 79111.9153, Val MSE: 20321677506.9644, Val R2: -0.0325\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2692\n",
      "Val RMSE: 140547.4698, Val MAE: 82005.8898, Val MSE: 19753591279.4060, Val R2: -0.0036\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2497, Val Loss: 0.2645\n",
      "Val RMSE: 139275.6221, Val MAE: 81384.4187, Val MSE: 19397698919.8585, Val R2: 0.0145\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2423, Val Loss: 0.2614\n",
      "Val RMSE: 135574.2060, Val MAE: 81717.8549, Val MSE: 18380365342.1026, Val R2: 0.0662\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2427, Val Loss: 0.2518\n",
      "Val RMSE: 134869.9898, Val MAE: 77721.7213, Val MSE: 18189914153.9096, Val R2: 0.0758\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2377, Val Loss: 0.2525\n",
      "Val RMSE: 134569.2183, Val MAE: 79465.2899, Val MSE: 18108874513.7141, Val R2: 0.0800\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2361, Val Loss: 0.2669\n",
      "Val RMSE: 135004.9425, Val MAE: 81836.7125, Val MSE: 18226334493.4505, Val R2: 0.0740\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2295, Val Loss: 0.2347\n",
      "Val RMSE: 131000.7605, Val MAE: 73594.0662, Val MSE: 17161199248.7181, Val R2: 0.1281\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2182, Val Loss: 0.2319\n",
      "Val RMSE: 131844.2142, Val MAE: 73273.5625, Val MSE: 17382896817.0476, Val R2: 0.1168\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2127, Val Loss: 0.2294\n",
      "Val RMSE: 130925.6009, Val MAE: 71295.4715, Val MSE: 17141512978.9091, Val R2: 0.1291\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2081, Val Loss: 0.2281\n",
      "Val RMSE: 131651.4712, Val MAE: 68839.0763, Val MSE: 17332109868.7372, Val R2: 0.1194\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2030, Val Loss: 0.2723\n",
      "Val RMSE: 144601.7697, Val MAE: 81689.3387, Val MSE: 20909671801.5924, Val R2: -0.0623\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2022, Val Loss: 0.2287\n",
      "Val RMSE: 130369.8476, Val MAE: 70501.8533, Val MSE: 16996297169.2323, Val R2: 0.1365\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2297\n",
      "Val RMSE: 129732.3411, Val MAE: 70831.4755, Val MSE: 16830480317.9600, Val R2: 0.1449\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1958, Val Loss: 0.2226\n",
      "Val RMSE: 128360.1381, Val MAE: 70993.0839, Val MSE: 16476325058.9886, Val R2: 0.1629\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1910, Val Loss: 0.2202\n",
      "Val RMSE: 125034.3072, Val MAE: 69679.2647, Val MSE: 15633577968.7408, Val R2: 0.2057\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1809, Val Loss: 0.2102\n",
      "Val RMSE: 117283.2729, Val MAE: 68814.5474, Val MSE: 13755366094.2115, Val R2: 0.3011\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1784, Val Loss: 0.1996\n",
      "Val RMSE: 111873.1323, Val MAE: 66604.7146, Val MSE: 12515597733.8891, Val R2: 0.3641\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1739, Val Loss: 0.1917\n",
      "Val RMSE: 108544.1779, Val MAE: 64233.1216, Val MSE: 11781838557.5350, Val R2: 0.4014\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1657, Val Loss: 0.1777\n",
      "Val RMSE: 102477.0509, Val MAE: 62011.5723, Val MSE: 10501545961.0068, Val R2: 0.4665\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1610, Val Loss: 0.1708\n",
      "Val RMSE: 101462.4550, Val MAE: 59495.6050, Val MSE: 10294629782.0279, Val R2: 0.4770\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1552, Val Loss: 0.1613\n",
      "Val RMSE: 99404.0631, Val MAE: 57039.4883, Val MSE: 9881167759.7376, Val R2: 0.4980\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1551, Val Loss: 0.1660\n",
      "Val RMSE: 101220.4859, Val MAE: 57505.5384, Val MSE: 10245586767.7789, Val R2: 0.4795\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1496, Val Loss: 0.1548\n",
      "Val RMSE: 96206.9161, Val MAE: 57691.5220, Val MSE: 9255770710.7941, Val R2: 0.5297\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1455, Val Loss: 0.1486\n",
      "Val RMSE: 94523.8624, Val MAE: 54512.3013, Val MSE: 8934760567.2563, Val R2: 0.5461\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1439, Val Loss: 0.1516\n",
      "Val RMSE: 95880.9990, Val MAE: 54039.7156, Val MSE: 9193165965.2517, Val R2: 0.5329\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1503\n",
      "Val RMSE: 94230.5403, Val MAE: 54418.3424, Val MSE: 8879394716.2587, Val R2: 0.5489\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1400, Val Loss: 0.1478\n",
      "Val RMSE: 93883.3581, Val MAE: 54041.2782, Val MSE: 8814084926.1158, Val R2: 0.5522\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1353, Val Loss: 0.1379\n",
      "Val RMSE: 91545.8389, Val MAE: 51265.2248, Val MSE: 8380640611.9059, Val R2: 0.5742\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1332, Val Loss: 0.1458\n",
      "Val RMSE: 93815.8672, Val MAE: 51642.1529, Val MSE: 8801416935.3705, Val R2: 0.5528\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1367, Val Loss: 0.1319\n",
      "Val RMSE: 89632.6344, Val MAE: 50398.4018, Val MSE: 8034009153.1300, Val R2: 0.5918\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1286, Val Loss: 0.1351\n",
      "Val RMSE: 90537.6023, Val MAE: 48900.6942, Val MSE: 8197057438.0423, Val R2: 0.5835\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1200, Val Loss: 0.1335\n",
      "Val RMSE: 90385.0671, Val MAE: 48587.0366, Val MSE: 8169460349.1795, Val R2: 0.5849\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1135, Val Loss: 0.1272\n",
      "Val RMSE: 89023.1119, Val MAE: 46906.0604, Val MSE: 7925114454.1714, Val R2: 0.5974\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1079, Val Loss: 0.1321\n",
      "Val RMSE: 91492.4169, Val MAE: 47462.7436, Val MSE: 8370862349.0447, Val R2: 0.5747\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1043, Val Loss: 0.1178\n",
      "Val RMSE: 86114.8005, Val MAE: 44619.3762, Val MSE: 7415758864.4744, Val R2: 0.6232\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1002, Val Loss: 0.1355\n",
      "Val RMSE: 93575.5982, Val MAE: 46906.8326, Val MSE: 8756392578.6994, Val R2: 0.5551\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0977, Val Loss: 0.1436\n",
      "Val RMSE: 93425.7750, Val MAE: 51934.7725, Val MSE: 8728375430.6587, Val R2: 0.5565\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0985, Val Loss: 0.1349\n",
      "Val RMSE: 94491.3360, Val MAE: 47112.1472, Val MSE: 8928612582.3738, Val R2: 0.5464\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0930, Val Loss: 0.1367\n",
      "Val RMSE: 85709.3651, Val MAE: 46030.3613, Val MSE: 7346095271.4019, Val R2: 0.6268\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1200\n",
      "Val RMSE: 83411.7495, Val MAE: 44199.1056, Val MSE: 6957519956.7000, Val R2: 0.6465\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0865, Val Loss: 0.1167\n",
      "Val RMSE: 83626.9491, Val MAE: 43963.3765, Val MSE: 6993466623.6066, Val R2: 0.6447\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0832, Val Loss: 0.1218\n",
      "Val RMSE: 82016.2757, Val MAE: 43682.5514, Val MSE: 6726669474.2818, Val R2: 0.6582\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0821, Val Loss: 0.1330\n",
      "Val RMSE: 87980.0975, Val MAE: 45241.5993, Val MSE: 7740497559.5265, Val R2: 0.6067\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0835, Val Loss: 0.1306\n",
      "Val RMSE: 82960.9277, Val MAE: 44034.5364, Val MSE: 6882515529.0246, Val R2: 0.6503\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0813, Val Loss: 0.1291\n",
      "Val RMSE: 82514.1171, Val MAE: 44611.4242, Val MSE: 6808579520.8512, Val R2: 0.6541\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0775, Val Loss: 0.1247\n",
      "Val RMSE: 84372.9748, Val MAE: 44430.4873, Val MSE: 7118798877.9145, Val R2: 0.6383\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1265\n",
      "Val RMSE: 83175.7778, Val MAE: 44637.6748, Val MSE: 6918210011.1816, Val R2: 0.6485\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0753, Val Loss: 0.1272\n",
      "Val RMSE: 82673.7254, Val MAE: 44531.1467, Val MSE: 6834944863.8947, Val R2: 0.6527\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0737, Val Loss: 0.1200\n",
      "Val RMSE: 77962.2466, Val MAE: 43721.0824, Val MSE: 6078111892.2568, Val R2: 0.6912\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1142\n",
      "Val RMSE: 77159.5554, Val MAE: 44220.8175, Val MSE: 5953596982.9917, Val R2: 0.6975\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1204\n",
      "Val RMSE: 77379.4204, Val MAE: 42891.0211, Val MSE: 5987574703.5856, Val R2: 0.6958\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0714, Val Loss: 0.1203\n",
      "Val RMSE: 78604.6348, Val MAE: 43207.4511, Val MSE: 6178688611.9881, Val R2: 0.6861\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0712, Val Loss: 0.1178\n",
      "Val RMSE: 76024.2004, Val MAE: 42963.8235, Val MSE: 5779679044.7810, Val R2: 0.7064\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1061\n",
      "Val RMSE: 71655.4394, Val MAE: 40685.1157, Val MSE: 5134501993.0075, Val R2: 0.7391\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1236\n",
      "Val RMSE: 80859.6619, Val MAE: 45100.0244, Val MSE: 6538284927.3690, Val R2: 0.6678\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1145\n",
      "Val RMSE: 75666.7240, Val MAE: 43355.9799, Val MSE: 5725453120.1658, Val R2: 0.7091\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0658, Val Loss: 0.1245\n",
      "Val RMSE: 79215.6350, Val MAE: 45686.4419, Val MSE: 6275116828.9726, Val R2: 0.6812\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0643, Val Loss: 0.1194\n",
      "Val RMSE: 76692.0665, Val MAE: 42783.0432, Val MSE: 5881673070.2309, Val R2: 0.7012\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1150\n",
      "Val RMSE: 77202.7132, Val MAE: 41507.0859, Val MSE: 5960258931.8443, Val R2: 0.6972\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0613, Val Loss: 0.1194\n",
      "Val RMSE: 79004.7341, Val MAE: 42032.6347, Val MSE: 6241748013.1073, Val R2: 0.6829\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0603, Val Loss: 0.1302\n",
      "Val RMSE: 80457.2449, Val MAE: 43368.9613, Val MSE: 6473368254.6416, Val R2: 0.6711\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0612, Val Loss: 0.1249\n",
      "Val RMSE: 79981.5121, Val MAE: 42602.9840, Val MSE: 6397042270.0662, Val R2: 0.6750\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0586, Val Loss: 0.1168\n",
      "Val RMSE: 77209.1088, Val MAE: 41629.8285, Val MSE: 5961246480.9621, Val R2: 0.6971\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0582, Val Loss: 0.1310\n",
      "Val RMSE: 80778.2089, Val MAE: 43046.9743, Val MSE: 6525119036.0098, Val R2: 0.6685\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1156\n",
      "Val RMSE: 77766.4236, Val MAE: 42882.7105, Val MSE: 6047616633.9409, Val R2: 0.6927\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0560, Val Loss: 0.1179\n",
      "Val RMSE: 78775.3409, Val MAE: 42778.0749, Val MSE: 6205554329.8548, Val R2: 0.6847\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1150\n",
      "Val RMSE: 78027.0609, Val MAE: 42012.5289, Val MSE: 6088222231.4583, Val R2: 0.6907\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0549, Val Loss: 0.1278\n",
      "Val RMSE: 81319.3104, Val MAE: 44994.1358, Val MSE: 6612830250.1212, Val R2: 0.6640\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0550, Val Loss: 0.1150\n",
      "Val RMSE: 76937.0827, Val MAE: 42617.8592, Val MSE: 5919314699.4412, Val R2: 0.6993\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1248\n",
      "Val RMSE: 80715.2300, Val MAE: 43005.8217, Val MSE: 6514948358.6824, Val R2: 0.6690\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0518, Val Loss: 0.1129\n",
      "Val RMSE: 74269.9050, Val MAE: 39589.5175, Val MSE: 5516018790.8845, Val R2: 0.7198\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0509, Val Loss: 0.1260\n",
      "Val RMSE: 80453.1408, Val MAE: 43024.0472, Val MSE: 6472707867.3304, Val R2: 0.6711\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1158\n",
      "Val RMSE: 77944.2645, Val MAE: 41995.4490, Val MSE: 6075308361.4094, Val R2: 0.6913\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0504, Val Loss: 0.1284\n",
      "Val RMSE: 81340.8415, Val MAE: 42910.5817, Val MSE: 6616332489.8978, Val R2: 0.6638\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.1163\n",
      "Val RMSE: 76599.0251, Val MAE: 41736.5724, Val MSE: 5867410639.2719, Val R2: 0.7019\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1163\n",
      "Val RMSE: 76992.7561, Val MAE: 41090.5514, Val MSE: 5927884484.4171, Val R2: 0.6988\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0495, Val Loss: 0.1176\n",
      "Val RMSE: 75468.9775, Val MAE: 40412.2757, Val MSE: 5695566564.2560, Val R2: 0.7106\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0505, Val Loss: 0.1173\n",
      "Val RMSE: 79269.7744, Val MAE: 41881.6259, Val MSE: 6283697131.0736, Val R2: 0.6807\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0481, Val Loss: 0.1194\n",
      "Val RMSE: 79231.5961, Val MAE: 41167.0473, Val MSE: 6277645814.2716, Val R2: 0.6811\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0485, Val Loss: 0.1168\n",
      "Val RMSE: 78426.2968, Val MAE: 40441.7995, Val MSE: 6150684032.9156, Val R2: 0.6875\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0484, Val Loss: 0.1224\n",
      "Val RMSE: 77144.5350, Val MAE: 40947.0688, Val MSE: 5951279286.2191, Val R2: 0.6976\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0474, Val Loss: 0.1255\n",
      "Val RMSE: 85979.2653, Val MAE: 42405.1266, Val MSE: 7392434063.4488, Val R2: 0.6244\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0469, Val Loss: 0.1123\n",
      "Val RMSE: 77888.1183, Val MAE: 39565.7030, Val MSE: 6066558979.6410, Val R2: 0.6918\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0452, Val Loss: 0.1338\n",
      "Val RMSE: 87145.4778, Val MAE: 45561.8224, Val MSE: 7594334304.6992, Val R2: 0.6142\n",
      "Early stopping triggered after epoch 95\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 83682.4295, Test MAE: 46612.8904, Test MSE: 7002749004.7778, Test R2: 0.5511\n",
      "Inference Time: 4.116949668297401e-05 seconds per sample\n",
      "\n",
      "Iteration 99 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3804, Val Loss: 0.3038\n",
      "Val RMSE: 147925.4497, Val MAE: 81584.1073, Val MSE: 21881938658.0031, Val R2: -0.1117\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2834, Val Loss: 0.2777\n",
      "Val RMSE: 141582.1986, Val MAE: 84206.5081, Val MSE: 20045518946.7003, Val R2: -0.0184\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2740, Val Loss: 0.2778\n",
      "Val RMSE: 142849.6947, Val MAE: 82229.5078, Val MSE: 20406035285.7731, Val R2: -0.0368\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2689, Val Loss: 0.2743\n",
      "Val RMSE: 141156.7836, Val MAE: 84163.5982, Val MSE: 19925237550.7824, Val R2: -0.0123\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2663, Val Loss: 0.2743\n",
      "Val RMSE: 141891.1821, Val MAE: 82872.8174, Val MSE: 20133107561.3892, Val R2: -0.0229\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2631, Val Loss: 0.2829\n",
      "Val RMSE: 144162.1613, Val MAE: 80996.0254, Val MSE: 20782728758.3731, Val R2: -0.0559\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2578, Val Loss: 0.2735\n",
      "Val RMSE: 142458.2550, Val MAE: 82007.2275, Val MSE: 20294354409.4686, Val R2: -0.0311\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2573, Val Loss: 0.2695\n",
      "Val RMSE: 141020.8051, Val MAE: 82405.9122, Val MSE: 19886867464.4289, Val R2: -0.0104\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2570, Val Loss: 0.2676\n",
      "Val RMSE: 142083.3446, Val MAE: 79802.3894, Val MSE: 20187676821.3677, Val R2: -0.0257\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2529, Val Loss: 0.2674\n",
      "Val RMSE: 141006.5821, Val MAE: 80692.2796, Val MSE: 19882856192.9377, Val R2: -0.0102\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2520, Val Loss: 0.2656\n",
      "Val RMSE: 139120.3811, Val MAE: 82991.7625, Val MSE: 19354480443.2771, Val R2: 0.0167\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2547, Val Loss: 0.2708\n",
      "Val RMSE: 140590.9936, Val MAE: 84026.8217, Val MSE: 19765827478.4300, Val R2: -0.0042\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2553, Val Loss: 0.2691\n",
      "Val RMSE: 140856.9954, Val MAE: 80689.9681, Val MSE: 19840693162.8009, Val R2: -0.0080\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2487, Val Loss: 0.2665\n",
      "Val RMSE: 141252.6797, Val MAE: 78608.5200, Val MSE: 19952319531.9564, Val R2: -0.0137\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2410, Val Loss: 0.2516\n",
      "Val RMSE: 135905.3141, Val MAE: 75168.8323, Val MSE: 18470254407.8182, Val R2: 0.0616\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2302, Val Loss: 0.2441\n",
      "Val RMSE: 133216.3050, Val MAE: 75708.7132, Val MSE: 17746583925.9534, Val R2: 0.0984\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2240, Val Loss: 0.2375\n",
      "Val RMSE: 131805.2650, Val MAE: 73960.6166, Val MSE: 17372627881.8849, Val R2: 0.1174\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2163, Val Loss: 0.2308\n",
      "Val RMSE: 131964.6281, Val MAE: 71156.7413, Val MSE: 17414663082.1635, Val R2: 0.1152\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2085, Val Loss: 0.2524\n",
      "Val RMSE: 140843.0928, Val MAE: 77541.2433, Val MSE: 19836776792.3132, Val R2: -0.0078\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2080, Val Loss: 0.2338\n",
      "Val RMSE: 133667.7419, Val MAE: 74052.7334, Val MSE: 17867065226.0071, Val R2: 0.0922\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2053, Val Loss: 0.2268\n",
      "Val RMSE: 129479.3531, Val MAE: 71966.4045, Val MSE: 16764902888.8331, Val R2: 0.1482\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2043, Val Loss: 0.2276\n",
      "Val RMSE: 130926.1155, Val MAE: 70816.8894, Val MSE: 17141647725.1383, Val R2: 0.1291\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2015, Val Loss: 0.2270\n",
      "Val RMSE: 129721.8583, Val MAE: 72282.2067, Val MSE: 16827760515.0189, Val R2: 0.1450\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2005, Val Loss: 0.2343\n",
      "Val RMSE: 129286.2885, Val MAE: 74716.1774, Val MSE: 16714944397.9174, Val R2: 0.1508\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1979, Val Loss: 0.2207\n",
      "Val RMSE: 127384.2955, Val MAE: 69446.8008, Val MSE: 16226758750.6203, Val R2: 0.1756\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1906, Val Loss: 0.2162\n",
      "Val RMSE: 118865.8064, Val MAE: 70707.7700, Val MSE: 14129079931.7799, Val R2: 0.2822\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1866, Val Loss: 0.2246\n",
      "Val RMSE: 122842.2562, Val MAE: 69150.5792, Val MSE: 15090219897.5930, Val R2: 0.2333\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1827, Val Loss: 0.2067\n",
      "Val RMSE: 115215.9109, Val MAE: 69006.2625, Val MSE: 13274706124.4962, Val R2: 0.3256\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1751, Val Loss: 0.1845\n",
      "Val RMSE: 105121.4014, Val MAE: 62259.0511, Val MSE: 11050509040.7727, Val R2: 0.4386\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1704, Val Loss: 0.1894\n",
      "Val RMSE: 106945.6343, Val MAE: 64564.8217, Val MSE: 11437368686.8146, Val R2: 0.4189\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1731, Val Loss: 0.2077\n",
      "Val RMSE: 115448.6344, Val MAE: 67085.8230, Val MSE: 13328387196.3680, Val R2: 0.3228\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1718, Val Loss: 0.1860\n",
      "Val RMSE: 103971.0510, Val MAE: 64294.4085, Val MSE: 10809979442.2634, Val R2: 0.4508\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1680, Val Loss: 0.1771\n",
      "Val RMSE: 102515.2602, Val MAE: 61762.7887, Val MSE: 10509378578.0185, Val R2: 0.4661\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1617, Val Loss: 0.1709\n",
      "Val RMSE: 99664.2541, Val MAE: 61948.4731, Val MSE: 9932963537.2441, Val R2: 0.4953\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1575, Val Loss: 0.1712\n",
      "Val RMSE: 99933.5775, Val MAE: 58006.3975, Val MSE: 9986719919.3345, Val R2: 0.4926\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1560, Val Loss: 0.1688\n",
      "Val RMSE: 99233.0880, Val MAE: 58084.1986, Val MSE: 9847205745.5115, Val R2: 0.4997\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1514, Val Loss: 0.1674\n",
      "Val RMSE: 97976.7805, Val MAE: 58128.1769, Val MSE: 9599449515.0102, Val R2: 0.5123\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1494, Val Loss: 0.1693\n",
      "Val RMSE: 98177.7787, Val MAE: 57900.5342, Val MSE: 9638876237.4779, Val R2: 0.5103\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1453, Val Loss: 0.1535\n",
      "Val RMSE: 96074.6841, Val MAE: 55345.6324, Val MSE: 9230344933.2163, Val R2: 0.5310\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1460, Val Loss: 0.1767\n",
      "Val RMSE: 98049.0446, Val MAE: 60508.9646, Val MSE: 9613615146.3034, Val R2: 0.5116\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1379, Val Loss: 0.1487\n",
      "Val RMSE: 94097.5370, Val MAE: 53567.1702, Val MSE: 8854346471.1352, Val R2: 0.5501\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1342, Val Loss: 0.1593\n",
      "Val RMSE: 95132.4568, Val MAE: 58876.6613, Val MSE: 9050184345.7703, Val R2: 0.5402\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1319, Val Loss: 0.1380\n",
      "Val RMSE: 92152.2121, Val MAE: 51064.3458, Val MSE: 8492030195.0746, Val R2: 0.5686\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1263, Val Loss: 0.1390\n",
      "Val RMSE: 90911.7678, Val MAE: 50471.1123, Val MSE: 8264949531.3802, Val R2: 0.5801\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1211, Val Loss: 0.1343\n",
      "Val RMSE: 89873.5936, Val MAE: 48956.1252, Val MSE: 8077262818.6373, Val R2: 0.5896\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1569\n",
      "Val RMSE: 94606.3260, Val MAE: 53700.0318, Val MSE: 8950356922.9430, Val R2: 0.5453\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1181, Val Loss: 0.1265\n",
      "Val RMSE: 89242.9542, Val MAE: 48532.9673, Val MSE: 7964304869.9107, Val R2: 0.5954\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1132, Val Loss: 0.1368\n",
      "Val RMSE: 93052.2555, Val MAE: 48652.3034, Val MSE: 8658722248.5932, Val R2: 0.5601\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1076, Val Loss: 0.1236\n",
      "Val RMSE: 88193.8433, Val MAE: 48270.5297, Val MSE: 7778154004.7628, Val R2: 0.6048\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1048, Val Loss: 0.1396\n",
      "Val RMSE: 94074.5480, Val MAE: 49736.7024, Val MSE: 8850020586.0954, Val R2: 0.5504\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1029, Val Loss: 0.1459\n",
      "Val RMSE: 96723.7071, Val MAE: 50771.2953, Val MSE: 9355475516.3479, Val R2: 0.5247\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1003, Val Loss: 0.1198\n",
      "Val RMSE: 87210.5970, Val MAE: 46764.7816, Val MSE: 7605688221.3947, Val R2: 0.6136\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0946, Val Loss: 0.1342\n",
      "Val RMSE: 89847.8306, Val MAE: 48826.8982, Val MSE: 8072632671.2465, Val R2: 0.5899\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0920, Val Loss: 0.1329\n",
      "Val RMSE: 88148.5042, Val MAE: 52790.6883, Val MSE: 7770158793.2616, Val R2: 0.6052\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0916, Val Loss: 0.1226\n",
      "Val RMSE: 85189.8854, Val MAE: 48220.4663, Val MSE: 7257316575.9954, Val R2: 0.6313\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0900, Val Loss: 0.1231\n",
      "Val RMSE: 85926.7600, Val MAE: 46343.3861, Val MSE: 7383408083.8013, Val R2: 0.6249\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0863, Val Loss: 0.1284\n",
      "Val RMSE: 86565.8719, Val MAE: 46606.9763, Val MSE: 7493650170.3861, Val R2: 0.6193\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.1456, Val Loss: 0.2366\n",
      "Val RMSE: 125162.2408, Val MAE: 73822.7871, Val MSE: 15665586520.3582, Val R2: 0.2041\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.1868, Val Loss: 0.2245\n",
      "Val RMSE: 120539.3451, Val MAE: 71091.4295, Val MSE: 14529733715.7758, Val R2: 0.2618\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.1584, Val Loss: 0.1821\n",
      "Val RMSE: 106336.3017, Val MAE: 62554.0975, Val MSE: 11307409063.1422, Val R2: 0.4255\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.1289, Val Loss: 0.1655\n",
      "Val RMSE: 99631.8456, Val MAE: 57642.4222, Val MSE: 9926504649.7120, Val R2: 0.4957\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.1144, Val Loss: 0.1475\n",
      "Val RMSE: 94210.1913, Val MAE: 52787.5916, Val MSE: 8875560152.3680, Val R2: 0.5491\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.1037, Val Loss: 0.1349\n",
      "Val RMSE: 89813.0944, Val MAE: 49972.7924, Val MSE: 8066391921.2111, Val R2: 0.5902\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0993, Val Loss: 0.1443\n",
      "Val RMSE: 93710.2321, Val MAE: 53228.4573, Val MSE: 8781607607.6856, Val R2: 0.5538\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0953, Val Loss: 0.1310\n",
      "Val RMSE: 86776.8564, Val MAE: 50351.4947, Val MSE: 7530222804.3481, Val R2: 0.6174\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0919, Val Loss: 0.1333\n",
      "Val RMSE: 85640.9058, Val MAE: 50952.9366, Val MSE: 7334364753.5567, Val R2: 0.6274\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0888, Val Loss: 0.1276\n",
      "Val RMSE: 83360.7986, Val MAE: 49532.4687, Val MSE: 6949022739.1390, Val R2: 0.6469\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0880, Val Loss: 0.1229\n",
      "Val RMSE: 80650.2292, Val MAE: 48557.3348, Val MSE: 6504459462.1309, Val R2: 0.6695\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0871, Val Loss: 0.1261\n",
      "Val RMSE: 82666.4714, Val MAE: 48735.2728, Val MSE: 6833745492.0064, Val R2: 0.6528\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0859, Val Loss: 0.1337\n",
      "Val RMSE: 83471.4011, Val MAE: 50300.3241, Val MSE: 6967474802.4346, Val R2: 0.6460\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1344\n",
      "Val RMSE: 84561.7805, Val MAE: 50595.5973, Val MSE: 7150694718.5523, Val R2: 0.6367\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0810, Val Loss: 0.1338\n",
      "Val RMSE: 80558.7357, Val MAE: 51921.5328, Val MSE: 6489709899.9277, Val R2: 0.6703\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0808, Val Loss: 0.1306\n",
      "Val RMSE: 82252.4903, Val MAE: 49478.3865, Val MSE: 6765472163.5289, Val R2: 0.6563\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0772, Val Loss: 0.1350\n",
      "Val RMSE: 83652.1259, Val MAE: 50100.4282, Val MSE: 6997678164.9118, Val R2: 0.6445\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0769, Val Loss: 0.1186\n",
      "Val RMSE: 76071.4517, Val MAE: 47195.9117, Val MSE: 5786865765.2777, Val R2: 0.7060\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0774, Val Loss: 0.1239\n",
      "Val RMSE: 78650.9752, Val MAE: 48489.8865, Val MSE: 6185975900.7530, Val R2: 0.6857\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0729, Val Loss: 0.1285\n",
      "Val RMSE: 80216.5648, Val MAE: 48367.5083, Val MSE: 6434697272.0402, Val R2: 0.6731\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1218\n",
      "Val RMSE: 77720.6520, Val MAE: 48210.1669, Val MSE: 6040499741.1104, Val R2: 0.6931\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0720, Val Loss: 0.1194\n",
      "Val RMSE: 76806.4563, Val MAE: 47056.3417, Val MSE: 5899231734.9212, Val R2: 0.7003\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1316\n",
      "Val RMSE: 81130.6842, Val MAE: 48714.6685, Val MSE: 6582187926.7903, Val R2: 0.6656\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1244\n",
      "Val RMSE: 79373.3539, Val MAE: 47613.7819, Val MSE: 6300129312.8130, Val R2: 0.6799\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0699, Val Loss: 0.1230\n",
      "Val RMSE: 76260.5304, Val MAE: 47820.0319, Val MSE: 5815668501.7494, Val R2: 0.7045\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0689, Val Loss: 0.1236\n",
      "Val RMSE: 75906.8272, Val MAE: 48046.1096, Val MSE: 5761846412.1093, Val R2: 0.7073\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0678, Val Loss: 0.1163\n",
      "Val RMSE: 74608.1099, Val MAE: 45525.9208, Val MSE: 5566370065.6961, Val R2: 0.7172\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0662, Val Loss: 0.1289\n",
      "Val RMSE: 78120.4105, Val MAE: 48775.5964, Val MSE: 6102798534.4362, Val R2: 0.6899\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0652, Val Loss: 0.1187\n",
      "Val RMSE: 75737.7973, Val MAE: 46181.4320, Val MSE: 5736213946.9256, Val R2: 0.7086\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0641, Val Loss: 0.1207\n",
      "Val RMSE: 76330.8446, Val MAE: 46440.7485, Val MSE: 5826397840.5983, Val R2: 0.7040\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1167\n",
      "Val RMSE: 74939.6646, Val MAE: 45634.0499, Val MSE: 5615953334.8458, Val R2: 0.7147\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0633, Val Loss: 0.1187\n",
      "Val RMSE: 74775.3383, Val MAE: 46374.3629, Val MSE: 5591351221.1274, Val R2: 0.7159\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0615, Val Loss: 0.1165\n",
      "Val RMSE: 73990.9582, Val MAE: 46437.9175, Val MSE: 5474661890.8399, Val R2: 0.7219\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1253\n",
      "Val RMSE: 76168.7599, Val MAE: 47793.5890, Val MSE: 5801679982.1300, Val R2: 0.7052\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0594, Val Loss: 0.1226\n",
      "Val RMSE: 75306.6577, Val MAE: 47363.9034, Val MSE: 5671092688.0375, Val R2: 0.7119\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1235\n",
      "Val RMSE: 76499.6158, Val MAE: 48146.2279, Val MSE: 5852191212.1513, Val R2: 0.7027\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0577, Val Loss: 0.1200\n",
      "Val RMSE: 73678.4463, Val MAE: 46609.9411, Val MSE: 5428513449.7083, Val R2: 0.7242\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1205\n",
      "Val RMSE: 74937.6851, Val MAE: 47361.7810, Val MSE: 5615656641.0450, Val R2: 0.7147\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0597, Val Loss: 0.1308\n",
      "Val RMSE: 76417.6498, Val MAE: 49405.5289, Val MSE: 5839657197.5479, Val R2: 0.7033\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0572, Val Loss: 0.1296\n",
      "Val RMSE: 78489.7397, Val MAE: 49175.7885, Val MSE: 6160639237.8355, Val R2: 0.6870\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0574, Val Loss: 0.1227\n",
      "Val RMSE: 75325.7422, Val MAE: 46852.4607, Val MSE: 5673967435.3867, Val R2: 0.7117\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0570, Val Loss: 0.1344\n",
      "Val RMSE: 79370.1265, Val MAE: 50294.0973, Val MSE: 6299616988.4429, Val R2: 0.6799\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0553, Val Loss: 0.1314\n",
      "Val RMSE: 78760.5829, Val MAE: 47944.6253, Val MSE: 6203229425.5986, Val R2: 0.6848\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 81402.2128, Test MAE: 47711.1542, Test MSE: 6626320252.0778, Test R2: 0.5752\n",
      "Inference Time: 5.595849110529973e-05 seconds per sample\n",
      "\n",
      "Iteration 100 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3512, Val Loss: 0.2897\n",
      "Val RMSE: 145043.4057, Val MAE: 81459.0164, Val MSE: 21037589532.5440, Val R2: -0.0688\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2765, Val Loss: 0.2758\n",
      "Val RMSE: 141525.1954, Val MAE: 83842.1202, Val MSE: 20029380935.4762, Val R2: -0.0176\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2728, Val Loss: 0.2762\n",
      "Val RMSE: 141835.7246, Val MAE: 83075.5216, Val MSE: 20117372761.7361, Val R2: -0.0221\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2676, Val Loss: 0.2769\n",
      "Val RMSE: 142318.1244, Val MAE: 82746.0084, Val MSE: 20254448537.9161, Val R2: -0.0291\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2642, Val Loss: 0.2798\n",
      "Val RMSE: 140942.2079, Val MAE: 87424.3753, Val MSE: 19864705975.4669, Val R2: -0.0093\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2604, Val Loss: 0.2736\n",
      "Val RMSE: 141588.6158, Val MAE: 83715.5233, Val MSE: 20047336111.6806, Val R2: -0.0185\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2599, Val Loss: 0.2742\n",
      "Val RMSE: 141884.0868, Val MAE: 83262.1984, Val MSE: 20131094084.1199, Val R2: -0.0228\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2773\n",
      "Val RMSE: 142169.8590, Val MAE: 84604.0365, Val MSE: 20212268798.6579, Val R2: -0.0269\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2557, Val Loss: 0.2747\n",
      "Val RMSE: 143157.2454, Val MAE: 79417.2823, Val MSE: 20493996905.4945, Val R2: -0.0412\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2528, Val Loss: 0.2714\n",
      "Val RMSE: 141540.5717, Val MAE: 82127.5355, Val MSE: 20033733435.2495, Val R2: -0.0178\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2523, Val Loss: 0.2672\n",
      "Val RMSE: 141686.9029, Val MAE: 79089.6929, Val MSE: 20075178445.4107, Val R2: -0.0199\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2543, Val Loss: 0.2744\n",
      "Val RMSE: 140447.7371, Val MAE: 85097.1876, Val MSE: 19725566853.5616, Val R2: -0.0022\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2530, Val Loss: 0.2669\n",
      "Val RMSE: 140606.1818, Val MAE: 81024.7331, Val MSE: 19770098352.1937, Val R2: -0.0044\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2454, Val Loss: 0.2771\n",
      "Val RMSE: 142889.4806, Val MAE: 81690.4332, Val MSE: 20417403676.2204, Val R2: -0.0373\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2471, Val Loss: 0.2707\n",
      "Val RMSE: 140229.8337, Val MAE: 83091.2875, Val MSE: 19664406258.2140, Val R2: 0.0009\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2435, Val Loss: 0.2622\n",
      "Val RMSE: 140396.9857, Val MAE: 79306.8928, Val MSE: 19711313589.6071, Val R2: -0.0015\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2420, Val Loss: 0.2746\n",
      "Val RMSE: 140285.8293, Val MAE: 83350.1239, Val MSE: 19680113912.3393, Val R2: 0.0001\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2390, Val Loss: 0.2610\n",
      "Val RMSE: 141110.0343, Val MAE: 77209.9809, Val MSE: 19912041780.5904, Val R2: -0.0117\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2320, Val Loss: 0.2714\n",
      "Val RMSE: 136824.6659, Val MAE: 79681.2762, Val MSE: 18720989203.9833, Val R2: 0.0489\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2304, Val Loss: 0.2454\n",
      "Val RMSE: 131143.8888, Val MAE: 75916.3337, Val MSE: 17198719570.5054, Val R2: 0.1262\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2181, Val Loss: 0.2321\n",
      "Val RMSE: 131124.3477, Val MAE: 74229.7141, Val MSE: 17193594555.3336, Val R2: 0.1265\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.2097, Val Loss: 0.2361\n",
      "Val RMSE: 134720.0511, Val MAE: 73211.1345, Val MSE: 18149492175.8607, Val R2: 0.0779\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.2020, Val Loss: 0.2267\n",
      "Val RMSE: 130714.7553, Val MAE: 69495.1074, Val MSE: 17086347251.4298, Val R2: 0.1319\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.2009, Val Loss: 0.2334\n",
      "Val RMSE: 130567.0285, Val MAE: 71736.1840, Val MSE: 17047748927.2467, Val R2: 0.1339\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1945, Val Loss: 0.2144\n",
      "Val RMSE: 125152.0874, Val MAE: 67934.7795, Val MSE: 15663044983.1736, Val R2: 0.2042\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1875, Val Loss: 0.2087\n",
      "Val RMSE: 117878.8600, Val MAE: 66111.2811, Val MSE: 13895425646.0988, Val R2: 0.2940\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1825, Val Loss: 0.2152\n",
      "Val RMSE: 115641.1564, Val MAE: 70778.2752, Val MSE: 13372877045.6089, Val R2: 0.3206\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1793, Val Loss: 0.1915\n",
      "Val RMSE: 105438.2468, Val MAE: 65986.6220, Val MSE: 11117223890.5334, Val R2: 0.4352\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1706, Val Loss: 0.1793\n",
      "Val RMSE: 103208.1757, Val MAE: 62378.4351, Val MSE: 10651927530.8703, Val R2: 0.4588\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1654, Val Loss: 0.1679\n",
      "Val RMSE: 101174.6254, Val MAE: 58752.0799, Val MSE: 10236304825.6649, Val R2: 0.4799\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1574, Val Loss: 0.1637\n",
      "Val RMSE: 99141.1703, Val MAE: 58759.6339, Val MSE: 9828971652.0100, Val R2: 0.5006\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1548, Val Loss: 0.1704\n",
      "Val RMSE: 101042.5670, Val MAE: 60338.5515, Val MSE: 10209600337.2712, Val R2: 0.4813\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1607, Val Loss: 0.1779\n",
      "Val RMSE: 104242.4144, Val MAE: 60536.1258, Val MSE: 10866480966.7233, Val R2: 0.4479\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1634, Val Loss: 0.1650\n",
      "Val RMSE: 100276.1421, Val MAE: 59690.8042, Val MSE: 10055304677.7667, Val R2: 0.4891\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1559, Val Loss: 0.1729\n",
      "Val RMSE: 101480.1914, Val MAE: 59704.8542, Val MSE: 10298229246.3221, Val R2: 0.4768\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1539, Val Loss: 0.1671\n",
      "Val RMSE: 100356.7775, Val MAE: 58290.3337, Val MSE: 10071482781.6518, Val R2: 0.4883\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1516, Val Loss: 0.1597\n",
      "Val RMSE: 98372.7043, Val MAE: 57313.9428, Val MSE: 9677188951.3563, Val R2: 0.5083\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1468, Val Loss: 0.1536\n",
      "Val RMSE: 96622.6240, Val MAE: 55823.8046, Val MSE: 9335931459.2322, Val R2: 0.5257\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1450, Val Loss: 0.1523\n",
      "Val RMSE: 95565.2177, Val MAE: 55155.2455, Val MSE: 9132710830.2697, Val R2: 0.5360\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1405, Val Loss: 0.1380\n",
      "Val RMSE: 92510.4575, Val MAE: 50707.7573, Val MSE: 8558184742.4341, Val R2: 0.5652\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1337, Val Loss: 0.1686\n",
      "Val RMSE: 96296.0853, Val MAE: 59548.2764, Val MSE: 9272936050.2139, Val R2: 0.5289\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1272, Val Loss: 0.1609\n",
      "Val RMSE: 95426.7475, Val MAE: 58718.5731, Val MSE: 9106264131.1396, Val R2: 0.5373\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1194, Val Loss: 0.1349\n",
      "Val RMSE: 90373.1032, Val MAE: 51736.0549, Val MSE: 8167297785.6617, Val R2: 0.5850\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1146, Val Loss: 0.1438\n",
      "Val RMSE: 96122.2163, Val MAE: 50241.5427, Val MSE: 9239480460.0425, Val R2: 0.5306\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1096, Val Loss: 0.1342\n",
      "Val RMSE: 92176.5482, Val MAE: 50928.2129, Val MSE: 8496516033.0776, Val R2: 0.5683\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1066, Val Loss: 0.1270\n",
      "Val RMSE: 88402.0175, Val MAE: 45239.8512, Val MSE: 7814916698.3039, Val R2: 0.6030\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1004, Val Loss: 0.1271\n",
      "Val RMSE: 86525.8796, Val MAE: 48566.6844, Val MSE: 7486727837.4749, Val R2: 0.6196\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0968, Val Loss: 0.1310\n",
      "Val RMSE: 87025.5191, Val MAE: 48044.0187, Val MSE: 7573440974.3677, Val R2: 0.6152\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0940, Val Loss: 0.1319\n",
      "Val RMSE: 87518.1859, Val MAE: 49540.8457, Val MSE: 7659432865.8948, Val R2: 0.6109\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0897, Val Loss: 0.1205\n",
      "Val RMSE: 83051.0725, Val MAE: 45162.5407, Val MSE: 6897480635.9168, Val R2: 0.6496\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0866, Val Loss: 0.1273\n",
      "Val RMSE: 83816.8460, Val MAE: 48029.8697, Val MSE: 7025263675.8323, Val R2: 0.6431\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0865, Val Loss: 0.1243\n",
      "Val RMSE: 81986.9411, Val MAE: 46188.1427, Val MSE: 6721858505.8797, Val R2: 0.6585\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0819, Val Loss: 0.1154\n",
      "Val RMSE: 78723.4078, Val MAE: 45609.7249, Val MSE: 6197374931.8555, Val R2: 0.6851\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0803, Val Loss: 0.1188\n",
      "Val RMSE: 79069.5307, Val MAE: 44885.2499, Val MSE: 6251990680.5007, Val R2: 0.6824\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0781, Val Loss: 0.1124\n",
      "Val RMSE: 76843.5109, Val MAE: 43852.4422, Val MSE: 5904925163.7712, Val R2: 0.7000\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0767, Val Loss: 0.1115\n",
      "Val RMSE: 76531.8030, Val MAE: 43605.2383, Val MSE: 5857116875.6319, Val R2: 0.7024\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1087\n",
      "Val RMSE: 75039.1088, Val MAE: 43226.2315, Val MSE: 5630867855.4092, Val R2: 0.7139\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0734, Val Loss: 0.1191\n",
      "Val RMSE: 78805.1376, Val MAE: 45861.9712, Val MSE: 6210249719.0583, Val R2: 0.6845\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0730, Val Loss: 0.1144\n",
      "Val RMSE: 75065.9333, Val MAE: 45063.2319, Val MSE: 5634894339.3726, Val R2: 0.7137\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1144\n",
      "Val RMSE: 75753.0304, Val MAE: 45852.8637, Val MSE: 5738521617.4575, Val R2: 0.7084\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0681, Val Loss: 0.1141\n",
      "Val RMSE: 73756.7842, Val MAE: 45366.0800, Val MSE: 5440063213.8299, Val R2: 0.7236\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0700, Val Loss: 0.1115\n",
      "Val RMSE: 74995.9232, Val MAE: 45311.4897, Val MSE: 5624388489.7570, Val R2: 0.7142\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0705, Val Loss: 0.1129\n",
      "Val RMSE: 74874.3459, Val MAE: 45115.4369, Val MSE: 5606167681.3138, Val R2: 0.7152\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0693, Val Loss: 0.1174\n",
      "Val RMSE: 79073.1011, Val MAE: 43841.3297, Val MSE: 6252555318.1466, Val R2: 0.6823\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0648, Val Loss: 0.1052\n",
      "Val RMSE: 73162.0506, Val MAE: 41242.4242, Val MSE: 5352685651.0304, Val R2: 0.7280\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0635, Val Loss: 0.1090\n",
      "Val RMSE: 72964.7411, Val MAE: 44092.0782, Val MSE: 5323853445.1890, Val R2: 0.7295\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0627, Val Loss: 0.1151\n",
      "Val RMSE: 74904.1944, Val MAE: 46703.4201, Val MSE: 5610638340.3349, Val R2: 0.7149\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0621, Val Loss: 0.1068\n",
      "Val RMSE: 73346.1560, Val MAE: 41781.0088, Val MSE: 5379658595.8757, Val R2: 0.7267\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0606, Val Loss: 0.1029\n",
      "Val RMSE: 73599.1914, Val MAE: 41556.4957, Val MSE: 5416840973.9191, Val R2: 0.7248\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0622, Val Loss: 0.1173\n",
      "Val RMSE: 75355.5391, Val MAE: 48299.3812, Val MSE: 5678457272.0529, Val R2: 0.7115\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0601, Val Loss: 0.1142\n",
      "Val RMSE: 75642.8035, Val MAE: 47360.5381, Val MSE: 5721833726.8790, Val R2: 0.7093\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0581, Val Loss: 0.1101\n",
      "Val RMSE: 75067.6701, Val MAE: 43285.8073, Val MSE: 5635155099.5496, Val R2: 0.7137\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0568, Val Loss: 0.1057\n",
      "Val RMSE: 71557.5153, Val MAE: 43000.3539, Val MSE: 5120478001.7169, Val R2: 0.7398\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0667, Val Loss: 0.1237\n",
      "Val RMSE: 76549.2184, Val MAE: 49010.4051, Val MSE: 5859782830.3137, Val R2: 0.7023\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0617, Val Loss: 0.1064\n",
      "Val RMSE: 72433.1794, Val MAE: 44759.1325, Val MSE: 5246565481.4938, Val R2: 0.7334\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0563, Val Loss: 0.0997\n",
      "Val RMSE: 69599.6237, Val MAE: 41708.2574, Val MSE: 4844107620.9091, Val R2: 0.7539\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0559, Val Loss: 0.0992\n",
      "Val RMSE: 70112.4080, Val MAE: 40636.2667, Val MSE: 4915749751.0757, Val R2: 0.7502\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0552, Val Loss: 0.1120\n",
      "Val RMSE: 74963.9363, Val MAE: 44168.7089, Val MSE: 5619591744.3899, Val R2: 0.7145\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0535, Val Loss: 0.1010\n",
      "Val RMSE: 72233.9583, Val MAE: 41065.7374, Val MSE: 5217744736.2826, Val R2: 0.7349\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0524, Val Loss: 0.1062\n",
      "Val RMSE: 74674.2850, Val MAE: 41293.3425, Val MSE: 5576248837.8117, Val R2: 0.7167\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0528, Val Loss: 0.1064\n",
      "Val RMSE: 72495.1911, Val MAE: 45561.5429, Val MSE: 5255552730.3040, Val R2: 0.7330\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0530, Val Loss: 0.1022\n",
      "Val RMSE: 70234.1928, Val MAE: 43107.3846, Val MSE: 4932841840.7808, Val R2: 0.7494\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0506, Val Loss: 0.1165\n",
      "Val RMSE: 76787.2559, Val MAE: 46532.6979, Val MSE: 5896282674.2289, Val R2: 0.7004\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0489, Val Loss: 0.1129\n",
      "Val RMSE: 77898.3734, Val MAE: 43237.8208, Val MSE: 6068156578.6789, Val R2: 0.6917\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0510, Val Loss: 0.1110\n",
      "Val RMSE: 75600.7627, Val MAE: 43353.7508, Val MSE: 5715475324.2346, Val R2: 0.7096\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0515, Val Loss: 0.1262\n",
      "Val RMSE: 79490.6681, Val MAE: 50075.4104, Val MSE: 6318766318.3123, Val R2: 0.6790\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0500, Val Loss: 0.1052\n",
      "Val RMSE: 73428.5242, Val MAE: 41618.0391, Val MSE: 5391748173.0770, Val R2: 0.7261\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0493, Val Loss: 0.1101\n",
      "Val RMSE: 76093.0172, Val MAE: 43185.8379, Val MSE: 5790147267.7687, Val R2: 0.7058\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0479, Val Loss: 0.1057\n",
      "Val RMSE: 74403.7137, Val MAE: 41008.3683, Val MSE: 5535912606.7812, Val R2: 0.7187\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0494, Val Loss: 0.1077\n",
      "Val RMSE: 75202.7103, Val MAE: 43033.0265, Val MSE: 5655447640.6798, Val R2: 0.7127\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0478, Val Loss: 0.1126\n",
      "Val RMSE: 76347.1131, Val MAE: 40960.6270, Val MSE: 5828881676.3998, Val R2: 0.7039\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0460, Val Loss: 0.1046\n",
      "Val RMSE: 74058.7160, Val MAE: 40935.8605, Val MSE: 5484693409.7910, Val R2: 0.7213\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0458, Val Loss: 0.1004\n",
      "Val RMSE: 71125.2859, Val MAE: 42473.0759, Val MSE: 5058806295.4752, Val R2: 0.7430\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0467, Val Loss: 0.1203\n",
      "Val RMSE: 80812.0627, Val MAE: 48124.2177, Val MSE: 6530589472.6465, Val R2: 0.6682\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0463, Val Loss: 0.1195\n",
      "Val RMSE: 78825.5025, Val MAE: 47171.5020, Val MSE: 6213459845.2726, Val R2: 0.6843\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0451, Val Loss: 0.1099\n",
      "Val RMSE: 75127.8194, Val MAE: 43416.1400, Val MSE: 5644189253.2369, Val R2: 0.7132\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0497, Val Loss: 0.1057\n",
      "Val RMSE: 73880.0102, Val MAE: 43419.1114, Val MSE: 5458255903.5224, Val R2: 0.7227\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0468, Val Loss: 0.1045\n",
      "Val RMSE: 75746.4876, Val MAE: 41120.2649, Val MSE: 5737530378.0968, Val R2: 0.7085\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0450, Val Loss: 0.1068\n",
      "Val RMSE: 74663.1189, Val MAE: 42447.3188, Val MSE: 5574581326.8029, Val R2: 0.7168\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0447, Val Loss: 0.1090\n",
      "Val RMSE: 74908.5609, Val MAE: 43021.6924, Val MSE: 5611292490.6490, Val R2: 0.7149\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 69810.9331, Test MAE: 40089.9075, Test MSE: 4873566381.7718, Test R2: 0.6876\n",
      "Inference Time: 2.4358309232271635e-05 seconds per sample\n",
      "\n",
      "Iteration 101 / 100\n",
      "Epoch [1/100]\n",
      "Train Loss: 0.3971, Val Loss: 0.2835\n",
      "Val RMSE: 142973.9501, Val MAE: 83323.0872, Val MSE: 20441550410.8907, Val R2: -0.0386\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.2781, Val Loss: 0.2765\n",
      "Val RMSE: 140680.2588, Val MAE: 85999.1136, Val MSE: 19790935222.6018, Val R2: -0.0055\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.2718, Val Loss: 0.2760\n",
      "Val RMSE: 141327.1857, Val MAE: 84020.3789, Val MSE: 19973373420.5181, Val R2: -0.0148\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.2695, Val Loss: 0.2767\n",
      "Val RMSE: 141610.6381, Val MAE: 83444.0824, Val MSE: 20053572831.2875, Val R2: -0.0188\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.2643, Val Loss: 0.2797\n",
      "Val RMSE: 142431.7483, Val MAE: 82789.3067, Val MSE: 20286802918.6235, Val R2: -0.0307\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.2645, Val Loss: 0.2763\n",
      "Val RMSE: 141254.2445, Val MAE: 84670.9135, Val MSE: 19952761582.3317, Val R2: -0.0137\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2742\n",
      "Val RMSE: 141482.9439, Val MAE: 84366.2253, Val MSE: 20017423406.0428, Val R2: -0.0170\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.2601, Val Loss: 0.2777\n",
      "Val RMSE: 142619.9986, Val MAE: 81296.9893, Val MSE: 20340463992.3280, Val R2: -0.0334\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.2579, Val Loss: 0.2773\n",
      "Val RMSE: 141918.6300, Val MAE: 83663.9867, Val MSE: 20140897534.1929, Val R2: -0.0233\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.2554, Val Loss: 0.2704\n",
      "Val RMSE: 140577.5913, Val MAE: 84088.2527, Val MSE: 19762059179.6704, Val R2: -0.0040\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.2533, Val Loss: 0.2635\n",
      "Val RMSE: 139748.7335, Val MAE: 77315.4025, Val MSE: 19529708514.6314, Val R2: 0.0078\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.2465, Val Loss: 0.2625\n",
      "Val RMSE: 137649.7813, Val MAE: 77387.2239, Val MSE: 18947462279.3303, Val R2: 0.0373\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.2401, Val Loss: 0.2528\n",
      "Val RMSE: 136277.7686, Val MAE: 74790.8553, Val MSE: 18571630216.8394, Val R2: 0.0564\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.2372, Val Loss: 0.2492\n",
      "Val RMSE: 135157.4553, Val MAE: 76074.6914, Val MSE: 18267537713.6440, Val R2: 0.0719\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.2368, Val Loss: 0.2602\n",
      "Val RMSE: 137507.0766, Val MAE: 76960.2300, Val MSE: 18908196110.0677, Val R2: 0.0393\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.2334, Val Loss: 0.2629\n",
      "Val RMSE: 137447.1142, Val MAE: 74391.2277, Val MSE: 18891709191.2503, Val R2: 0.0402\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.2221, Val Loss: 0.2291\n",
      "Val RMSE: 131246.6253, Val MAE: 72943.5231, Val MSE: 17225676651.1992, Val R2: 0.1248\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.2134, Val Loss: 0.2331\n",
      "Val RMSE: 133125.6576, Val MAE: 71948.7598, Val MSE: 17722440698.4632, Val R2: 0.0996\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.2077, Val Loss: 0.2361\n",
      "Val RMSE: 131301.7742, Val MAE: 74677.9049, Val MSE: 17240155897.8473, Val R2: 0.1241\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.2135, Val Loss: 0.2285\n",
      "Val RMSE: 130720.8121, Val MAE: 69544.0062, Val MSE: 17087930712.3373, Val R2: 0.1318\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.2047, Val Loss: 0.2302\n",
      "Val RMSE: 130371.5403, Val MAE: 70226.3262, Val MSE: 16996738516.2178, Val R2: 0.1365\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.1952, Val Loss: 0.2462\n",
      "Val RMSE: 133905.5652, Val MAE: 76344.6171, Val MSE: 17930700380.3760, Val R2: 0.0890\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.1936, Val Loss: 0.2457\n",
      "Val RMSE: 136442.5849, Val MAE: 74461.9378, Val MSE: 18616578980.3920, Val R2: 0.0542\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.1889, Val Loss: 0.2299\n",
      "Val RMSE: 123944.4924, Val MAE: 69143.9519, Val MSE: 15362237195.3244, Val R2: 0.2195\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.1767, Val Loss: 0.2020\n",
      "Val RMSE: 111287.1572, Val MAE: 64518.2245, Val MSE: 12384831367.8684, Val R2: 0.3708\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.1692, Val Loss: 0.1831\n",
      "Val RMSE: 106078.9543, Val MAE: 61641.4794, Val MSE: 11252744541.8736, Val R2: 0.4283\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.1600, Val Loss: 0.1689\n",
      "Val RMSE: 102317.1014, Val MAE: 58683.4987, Val MSE: 10468789238.1987, Val R2: 0.4681\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.1591, Val Loss: 0.1664\n",
      "Val RMSE: 100138.1071, Val MAE: 59341.0588, Val MSE: 10027640499.2527, Val R2: 0.4905\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.1550, Val Loss: 0.1613\n",
      "Val RMSE: 98745.8419, Val MAE: 57676.0933, Val MSE: 9750741287.8420, Val R2: 0.5046\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.1488, Val Loss: 0.1603\n",
      "Val RMSE: 99034.1289, Val MAE: 56780.1358, Val MSE: 9807758683.3852, Val R2: 0.5017\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.1470, Val Loss: 0.1519\n",
      "Val RMSE: 96679.3337, Val MAE: 54046.5570, Val MSE: 9346893563.9297, Val R2: 0.5251\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.1418, Val Loss: 0.1478\n",
      "Val RMSE: 93993.9094, Val MAE: 53563.2105, Val MSE: 8834855011.9309, Val R2: 0.5511\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.1419, Val Loss: 0.1577\n",
      "Val RMSE: 96113.2393, Val MAE: 54969.1222, Val MSE: 9237754763.3619, Val R2: 0.5307\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.1404, Val Loss: 0.1463\n",
      "Val RMSE: 92313.9114, Val MAE: 53379.6959, Val MSE: 8521858247.0814, Val R2: 0.5670\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.1336, Val Loss: 0.1374\n",
      "Val RMSE: 90974.3815, Val MAE: 49868.3936, Val MSE: 8276338083.8072, Val R2: 0.5795\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.1305, Val Loss: 0.1430\n",
      "Val RMSE: 91574.8053, Val MAE: 53123.8071, Val MSE: 8385944964.7828, Val R2: 0.5739\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.1276, Val Loss: 0.1510\n",
      "Val RMSE: 94295.5797, Val MAE: 52462.4877, Val MSE: 8891656351.9689, Val R2: 0.5482\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.1256, Val Loss: 0.1356\n",
      "Val RMSE: 91113.6077, Val MAE: 49092.3685, Val MSE: 8301689501.6933, Val R2: 0.5782\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.1215, Val Loss: 0.1394\n",
      "Val RMSE: 89217.8120, Val MAE: 50541.1242, Val MSE: 7959817984.8410, Val R2: 0.5956\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.1211, Val Loss: 0.1264\n",
      "Val RMSE: 86717.9963, Val MAE: 49889.2527, Val MSE: 7520010880.1757, Val R2: 0.6179\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.1175, Val Loss: 0.1474\n",
      "Val RMSE: 92707.8947, Val MAE: 53263.7729, Val MSE: 8594753744.6429, Val R2: 0.5633\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.1139, Val Loss: 0.1202\n",
      "Val RMSE: 85891.3116, Val MAE: 47851.4961, Val MSE: 7377317410.9173, Val R2: 0.6252\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.1137, Val Loss: 0.1244\n",
      "Val RMSE: 86409.4941, Val MAE: 48408.4189, Val MSE: 7466600662.3771, Val R2: 0.6206\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.1105, Val Loss: 0.1260\n",
      "Val RMSE: 86770.9203, Val MAE: 47286.9610, Val MSE: 7529192615.7005, Val R2: 0.6175\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.1108, Val Loss: 0.1248\n",
      "Val RMSE: 86453.8805, Val MAE: 46034.7590, Val MSE: 7474273449.8143, Val R2: 0.6203\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.1114, Val Loss: 0.1260\n",
      "Val RMSE: 87331.8997, Val MAE: 46752.4813, Val MSE: 7626860712.1146, Val R2: 0.6125\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.1079, Val Loss: 0.1307\n",
      "Val RMSE: 87372.4229, Val MAE: 49710.0228, Val MSE: 7633940286.7955, Val R2: 0.6121\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.1082, Val Loss: 0.1304\n",
      "Val RMSE: 87357.5989, Val MAE: 49645.4952, Val MSE: 7631350088.1598, Val R2: 0.6123\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.1083, Val Loss: 0.1338\n",
      "Val RMSE: 90668.1811, Val MAE: 50097.8517, Val MSE: 8220719060.3727, Val R2: 0.5823\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.1074, Val Loss: 0.1275\n",
      "Val RMSE: 86948.4848, Val MAE: 49581.1399, Val MSE: 7560039010.4989, Val R2: 0.6159\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.1053, Val Loss: 0.1393\n",
      "Val RMSE: 89941.9078, Val MAE: 50707.9897, Val MSE: 8089546771.5991, Val R2: 0.5890\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.1057, Val Loss: 0.1301\n",
      "Val RMSE: 89171.5656, Val MAE: 46956.1597, Val MSE: 7951568105.9792, Val R2: 0.5960\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.1014, Val Loss: 0.1267\n",
      "Val RMSE: 86079.0256, Val MAE: 47758.0181, Val MSE: 7409598639.6787, Val R2: 0.6235\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.1008, Val Loss: 0.1325\n",
      "Val RMSE: 87827.8418, Val MAE: 47909.5294, Val MSE: 7713729788.3570, Val R2: 0.6081\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0981, Val Loss: 0.1271\n",
      "Val RMSE: 86080.9172, Val MAE: 46869.5874, Val MSE: 7409924304.9365, Val R2: 0.6235\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0972, Val Loss: 0.1351\n",
      "Val RMSE: 87897.0225, Val MAE: 47983.7900, Val MSE: 7725886561.3898, Val R2: 0.6075\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0932, Val Loss: 0.1332\n",
      "Val RMSE: 85861.3878, Val MAE: 47468.0430, Val MSE: 7372177915.0765, Val R2: 0.6254\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0911, Val Loss: 0.1347\n",
      "Val RMSE: 87381.1304, Val MAE: 49974.6136, Val MSE: 7635461949.8886, Val R2: 0.6121\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0873, Val Loss: 0.1263\n",
      "Val RMSE: 84101.5917, Val MAE: 46193.2433, Val MSE: 7073077727.8580, Val R2: 0.6406\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0884, Val Loss: 0.1314\n",
      "Val RMSE: 87033.3738, Val MAE: 47912.6323, Val MSE: 7574808149.9585, Val R2: 0.6152\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0857, Val Loss: 0.1175\n",
      "Val RMSE: 77679.8083, Val MAE: 45652.7405, Val MSE: 6034152616.1524, Val R2: 0.6934\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0822, Val Loss: 0.1234\n",
      "Val RMSE: 79127.9894, Val MAE: 45036.6760, Val MSE: 6261238709.0594, Val R2: 0.6819\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0809, Val Loss: 0.1209\n",
      "Val RMSE: 80533.1997, Val MAE: 45948.2294, Val MSE: 6485596256.8425, Val R2: 0.6705\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0800, Val Loss: 0.1237\n",
      "Val RMSE: 80085.0766, Val MAE: 44847.6045, Val MSE: 6413619493.1854, Val R2: 0.6741\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0788, Val Loss: 0.1141\n",
      "Val RMSE: 75869.6894, Val MAE: 43487.9009, Val MSE: 5756209774.1377, Val R2: 0.7075\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1233\n",
      "Val RMSE: 79581.8600, Val MAE: 45535.8386, Val MSE: 6333272440.8035, Val R2: 0.6782\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0757, Val Loss: 0.1121\n",
      "Val RMSE: 73011.0006, Val MAE: 44559.4589, Val MSE: 5330606210.6699, Val R2: 0.7292\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0752, Val Loss: 0.1206\n",
      "Val RMSE: 74476.2967, Val MAE: 45206.8554, Val MSE: 5546718773.1425, Val R2: 0.7182\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0756, Val Loss: 0.1215\n",
      "Val RMSE: 74165.5575, Val MAE: 43332.8674, Val MSE: 5500529924.5580, Val R2: 0.7205\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0731, Val Loss: 0.1136\n",
      "Val RMSE: 73419.5143, Val MAE: 44772.1312, Val MSE: 5390425086.0134, Val R2: 0.7261\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0711, Val Loss: 0.1154\n",
      "Val RMSE: 73405.6769, Val MAE: 43145.7289, Val MSE: 5388393398.1425, Val R2: 0.7262\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0694, Val Loss: 0.1263\n",
      "Val RMSE: 77436.6318, Val MAE: 44491.7792, Val MSE: 5996431937.4162, Val R2: 0.6953\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0691, Val Loss: 0.1116\n",
      "Val RMSE: 72512.0729, Val MAE: 42352.7274, Val MSE: 5258000719.6871, Val R2: 0.7329\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0723, Val Loss: 0.1129\n",
      "Val RMSE: 72089.7549, Val MAE: 42723.9593, Val MSE: 5196932761.9333, Val R2: 0.7360\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0701, Val Loss: 0.1087\n",
      "Val RMSE: 70394.2903, Val MAE: 42783.7608, Val MSE: 4955356105.2646, Val R2: 0.7482\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0674, Val Loss: 0.1276\n",
      "Val RMSE: 77906.4965, Val MAE: 45435.4417, Val MSE: 6069422198.6037, Val R2: 0.6916\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0673, Val Loss: 0.1176\n",
      "Val RMSE: 73785.0791, Val MAE: 42617.8498, Val MSE: 5444237890.6180, Val R2: 0.7234\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0632, Val Loss: 0.1140\n",
      "Val RMSE: 72252.8647, Val MAE: 42046.3900, Val MSE: 5220476461.2188, Val R2: 0.7348\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0636, Val Loss: 0.1060\n",
      "Val RMSE: 69772.9311, Val MAE: 41952.1220, Val MSE: 4868261912.6478, Val R2: 0.7527\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0614, Val Loss: 0.1133\n",
      "Val RMSE: 70994.6113, Val MAE: 40631.4902, Val MSE: 5040234836.2778, Val R2: 0.7439\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0631, Val Loss: 0.1129\n",
      "Val RMSE: 72319.0709, Val MAE: 43822.4932, Val MSE: 5230048021.6861, Val R2: 0.7343\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0608, Val Loss: 0.1133\n",
      "Val RMSE: 71758.9251, Val MAE: 42040.0139, Val MSE: 5149343336.8250, Val R2: 0.7384\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0610, Val Loss: 0.1148\n",
      "Val RMSE: 72268.1073, Val MAE: 43416.3748, Val MSE: 5222679328.5670, Val R2: 0.7347\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0585, Val Loss: 0.1121\n",
      "Val RMSE: 70624.5175, Val MAE: 41000.1976, Val MSE: 4987822476.6058, Val R2: 0.7466\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0598, Val Loss: 0.1087\n",
      "Val RMSE: 71223.6401, Val MAE: 41777.5493, Val MSE: 5072806913.9349, Val R2: 0.7423\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0587, Val Loss: 0.1097\n",
      "Val RMSE: 71809.7989, Val MAE: 41299.9281, Val MSE: 5156647221.7946, Val R2: 0.7380\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1062\n",
      "Val RMSE: 69069.4961, Val MAE: 40699.6172, Val MSE: 4770595284.8234, Val R2: 0.7576\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0580, Val Loss: 0.1040\n",
      "Val RMSE: 67553.5458, Val MAE: 42039.6545, Val MSE: 4563481551.2880, Val R2: 0.7681\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0565, Val Loss: 0.1043\n",
      "Val RMSE: 69479.1943, Val MAE: 40262.0994, Val MSE: 4827358446.5392, Val R2: 0.7547\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0561, Val Loss: 0.1053\n",
      "Val RMSE: 69496.1599, Val MAE: 39765.5272, Val MSE: 4829716236.0345, Val R2: 0.7546\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0568, Val Loss: 0.1083\n",
      "Val RMSE: 70923.0136, Val MAE: 40600.3238, Val MSE: 5030073852.8698, Val R2: 0.7444\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1173\n",
      "Val RMSE: 73737.8875, Val MAE: 43349.6189, Val MSE: 5437276058.0669, Val R2: 0.7238\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0556, Val Loss: 0.1099\n",
      "Val RMSE: 70254.6919, Val MAE: 43571.5049, Val MSE: 4935721733.5873, Val R2: 0.7492\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0546, Val Loss: 0.1087\n",
      "Val RMSE: 70258.3358, Val MAE: 40937.4024, Val MSE: 4936233754.4466, Val R2: 0.7492\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0543, Val Loss: 0.1096\n",
      "Val RMSE: 71021.4768, Val MAE: 41244.9186, Val MSE: 5044050163.9313, Val R2: 0.7437\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0544, Val Loss: 0.1077\n",
      "Val RMSE: 71410.6428, Val MAE: 40036.6772, Val MSE: 5099479908.8473, Val R2: 0.7409\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0536, Val Loss: 0.1093\n",
      "Val RMSE: 72725.9928, Val MAE: 42089.9329, Val MSE: 5289070027.4031, Val R2: 0.7313\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0525, Val Loss: 0.1105\n",
      "Val RMSE: 71385.1953, Val MAE: 42751.4164, Val MSE: 5095846112.0388, Val R2: 0.7411\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0523, Val Loss: 0.1141\n",
      "Val RMSE: 72889.3822, Val MAE: 42879.5103, Val MSE: 5312862036.7819, Val R2: 0.7301\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0522, Val Loss: 0.1272\n",
      "Val RMSE: 76619.2626, Val MAE: 47568.2636, Val MSE: 5870511404.2074, Val R2: 0.7017\n",
      "\n",
      "Final Test Metrics after loading best model:\n",
      "Test RMSE: 71132.7854, Test MAE: 40665.0647, Test MSE: 5059873156.3019, Test R2: 0.6757\n",
      "Inference Time: 2.878247774564303e-05 seconds per sample\n"
     ]
    }
   ],
   "source": [
    "rmse_lst, mae_lst, mse_lst, r2_lst, infer_time_lst = [], [], [], [], []\n",
    "\n",
    "for iter in range(101):\n",
    "    print(f'\\nIteration {iter + 1} / 100')\n",
    "    # Create model\n",
    "    model = PCTransformer(input_dim, d_model, num_heads, d_ff, num_layers, output_dim, dropout).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(model, dataloaders, num_epochs, device, scaler)\n",
    "\n",
    "    model.load_state_dict(torch.load('../models_HCMUT/best_pc_transformer_model.pth', map_location=device))\n",
    "    rmse, mae, mse, r2, infer_time = model.evaluate_model(model, dataloaders['test'], device, scaler, input_dim)\n",
    "\n",
    "    rmse_lst.append(rmse)\n",
    "    mae_lst.append(mae)\n",
    "    mse_lst.append(mse)\n",
    "    r2_lst.append(r2)\n",
    "    infer_time_lst.append(infer_time)\n",
    "\n",
    "    print(f'\\nFinal Test Metrics after loading best model:')\n",
    "    print(f'Test RMSE: {rmse:.4f}, Test MAE: {mae:.4f}, Test MSE: {mse:.4f}, Test R2: {r2:.4f}')\n",
    "    print(f'Inference Time: {infer_time} seconds per sample')\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'RMSE': rmse_lst,\n",
    "    'MAE': mae_lst,\n",
    "    'MSE': mse_lst,\n",
    "    'R2': r2_lst,\n",
    "    'Inference Time': infer_time_lst\n",
    "})\n",
    "results_df.to_csv('../output_HCMUT/pc_transformer_results.csv', index=False)\n",
    "# Final evaluation on test set\n",
    "# test_rmse, test_mae, test_mse, test_r2 = model.evaluate_model(model, dataloaders['test'], device, scaler, input_dim)\n",
    "# print(f'\\nFinal Test Metrics:')\n",
    "# print(f'Test RMSE: {test_rmse:.4f}, Test MAE: {test_mae:.4f}, Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}')\n",
    "# print(f'Training time: {end - start:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
