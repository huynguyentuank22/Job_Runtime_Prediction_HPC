{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddb54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import joblib\n",
    "from preprocessing import *\n",
    "from JREP import JREP\n",
    "from PC_transformer import PCTransformer\n",
    "from RNN import RNN\n",
    "from LSTM import LSTM\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57767987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'output_csv\\HCMUT-SuperNodeXP-2017-1.0.swf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be08581",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['requested_processors', 'requested_time', 'avg_cpu_time_used', 'used_memory', 'submit_time', 'wait_time', 'user_id', 'group_id', 'executable_id', 'queue_id']\n",
    "target_column = 'run_time'\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = len(feature_columns)    # Example input dimension\n",
    "d_model = 64      # Model dimension\n",
    "num_heads = 8     # Number of attention heads\n",
    "d_ff = 256        # Feed-forward dimension\n",
    "num_layers = 3    # Number of transformer blocks\n",
    "output_dim = 1    # Output dimension\n",
    "batch_size = 128  # Batch size\n",
    "seq_len = 20      # Length of data group\n",
    "num_epochs = 10   # Number of training epochs\n",
    "num_hidden = 64   # Number of hidden units\n",
    "dropout = 0.2     # Dropout rate\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "dataloaders, scaler_seq = prepare_data_seq(df, feature_columns, target_column, seq_len=seq_len, batch_size=batch_size)\n",
    "X_train, X_test, Y_train, Y_test, scaler = prepare_data(df, feature_columns, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0c1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCTransformer_model = PCTransformer(input_dim, d_model, num_heads, d_ff, num_layers, output_dim, dropout).to(device)\n",
    "PCTransformer_model.load_state_dict(torch.load('models/best_pc_transformer_model.pth', map_location=device))\n",
    "PCTransformer_rmse, PCTransformer_mae, PCTransformer_mse, PCTransformer_r2 = PCTransformer_model.evaluate_model(PCTransformer_model, dataloaders['test'], device, scaler_seq, input_dim)\n",
    "\n",
    "rnn_model = RNN(input_dim, num_hidden, num_layers, dropout).to(device)\n",
    "rnn_model.load_state_dict(torch.load('models/best_rnn_model.pth', map_location=device))\n",
    "rnn_rmse, rnn_mae, rnn_mse, rnn_r2 = rnn_model.evaluate_model(rnn_model, dataloaders['test'], scaler_seq, input_dim)\n",
    "\n",
    "lstm_model = LSTM(input_dim, num_hidden, num_layers, dropout).to(device)\n",
    "lstm_model.load_state_dict(torch.load('models/best_lstm_model.pth', map_location=device))\n",
    "lstm_rmse, lstm_mae, lstm_mse, lstm_r2 = lstm_model.evaluate_model(lstm_model, dataloaders['test'], scaler_seq, input_dim)\n",
    "\n",
    "JREP_model = JREP()\n",
    "stacking_model = joblib.load('models/stacking_model.pkl')\n",
    "JREP_model.stacking_model = stacking_model\n",
    "Y_pred = JREP_model.predict(X_test, scaler, len(feature_columns))\n",
    "JREP_rmse, JREP_mae, JREP_mse, JREP_r2 = JREP_model.evaluate_model(Y_test, Y_pred, scaler, len(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a425fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCTransformer RMSE: 94262.0653\n",
      "PCTransformer MAE: 62498.5468\n",
      "PCTransformer MSE: 8885336957.2278\n",
      "PCTransformer R2: 0.1522\n"
     ]
    }
   ],
   "source": [
    "print(f\"PCTransformer RMSE: {PCTransformer_rmse:.4f}\")\n",
    "print(f\"PCTransformer MAE: {PCTransformer_mae:.4f}\")\n",
    "print(f\"PCTransformer MSE: {PCTransformer_mse:.4f}\")\n",
    "print(f\"PCTransformer R2: {PCTransformer_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccdb79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JREP RMSE: 28223.2052\n",
      "JREP MAE: 11600.8960\n",
      "JREP MSE: 796549314.0460\n",
      "JREP R2: 0.9499\n"
     ]
    }
   ],
   "source": [
    "print(f\"JREP RMSE: {JREP_rmse:.4f}\")\n",
    "print(f\"JREP MAE: {JREP_mae:.4f}\")\n",
    "print(f\"JREP MSE: {JREP_mse:.4f}\")\n",
    "print(f\"JREP R2: {JREP_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d07a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN RMSE: 61268.9908\n",
      "RNN MAE: 39725.8433\n",
      "RNN MSE: 3753889238.2746\n",
      "RNN R2: 0.7621\n"
     ]
    }
   ],
   "source": [
    "print(f\"RNN RMSE: {rnn_rmse:.4f}\")\n",
    "print(f\"RNN MAE: {rnn_mae:.4f}\")\n",
    "print(f\"RNN MSE: {rnn_mse:.4f}\")\n",
    "print(f\"RNN R2: {rnn_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d323e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM RMSE: 81792.7611\n",
      "LSTM MAE: 57900.6272\n",
      "LSTM MSE: 6690055763.9777\n",
      "LSTM R2: 0.5760\n"
     ]
    }
   ],
   "source": [
    "print(f'LSTM RMSE: {lstm_rmse:.4f}')\n",
    "print(f'LSTM MAE: {lstm_mae:.4f}')\n",
    "print(f'LSTM MSE: {lstm_mse:.4f}')\n",
    "print(f'LSTM R2: {lstm_r2:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
